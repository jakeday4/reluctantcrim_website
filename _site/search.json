[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "reluctant criminologists",
    "section": "",
    "text": "My job is to introduce a little tension into an otherwise harmonious system.\n— Charles Tittle in “The Arrogance of Public Sociology”\nWelcome to our site! We are Jon Brauer and Jake Day, aka the “reluctant criminologists.”\nWe created this site to publicly share course materials and musings about scientific theory and methods. In particular, we provide course materials containing crime-relevant examples to help interested scholars in our field learn to use R and to improve the reproducibility of their workflows. Additionally, we will post occasional blog entries about topics in our areas of interest, including philosophy of science, criminology theory, and statistical techniques (e.g., ordinal modeling; Bayesian estimation; data visualization). We are also open to the idea of collaborating with or posting others’ course materials and topical blog posts, so feel free to contact us with your ideas.\nWith respect to philosophy of science and criminology theory, we were both heavily influenced by the late Dr. Charles R. Tittle. The name of our site is meant to be a cheeky reference to one of our favorite pieces written by Charles: “Reflections of a Reluctant but Committed Criminologist” in Gilbert Geis and Mary Dodge’s Lessons of Criminology (pp.23-45). You can read more about how he directly inspired our site’s name (“Reluctant Criminologists”) in our welcome blog. However, we wish to make it clear that although we were influenced and inspired by him, Charles in no way endorsed the project, and he likely would have thought it was a waste of time better spent contributing (in more traditional ways) to scientific theory development and testing. We think it’s safe to say that we are both more “reluctant” and less “committed” criminologists than Charles was.\nIn sharing course content and posts containing R code, we are committing to the practice of coding in public. Likewise, we expect to learn more than we teach through readers’ constructive feedback on our innumerable coding inefficiencies and inevitable errors. So, please do reach out with suggestions or corrections.\nFinally, if we contribute anything of value on this site, undoubtedly someone else - one or more of our many countless scientific heroes who tirelessly publish through traditional scientific outlets and/or share scientific information and resources via their own blogs, bookdowns, and videos - deserve the lion’s share of credit for it. To borrow again from Charles Tittle (and specifically his preface to Control Balance), none of these people contributed to the errors or other shortcomings found in any materials that we post on this site."
  },
  {
    "objectID": "about.html#about-the-reluctant-criminologists",
    "href": "about.html#about-the-reluctant-criminologists",
    "title": "reluctant criminologists",
    "section": "about the reluctant criminologists",
    "text": "about the reluctant criminologists"
  },
  {
    "objectID": "blog-posts/[1]/welcome-blog.html",
    "href": "blog-posts/[1]/welcome-blog.html",
    "title": "Welcome to the reluctant criminologists",
    "section": "",
    "text": "Reluctant criminologists logo"
  },
  {
    "objectID": "blog-posts/[1]/welcome-blog.html#why-are-we-doing-this",
    "href": "blog-posts/[1]/welcome-blog.html#why-are-we-doing-this",
    "title": "Welcome to the reluctant criminologists",
    "section": "Why are we doing this?",
    "text": "Why are we doing this?\nFirst, this site is intended primarily as a central repository for conveniently sharing our course material and preliminary ideas with students and colleagues. It allows us to simply point people to a website rather than sending large html files via email or proliferating dropbox links. If it serves only this purpose effectively, we will be happy.\nSecond, this site is a direct consequence of our recent efforts to re-tool our approaches to doing science. We think this site will serve as evidence for how much we have learned - and likely as even stronger evidence of how much more we have yet to learn.\nOf course, this begs the question: Why have we been re-tooling our approaches to science? Well, answering that question requires a longer conversation with multiple threads, and we anticipate weaving some of those threads into our future blog posts. For now, it may be clear from our posted materials that we are motivated to act in response to increasing concerns about replication failures across multiple scientific disciplines and awareness of subsequent reforms. We are also motivated by the perception that our academic disciplines of sociology and criminology, with some exceptions, may be lagging behind other fields like psychology in self-reflection on these important issues and widespread adoption of potentially effective reforms. Likewise, we are moved by our own experiences with reproducing high-profile work and attempting to raise awareness through the traditional academic peer-review publication process about concerns regarding underpowered null hypothesis significance tests and common misinterpretations of null findings from such tests.\nIt is also fair to say that this site is indicative of early-mid-career crises of sorts brought on by other factors such as post-tenure malaise and serious reflections about what we are doing with our limited time in the aftermath of the global COVID-19 pandemic.\nIn fact, the initial idea for the blog emerged during the height of the pandemic in a long email thread between Jon and Jake. In a somewhat typical exchange, Jake was asking Jon to explain a relatively complex statistical topic (e.g., latent variable modeling in SEM vs. multilevel modeling). Jon was sharing resources, summarizing debates, and explaining issues that have been published on the topic across disparate statistical literatures over the years. Jake thought putting these types of discussions into a blog might be beneficial for multiple reasons. First, rather than burying this writing in emails, others might also appreciate such reviews or tutorials if they were available in a free, public-facing blog. Second, Jon seemed reluctant to write traditional academic articles on such topics since, from his perspective, they would be redundant - the reviews and debates are already out there, you just need to go read them (often in other fields). Meanwhile, Jon was receptive to the idea of a blog; he thought Jake should write more, and a blog might be a good way for both of them to spill ink and “try out” ideas under a critical public eye while perhaps even helping some students and colleagues along the way. So, here we are."
  },
  {
    "objectID": "blog-posts/[1]/welcome-blog.html#how-we-were-inspired-by-charles",
    "href": "blog-posts/[1]/welcome-blog.html#how-we-were-inspired-by-charles",
    "title": "Welcome to the reluctant criminologists",
    "section": "How we were inspired by Charles",
    "text": "How we were inspired by Charles\nThe name of our site pays homage to our late mentor and friend, Dr. Charles R. Tittle. It is meant to be a cheeky reference to his chapter entitled “Reflections of a Reluctant but Committed Criminologist” in Gilbert Geis and Mary Dodge’s Lessons of Criminology (pp.23-45).\nThis is one of our favorite pieces written by Charles. Our perspectives on the field of criminology and criminal justice were heavily shaped by Charles and are thus quite comparable to the views he presents in that chapter. Here is how that chapter starts (p.23):\n\n\n“I didn’t intend to become a criminologist. Rather, happenstance led me to investigate certain sociological problems that resulted in my being labeled a criminologist (Tittle, 1991). After a while the reactions of others had the effects that symbolic interactionist theory would predict - I began to think of myself as a criminologist, although one with a larger allegiance. In fact, one of the first conclusions I drew as a criminologist is that criminology ought not be thought of as a discipline. Disciplines have unifying perspectives; criminology does not. Criminology is an umbrella term encompassing diverse studies of crime and crime-relevant phenomena undertaken from many disciplinary points of view. It makes sense to speak of an economic perspective, a political perspective, a historical perspective, or a sociological perspective. It makes no sense to speak of a criminological, a criminal justice, or a criminal perspective (at least not in an academic context). In my mind, the best criminology is done by those with a firm grounding in some discipline, or by those with an appreciation of several different disciplines, the insights of which are then brought to bear on criminological issues.”\n\nThe chapter then proceeds to introduce several lessons that Charles learned throughout his illustrious career, which he later summarized as follows (pp.40-41):\n\n\nCriminology is not a discipline but a topical area dependent on a variety of disciplines and that criminological knowledge is best pursued and dispensed within the context of a liberal arts education\nOur methods of identifying and recruiting new scholars must be improved\nEvidence concerning most important issues having to do with crime and crime-relevant phenomena is weak; success requires that we commit ourselves to a long-range mission of improving that situation\nThings are more complicated than our extant theories show, calling for improved theories specifying contingent and interactive effects\nThe most effective criminology demands that we be aware of and committed to the goal of developing general explanatory schemes refined through test and feedback\nScience is the best model to follow in developing criminological knowledge\nWeak science, which is likely to continue to characterize criminology for some time, is hardly a basis for policy\nThe barriers to, and distractions from, good scientific criminology, especially the widespread practice of ad hoc work and the intrusion of personal biases and larger ideologies, must be countered\nCivility within the scholarly community is necessary for maximum collective effort\n\n\nIf you are interested in learning more about some of Charles Tittle’s intellectual contributions, check out our blog post on the topic, which contains comments delivered in a tribute panel for Charles at the 2021 American Society of Criminology annual meetings. To be clear, as we also note on our About page, we were inspired by Charles but he did not endorse this project in any way; in fact, he likely would have thought it was a waste of time better spent contributing in more traditional ways to scientific theory development and testing. We think it’s safe to say that we are both more “reluctant” and less “committed” criminologists than Charles was."
  },
  {
    "objectID": "blog-posts/[1]/welcome-blog.html#but-really-why-are-we-doing-this",
    "href": "blog-posts/[1]/welcome-blog.html#but-really-why-are-we-doing-this",
    "title": "Welcome to the reluctant criminologists",
    "section": "But really, why are we doing this?",
    "text": "But really, why are we doing this?\nIf we have a loftier aim for our site, it is to answer the call expressed in Charles’ lessons above by contributing modestly to the advancement of scientific criminology. In other words, this site is an attempt to help improve upon, even if just a little, what we perceive are systemic shortcomings in our respective fields.\nOf course, we are not alone - scholars raise similar concerns in other social scientific disciplines, including psychology, marketing, and evolutionary anthropology to name a few. Likewise, we benefit immensely from the contributions in blogs and bookdown projects shared freely for the collective good by so many people from various disciplinary perspectives working within and outside academia. We encourage you to check out our favorite links post for some excellent examples. Our hope is that this site might offer a comparable (derivative, bargain-basement) version that enriches conversations in our fields about how we can collectively strengthen our science through concerted efforts to improve our theories and the methods we use to generate knowledge about them.\nIn our own academic careers and scholarly pursuits, we continually try to improve our understanding of philosophies of science, substantive theories of crime and deviance, and quantitative methods used to test social scientific theories. Rather than solely bothering seemingly uninterested authors about these issues in the reviews we write for journals (we both now sign our reviews but the editors often take our names off), we thought we might as well put our thoughts out in public and subject them to criticism. Of course, we recognize the most likely outcome is that our thoughts, like in many of the reviews we write, will simply be (justifiably?) ignored. But we expect our own thinking on these matters will be strengthened by forcing ourselves to write them down and, ideally, by then accounting for your feedback.\nSo welcome to our blog! We’ll try to keep the navel gazing to a minimum from here on out."
  },
  {
    "objectID": "blog-posts/[2]/favorite_links.html",
    "href": "blog-posts/[2]/favorite_links.html",
    "title": "Check out some of our favorite sites",
    "section": "",
    "text": "Melting heart of statistics in Salvadore Dali’s surrealist style, by DALL-E\nWe have learned so much from blogs, bookdowns, and videos openly shared by others. Here, we compiled a list of some of our favorite resources.\nThis list is far from exhaustive; there are too many influential sources to recall and credit as deserved. Nonetheless, we felt it would be helpful to pull together some of those that we routinely find ourselves revisiting and recommending to others."
  },
  {
    "objectID": "blog-posts/[2]/favorite_links.html#statistics-especially-bayesian-approaches-and-more",
    "href": "blog-posts/[2]/favorite_links.html#statistics-especially-bayesian-approaches-and-more",
    "title": "Check out some of our favorite sites",
    "section": "statistics, especially Bayesian approaches, and more",
    "text": "statistics, especially Bayesian approaches, and more\nAndrew Gelman’s blog is perhaps our favorite place to go for musings on all things statistics, especially Bayesian inference, frequentist evaluation, causal inference, multilevel modeling, uncertainty, and reproducibility. We also appreciate the frequent attention paid to philosophy of science issues throughout many posts. Bonus: if you browse long enough, you might even stumble upon an answer to the question that perennially motivates a career crisis for us: The social sciences are useless, so why do we even study them?.\nSpeaking of Andrew Gelman - do you want to learn regression or Bayesian modeling? Gelman and colleagues’ books and accompanying websites are excellent resources on these topics. However, our go-to resource for learning statistics from a Bayesian framework is Richard McElreath’s Rethinking Statistics (2nd Ed.). All code from the book and a corresponding R package (rethinking) are openly shared online, and McElreath’s brilliant video lectures on YouTube, which he routinely updates, simply are without equal. Seriously - stop reading our site now and go work your way through those lectures and associated code.\nAs much as we love McElreath’s book and lectures for learning a Bayesian approach to data analysis, we usually rely on Paul Bürkner’s “Bayesian regression models using Stan,” or brms(), R package for everyday Bayesian modeling tasks. In addition to the brms() package, we recommend checking out Bürkner’s research projects and publications. In particular, we especially appreciate his work on modeling and visualizing uncertainty in (Bayesian) model comparison and his efforts to incorporate cumulative link functions for modeling monotonic effects of ordinal predictors in Bayesian regression models. Meanwhile, we are particularly fond of Bürkner’s brms vignettes, especially those on multivariate (i.e., multiple response variables) models and monotonic effects. You can also watch his talk on multilevel modeling in brms for free courtesy of @GenerableHQ.\nSo, what if you want to learn Bayesian analysis from McElreath’s book and lectures, yet you also want to follow along with his examples using the brms() package? Enter Solomon Kurz, the data science hero we need but do not deserve. Kurz has dedicated an unfathomable amount of energy to developing Bayesian translations of some of our favorite statistics books into R language and the brms() package, then sharing these valiant efforts in open-access bookdown projects. Specifically, here are Kurz’s translations of the first edition and second edition of McElreath’s book. Additionally, many years agom Jake and I initially learned longitudinal data analysis in the SAS program using Singer and Willett’s (2003) now-classic book; Kurz actually offers a free tidyverse and brms translation of their book as well! Likewise, he has similarly translated two other favorites of ours: Kruschke’s Doing Bayesian Data Analysis and Hayes’ Introduction to Mediation, Moderation, and Conditional Process Analysis. If you make it through all that free content, then we suggest heading over to his informative blog on data analysis in R for more useful content.\nThere are so many others worth mentioning in this section but, in respect of your time, we will simply share the rest in list format:\n\nMatthew Kay’s site for inspiration on communicating and visualizing uncertainty with tidybayes and ggdist. In particular, we recommend Kay’s various package vignettes, such as this one on using tidy data with Bayesian models and this one on slab + interval stats and geoms with ggdist. Also, you can watch Kay’s talk on visualizing uncertainty courtesy of @GenerableHQ.\n\nAndrew Heiss’s blog, especially entries on different types of posterior predictions, marginal effects terminology, and conditional and marginal effects in multilevel models\nAki Vehtari’s work, especially that on model selection, model checking and cross-validation, and posterior stacking. Also, be sure to check out his various videos, like this one on Bayesian workflow or his open access course videos on Bayesian data analysis.\nMichael Betancourt’s writing and videos on probabilistic modeling in Stan, and especially those on adopting a principled Bayesian workflow.\nThe 100% CI is a newer favorite. We are especially fond of Julia Rohrer’s (one of the site’s authors) various writing related to causal inference, like these on directed acyclic graphs, collider bias, and what can go wrong with nonrepresentative samples.\nThe Data Colada blog offers great analysis on various topics. For instance, they write about replication, conduct preregistered replications, and even offer an R package (groundhog) for improving reproducibililty of code. They also have interesting things to say about meta-analysis and problems with common techniques such as funnel plots and trim and fill “corrections”.\nDan Quintana, co-host of the Everything Hertz podcast, also has a blog containing great resources for meta-analysis and more in R.\n\nDaniel Lakens’ blog, the 20% statistician, is rife with useful posts about two of our favorite topics - statistics and philosophy of science. Some of our favorites include posts about p-values, power and observed power, the smallest effect size of interest, or whether philosophy of science matters in practice (we think it does a lot in criminology). Several of his lecture videos are also available online, including this one that corresponds to another favorite post discussing why more of us should seriously consider whether we are really ready to test a hypothesis in our research. Lakens has combined and expanded on a lot of these materials in his open access book, Improving Your Statistical Inferences and his free coursera course of the same name.\n\nOf all the podcasts we enjoy, the Quantitude podcast deserves a special shout-out for its highly informative yet quirky and accessible introduction to all sorts of important issues in statistics. Now, if only the hosts would join the Bayesian dark side.\nJacob Kaplan has multiple resources related to R that are geared specifically to Criminologists. Perhaps most notably is a free online book Crime by the Numbers: A Criminologist’s Guide to R. Kaplan has great programming skills and, as such, many of his examples rely on base R functionality more so than ours do."
  },
  {
    "objectID": "blog-posts/[2]/favorite_links.html#learning-data-science-with-r",
    "href": "blog-posts/[2]/favorite_links.html#learning-data-science-with-r",
    "title": "Check out some of our favorite sites",
    "section": "learning data science with R",
    "text": "learning data science with R\nWhile there is so much to learn from resources found at the links shared above, those are not the first places we send our students and friends that are interested in learning data science skills in R, yet that lack any R programming experience. We find the following links to be especially useful for these purposes - so much so that they deserve their own dedicated section! Of course, we also hope our course materials might be useful in this regard to some of you.\nDanielle Navarro’s blog is as delightful as it is informative. The blog is a model for reproducible R programming and showcases Danielle’s inspiring art throughout the site (see more of Danielle’s computational art here). The newest version of the blog often focuses on technical posts addressing issues beyond our range of program expertise. However, we love various topical essays from earlier blog renditions, like this one on preregistration, and we strongly recommend Danielle’s Data Science with R course and associated video tutorials for R beginners or those interested in leveling up their R skills.\nAllison Hill’s blog is a great place to find resources for learning to do as well as to teach R-related topics. For instance, we especially appreciate her post on teaching R Markdown, which was influential in creating our own courses, as well as her post on transitioning to Quarto, which was helpful to us in creating our blog.\nThe psyTeachR website is a phenomenal repository of resources for learning and teaching reproducible research using R. They offer a wealth of open access courses and tutorials for undergraduate and graduate levels.\nThe easystats collection of R packages is a great place for those new to R to learn basic skills related to modeling, visualization, and reporting within a relatively unified framework. Those new Unlike curated nature of R and package conflicts Those transitioning from curated statistical packages to R’s open-source environment, with its a la carte format and associated challenges (e.g., package conflicts), may find the easystats suite of packages especially helpful.\nOf course, we also love creating data visualizations with ggplot2 in R, so we owe a huge shout out to Hadley Wickham for all his R programming efforts and clear tutorials and foundational texts, which you can learn more about and freely access via his website."
  },
  {
    "objectID": "blog-posts/[2]/favorite_links.html#creating-a-website",
    "href": "blog-posts/[2]/favorite_links.html#creating-a-website",
    "title": "Check out some of our favorite sites",
    "section": "creating a website",
    "text": "creating a website\nIf you want to learn to create your own website or blog using R, we recommend checking out Andrew Rapp’s ultimate guide to creating a Quarto blog, Beatriz Mills’ guide to creating a blog with Quarto in 10 steps, Samantha Csik’s tutorial on adding a blog to your existing Quarto website, and Ezekiel Ekunola’s instructions for setting up a personalized domain address for your site.\nIn addition to R-based visualizations, we relied heavily upon Allison Horst’s website, where she freely shares amazing data science, statistics, and R themed artwork, to help improve our site’s aesthetics. We also had fun generating custom images and art using the artificial intelligence system DALL-E."
  },
  {
    "objectID": "blog-posts/[3]/charles-memorial.html",
    "href": "blog-posts/[3]/charles-memorial.html",
    "title": "Dr. Charles R. Tittle’s intellectual contributions",
    "section": "",
    "text": "Dr. Charles R. Tittle\nThe comments below were delivered in one of two tribute panels dedicated to Dr. Charles R. Tittle’s intellectual and interpersonal contributions to criminology at the 2021 American Society of Criminology annual meeting in Chicago. While others contributed additional comments on the spot, the following include only those formally scheduled comments delivered about Charles’ intellectual contributions to the field. Click on a panel topic below to expand and view its contents:\nCharles R. Tittle Tribute I: Intellectual Contributions to Criminology\nFor additional reflections about Charles from a few of his former students and colleagues, see Washington State University’s wonderful Remembering Charles Tittle memorial tribute."
  },
  {
    "objectID": "blog-posts/[3]/charles-memorial.html#sec-charles_international",
    "href": "blog-posts/[3]/charles-memorial.html#sec-charles_international",
    "title": "Dr. Charles R. Tittle’s intellectual contributions",
    "section": "Contributions to International Criminology",
    "text": "Contributions to International Criminology\nby Katya Botchkovar\nKatya gave us permission to share the recorded video of her presentation, which was delivered remotely for the ASC tribute session:"
  },
  {
    "objectID": "blog-posts/[3]/charles-memorial.html#sec-charles_measurement",
    "href": "blog-posts/[3]/charles-memorial.html#sec-charles_measurement",
    "title": "Dr. Charles R. Tittle’s intellectual contributions",
    "section": "Contributions to Measurement and Theory Testing",
    "text": "Contributions to Measurement and Theory Testing\nby Carter Hay\n\nIntroduction\nCarter gave us permission to share the written notes for his comments delivered for the ASC tribute session:\nThank you Jon, and thank you for all of your organizing these sessions that allow us to reflect on Charles as such an important scholar and person for the field of criminology but also in our lives. My areas to cover are measurement and theory testing, and it was a wonderful idea to put those two together because when we look at Charles’s research in broad strokes, those two are inherently linked. I think of it in this way:\n\nCharles was as theoretical as they come — he approached each issue with a deep concern for theory.\nBut he also was immensely empirical; analyzing data and testing hypotheses are the core of his research activities.\nBut a third thing: He commonly used data that he had some part in collecting, which meant that he wasn’t having to rely on the measures available in secondary data; instead, he played a role in shaping new novel measures of theoretical concepts.\n\nThis ultimately translated into extraordinary number of novel creative tests—studies that are among the best and most influential tests of a given theory, and this often was due in part to measurement.\nAnd he did this for MANY different theories — by my count, it’s at 10 different theories not just that Charles was able to test, but that he was able to test with original data that enabled he and his co-authors to design their own measures:\n\nDifferential association theory\nSelf-control theory\nDeterrence theory\nReintegrative shaming and labeling theory\nStrain theory, including general strain theory\nSituational action theory\nColvin’s social support/coercion theory\n\nAnd then there also are theoretical topics that cut across multiple theories, including innovative work on:\n\ncriminal motivations\nmorality and crime and religiosity and crime.\n\nIt’s not possible talk about all of those areas where Charles had a big impact with respect to measurement and empirical testing. I’m instead going to discuss two of those areas—deterrence and self-control—in some detail as illustrations of his general approach and his lasting influence.\n\n\nDeterrence\nSo the first area I want to focus on is deterrence. Charles’s work in this area most clearly begins with the Tittle (1969) article that used official data for the 50 states to reveal that the certainty of punishment—as indicated by the probability of imprisonment—was associated with lower crime and that severity (the length of prison sentences) also could reduce crime when certainty was at high levels. Charles’s key point in that article and in several others that followed in the 1970s was that deterrence needed to be taken seriously; it had been dismissed, but this wasn’t because good testing or good data had found problems; instead, he saw biases in play along with a tendency to go along with the conventional wisdom even when it wasn’t on firm ground.\nCharles wasn’t in favor of deterrence theory, he wasn’t opposed to it—he wanted to test it effectively.\nAnd his ideas on how best to test deterrence evolved fairly quickly and they would help shape the field. In 1972, Charles gets an NSF grant of $100,000 to fund a survey approach to testing deterrence theory. The results of that work were published in the book Sanctions and Social Deviance was published in 1980 and in some other articles published around that time.\nEarly in the book, he makes the case for studying deterrence with surveys, which of course, was quite different than his 1969 test that attracted so much attention—he expressed some real doubts that the macro-level research could ever explicitly reveal fear of sanctions as the operative mechanism, and this was crucial for distinguishing deterrence from other mechanisms by which punishment can affect crime.\nAlso, Charles felt that causal order issues would be tough to parse out because of how legal systems are embedded in complicated social contexts where history looms large. Even with sophisticated analyses, it was difficult to determine whether low certainty was leading to high crime, or conversely, whether high crime was leading to low certainty.\nSo he set out to try to address these two issues with a survey of roughly 2,000 adults randomly selected from three states: Iowa, Oregon, and New Jersey.\nSo on that first issue, Charles’s created an comprehensive measure of fear of sanctions. He identified multiple indicators of fear that were used for a multitude of different rule violations, with these capturing:\n\nthe chances that people would find out?\nwould those be people you know?\nwould lots of people in the community find out?\nwould there be a loss of respect?\nwould it produce an arrest?\nwould produce jail?\n\nAnd then scores were further adjusted based on the person’s peer deviance—if most of the people that someone knew engaged in deviance, then them finding out probably shouldn’t be seen as increasing sanction fear.\nNow, I’ll emphasize that Charles was not the only one pursuing this survey approach at this time (Waldo, Chiricos, Anderson), but his comprehensive approach to measurement was unique and his attention to scaling was meticulous.\n\nAnd let me mention something in connection to that — when you go to Charles’s CV, you see that 4 of his first 6 publications were explicitly measurement-oriented methodological pieces — measurement and scaling were the explicit priorities of the paper. This included articles or research notes from 1966-68 in American Journal of Sociology, Public Opinion Quarterly, Sociometry, and Social Forces. Collectively, they were cited more than 600 times and often re-printed.\nThese articles precede the articles in criminology that we think of regarding Charles’s career, and they dealt with things like political activity and bureaucratization, but there’s some foreshadowing that innovation and rigor in the area of measurement would be central to his work.\n\nBut the scope of his survey-based approach to deterrence theory also was unique—it was a big project drawing a very diverse set of subjects from 3 states to ensure big variations in social contexts—which is critical to testing deterrence theory—a convenience sample taken from a group of people in the same social context simply isn’t the best test.\nSo that’s innovation #1 — taking the most rigorous approach possible to get at that mechanism of fear.\nThe second innovation dealt with this causal order issue, which had its own problems when using the survey approach. In cross-sectional studies, perceived certainty, severity, or fear of sanctions is measured at the time of the survey and offending is measured for the prior 6 or 12 months creating an obvious causal order concern in which offending precede perceptions of sanctions.\nNow longitudinal panel data could be used but that’s difficult to come by and it creates the problem of lags—current perceptions are being used to predict future behavior, but what if perceptions of sanctions change and those current perceptions being measured at the time of the survey become outdated.\nSo Charles had an interesting fix for this — he measured projected deviance.\nHe asked this question: “If you were in a situation tomorrow where you had an extremely strong desire or need to [fill in the blank on the behavior], what are the chances that you would actually do it?”\nSo he used current perceptions of punishment to predict this measure of projected deviance, but he also measured prior deviance — it could be used as a conditioning variable or a control variable, and this measurement advance created much stronger causal inferences, especially in light of the later research that would show that projections of future deviance often were strongly correlated with actual deviance.\nAnd this approach becomes the basis for many criminological studies that in some way make use of projected deviance or crime, intentions to offend, willingness to offend, and the vignette studies. These studies go beyond deterrence theory—studies on strain theory, differential association theory, self-control theory, and so on. In many instances, they cite Tittle’s earlier work—that’s especially true for the people in this room because there are a lot of us who have used these measures—but even when Tittle wasn’t cited, they typically lean on the same basic rational that Charles drew attention to more than 40 years ago:\nthe desire to use cross-sectional data to examine contemporaneous or short-term effects (rather than lagged effects) and to do so with stronger causal inferences.\nTaking these two innovations together, what did Charles find? Findings that are very close to the current state of knowledge today. He found that:\n\nSanction fear reduces offending but fairly modestly.\nPerceived informal sanctions tends to matter more than perceived formal sanctions.\nAnd sanction fear generally has smaller effects than other theoretical variables, including moral commitments, social bonding, and differential associations.\n\nAnd Charles discovered lots of contingencies. His findings on this are immensely valuable; they laid the groundwork for interesting work to come on the idea of differential deterrability — with sanction fear operating more for some people and under some circumstances than others.\n\n(Mark Stafford on deterrence)\nAnd this issue of contingencies is something that Mark Stafford emphasized in comments that he sent me. Mark had a family issue arise and he wasn’t able to travel to Chicago, but I wanted to share with you his comments on this issue:\n\nMost deterrence researchers have paid lip-service to the idea that the threat of legal punishment probably interacts with other variables to affect the likelihood of crime. However, few have followed through on it, and no one as much as Charles. This was a central theme in his Sanctions and Social Deviance: The Question of Deterrence. A brief perusal of his deterrence studies over the years reveals that he looked at interactions between punishment threats and age, gender, informal punishments, self-control, and morality.\n\n\nProbably my favorite deterrence research by Charles focused on the possible interaction between punishment threats and motivation to commit crime. When I was a graduate student at the University of Arizona, I remember students (Mark Warr, Kirk Williams, Joe Rankin, and I) drinking with faculty (Jack Gibbs, Maynard Erickson, and Gary Jensen) on many occasions and discussing the obvious that punishment threats could not deter unless people were motivated to commit crime. We concluded, however, that motivation was too complex to capture in a simple measure. Move ahead decades later and that is exactly what Charles did – he measured motivation, and by simply asking people how much they wanted to commit crime. It turned out that this measure interacted with punishment threats to form a strong predictor of crime. Charles had a real talent of taking complex ideas and reducing them to their basics. What was too complex for the rest of us was easy for Charles. As a consequence, deterrence research is decades ahead of where it would have been without Charles. Perhaps it is hyperbole to compare Charles with Bentham and Beccaria, but I bet they would have liked to pick Charles’ brain about deterrence, and I bet Charles would tell them many things they got wrong.\n\n\n\n\nSelf-control theory—many innovations here\nLet me pivot now to self-control theory, which is an area where Charles’s contributions are immense. Many of the things we know about this theory are things we learned from Charles’s work.\nIf you look at Charles’s book reviews and commentaries on Gottfredson and Hirschi’s self-control theory, along with comments he’d make, three things were clear: (1) he saw some shortcomings in the theory, (2) he was nevertheless impressed by the case they made for self-control being an important neglected variable, and (3) he knew the theory would attract a lot of attention and testing.\nAnd a question has occurred to me, one that I wished I’d asked him: In 1991, when Charles published one of the first reviews of Gottfredson and Hirschi’s book, did he anticipate that he himself would become so central to the empirical testing of the theory? I don’t know; maybe some of you do.\nBut his centrality is unquestioned.\nIt begins obviously with the Grasmick et al. self-control scale, which of course never gets referred to by the more long-winded label of the Grasmick, Tittle, Bursik, and Arneklev scale. But I do know that Charles was quite involved in the development of that scale because he once described the painstaking process he went through to try to identify items from the California Psychological Inventory, along with the recognition at various points that newly invented items also would be needed.\nThat resulting scale they came up with was examined with new data from the Oklahoma City Survey in one the first tests of the theory, and that scale or subsets of it of it have been used in scores of studies. And their original study also has been cited more than 2600 times. The bottom line is that this scale is in many ways the gold standard for measuring self-control in criminology, and the meticulous attention to its scaling has inspired further research into not just this measure but possible limitations in Gottfredson and Hirschi’s initial conceptualization of self-control.\nAnother notable innovation of Charles’s in this area involves the distinction between self-control ability and self-control interest, along with his creative attempts to empirically distinguish them. This 2004 article with Grasmick and Ward really displays Charles’s skill in getting at the interplay between theoretical creativity and measurement. This study went beyond the arguments of the theory to consider something new, but rather than just making an interesting argument, he used data and creative measurement to test it.\nThe argument was this: self-control theory and research had been really centered on the idea that people differ in the ABILITY (or capacity) to exercise self-control—some people have that ability, some people don’t. Charles’s point was that there also could be variation in self-control INTEREST. Here’s what he said:\n\nsome people may have a strong capacity for self-control but may not always want to exercise it, while others may have weak self-control ability but have such a keen interest in controlling their deviant impulses that they end up conforming.\n\nSo these two things—ability and interest—can both be consequential and maybe they even interact with each other. Maybe the effect that one has on crime depends on how much of the other they possess.\n\nAnd he also raises this interesting possibility: self-control interest could be distinct from ability in being especially responsive to social stimuli. Maybe self-control ability is pretty stable in the way that the theory predicts, but interest—do you feel like exercising the self-control you really do possess or do you not feel like it?—is probably a much more situationally-fluid variable.\n\nSo in this study, using Oklahoma City Survey data, they construct a measure of self-control interest, and they do so with items that place a person in a situation in which they have the option of REFRAINING from some deviant action, and they ask might come from refraining—\n\nwould it allow them to feel proud?\nto earn praise from others?\nto avoid losing the respect of people they care about?\nto avoid feeling guilty?\n\nIf they say yes to these things, that’s an interest in exercising self-control.\nAnd very quickly on the findings:\n\nThey found that items measuring self-control interest coalesced nicely, loading on the same factor and not loading on a 2nd factor that including the traditional self-control ABILITY items.\nSelf control interest and self-control ability BOTH affected offending, often similarly, but when differences did emerge, it was INTEREST having the greater effect\nThere was some evidence of interaction such that self-control ability mattered less when a person was really INTERESTED in exercising self-control.\n\nNow there are other innovations that Charles had on self-control research, including measurement, but I’m running out of time. And there are other areas beyond deterrence and self-control theory that I would have liked to discuss. In particular, Charles’s research with Jon Brauer on Colvin’s social support and coercion theory in my mind provides a similar gold standard for testing that theory and measuring its concepts in both global and domain-specific ways.\nBut there’s not time, so I’ll just conclude by saying that the lasting influence of Charles’s research on theory testing and measurement comes back to a simple premise that seemed to always guide him, and we should be inspired to have it guide us as well. I believe that premise that really guided Charles was this:\n\nBefore reaching a conclusion on something, get the highest quality evidence you can, even if doing that is really hard. And it probably will be really hard. Press on and do it anyway."
  },
  {
    "objectID": "blog-posts/[3]/charles-memorial.html#sec-charles_science",
    "href": "blog-posts/[3]/charles-memorial.html#sec-charles_science",
    "title": "Dr. Charles R. Tittle’s intellectual contributions",
    "section": "Advocate for Theoretical Science in Criminology",
    "text": "Advocate for Theoretical Science in Criminology\nby Jon Brauer\n\nIntroduction\nAs my colleagues have described, Charles’ scholarship advanced so many areas of criminological inquiry, including: (1) several important substantive debates in criminology; (2) concept measurement & theory testing using survey research; (3) and assessment of the generality of criminological patterns & theories across international contexts. As scholars, many of us would love to make meaningful contributions to any single issue within one of these broad areas. The breadth, magnitude, and consistency of his contributions cements Charles Tittle’s status as one of the brightest stars in our criminological universe.\nThroughout all this work, one would be hard-pressed to find a theory of crime or deviance that was popular or that emerged during his illustrious 55+ year career that Charles had not read, reviewed, and even directly tested himself. Think about that a moment. He did not devote his time to becoming a specialist in any one theory or any particular area of inquiry. Rather, he devoted his time to becoming a specialist in countless theories and interdisciplinary areas relevant to his vast domain of inquiry – human behavior. That is, Charles embodied a generalist or Renaissance model of scholarship that seems all too rare in today’s knowledge silos, perpetuated by narrow training specializations, focused research funding and accomplishments, and exponential growth in short, quick-hitting publications.\nCharles’ varied contributions stemmed directly from his philosophy of science. He was not simply jumping from latest fad to latest fad. He was not an opportunist doggedly seeking to aim his crosshairs at every emergent idea from other hard-working scholars. He was not just publishing because that is what we do. No, Charles had much loftier aims with his research and writing. Individually and in their totality, his publications reflect his deep commitment to the health and vibrancy of the field of criminology. In fact, to Charles, the health and vibrancy of a scientific field is tantamount to the health and vibrancy of theoretical development in that field.\nLikewise, Charles devoted his entire career – and such a massive portion of his precious hours spent on this Earth – to trying to improve our theories: by reading them, thinking about them, testing them, critiquing them, developing them, and by advocating for and training others to do the same.\n\n\nCharles’ Philosophy & The Mansion of Science\nCharles was not known as someone who spent much time writing explicitly about philosophy of science. Yet, he certainly had a coherent working scientific philosophy – his belief in and advocacy for the centrality of theories to scientific progress was a cornerstone – and while his scientific philosophy was readily apparent to those who knew him well, it also emanated from his teachings and writings.\nIn the introductory lecture to one of his foundational graduate theory courses, Charles would begin by describing the “mansion of science” as having many rooms, with these rooms divided into blocks representing different paradigms or models of science. After describing other complementary or competing models of science, such as descriptive, vehrstehen, engineering, critical, nihilistic approaches, and the like, Charles would then endorse the “theoretical science” model, which he viewed as the most efficient, reliable means of fostering scientific progress. He would also pointedly profess that the theoretical science model occupied the most rooms and held the best real estate in the mansion of science.\nIn this regard, Charles views were heavily influenced by works such as Richard Braithwaite’s classic 1953 book, Scientific Explanation, and by Paul Reynolds’ 1971 book, A Primer in Theory Construction. Reynolds’ book was particularly influential to Charles’ working scientific philosophy.\nLike Reynolds, Charles viewed the goals of science and scientific activity as:\n\nproviding typologies, or identification and organization of phenomena into conceptual categories of similar and different things;\npermitting the accurate prediction of future phenomena;\nproviding accurate explanations for past phenomena; and\nproviding people a sense of understanding about how and why phenomena occur via full articulation of the causal mechanisms linking changes in some concepts (causes) with changes in other concepts (effects).\n\n(Many would add the potential for control of phenomena as a secondary consequence of accurate explanation and prediction, though Charles was infamously resistant to making the jump from is-based knowledge to ought-based control or policy prescriptions given the state of our evidence, to which I will return soon.)\nIf these indeed are the primary goals of scientific activity, then theory development is central to science. Theories provide our typologies, or our conceptual categories and shared language about phenomena. Theories are our explanations of phenomena, and we use them to generate and test predictions. Likewise, theories are our (variably) formalized answers to why and how things occur and, as such, they do, or they fail to, provide us with a sense of understanding about – or potential for effective control of – phenomena. So, for Charles, science goes as our theories go. Also, like Reynolds, Charles viewed scientific progress or the successful pursuit of these goals as occurring most efficiently through what is reminiscent of a Lakatosian process involving:\n\nObserving, describing, & making initial empirical generalizations about phenomena ->\nDeveloping initial hypotheses, or what Charles endearingly called “simple theories,” that explain some of those descriptive patterns or empirical generalizations ->\nRigorous testing of these (often numerous, varied, & competing) hypotheses or “simple theories” ->\nSlow accumulation of knowledge from these tests; identification of additional generalizations & negative cases; and, ultimately, the development of new theories that better account for patterns observed in accumulated knowledge base through processes such as theoretical invention, elaboration, or integration.\n\nCharles most explicitly outlines his adherence to this philosophy in one of my favorite pieces of his – a chapter in Gilbert Geis & Mary Dodge’s wonderful 2002 book, Lessons of Criminology (see p.32-3), entitled “Confessions of a Reluctant but Committed Criminologist.” In it, he describes the eventual development of adequate theories ultimately is what will permit “explanation, prediction, and sometimes control of criminal/deviant or other human behavior.” He warns, a la Lakatos, that “[t]he whole process, however, is long and tedious, with knowledge growing in a cumulative process. One study means nothing; collections of large numbers and varieties of progressively more refined studies are required.” (p.33).\n\n\nLessons of a Reluctant but Committed Criminologist\nIn that Reflections chapter, Charles also described the first four important lessons of his academic career, which crystallized during his time on the faculty at Washington State University. Those are that:\n\nOur body of verified scientific knowledge is exceptionally weak\n[Theoretical] Science is the best model for criminological work\nBias is pervasive in social science, including criminology, & is an archenemy of knowledge\nRecommendations or guidelines from criminologists for social policy should be delayed until there is a strong scientific base of relevant knowledge\n\nCharles then states: “…to fully comprehend their import [of these four lessons] one must share certain definitions and orientations about the meaning of science.” That is, one must share a view of science as ideally involving the slow process of knowledge construction through careful observation, empirical generalization, explanation, testing, evolution of community consensus about the adequacy an explanation following accumulation of supporting and challenging test results, development of refined explanations under more general explanatory schemes or adequate theories, and rinse and repeat.\nCharles worked with intention according to these lessons. His strong dedication to theory development always involved frequent testing of others’ ideas; ultimately, these efforts also culminated in his magnum opus, Control Balance: Toward a General Theory of Deviance. His advocacy for theoretical science was readily apparent in his book, in his reactions to critics of the book, and in his later published refinements to control balance theory.\n\n\nCulmination in His Magnum Opus, Control Balance\nIn the first sentence of his published reply in Theoretical Criminology to John Braithwaite’s review of Control Balance, Charles summarized the dual aims of his book:\n\n“Control Balance… tries to do two things. One is to set forth a paradigm for theory building and the other is to present an exemplar to be used as a starting point for the application of that paradigm. An important theme contained within the paradigm is that theory must represent the collective efforts of the community of scholars. No specific theoretical effort should be owned by anybody, a specific formulation is always tentative, and theory cumulates and improves as many individuals add their ideas and the results of research to the enterprise…”\n\nThe paradigm he envisions here is a theoretical science of criminology oriented toward the collective, collaborative construction of causal process theories. The first half of Control Balance described this paradigm in detail. He started by illustrating both the utility and deficiencies inherent in existing “simple theories” of crime and deviance, thereby convincingly highlighting the need for a new paradigm such as his – and likely disaffecting at least as many readers as he convinced in the process. He then described core features of an adequate theory, calling for criminologists to work towards developing theories with sufficient breadth, comprehensiveness, precision, and depth. He subsequently argued that integration around central causal processes or mechanisms, as opposed to invention or elaboration, holds the greatest promise for collaborative efforts at effective theory development.\nI am convinced our field would benefit from widely disseminating these initial chapters as a touchstone by which we judge our ideas and organize our efforts. In particular, I think we really need collective commitment to improving the precision of our causal predictions – to “identifying the conditions that influence exactly when and to what degree causal processes will unfold, the nature of the causal effects, the time interval between the proposed causes and expected effects” (or timing, magnitude, and functional form), and other contingencies that specify the scope or conditions under which the causal processes and predictions are expected to vary.\nAdditionally, Charles thought our best chance at accumulating a meaningful body of scientific knowledge in criminology was for us to build a community of like-minded scholars dedicated to the same cause. Toward this end, foreshadowing post-replication crisis movements, Charles put forth provocative suggestions for a more collaborative peer review system (in The Criminologist), and he advocated for changes to our incentive structures and training regimes to foster theoretical science pursuits. For instance, in his 2002 Reflections chapter, Charles stated (p.33):\n\n“For science to operate and to produce the desired outcomes, it must be supported by a community of scholars dedicated to the scientific enterprise. This community of scholars must structure itself to reward those who follow its dictates and ignore those who do not, and it must socialize new members in the values and methods of science. Those values include dedication to: (1) knowledge gained through the scientific method, (2) objectivity, (3) the search for truth, (4) open discussion and sharing of information, and (5) skepticism and mutual criticism. Science, therefore, is not value free. It is absolutely committed to a value system – the values of science. Moreover, science is a jealous master, insisting that other values (ideology and personal commitments) be rejected or overcome, at least when attempting to do science.”\n\nCharles also insisted that, this being a difficult task, we scientists organize our community to check competing values by “insisting on review by demanding critics, rewarding those who work against their own personal interests and values, and granting prestige to those who most fully exhibit the ideals of science while stigmatizing those who betray the cause.” If we meet these ideals, Charles asserted that “science can lead to knowledge that is more reliable, satisfying, and useful than any other paradigm by which people seek to understand human behavior and social organization.” However, “practicing science is difficult, especially for those who study social phenomena.” So, “the best that we criminologists can do is to practice science to the fullest extent possible, recognizing that our work often falls short and being cautious in our claims.”\n\n\nBack to the Mansion\nHow did Charles think we criminologists are doing in this regard? Well, remember that mansion of science? I will refrain from elaborating on our self-derogatory conversations about which floors (or subfloors) our fields – sociology, criminology, & criminal justice – took up in the mansion. What I will say, though, is that over their final several years attending ASC, Charles and his close friend Jim Short would frequently lament about the diminishing number of ASC panels devoted specifically to theory compared to the burgeoning number of panels representing work within those other paradigms. Moreover, in our last conversations, Charles expressed much pessimism about the health of criminology and the future of theoretical development in our field.\nI certainly empathized with his viewpoint – much more so than I let him know in those conversations. However, I also pointed to various developments – such as emerging theoretical solutions to the replication crisis; advances in formal modeling; sophisticated theorizing and prediction in the Bayesian movement; and theoretical advancements tied to the counterfactual causal revolution – that I think hold much promise for interdisciplinary social science. He was also encouraged when I summarized Proctor & Niemeyer’s new book, Mechanistic Criminology, which (I think) in many ways represents a new generation of criminologists carrying Charles’ paradigmatic torch into exciting unexplored theoretical territory and, likewise, holds much promise for our field.\nMost importantly, across more than a half-century of scholarship, Charles practiced science to the fullest extent possible, he never failed to recognize that his work often fell short, and likewise he was consistently cautious in his claims. In doing so, he was perhaps most effective as a relentless advocate for theoretical science in criminology in leading us by example. His writings will live on in the scholarly record – with each of his individual studies meaning nothing on their own but, collectively, each contributing as “grist for the mill” of science in the long and tedious process of cumulative knowledge production. Additionally, likely without explicitly intending to do so, he built a community of like-minded scholars – including many of you in this room – who share his pursuit and, in doing so, make his journey and his immense sacrifices on the alter of science meaningful.\n\n\nCommunity Building by Example\nFinally, as a last testament to his advocacy and community building by example, I would like to close with quotes from a few students of Charles’ students – these are young scholars, a generation removed, most of whom never had the pleasure of meeting the man, the myth, the legend in black jeans and cowboy boots.\nAs these excerpts come from a list of longer quotes that I collected for a different purpose – to read to Charles as he neared the end – I have kept the authors’ names anonymous here. They are a small sample, but I think these effectively represent the legacy of influence that Charles Tittle has left with his students and colleagues.\nFirst, two assistant professors who never met Charles but had read Control Balance in a graduate course state that reading Control Balance theory reminded them:\n\n“of the creativity, effort, and time it takes to actually put forth a theory. Your review of previous criminological theories and their weaknesses to even set up Control Balance Theory shows how meticulous you were in theory building approach. In today’s race to publish, it is easy to lose sight of the difficulty and time it takes to develop a comprehensive framework for thinking about crime.”\n\nAn advanced doctoral student states that “Dr. Charles Tittle was the first scholar who was able to convince me of the value and power of theory and” that reading Control Balance “was, in the deepest sense of the word, enlightening.” After reading it, this student says:\n\n“I now think theory development and testing are some of the most important scientific endeavors social scientists can and should engage in–moreover, I find them the most intellectually satisfying! It turns out I love theory. His book, his articles, and even discussions with his former students influenced by his work have certainly shaped my trajectory as a student and a scholar. And I am certain that echoes of his influence will continue to shape the rest of my academic career.”\n\nAn advanced graduate student states that:\n\n“Control Balance had a tremendous influence on me… in illustrating and breaking down all the complexities that go into theory building and integration. We all know human behavior is a complicated phenomenon, but the way Control Balance looks at the integration of theories to build a general theory of crime and how it connects the numerous converging variables, which each exists on their own continuum, is just artistry. Dr. Tittle’s work really stuck with me in enumerating how much work we have ahead of us in our field (and in many other fields) to truly understanding the nature of crime and deviance. His call for the continued elaboration on his work really sets a precedence for how we as scholars should approach and encourage critiques, elaboration, and hopefully integration on our own work instead of falling into the time-old tradition of pure competition.”\n\nA newer doctoral student says that prior to reading Control Balance for a course:\n\n“I had not, in fact, taken any interest in theory construction or debate, believing it to be outside of my level of comprehension. Upon reading Control Balance, I realized that theory is not a tool that one can afford to overlook out of fear of dissonance and ambiguity. As an individual who has only just begun to break into the world of theoretical science…, your book could not have come to me at a better time. For that, I thank you and proudly take up your call toward better theory, debate, and collaboration…”\n\nFinally, an advanced doctoral student explains various lessons learned from Charles work:\n\n“…your [Reflections chapter] taught me that it is important to be nice in the work that we do (from your conversation with Dr. Short), that it is okay to do science for the sake of science, and not to be supremely concerned with policy relevance. Along similar lines, your article The Arrogance of Public Sociology taught me to employ healthy skepticism regarding research that is primarily public/policy driven. Additionally, your work on Control Balance Theory has helped me see where existing theories are deficient, how they can potentially be improved, and how complex it is to formulate a grand theory of deviant/criminal behavior.”\n\nThis student also reflected on how Charles’ legacy of mentorship was indirectly influential in teaching the importance of:\n\n“…increasing methodological rigor in research methodology/statistical analysis, creating a more transparent and cumulative science, being honest about things we do not know in the field, and an appreciation for the importance of testing and refining criminological theory. … I am forever grateful to you and cannot wait to pass on these principles to students of my own one day.”\n\nI could not have said that better myself. Thank you, Charles."
  },
  {
    "objectID": "blog-posts/[4]/causation-no-corr.html",
    "href": "blog-posts/[4]/causation-no-corr.html",
    "title": "Causation without Correlation?",
    "section": "",
    "text": "Empty Easter egg, or countervailing causation?"
  },
  {
    "objectID": "blog-posts/[4]/causation-no-corr.html#sec-ladder",
    "href": "blog-posts/[4]/causation-no-corr.html#sec-ladder",
    "title": "Causation without Correlation?",
    "section": "Thinking up the ladder of causation",
    "text": "Thinking up the ladder of causation\nI have taught a version of my undergraduate introductory course on theories of crime and deviance (CJUS-P 200 at Indiana University) nearly every semester for the past 15 years and across three different universities. In each of those courses, my second lecture has always been devoted to teaching principles of causality.\nI start that segment with a thought question and class discussion about what it means to say that something “causes” something else. Most of the time, students start with correlational descriptions of causality, such as “X causes Y means that when X changes, Y tends to change.” Such answers are what Pearl & Mackenzie refer to as a “rung one” observation on the ladder of causation. In contrast, it is much rarer for students to intuit with minimal prompting a counterfactual or “rung three” description of causality, such as “if X caused Y, then Y might not have changed if X had not changed.”\nAt first glance, this may be a bit unexpected. We seem to engage in counterfactual thinking naturally, as it appears central to imagination and rational agency. Pearl and Mackenzie go so far as to claim that the ability to use counterfactual thinking to make “explanation-seeking inferences reliably and repeatably” is what “most distinguishes human from animal intelligence, as well as from model-blind versions of AI and machine learning” (2018, p.33). Moreover, the belief that randomization in controlled experiments offers a valid mechanism for making causal inferences relies upon counterfactual reasoning about potential outcomes; these counterfactual justifications underlying classical statistics were proposed by pioneers Jersey Neyman and Sir Ronald Fisher a century ago! Meanwhile, principled counterfactual frameworks using potential outcomes to make causal inferences with observational data have been in use since the 1970s and represent arguably the best approach to causal identification with observational data today.\nYet, counterfactuals also are weird and can be difficult to comprehend, particularly when using formal statistical notation. So, I still start with a discussion of the three basic criteria for establishing causal claims found in most sociology and criminology textbooks (correlation; nonspuriousness; temporal order). From there, I very briefly introduce students to some more advanced ideas, such as simple versus complex causality, causal chains, causal mechanisms and mediation, effect heterogeneity and moderation, and, of course, counterfactual causality. In doing so, I often tell students that, while they might know that correlation does not necessarily imply causation, they may be surprised to learn that causation may exist even in the absence of observed correlation."
  },
  {
    "objectID": "blog-posts/[4]/causation-no-corr.html#sec-reasons",
    "href": "blog-posts/[4]/causation-no-corr.html#sec-reasons",
    "title": "Causation without Correlation?",
    "section": "Causation without correlation",
    "text": "Causation without correlation\n\n\n\nPop art portrait of someone very confused, by DALL-E\n\n\nTo say students are surprised by this claim is an understatement - many seem confused or downright skeptical when I state it. After all, didn’t we just discuss how a basic criteria for establishing that X causes Y is observing a correlation between X and Y? Anticipating this confusion, I provide an example involving multiple mediation.\nIn fact, there are a number of reasons why two variables, X & Y, can be causally related despite the lack of an observed bivariate or conditional (partial) correlation between them that have nothing to do with multiple mediation. Many of these reasons involve a failure to detect a correlation where one is expected to exist due to an existing causal relationship (notice the counterfactual reasoning again?). Examples include poor measurement and insufficient statistical power of a test to detect an effect, or improper modeling of nonlinear (e.g., parabolic) functional relationships, or sample selection bias. Interestingly, it is possible to fail to observe a correlation between two variables even when in situations where there is nearly perfect functional causality (see advanced example at end here).\nWhile it is certainly important to understand how and why we might sometimes fail to statistically detect a correlation between X & Y where one might be causally expected, the example I use draws from a different situation in which one would not even expect the existence of a statistical correlation between X & Y even with precise measurement, sufficient power, careful sampling, and so on, and despite a reasonable belief in the existence of causal processes or mechanisms connecting X & Y. Examples of this situation might include counteracting direct and indirect effects or multiple countervailing mediators.\nThe statistical literature on mediation was particularly formative for my thinking on this topic. For example, consider the following excerpt from Andrew Hayes’ (2009, p.413) article, Beyond Baron & Kenny: Statistical Mediation Analysis in the New Millennium, which was published around the time I first started teaching my theories of crime course and in the same year that I published my very first article, which included a “test” of a mediation hypothesis using the old school Baron & Kenny method:\n\nCan Effects that Don’t Exist be ‘Mediated’?\n If a mediator is a variable, M, that is causally between X and Y and that accounts at least in part for the association between X and Y, then by definition X and Y must be associated in order for M to be a mediator of that effect. According to this logic, if there is no evidence that X affects Y, then how can X’s effect on Y be mediated and so what is the point of estimating indirect and direct effects? But it is possible for M to be causally between X and Y even if X and Y aren’t associated. In this case, some prefer to avoid the term mediator when describing M and instead refer simply to X’s indirect effect on Y through M…\n The distinction between mediation and indirect effect is not always made by users of the Baron and Kenny method, who may prematurely end the hunt for evidence of indirect effects if there is no evidence that X and Y are associated. If the size of c [path coefficients] constrained the size of a and b and therefore their product, this logic would make sense. Unfortunately, no such constraints exist, and it is easy to show that the claim that X can’t affect Y indirectly in the absence of a detectable total effect is false.\n\nIn this excerpt, Hayes first expresses the common sentiment that X & Y must be correlated if they are causally connected through a mediator, then proceeds to inform us that this view has been debunked as a myth. Yet, despite this being a well-established fact in the mediation/indirect effect literature for many years, I was surprised to find very few accessible examples online to which I could point students and colleagues for a more detailed illustration of the type of situation I regularly describe to them. So, I did what any nerd who recently learned R would do - I simulated some data to help my students better visualize an example. Then, I thought that others also might be uninformed or confused about the issue, and here we are."
  },
  {
    "objectID": "blog-posts/[4]/causation-no-corr.html#sec-ai",
    "href": "blog-posts/[4]/causation-no-corr.html#sec-ai",
    "title": "Causation without Correlation?",
    "section": "AI to the rescue?",
    "text": "AI to the rescue?\n\n\n\nCartoon person seeking wisdom from a computer oracle, by DALL-E\n\n\nBefore transforming my simulation example for students into a blog entry, I sought the wisdom of the artificial intelligence oracle ChatGPT, thinking it might lead me to existing examples that I was missing. I realize that, at present, ChatGPT is not particularly well-suited for causal reasoning, as Pearl himself has documented and the AI oracle itself has humbly admitted, though it also notes some ability to extract, mimic, or make guesses from data containing information about causal relations. Nonetheless, I asked the oracle: “Is it possible to have causation without correlation?”\nFor those interested in such things, I have included the full conversation with ChatGPT in the expandable link below.\n\n\nConversation with ChatGPT (4/5/2023, 12:20am)\n\n\n\n\nJon Brauer  Is it possible to have causation without correlation?\n\n\nChatGPT  Yes, it is possible to have causation without correlation. While causation and correlation are often related, they are not the same thing.\nCorrelation refers to a statistical relationship between two variables, where a change in one variable tends to be associated with a change in the other variable. However, correlation does not necessarily imply causation, because there could be other factors at play that influence both variables. For example, there is a correlation between the number of ice cream cones sold and the number of drownings each year, but this does not mean that ice cream causes drownings.\nCausation, on the other hand, refers to a relationship where one event (the cause) brings about another event (the effect). A causal relationship can exist even if there is no correlation between the two variables, because the relationship is not dependent on a statistical pattern. For example, smoking causes lung cancer, but not everyone who smokes gets lung cancer, and not everyone with lung cancer smokes.\nIn summary, while correlation and causation are often linked, they are not the same thing, and it is possible to have causation without correlation.\n\n\nJon Brauer  In your smoking example, if smoking causes lung cancer, wouldn’t there also be a statistical relationship (i.e., a correlation) between smoking and lung cancer? The statement that “not everyone who smokes gets lung cancer, and not everyone with lung cancer smokes” does not rule out the possibility (or the likelihood) of a statistical relationship - it only rules out the possibility of a perfect correlation.\n\n\nChatGPT  You are correct that in the case of smoking causing lung cancer, there is typically a statistical relationship (i.e., a correlation) between smoking and lung cancer. In fact, smoking is one of the strongest risk factors for developing lung cancer, and studies have consistently shown a strong correlation between smoking and lung cancer.\nMy previous statement about not everyone who smokes getting lung cancer and not everyone with lung cancer smoking was intended to highlight the fact that while there is a strong correlation between smoking and lung cancer, it is not a perfect correlation. In other words, there are some people who smoke and do not develop lung cancer, and there are some people who develop lung cancer even though they have never smoked.\nSo while a correlation between smoking and lung cancer does exist, it is not a one-to-one relationship, and it is possible for some smokers to avoid lung cancer and for some non-smokers to develop lung cancer. However, this does not negate the fact that smoking is a significant risk factor for developing lung cancer, and the statistical relationship between the two remains strong.\n\n\nJon Brauer  Yes, but the question was whether it is possible to have causation without correlation. You gave an example of causation with correlation.\n\n\nChatGPT  You are correct, my apologies for any confusion. The smoking example I gave was indeed an example of causation with correlation.\nTo provide an example of causation without correlation, imagine a scenario where a scientist discovers that a specific gene mutation causes a rare disease that affects only a small portion of the population. In this case, there may not be a statistical relationship or correlation between the gene mutation and the disease in the general population, because the disease is so rare and the gene mutation is only found in a small portion of the population. However, there is a clear causal relationship between the gene mutation and the disease.\nSo, to answer the original question more accurately, it is possible to have causation without a statistically significant correlation between the two variables in the general population, as in the rare disease example described above.\n\n\nJon Brauer  In that example, again, there is a correlation between the gene mutation and the disease. I did not ask about whether there could be causation without a statistically significant correlation - statistical significance depends on power of the test. So, in this causal example, if you had a sufficiently large sample, the correlation would also be detected, making it another example of causation with correlation.\n\n\nChatGPT  You are correct, and I apologize for the confusion. In the scenario I described, there is indeed a correlation between the gene mutation and the rare disease, even though it may not be statistically significant in the general population due to the low prevalence of the disease.\nIt is true that statistical significance depends on the power of the test and the sample size, and it is possible that a correlation between two variables could become statistically significant with a larger sample size. Therefore, in this case, with a larger sample size, the correlation between the gene mutation and the rare disease would likely be detected, and it would be an example of causation with correlation.\nThank you for pointing out this mistake in my previous responses, and I hope this clarification is helpful.\n\n\nJon Brauer  So, can you think of another example of causation without correlation that does not involve an insufficiently powered test for detecting correlation?\n\n\nChatGPT  Yes, I can provide another example of causation without correlation that does not involve an insufficiently powered test for detecting correlation.\nConsider the example of a person who takes a medication that causes a significant reduction in their symptoms of a medical condition. In this case, there is a clear causal relationship between taking the medication and the improvement in symptoms, but there may not be a statistical correlation between the two variables in the general population.\nThis lack of correlation could be due to a number of factors, such as individual differences in the severity or type of the medical condition, or differences in the dosage or timing of the medication. Additionally, the relationship between the medication and the symptoms could be confounded by other factors, such as the person’s diet, exercise habits, or stress levels.\nSo, in this scenario, while there may not be a statistically significant correlation between taking the medication and the improvement in symptoms in the general population, there is a clear causal relationship between the two variables in the individual person who experienced the improvement in symptoms.\n\n\nJon Brauer  This example again leverages a lack of statistical significance, which I am unmoved by such arguments. For instance, here, there is causation and likely correlation - but the correlation is not detectable due to improper modeling due to issues like heterogeneity in the strength of the effect, confounding, poor measurement, or inadequately specifying dosage and time. Can you think of any other examples that are different from these?\n\n\nChatGPT  Thank you for the feedback and clarification. I will provide another example of causation without correlation that is different from the previous examples.\nConsider the example of a person who develops a fear of flying after experiencing a traumatic event on a plane, such as severe turbulence or an emergency landing. In this case, the traumatic event on the plane is the direct cause of the person’s fear of flying.\nHowever, there may not be a statistical correlation between traumatic events on planes and the development of a fear of flying in the general population. This is because not everyone who experiences a traumatic event on a plane will develop a fear of flying, and some people may develop a fear of flying for other reasons unrelated to traumatic events.\nTherefore, in this scenario, there is a clear causal relationship between the traumatic event on the plane and the person’s fear of flying, but there may not be a statistically significant correlation between the two variables in the general population.\n\n\nJon Brauer  Interesting. If it was a singular event, then would there not be a perfect correlation between flight exposure and fear of flying since there are two data points (pre-exposure level of fear & post-exposure levels of fear)? If it is not a singular event and there is some proportion of the population that develops fear of flying after exposure to flying, then again we are back to the rare genetic cause of disease example - with sufficient data, we would be able to detect this causally driven correlation in the population. Any other ideas?\n\n\nChatGPT  You make a good point, and I apologize for any confusion. The example I provided may not be a good example of causation without correlation.\nAnother example of causation without correlation could be the case of a person who develops an allergic reaction to a specific food after consuming it for the first time. In this case, the food is the direct cause of the allergic reaction, but there may not be a statistically significant correlation between consuming the food and developing an allergic reaction in the general population.\nThis lack of correlation could be due to individual differences in genetics or immune system function, or differences in the amount or preparation of the food consumed. Additionally, the relationship between the food and the allergic reaction could be confounded by other factors, such as the person’s age or other underlying health conditions.\nTherefore, in this scenario, while there may not be a statistically significant correlation between consuming the food and developing an allergic reaction in the general population, there is a clear causal relationship between the two variables in the individual person who experienced the allergic reaction.\n\n\nJon Brauer  Again, this example seems to have a very similar logical structure and empirical implications of your previous examples. I am going to write a blog entry on causation without correlation that covers a different type of example. I will share the idea with you in case it helps you answer questions like this. Another reason there might be causation without correlation is that an exposure affects multiple mechanisms that have countervailing effects on an outcome. For instance, the exposure might be causally related to the mediators and correlated with the mediators, but and the mediators are causally related to the outcome and correlated with the outcome but in opposite directions, thereby resulting in a null (negated or cancelled out) correlation in the population. There would still be causation, though, since one could imagine intervening on one mediating pathway to hold it constant, then the exposure would cause change the outcome - and be correlated with the outcome - through the other mediating pathway. Have you encountered any examples like this before?\n\n\nChatGPT  Thank you for sharing your idea. That is a very interesting perspective on causation without correlation, and it makes sense that an exposure affecting multiple mechanisms could result in countervailing effects on an outcome, leading to a null correlation in the population.\nI have not encountered this specific example before, but I can see how it could arise in situations where there are complex and interrelated causal pathways between an exposure and an outcome. For example, in a study investigating the effects of a particular medication on a disease outcome, the medication may affect multiple biological pathways that have opposing effects on the disease outcome. As a result, the overall correlation between medication use and disease outcome may be null or weak, even though the medication is causing changes in the underlying biological pathways and ultimately influencing the disease outcome.\nI hope this example helps to provide a different perspective on causation without correlation, and thank you for bringing up this interesting topic.\n\n\nTo its credit, ChatGPT recognized the possibility of causation without correlation. However, it primarily provided examples where causation exists and correlation would be expected to exist but, for reasons such as event rarity, shoddy measurement, or insufficiently powered tests, researchers are unable to detect an actually existing (i.e., nonzero) correlation. Again, what I wanted was an example where causality exists, yet where we would not expect to detect a correlation (e.g., we might expect r=0)."
  },
  {
    "objectID": "blog-posts/[4]/causation-no-corr.html#sec-dependence",
    "href": "blog-posts/[4]/causation-no-corr.html#sec-dependence",
    "title": "Causation without Correlation?",
    "section": "Causation does require statistical dependence",
    "text": "Causation does require statistical dependence\nOne final point of clarification before getting to an example. The basic criteria are not really wrong. Causation involves statistical dependence between X and (mechanisms of) Y, and statistical dependence may exist despite a lack of observed linear correlation. I think it may be easier for some people to understand how this might happen for methodological reasons (e.g., imprecise measures; insufficient data; mispecified model) than it is to understand how this might happen for theoretical reasons. Counterfactual reasoning can help; so can causal models or directed acyclic graphs (DAGs).\nFor instance, you might be wondering if it is really useful or accurate to say that X causes Y if there is no (total) statistical dependence between X & Y - that is, if (in some populations or samples comprised of units with particular levels of key variables) Y does not reliably change after X changes. Yes, I think so! To understand why, it is helpful to consider an example, to rely on causal models, and to engage in counterfactual thinking. There are many possible examples; for simplicity, let’s imagine only four variables - X, M1, M2, and Y - that are causally related like so:\n\n\nShow code\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(psych)\n# library(devtools)\n# install_github(\"jtextor/dagitty/r\")\nlibrary(dagitty)\n\nXYdag <- dagitty(\"dag{\n  X -> M1 -> Y\n  X -> M2 -> Y\n   }\") \ncoordinates(XYdag) <- list(\n  x=c(X=1, M1=2, M2=2, Y=3),\n  y=c(X=2, M1=1, M2=3, Y=2) )\n\nplot(XYdag)\n\n\n\n\n\nIn this hypothetical example, imagine that increasing or “dialing up the knob” on X causes an increase in both M1 and M2. Imagine also that increasing or dialing up M1 causes an increase in Y, whereas an increase in M2 causes a decrease in Y of comparable magnitude in the opposite direction (i.e., countervailing indirect effects). So, when we dial up X, we also causally up M1 and M2, which in turn equivalently dials Y up (through M1) and down (through M2) - meaning Y does not change when X changes despite changes in mediators.\nSo, you might still be wondering whether it is reasonable to describe this situation as one in which X causes Y, or whether this is an example of causation without (XY) correlation. Again, I say YES! To understand why, let’s use counterfactual reasoning. I want you to further imagine that we identify a way to intervene on the X -> M1 -> Y pathway. For instance, perhaps we design an intervention to mitigate or disrupt the X -> M1 causal effect so that, when we dial up X, M1 no longer subsequently increases or it increases to a much lesser degree; that is, our intervention allows us to hold constant the level of M1 following a change in X, thereby negating the positive indirect effect of X on Y through M1. Now in this counterfactual situation, when we dial up X, what would happen to Y? It would change in a causally predictable way: If X increases, Y would decrease due to the negative indirect effect of X on Y through M2!\nI hope this abstract example helps illustrate why, without the proper causal model guiding our statistical modeling decisions and interpretations of data, it is easy to fail to observe statistical dependence where it exists (and vice versa) and then to incorrectly infer a lack of causality (or its presence) from the absence (or presence) of observed correlation. To avoid such traps, what we need is to understand theoretically how and why X is related to Y - e.g., by creating a causal diagram that accurately depicts the causal relationship(s) between these variables and by using counterfactual reasoning. Once we identify the correct causal model generating the data, then we can model the data in a way that permits us to observe statistical dependence and identify the causal effect(s) of X on Y. In short, we really need to understand theory, or logical statements of the causal relations between concepts, to properly model and interpret our data.\nWith all that said, it can be difficult to grasp abstract examples, and it may be tempting to wonder whether such situations really exist in our world. So, let’s draw inspiration from a real study in criminology to add meat to the abstract bones of our example."
  },
  {
    "objectID": "blog-posts/[4]/causation-no-corr.html#sec-sescrim",
    "href": "blog-posts/[4]/causation-no-corr.html#sec-sescrim",
    "title": "Causation without Correlation?",
    "section": "Example from criminology",
    "text": "Example from criminology\nSpecifically, we will draw inspiration from Bradley Wright and colleagues’ (1999) paper in Criminology entitled “Reconsidering the relationship between SES and delinquency: Causation but not correlation.” Seems fitting, eh?\nThe basic idea is this: There is a long history of debates over the SES-delinquency relationship. Some theories specifically posit a negative causal relationship (i.e., low SES -> high delinquency), yet observational research has documented inconsistent patterns (e.g., weak negative, nonexistent, or even positive relationships). Wright and colleagues argue that this state of affairs may be due to SES simultaneously having positive and negative causal effects on crime through countervailing mechanisms. Together, the positive and negative effects of these mechanisms may generally offset each other in many survey datasets, which might result in observing a lack of any bivariate correlation between SES and delinquency (i.e., “total effect” estimate = 0) and/or inconsistent partial correlations (i.e., variable conditional direct effect etimates) depending on which mechanisms are included or excluded from researchers’ statistical models.\nWe will illustrate how something like this might happen using simulated data. Specifically, we will simulate data for parental SES, child delinquency, and two potential countervailing mechanisms - financial strain and perceived risk of detection of delinquent behaviors. In our simulated example, we will assume parental SES does not directly cause child delinquency and that it indirectly causes child delinquency through both mediating mechanisms. Additionally, we will assume that the causal effects of Parental SES on financial strain and perceived risk of detection are equal in magnitude and that the causal effect of financial strain on delinquency is equal in magnitude yet opposite in direction, such that both indirect or mediated effects offset one another. Below is a directed acyclic graph, or DAG, of this simple causal structure.\n\n\nShow code\nSESdag <- dagitty(\"dag{\n  SES -> Strain -> Delinquency\n  SES -> Risk -> Delinquency\n   }\") \ncoordinates(SESdag) <- list(\n  x=c(SES=1, Strain=2, Risk=2, Delinquency=3),\n  y=c(SES=2, Strain=1, Risk=3, Delinquency=2) )\n\nplot(SESdag)\n\n\n\n\n\nNow let’s simulate some data. In doing so, note we round data drawn from continuous (i.e., normal & Poisson) distributions to integers; this adds a bit of noise to the data yet also makes our variables more comparable to the types of ordinal, Likert-type measures we see in our field.\n\n\nShow code\n# X = Parental SES\n# Y = Child delinquent behavior\n# F = Mediatior through which high Parent SES might decrease delinquency - e.g., less financial (S)train\n# P = Mediators through which high Parent SES increase delinquency - e.g., lower perceived (R)isk of detection\n\n# Strain -> Delinquency <- Risk \n# Strain <- SES -> Risk\n\nset.seed(1138)\nn <- 1000\n\n# McElreath method (p.153)\n# SES <- rnorm(n)\n# Strain <- rnorm(n,SES)\n# Risk <- rnorm(n,SES)\n# Delinquency <- rnorm(n,Strain-Risk)\n# \n\n# https://www.tandfonline.com/doi/pdf/10.1080/10691898.2020.1752859\nset.seed(1138)\nn <- 1000\nSES <- round(rnorm(n),digits=0)\nStrain <- round(-.5*SES + rnorm(n),digits=0)\nRisk <- round(-.5*SES + rnorm(n),digits=0)\nDelinquency <- round(.5*Strain + -.5*Risk + 0*SES + rpois(n,1),digits=0)\n\nsimdata <- tibble(SES, Strain, Risk, Delinquency)\nsimdata <- simdata %>% mutate(\n  Delinquency = ifelse(Delinquency < 0, Delinquency == 0, Delinquency)\n)\n\nsimdata\n\n\n# A tibble: 1,000 × 4\n     SES Strain  Risk Delinquency\n   <dbl>  <dbl> <dbl>       <dbl>\n 1    -1      1     0           2\n 2    -1     -1     0           0\n 3     0      1     1           2\n 4     0     -1     0           0\n 5    -1      0     1           0\n 6    -1      1     0           2\n 7     2     -1    -1           1\n 8    -1      0    -1           4\n 9     0      0    -2           2\n10     1      0    -1           4\n# … with 990 more rows\n\n\nShow code\nSESplot <- simdata %>% ggplot() +\n  geom_histogram(aes(x=SES, y=..density..),\n                 color=\"#1fa187\", fill=\"#4ac16d\", alpha=.7,\n                 position=\"identity\", \n                 breaks = seq(-4, 4, by = 1)) + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"Parental SES\", y=NULL)\n\nStrainplot <- simdata %>% ggplot() +\n  geom_histogram(aes(x=Strain, y=..density..),\n                 color=\"#1fa187\", fill=\"#4ac16d\", alpha=.7,\n                 position=\"identity\", \n                 breaks = seq(-4, 4, by = 1)) + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"Financial strain\", y=NULL)\n\nRiskplot <- simdata %>% ggplot() +\n  geom_histogram(aes(x=Risk, y=..density..),\n                 color=\"#1fa187\", fill=\"#4ac16d\", alpha=.7,\n                 position=\"identity\", \n                 breaks = seq(-4, 4, by = 1)) + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"Perceived risk of detection\", y=NULL)\n\nDelqplot <- simdata %>% ggplot() +\n  geom_histogram(aes(x=Delinquency, y=..density..),\n                 color=\"#1fa187\", fill=\"#4ac16d\", alpha=.7,\n                 position=\"identity\") + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"Child delinquency\", y=NULL)\n\n\nSESplot + Strainplot + Riskplot + Delqplot\n\n\n\n\n\n\nBivariate correlation\nLet’s examine the bivariate correlations between our simulated variables.\n\n\nShow code\n# https://r-coder.com/correlation-plot-r/  \n\npairs.panels(simdata,\n             smooth = FALSE,      # If TRUE, draws loess smooths\n             scale = FALSE,      # If TRUE, scales the correlation text font\n             density = TRUE,     # If TRUE, adds density plots and histograms\n             ellipses = FALSE,    # If TRUE, draws ellipses\n             method = \"pearson\", # Correlation method (also \"spearman\" or \"kendall\")\n             pch = 21,           # pch symbol\n             lm = TRUE,         # If TRUE, plots linear fit rather than the LOESS (smoothed) fit\n             cor = TRUE,         # If TRUE, reports correlations\n             jiggle = FALSE,     # If TRUE, data points are jittered\n             factor = 2,         # Jittering factor\n             hist.col = 3,       # Histograms color\n             stars = TRUE,       # If TRUE, adds significance level with stars\n             ci = TRUE)          # If TRUE, adds confidence intervals\n\n\n\n\n\nAs the pairs plot shows, there is virtually no correlation between SES and delinquency (r = -0.01). However, SES is negatively correlated with both mediators - financial strain (r = -0.43) and perceived risk (r = -0.40). Additionally, the mediator-delinquency correlations are similar in magnitude but opposite in direction (r = 0.30 for financial strain; r = -0.35 for perceived risk).\nGiven this, if we estimate a linear model1 regressing delinquency on SES without the mediators, we should see another near-zero association between SES and delinquency because this model essentially reproduces the bivariate correlation (with a partially standardized beta coefficient). This means the total effect of SES - its direct effect plus all indirect effects through other mechanisms like financial strain and perceived risk, all combined - is estimated to be virtually zero (b = -0.01, se = 0.04). Thus, either SES has no direct or indirect causal effects on delinquency, or SES has direct and/or indirect causal effects on delinquency but we have failed to adequately identify it with our statistical model (and with the assumed causal model underlying it). For instance, perhaps the causal effect is non-linear, with positive and negative effects on delinquency at different levels of SES that average out to a null total effect. Or, perhaps SES has countervailing indirect effets through different mediating mechanisms and, together, the mediators offset each other to result in no total causal effect.\nOf course, we know this last explanation is the true data generating process here because we simulated the data accordingly! However, in real-world data analysis, if you were to observe no correlation between two variables, you now know that it is unwise to immediately assume that there is no causal relationship between them.\n\n\nLinear regressions\nThe scatterplot and regression line from our bivariate linear regression model again illustrates the lack of total association between our simulated SES and delinqueny variables.2\n\n\nShow code\nlm1a <- lm(Delinquency ~ SES, data=simdata)\n# summary(lm1a)\nsummary(lm1a)$coefficients[,1:2]\n\n\n               Estimate Std. Error\n(Intercept)  1.09914632 0.03855249\nSES         -0.01125514 0.03849479\n\n\nShow code\n# plot(simdata$SES, simdata$Delinquency)\n# abline(lm1a)\n\n#equation for delinquency regression line  \neqY1a=function(x){\n  coef(lm1a)[2]*x + coef(lm1a)[1]\n  }\n\nlmYplot <- ggplot(simdata,aes(y=Delinquency,x=SES)) +\n  geom_jitter(alpha=.4, shape=21, size=2, width=.2, height=.2, color=\"#009E73\") + \n  stat_function(fun=eqY1a, geom=\"line\", color=\"#009E73\", size=1.5) +\n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"SES\", y=\"Delinquency\")\nlmYplot\n\n\n\n\n\nNow, let’s estimate a linear model regressing delinquency on SES and include both mediators as predictors in the model as well and then plot the regression line (with mediators set at their mean values). Once again, we should see a near-zero association between SES and delinquency, but for very different reasons this time. In this model, we are estimating what is commonly referred to as the direct effect of SES after stratifying on (aka, adjusting for) any potential indirect effects through financial strain and perceived risk mechanisms. Of course, we simulated our data in such a way that there would be no direct causal effect of SES on delinquency in our simulated data and, after including both mechanisms in the model, we accurately estimate virtually no direct effect of SES on delinquency (b = -0.03, se = 0.04). Hence, this plot looks comparable to the bivariate one above.\n\n\nShow code\nlm1b <- lm(Delinquency ~ SES + Strain + Risk, data=simdata)\n# summary(lm1b)\nsummary(lm1b)$coefficients[,1:4]\n\n\n               Estimate Std. Error     t value      Pr(>|t|)\n(Intercept)  1.07938412 0.03338240  32.3339287 2.126993e-157\nSES         -0.02905861 0.03980686  -0.7299899  4.655680e-01\nStrain       0.38859596 0.03290744  11.8087577  3.274331e-30\nRisk        -0.43975564 0.03164821 -13.8951191  2.980525e-40\n\n\nShow code\n# plot(simdata$SES, simdata$Delinquency)\n# abline(lm1b)\n\n#equation for delinquency regression line in model with both mediators at means  \neqY1b=function(x){\n  coef(lm1b)[2]*x + coef(lm1b)[1] +\n    coef(lm1b)[3]*mean(simdata$Strain) + coef(lm1b)[4]*mean(simdata$Risk)\n  }\n\nlmYplot2 <- ggplot(simdata,aes(y=Delinquency,x=SES)) +\n  geom_jitter(alpha=.4, shape=21, size=2, width=.2, height=.2, color=\"#009E73\") + \n  stat_function(fun=eqY1b, geom=\"line\", color=\"#009E73\", size=1.5) +\n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"SES\", y=\"Delinquency\")\nlmYplot2\n\n\n\n\n\nNote that this model above also estimates a positive effect of financial strain (b = 0.39, se = 0.03) and a negative effect of perceived risk (b = -0.44, se = 0.03) on delinquency. So, we might conclude that these theoretical mechanisms are related to delinquency as expected. But how would we know SES has indirect causal effects on delinquency through these mechanisms - i.e., that these variables mediate the SES-delinquency relationship? Well, we could estimate additional models regressing each mediator on SES; if SES predicts each mediator (which we know it does in our simulated data) and if each mediator predicts delinquency then, with certain strong assumptions in place (e.g., no exposure-mediator interaction and no unmeasured confounding of any paths; see here, here, and here), we can infer indirect causal effects of SES on delinquency. This is essentially the logic behind the classic Baron & Kenny method. We can also extend this logic to test for and estimate the magnitude and confidence intervals around such indirect effects through each specific mediator.3\n\n\nSpringing the causal trap\nBut without jumping ahead to mediation tests, what would have happened if we had failed to specify the appropriate causal model ahead of time and, as a result, we mistakenly included only one mediator in the model with SES predicting delinquency? Let’s add financial strain to the model and exclude perceived risk from the model, then see what happens.\n\n\nShow code\nlm1c <- lm(Delinquency ~ SES + Strain, data=simdata)\n# summary(lm1c)\nsummary(lm1c)$coefficients[,1:3]\n\n\n             Estimate Std. Error   t value\n(Intercept) 1.0982531 0.03642628 30.150019\nSES         0.1790345 0.04027868  4.444895\nStrain      0.3951323 0.03593409 10.996029\n\n\nShow code\n# plot(simdata$SES, simdata$Delinquency)\n# abline(lm1c)\n\n#equation for delinquency regression line in model with one mediator (at its mean)  \neqY1c=function(x){\n  coef(lm1c)[2]*x + coef(lm1c)[1] +\n    coef(lm1c)[3]*mean(simdata$Strain) \n  }\n\nlmYplot3 <- ggplot(simdata,aes(y=Delinquency,x=SES)) +\n  geom_jitter(alpha=.4, shape=21, size=2, width=.2, height=.2, color=\"#009E73\") + \n  stat_function(fun=eqY1c, geom=\"line\", color=\"#009E73\", size=1.5) +\n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"SES\", y=\"Delinquency\")\nlmYplot3\n\n\n\n\n\nUh oh. Suddenly, our model estimates a positive effect of SES on delinquency! Why?! Well, since we stratified on (adjusted for) financial strain, we essentially removed SES’s indirect effect on delinquency that operates through financial strain from our causal estimate. However, since we simulated these data, we know that SES also has an indirect effect on delinquency through perceived risk that is excluded from our model. So, the positive causal estimate of SES on delinquency in this model (b = 0.18, se = 0.04) reflects any direct effects of SES on delinquency (which we set to equal “0” in our simulation) and any indirect effects of SES on delinquency through unmeasured mediators - in this case, through perceived risk. We know that, in our simulated example, SES increases delinquency by reducing perceived risk of detection among those with high SES - that is, SES has a positive indirect causal effect on delinquency through perceived risk. Likewise, if we stratify on financial strain, thereby adjusting our estimate for this other known mediator, we are left with a positive estimate of the net causal effect of SES on delinquency (which we know is through perceived risk).\nThis should help illustrate an important point about so-called direct effect estimates - they are not really estimating “direct” effects at all. Rather, like bivariate correlation and regression coefficients, they are simply descriptive statistics that summarize the total effect of a predictor (SES) on an outcome (delinquency) through any and all unmeasured mechanisms.\nThis is an essential point. Imagine we were analyzing real non-simulated observational data and, after including measures of known mediating mechanisms (e.g., financial strain; perceived risk) in our model, we observed no association or “direct effect” of SES on delinquency (like in our second model lm1b above). In that situation, it is possible that there are no other mediating mechanisms through which SES might cause delinquency. However, it is also possible that there are additional unmeasured mechanisms that, combined, offset each other to result in a near-zero total remaining causal effect!\nMoreover, bivariate correlations and partial regression coefficients also may be biased by effects of other unmeasured sources of confounding as well. In our simulation, we made a strong simplifying assumption that there were no such unmeasured sources of confounding and that we had identified all relevant mechanisms. However, with real data, such assumptions often are highly implausible. Hence, if one cares about causal effects of a variable (SES) on an outcome (delinquency) - total, indirect, or otherwise - then it is essential to identify the appropriate causal model and then to include (or exclude) variables as appropriate to accurately estimate the causal effect of interest. One cannot simply let the data speak.\n\n\n\nData cannot speak meme\n\n\n\n\nSimple mediation tests\nFinally, let’s illustrate a simple test of the indirect effect of SES on delinquency using mediate() from the psych package.4\n\n\nShow code\nmediate(Delinquency ~ SES + (Strain) + (Risk), data = simdata, n.iter = 10000) %>% print(short = TRUE)\n\n\n\n\n\n\nMediation/Moderation Analysis \nCall: mediate(y = Delinquency ~ SES + (Strain) + (Risk), data = simdata, \n    n.iter = 10000)\n\nThe DV (Y) was  Delinquency . The IV (X) was  SES . The mediating variable(s) =  Strain Risk .\n\nTotal effect(c) of  SES  on  Delinquency  =  -0.01   S.E. =  0.04  t  =  -0.29  df=  998   with p =  0.77\nDirect effect (c') of  SES  on  Delinquency  removing  Strain Risk  =  -0.03   S.E. =  0.04  t  =  -0.73  df=  996   with p =  0.47\nIndirect effect (ab) of  SES  on  Delinquency  through  Strain Risk   =  0.02 \nMean bootstrapped indirect effect =  0.02  with standard error =  0.03  Lower CI =  -0.04    Upper CI =  0.08\nR = 0.5 R2 = 0.25   F = 112.47 on 3 and 996 DF   p-value:  3.83e-79 \n\n To see the longer output, specify short = FALSE in the print statement or ask for the summary\n\n\nAs before, these models estimate a near-zero total effect (c = -0.01) and so-call “direct effect” (c’ = -0.03) of SES on delinquency. However, SES is negatively associated with both mediators, and each mediator has a comparably sized yet opposite effect on delinquency. The text results also indicate that the total indirect effect of SES on delinquency through both mediators is nearly zero as well (Mean bootstrapped indirect effect [ab] of SES on Delinquency through Strain and Risk = 0.02; standard error = 0.03; 95% CI = [-0.04, 0.08]). This should be unsurprising since we simulated the data so that the two indirect effects would equally offset one other, resulting in a total indirect effect of zero.\nWe could re-estimate the model, specifying each mechanism separately as a posited mediator, to calculate an estimate of the specific indirect effect through each mediator. Or, we could multiply the SES->Mediator path coefficient and the Mediator->Delinquency path coefficient together to get basic estimates of these specific indirect effects. For instance, using this “product of ab coefficients” approach, we would estimate a negative indirect effect of SES on delinquency through financial strain (-0.48 * 0.39) approximately equal to -0.19 and a positive indirect effect through perceived risk (-0.47 * -0.44) approximately equal to 0.21.5 As expected, these countervailing indirect effects nearly perfectly offset one another!\nSo, this was a long-winded illustration of just one way that two variables might be causally related even in the absence of observing a (bivariate; total; direct) correlation between them!"
  },
  {
    "objectID": "blog-posts/[4]/causation-no-corr.html#sec-caution",
    "href": "blog-posts/[4]/causation-no-corr.html#sec-caution",
    "title": "Causation without Correlation?",
    "section": "Concluding cautions",
    "text": "Concluding cautions\nFinally, remember that although this example was inspired by a published study, ours is also a contrived example using simulated data designed to help you think more deeply about causation and (non)correlation. With simulated data, we create the rules and can ensure strong mediation assumptions are met. Yet, in the real world of messy observational data, there are often countless plausible causal models that could have generated the patterns of correlations in one’s data. For an excellent example, check out Julia Rohrer’s blog entry about hunting for indirect effects in the absence of a total effect (e.g., correlation) between X & Y. She warns:\n\nThird, be wary of mediation in the absence of a total effect. There may be scenarios in which it makes sense, but confounding may be the more plausible alternative explanation in other scenarios.\n\nHer example beautifully, or frighteningly, illustrates how a collider can produce an erroneous inference about an indirect effect. You might be wondering to yourself: what the heck is a collider? Great question. To us, it is the scary monster in our statistical modeling closet that keeps us up at night; neither of us have ever really seen the monster, but we’ve read enough stories about it to be convinced that it is there. We’ll try tackling that one another time…"
  },
  {
    "objectID": "blog-posts.html",
    "href": "blog-posts.html",
    "title": "a blog for criminologists, reluctant or otherwise",
    "section": "",
    "text": "Welcome to the reluctant criminologists\n\n\n\n\n\n\n\ngeneral\n\n\n\n\nYou found our repository for sharing course material and ideas. Congrats! Or condolences. Anyway, in this first post, we discuss our motives and aims for this site.\n\n\n\n\n\n\nMar 10, 2023\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\nCheck out some of our favorite sites\n\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\nbayesian\n\n\n\n\n\n\n\n\n\n\n\nMar 11, 2023\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\nDr. Charles R. Tittle’s intellectual contributions\n\n\n\n\n\n\n\ngeneral\n\n\n\n\nThis post is dedicated to the intellectual contributions of our late mentor, Dr. Charles R. Tittle.\n\n\n\n\n\n\nMar 12, 2023\n\n\n30 min\n\n\n\n\n\n\n  \n\n\n\n\nCausation without Correlation?\n\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\n\n\nYou’ve heard the phrase ‘correlation does not imply causation.’ But does causation imply correlation?\n\n\n\n\n\n\nApr 10, 2023\n\n\n38 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "course-materials/1_ugrad_stats/index.html",
    "href": "course-materials/1_ugrad_stats/index.html",
    "title": "Introduction to statistics in R for criminologists",
    "section": "",
    "text": "You can do this! Artwork by @allison_horst\n\n\nThe following assignments were created for Jon’s undergraduate statistics course (CJUS K300) with the help of Tyeisha Fordham, a PhD student at Indiana University. Here is an abridged syllabus for the course. Most of the assignments are based on exercises found in Bachman, Paternoster, & Wilson’s Statistics for Criminology & Criminal Justice, 5th Ed., which we refer to throughout as “BPW” book.\nThese assignments are designed to provide a (relatively) gentle introduction to elementary foundations of frequentist statistics using R via R Studio & R Markdown. Though initially designed for undergraduate students, the course is comparable to many introductory statistics courses that graduate students take in pursuit of Masters or PhD degrees in criminology/criminal justice. Hence, the R assignments may also provide a helpful bridge for graduate students prior to taking more advanced statistics courses that use R and, likewise, may be useful for criminologists at any educational or career stages interested in learning to use R for the first time.\n\n\n\n\n\nBelieve you can do this. We do! Artwork by @allison_horst\n\n\n\n\n\n\nIntroduction: Tips, troubleshooting, and why R?\nBefore you begin the assignments below, we recommend watching this brief introductory video. In it, Dr. Caitlin Ducate explains why it is worth your time to learn data analysis skills in R/RStudio, describes basic features of the R language, highlights things you can do in R, and gives advice for troubleshooting with R.\n\n\nIntroductory video (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of here() package by @allison_horst\n\n\n\n\n\n\nAssignment 1: Getting Started in R\nThe purpose of this first assignment is to demonstrate that you have downloaded the “base R” and “RStudio” statistical programs and can open a SPSS datafile in RStudio. Additionally, you will learn how to create, edit, and knit an R Markdown file.\n\n\nVideo walkthrough for Assignment 1 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of R Markdown by @allison_horst\n\n\n\n\n\n\nAssignment 2: Navigating Data\nIn this assignment, you will create an R Markdown file in which to save and present your work for this class. Additionally, following the goals of BPW’s chapter 1, you will use R/RStudio to view variables in a data file and find information about variables, including variable names, labels, and values. This assignment should help you navigate R/RStudio and become comfortable finding basic information within data files.\n\n\nVideo walkthrough for Assignment 2 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of dplyr::mutate() by @allison_horst\n\n\n\n\n\n\nAssignment 3: Describing Data Distributions\nChapters 2 & 3 of B&P’s book focused on data distributions and displaying data with tabular or graphical representations. In this assignment, you will learn how to recode variables, generate frequency tables, and create simple graphs in R.\n\n\nVideo walkthroughs for Assignment 3 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\n\nArtwork by @allison_horst\n\n\n\n\n\n\nAssignment 4: Central Tendency\nBPW’s chapter 4 focused on measures of central tendency (e.g., mean, median, and mode,) and their advantages and disadvantages as single statistical descriptions of a data distribution. Likewise, in this assignment, you will learn how to use R to calculate measures of central tendency and other statistics (e.g., skewness; kurtosis) that us help standardize and efficiently describe the shape of a data distribution. You will also get additional practice with creating frequency tables and simple graphs in R.\n\n\nVideo walkthrough for Assignment 4 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of ggplot2() by @allison_horst\n\n\n\n\n\n\nAssignment 5: Dispersion\nBPW’s chapter 5 covered measures of dispersion, including variation ratio, range, interquartile range, variance, and standard deviation. We use measures of dispersion to summarize the “spread” (rather than central tendency) of a data distribution. Likewise, in this assignment, you will learn how to use R to calculate measures of dispersion and create boxplots that help us standardize and efficiently describe the spread of a data distribution. You will also get additional practice with creating frequency tables and simple graphs in R, and you will learn how to modify some elements (e.g., color) of a ggplot object.\n\n\nVideo walkthrough for Assignment 5 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of dplyr::filter() by @allison_horst\n\n\n\n\n\n\nAssignment 6: Probability & Cross-tabulations\nBPW’s chapter 6 provided an introduction to probability, including foundational rules of probability and probability distributions. In the current assignment, you will gain a better understanding of frequentist probability by learning to create and interpret cross-tabulations or joint frequency contingency tables and by calculating z-scores.\n\n\nVideo walkthrough for Assignment 6 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nVisualizing confidence intervals around sample statistics\n\n\n\n\n\n\nAssignment 7: Sampling Variability & Confidence Intervals\nIn this assignment, we dig deeper into the process of making statistical inferences about population parameters from sample statistics. For instance, you will learn to think about sample descriptive statistics (e.g., a sample mean or correlation coefficient) as point estimates of population parameters. Relatedly, following BPW’s chapter 7, you will learn how to calculate confidence intervals around a point estimate in R and to interpret them appropriately. Additionally, you will learn how to simulate data from a probability distribution, which should help you better understand sampling variability and the need for interval estimates.\n\n\n\n\n\n\n\n\nVisualizing a one-sample hypothesis test\n\n\n\n\n\n\nAssignment 8: One-sample Null Hypothesis Test\nFollowing BPW’s chapter 8, in this assignment you will learn how to conduct a two-tail z-test and t-test and then, given the test results and the null hypothesis, to make an appropriate inference about the population parameter by either rejecting or failing to reject the null hypothesis. Along the way, you will explore plots of data distributions from random samples drawn from simulated population data. This exploration is intended to help you visualize the sampling distribution of a sample mean, which should lead to a better understanding of the underlying mechanisms that allow us to make valid population inferences from samples with null hypothesis significance testing.\n\n\n\n\n\n\n\n\nVisualizing a Chi-squared critical value\n\n\n\n\n\n\nAssignment 9: Chi-squared Test of Independence\nAs in BPW’s chapter 9, in this assignment you will learn how to make population inferences about the relationship between two categorical variables by conducting a chi-squared test of independence on a sample contingency table (crosstab). Additionally, we will briefly introduce you to the phi-coefficient and Cramer’s V, two measures of association that can be interpreted to describe the strength of an association between variables in a crosstab.\n\n\n\n\n\n\n\n\nVisualizing a two-sample hypothesis test\n\n\n\n\n\n\nAssignment 10: Two-sample Null Hypothesis Test\nBPW’s chapter 10 focused on null hypothesis tests to make inferences about the equality of two group means or proportions using sample data. Likewise, in this assignment, you will learn how to make an inference about the (in)equality of two population group means by conducting an independent sample t-test and then determining whether to reject or fail to reject the null hypothesis of no difference in population group means. We will also use simulations to visualize the sampling distribution of sample mean differences, briefly introduce Levene’s test of equality of population group variances, and introduce the half-violin/half-dotplot as a way to visualize variable distributions and potential outliers for two (or more) groups.\n\n\n\n\n\n\n\n\nVisualizing bivariate associations where Pearson’s r=0\n\n\n\n\n\n\nAssignment 11: Correlation & Regression\nBPW’s chapter 12 explored describing the association between two continuous numeric variables using a scatterplot, Pearson’s correlation coefficient (r), and an ordinary least-squared (OLS) linear regression model. In this assignment, you will learn how to estimate the strength of a linear association between two numeric variables by calculating Pearson’s correlation coefficient (r) and predict expected values of a dependent variable (Y) from the values of a linearly correlated predictor variable (X) using a linear regression model. Additionally, you will learn to visualize the association with a scatterplot and be introduced to some tools for checking model assumptions and assessing the fit of your regression model to the data.\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{brauerandtyeishafordham,\n  author = {Jon Brauer and Tyeisha Fordham},\n  title = {Introduction to Statistics in {R} for Criminologists},\n  url = {https://www.reluctantcriminologists.com/course-materials/1_ugrad_stats},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJon Brauer and Tyeisha Fordham. n.d. “Introduction to Statistics\nin R for Criminologists.” https://www.reluctantcriminologists.com/course-materials/1_ugrad_stats."
  },
  {
    "objectID": "course-materials/2_grad_RnR/index.html",
    "href": "course-materials/2_grad_RnR/index.html",
    "title": "Replication & reproducibility in social science (Graduate-level)",
    "section": "",
    "text": "Workflow, not just code, often hinders reproducibility. Artwork by @allison_horst\nIn the fall of 2021, Jon was on the schedule to teach a new course titled “Replication & Reproducibility in Social Science” as a substitute for IU Criminal Justice Department’s typical graduate “Methods” degree requirement. The same semester, Jake was scheduled to teach the “Social Research Methods” course to first-year MA students in UNCW’s Department of Sociology and Criminology. He decided to join Jon in revising the class to focus on replication and reproducibility. The result was a jointly designed course focusing on replication and reproducibility issues broadly across the social sciences, but with specific examples from sociology and criminology. You can take a look at both Jon’s syllabus and Jake’s syllabus for the course. They are basically identical, but Jon’s syllabus includes a complete reference list for the assigned and recommended readings. Also, because of a weird scheduling quirk, Jake had to combine two weeks into one (Hype and Perverse Incentives).\nIn addition to teaching our students about replication and reproducibility issues more generally, we also wanted to help them learn some practical skills to help them produce more reliable and transparent research. To do this, we had students complete two sets of assignments: 1) R Assignments intended to provide a basic introduction to conducting reproducible research using the R Statistical Computing Environment and RStudio and 2) a Reproducibility Project where they had the reproduce the (descriptive) results of a published article on a topic of interest to them. The “R Assignments” ended up being a basic introduction to data wrangling, data visualization and reporting, and reproducible workflow with a primary emphasis on the Tidyverse suite of packages. The “Reproducibility Project” was an opportunity for students to apply these new skills to a topic that interested them, get their hands dirty with real-world data, and develop an appreciation for the challenges involved in computationally reproducing published work when you do not have access to the code used to clean, wrangle and analyze the data.\nWe have included these assignments as they were assigned in Jon’s class with light editing, where necessary, for student privacy reasons. In a forthcoming blog post we will discuss what we learned from designing this course and note what we would change going forward (and what Jake did change when revising the course for senior-level undergraduate criminology majors)."
  },
  {
    "objectID": "course-materials/2_grad_RnR/index.html#r-assignments",
    "href": "course-materials/2_grad_RnR/index.html#r-assignments",
    "title": "Replication & reproducibility in social science (Graduate-level)",
    "section": "R Assignments",
    "text": "R Assignments\n\n\n\n\n\nLearning a new language like R can be frustrating. We all need breaks to breathe and vent. Artwork by @allison_horst\n\n\n\n\n\n\nAssignment 1: Getting Started in R\nThe purpose of this first assignment is to demonstrate that you have downloaded the “base R” and “RStudio” statistical programs and can open a SPSS datafile in RStudio.\n\n\n\n\n\n\n\n\nComputers crash. Files get corrupted or deleted. Plan on it in your workflow with cloud-based backups. Artwork by @allison_horst\n\n\n\n\n\n\nAssignment 2: Introduction to R Markdown\nThe purpose of this second assignment is to help you begin to explore your data in R and to do so within an RMarkdown document. The specific activities were inspired by the SPSS Exercises from the end of Chapter 1 in Bachman and Paternoster’s Statistics for Criminology & Criminal Justice, 4th Ed.\n\n\n\n\n\n\n\n\nStart with a blank canvas and build a masterpiece using ggplot2(). Artwork by @allison_horst\n\n\n\n\n\n\nAssignment 3: Direct Reproduction\nThe purpose of this assignment is to reproduce findings from a published study in R, particularly one where the data are housed on ICPSR. In order to accomplish this we will need to do and learn the following: - Identify the data being used in the now classic study by Mark Warr published in Criminology titled: “Age, Peers, and Delinquency” (Warr, 1993) - Download it from ICPSR - Identify and wrangle the specific variables/items used in the study using the dplyr package that is a part of the Tidyverse. - Combine multiple data sets into one. - Reproduce the first part of Figure 1 from Warr’s (1993) study (as displayed on pg. 22 in his article) by introducing you to the powerful data visualization package ggplot2, which is also a part of the Tidyverse.\n\n\n\n\n\n\n\n\nYou’ve learned so much! This is just the beginning of a challenging but worthwhile journey. Artwork by @allison_horst\n\n\n\n\n\n\nAssignment 4: Conceptual Replication\nThe purpose of this assignment is to perform a conceptual replication of some observations in Orcutt’s (1987) paper in Criminology titled: “Differential Association and Marijuana Use: A Closer Look at Sutherland (with a Little Help from Becker).” Since Orcutt’s (1987) original data are unavailable, we will assess whether some of his findings can be repeated with and generalize to a similar sample in the NYS data."
  },
  {
    "objectID": "course-materials/2_grad_RnR/index.html#reproducibility-project",
    "href": "course-materials/2_grad_RnR/index.html#reproducibility-project",
    "title": "Replication & reproducibility in social science (Graduate-level)",
    "section": "Reproducibility Project",
    "text": "Reproducibility Project\n\n\n\n\n\nFinding open crime data is challenging. Working with it can be even more challenging. Artwork from the Openscapes blog “Tidy Data for reproducibility, efficiency, and collaboration” by Julia Lowndes and Allison Horst”\n\n\n\n\n\n\nProject Assignment 1: Find Article with Data to Replicate\nThe primary purpose of this first project assignment is to find an article on a topic of interest to you that has data available online via ICSPR (or another repository); eventually, you will be required to use these data in an attempt to reproduce a basic descriptive finding reported in a table or figure from the article. A secondary purpose of this assignment is to develop a sense of how (un)common it is to find research articles in the top journals of your field for which the authors have openly shared their data and code for reproducibility purposes.\n\n\n\n\n\n\n\n\nYes, there is always more to learn, which means we can continue to grow and improve! Artwork by @allison_horst\n\n\n\n\n\n\nProject Assignment 2: Describe Reproduction, Share Image, Summarize Data\nUnlike previous assignments, this assignment was not organized into various numbered “parts” for students to follow and complete. Rather, it showed students some basics about publishing with R Markdown (e.g., inserting an image, editing the YAML header, etc.) and asked students to summarize the raw versions of the variables needed for their reproduction.\n\n\n\n\n\n\n\n\nFirst draft: You’ve learned the basics. Draw two ovals to start drawing the owl. Credit: Richard McElreath’s clever application of the “draw the owl” analogy to learning coding and statistics.\n\n\n\n\n\n\nProject Assignment 3: First Draft of Reproduction\nStudents are asked to create a first draft of their reproduction project which was ultimately peer-reviewed by one of their classmates. The directions are similar to Project Assignment 2 except students were expected to recode all variables and produce relatively clean and publication-ready versions of their tables and figures.\n\n\n\n\n\n\n\n\nFinal draft: Now, use what you’ve learned - and learn what you need - to draw the rest of the owl! Credit: Richard McElreath’s clever application of the “draw the owl” analogy to learning coding and statistics.\n\n\n\n\n\n\nProject Assignment 4: Final Draft of Reproduction\nStudents are asked to finalize their reproduction project and provide a reproducible file structure. Essentially, they were asked to apply the skills they had learned throughout the course to produce an article or blog reproducing some (descriptive) results of a published study."
  },
  {
    "objectID": "course-materials/3_ugrad_RnR/index.html",
    "href": "course-materials/3_ugrad_RnR/index.html",
    "title": "Criminology in crisis? Replication & reproducibility in criminology (Undergraduate-level)",
    "section": "",
    "text": "The struggle is real. We get it. We really do. Artwork by @allison_horst\nIn the Spring of 2022, the semester after teaching our graduate-level “Replication and Reproducibility” course, Jake was asked to teach a Senior Seminar (UNCW’s capstone course for criminology majors). He decided it would be a good opportunity to see if he could revise the course for senior-level criminology majors. Take a look at the syllabus to see how he changed the reading schedule for undergraduates. In terms of the assignments, there are two primary changes. First, he split the assignments into seven smaller chunks, including a specific assignment on creating a reproducible file structure (for which he borrowed heavily from Danielle Navarro’s “Project Structure” videos). Second, for “Replication and Reproducibility” project, he required everyone to reproduce or conceptually replicate an article using the at least one of the first seven waves of the National Youth Survey (NYS) data available on ICPSR.\nWe have included these assignments as they were assigned in Jake’s class with light editing, where necessary, for student privacy reasons. In a forthcoming blog post we will discuss what we learned from designing this course and note what we would change going forward. Jake is scheduled to teach the course again in the Fall 2023 semester, so he will have the opportunity to implement these changes."
  },
  {
    "objectID": "course-materials/3_ugrad_RnR/index.html#r-assignments",
    "href": "course-materials/3_ugrad_RnR/index.html#r-assignments",
    "title": "Criminology in crisis? Replication & reproducibility in criminology (Undergraduate-level)",
    "section": "R Assignments",
    "text": "R Assignments\n\n\n\n\n\nArtwork by @allison_horst\n\n\n\n\n\n\nR Assignment 1: Getting Started in R\nThe purpose of this first assignment is to demonstrate that you have downloaded the “R” statistical program and the “RStudio” Integrated Development Environment (IDE).\n\n\n\n\n\n\n\n\nArtwork by @allison_horst\n\n\n\n\n\n\nR Assignment 2: Introduction to R Markdown\nThe purpose of this second assignment is to introduce you to working in RMarkdown. This will be the primary file format in which you will save and present your work for this class.\n\n\n\n\n\n\n\n\nArtwork by @allison_horst\n\n\n\n\n\n\nR Assignment 3: Data Visualization\nThe purpose of this assignment is to introduce you to the powerful data visualization functionality in R and specifically the data visualization capabilities of the package “ggplot2”.\n\n\n\n\n\n\n\n\nArtwork by @allison_horst\n\n\n\n\n\n\nR Assignment 4: Reproducible File Structure\nCreating a reproducible file structure is important for efficiently working with and sharing your research and data. When you have a reproducible file structure, it will be easier for you to come back to a project after weeks or months of not working on it and pick up where you left off. Also, it will be easier for others to work directly with you, reproduce your work, and/or expand upon your work.\n\n\n\n\n\n\n\n\nArtwork by @allison_horst\n\n\n\n\n\n\nR Assignment 5: Downloading & Describing Data\nThe purpose of this assignment is to learn how to download and provide basic descriptions of data and specific variables analyzed in a published study.\n\n\n\n\n\n “Illustrations from the Openscapes blog Tidy Data for reproducibility, efficiency, and collaboration by Julia Lowndes and Allison Horst”\n\n\n\n\nR Assignment 6: Data Wrangling\nThe purpose of this assignment is to learn how to wrangle data in order to reproduce results from a published study (specifically figures 2-4 in Warr, 1993).\n\n\n\n\n\n\n\n\n\n\nR Assignment 7: Building Publishable Tables Data\nThe main purpose of this assignment is to teach you how to create publishable-ready tables entirely within the R ecosystem."
  },
  {
    "objectID": "course-materials/3_ugrad_RnR/index.html#reproducibility-project",
    "href": "course-materials/3_ugrad_RnR/index.html#reproducibility-project",
    "title": "Criminology in crisis? Replication & reproducibility in criminology (Undergraduate-level)",
    "section": "Reproducibility Project",
    "text": "Reproducibility Project\n\n\n\n\n\nA painting of teenagers taking a survey, by DALL-E\n\n\n\n\n\n\nProject Phase 1: Review NYS Data and Develop Research Topics/Questions\nThe primary purpose of this first project assignment is to familiarize yourself with the National Youth Survey (NYS) and begin to develop some ideas for research topics or questions that you will eventually examine with a replication study.\n\n\n\n\n\n\n\n\nA surrealist painting of a criminologist sharing their data, by DALL-E\n\n\n\n\n\n\nProject Phase 2: Identify Published Research on Topic/Question\nThe primary purpose of Phase 2 of the Replication and Reproducibility Project are to expose you to the academic literature surrounding your research topic and/or question. A secondary purpose of this assignment is for you to develop a sense of how (un)common it is to find research articles in the top journals in the field of Criminology for which the authors have openly shared their data and code for reproducibility purposes.\n\n\n\n\n\n\n\n\nA painting of a criminologist describing their data, by DALL-E\n\n\n\n\n\n\nProject Phase 3: Describe & Justify Reproduction or Conceptual Replication\nUnlike your previous assignments, this assignment will not be as explicitly directed or organized as previous assignments. While I will provide you with basic guidelines and things to include, this is your chance to demonstrate your own creativity and show what you have learned by crafting your own RMD file as you see fit. The final knitted file should contain the following parts: 1) Describe Article and Specific Findigs; 2) Insert Image and Description of Key Table(s) and/or Figure(s); and 3) Write Conclusion and Submit Knitted File and File Structure.\n\n\n\n\n\n\n\n\nA painting of a criminologist sharing their file structure, by DALL-E\n\n\n\n\n\n\nProject Phase 4: Identify & Describe Key Variables\nFor this assignment, you will begin the actual reproduction or replication by identifying and providing descriptive statistics for the key variables that will make up your analysis.\n\n\n\n\n\n\n\n\nA painting of a criminologist replicating a study, by DALL-E\n\n\n\n\n\n\nProject Phase 5: First Draft of Replication & Reproducibility Project\nIn this phase, you will complete a rough draft of your replication and reproducibility project.You have already drafted some of the following parts of this assignment in previous Project Assignments (e.g. Project Assignments #3 and #4). However, you should add and expand on those parts where appropriate (e.g., description of article, data source, and findings, and justification of replication or reproduction).\n\n\n\n\n\n\n\n\nA painting of a criminologist doing peer review, by DALL-E\n\n\n\n\n\n\nProject Phase 6: Peer Review\nPeer reviewers are responsible for providing detailed and constructive feedback (i.e., not just “good job!” – there are always ways we can improve our work) using a helpful and professional tone. In conducting your peer review, think about the steps you have taken so far and assess the things you have learned.\n\n\n\n\n\n\n\n\nA painting of a criminologist replicating a study, by DALL-E\n\n\n\n\n\n\nProject Phase 7: Final Replication & Reproducibility Project\nBased on feedback from your peer reviewer and instructor, submit a revised version of your replication and reproducibility project. This final version should be as polished as possible (e.g., free of grammatical, spelling, and coding errors). The computational goal is for your work to be completely reproducible (e.g., “one-click reproducibility”) while the substantive goal should be to write a well-organized, thorough, and thoughtful “article” or detailed “blog entry” replicating or reproducing an existing study."
  },
  {
    "objectID": "course-materials/4_grad_stats_Ducate/index.html",
    "href": "course-materials/4_grad_stats_Ducate/index.html",
    "title": "Introduction to statistics in R for criminologists",
    "section": "",
    "text": "Welcome to the R community! Artwork by @allison_horst\n\n\nThe following assignments were modified from Jon Brauer’s original undergraduate statistics course by Caitlin Ducate, an assistant professor the Department of Social Science at Texas A&M University San Antonio https://www.tamusa.edu/employees/faculty?dept=38. Here is a recent course syllabus. As with the original version, most of the assignments are based on exercises found in Bachman, Paternoster, & Wilson’s Statistics for Criminology & Criminal Justice, 5th Ed., which are referred to throughout as “BPW” book. Changes from original version mostly involve simplifying or adding additional images for clearer instructions; the most notable change in this version is that Brauer’s original Assignment #3 has been split into two separate assignments (Assignments #3 and #4).\nLike the original version, the R assignments for this course are designed to provide a (relatively) gentle introduction to elementary foundations of frequentist statistics using R via R Studio & R Markdown. Though initially designed for Master’s students, the course is comparable to introductory statistics courses that undergraduate students take as well as the initial statistics course in a sequence that many graduate students take in pursuit of PhD degrees in criminology/criminal justice. Hence, the R assignments may also provide a helpful bridge for graduate students prior to taking more advanced statistics courses that use R and, likewise, may be useful for criminologists at any educational or career stages interested in learning to use R for the first time.\n\n\n\n\n\nBelieve you can do this. We do! Artwork by @allison_horst\n\n\n\n\n\n\nIntroduction: Tips, troubleshooting, and why R?\nBefore you begin the assignments below, we recommend watching this brief introductory video. In it, Dr. Caitlin Ducate explains why it is worth your time to learn data analysis skills in R/RStudio, describes basic features of the R language, highlights things you can do in R, and gives advice for troubleshooting with R.\n\n\nIntroductory video (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of here() package by @allison_horst\n\n\n\n\n\n\nAssignment 1: Getting Started in R\nThe purpose of this first assignment is to demonstrate that you have downloaded the “base R” and “RStudio” statistical programs and can open a SPSS datafile in RStudio. Additionally, you will learn how to create, edit, and knit an R Markdown file.\n\n\nVideo walkthrough for Assignment 1 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of R Markdown by @allison_horst\n\n\n\n\n\n\nAssignment 2: Navigating Data\nIn this assignment, you will create an R Markdown file in which to save and present your work for this class. Additionally, following the goals of BPW’s chapter 1, you will use R/RStudio to view variables in a data file and find information about variables, including variable names, labels, and values. This assignment should help you navigate R/RStudio and become comfortable finding basic information within data files.\n\n\nVideo walkthrough for Assignment 2 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of tidy data by Julia Lowndes and Allison Horst\n\n\n\n\n\n\nAssignment 3: Describing Data Distributions\nChapter 2 of B&P’s book focused on data distributions. In this assignment, you will learn how to generate frequency tables in R.\n\n\nVideo walkthrough for Assignment 3 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of dplyr::mutate() by @allison_horst\n\n\n\n\n\n\nAssignment 4: Recode & Visualize Variables\nChapter 3 of B&P’s book focused on visualizing data. In this assignment, you will learn how to recode variables and create a simple graph in R.\n\n\nVideo walkthrough for Assignment 4 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtwork by @allison_horst\n\n\n\n\n\n\nAssignment 5: Central Tendency\nBPW’s chapter 4 focused on measures of central tendency (e.g., mean, median, and mode,) and their advantages and disadvantages as single statistical descriptions of a data distribution. Likewise, in this assignment, you will learn how to use R to calculate measures of central tendency and other statistics (e.g., skewness; kurtosis) that us help standardize and efficiently describe the shape of a data distribution. You will also get additional practice with creating frequency tables and simple graphs in R.\n\n\nVideo walkthrough for Assignment 5 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of ggplot2() by @allison_horst\n\n\n\n\n\n\nAssignment 6: Dispersion\nBPW’s chapter 5 covered measures of dispersion, including variation ratio, range, interquartile range, variance, and standard deviation. We use measures of dispersion to summarize the “spread” (rather than central tendency) of a data distribution. Likewise, in this assignment, you will learn how to use R to calculate measures of dispersion and create boxplots that help us standardize and efficiently describe the spread of a data distribution. You will also get additional practice with creating frequency tables and simple graphs in R, and you will learn how to modify some elements (e.g., color) of a ggplot object.\n\n\nVideo walkthrough for Assignment 6 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of dplyr::filter() by @allison_horst\n\n\n\n\n\n\nAssignment 7: Probability & Cross-tabulations\nBPW’s chapter 6 provided an introduction to probability, including foundational rules of probability and probability distributions. In the current assignment, you will gain a better understanding of frequentist probability by learning to create and interpret cross-tabulations or joint frequency contingency tables and by calculating z-scores.\n\n\nVideo walkthrough for Assignment 7 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nVisualizing confidence intervals around sample statistics\n\n\n\n\n\n\nAssignment 8: Sampling Variability & Confidence Intervals\nIn this assignment, we dig deeper into the process of making statistical inferences about population parameters from sample statistics. For instance, you will learn to think about sample descriptive statistics (e.g., a sample mean or correlation coefficient) as point estimates of population parameters. Relatedly, following BPW’s chapter 7, you will learn how to calculate confidence intervals around a point estimate in R and to interpret them appropriately. Additionally, you will learn how to simulate data from a probability distribution, which should help you better understand sampling variability and the need for interval estimates.\n\n\n\n\n\n\n\n\nVisualizing a one-sample hypothesis test\n\n\n\n\n\n\nAssignment 9: One-sample Null Hypothesis Test\nFollowing BPW’s chapter 8, in this assignment you will learn how to conduct a two-tail z-test and t-test and then, given the test results and the null hypothesis, to make an appropriate inference about the population parameter by either rejecting or failing to reject the null hypothesis. Along the way, you will explore plots of data distributions from random samples drawn from simulated population data. This exploration is intended to help you visualize the sampling distribution of a sample mean, which should lead to a better understanding of the underlying mechanisms that allow us to make valid population inferences from samples with null hypothesis significance testing.\n\n\n\n\n\n\n\n\nVisualizing a Chi-squared critical value\n\n\n\n\n\n\nAssignment 10: Chi-squared Test of Independence\nAs in BPW’s chapter 9, in this assignment you will learn how to make population inferences about the relationship between two categorical variables by conducting a chi-squared test of independence on a sample contingency table (crosstab). Additionally, we will briefly introduce you to the phi-coefficient and Cramer’s V, two measures of association that can be interpreted to describe the strength of an association between variables in a crosstab.\n\n\n\n\n\n\n\n\nVisualizing a two-sample hypothesis test\n\n\n\n\n\n\nAssignment 11: Two-sample Null Hypothesis Test\nBPW’s chapter 10 focused on null hypothesis tests to make inferences about the equality of two group means or proportions using sample data. Likewise, in this assignment, you will learn how to make an inference about the (in)equality of two population group means by conducting an independent sample t-test and then determining whether to reject or fail to reject the null hypothesis of no difference in population group means. We will also use simulations to visualize the sampling distribution of sample mean differences, briefly introduce Levene’s test of equality of population group variances, and introduce the half-violin/half-dotplot as a way to visualize variable distributions and potential outliers for two (or more) groups.\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{ducate,\n  author = {Caitlin Ducate},\n  title = {Introduction to Statistics in {R} for Criminologists},\n  url = {https://www.reluctantcriminologists.com/course-materials/4_grad_stats_Ducate},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nCaitlin Ducate. n.d. “Introduction to Statistics in R for\nCriminologists.” https://www.reluctantcriminologists.com/course-materials/4_grad_stats_Ducate."
  },
  {
    "objectID": "course-materials/intro-stats.html",
    "href": "course-materials/intro-stats.html",
    "title": "Introduction to statistics in R for criminologists",
    "section": "",
    "text": "Materials for an introductory course on frequentist statistics using R Studio & R Markdown. Course versions designed for undergraduates, graduate students, and researchers with little to no prior experience with R.\n\n\n\n\n\n\n\n\n\nVersion 1: archetypal lunacy (Brauer)\n\n\n\nTechniques of data analysis\n(Brauer; IUB CJUS-K300; Undergraduate)\nRecent syllabus\nThis is the original version created by Jon Brauer. Jon had taught previous versions of this course for many years, first by relying solely on hand-calculated statistics (at Nebraska) and then by combining hand calculations with SPSS assignments (at Indiana). For this current version, Jon continues to assign “by hand” calculations (found in Canvas assignments) but adapted the earlier SPSS assignments to R/RStudio assignments instead.\nCertain features of the course (e.g,. book selection; certain R package choices) were designed with the goal in mind of easing the transition to R for students and faculty with some prior experience using SPSS. Special shout-out to Tyeisha Fordham for helping draft the initial assignment transitions from SPSS to R.\n\n\n\n\n\n\n\n\n\n\n\nVersion 2: student is teacher (Ducate)\n\n\n\nIntroductory data analysis\n(Ducate; TAMUSA CRIM-5305; Master’s)\nRecent syllabus\nPrior to becoming a superhero professor, part of Dr. Caitlin Ducate’s origin story involved working with Jon Brauer as a graduate assistant for his statistics course at Indiana. Now, the student has become the teacher. Caitlin recently taught a modified version of Jon’s course to her Master’s students at her university and has graciously agreed to share her materials.\nChanges from original version mostly involve simplifying or adding images for clearer instructions. One notable change in this version is that Brauer’s original Assignment #3 has been split into two separate assignments (Assignments #3 and #4).\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{untitled,\n  author = {},\n  title = {Introduction to Statistics in {R} for Criminologists},\n  url = {https://www.reluctantcriminologists.com/intro-stats.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n“Introduction to Statistics in R for Criminologists.” n.d.\nhttps://www.reluctantcriminologists.com/intro-stats.html."
  },
  {
    "objectID": "course-materials/rnr.html",
    "href": "course-materials/rnr.html",
    "title": "Replication and reproducibility",
    "section": "",
    "text": "Materials for course dedicated to teaching students about replication and reproducibility issues in social science. Substantive readings in course also cover several core philosophies of science, with the aim of helping students understand logic of scientific inquiry and how/why replication and reproducibility are central to scientific knowledge construction. The first set of assignments in each course provide students a foundation for conducting minimally reproducible research using R Markdown. The second set of assignments guide students through the reproduction and/or conceptual replication of results from a published article. Course versions were designed for graduate and advanced undergraduate (senior seminar) students.\n\n\n\n\n\n\n\n\n\nVersion 1: tracing ovals (Brauer)\n\n\n\nReplication & Reproducibility in the Social Sciences\n(Brauer; IUB CJUS-P680; Graduate)\nRecent syllabus\nAssignments for graduate level replication and reproducibility course. Includes a crash course for conducting minimally reproducible research using R (#1-#4) and a ‘reproducibility project’ (#5-#8) where students reproduce or conceptually replicate results from a published article of their choice. Designed for accelerated Master’s (“4+1”) and PhD students.\n\n\n\n\n\n\n\n\n\n\n\nVersion 2: drawing owls (Day)\n\n\n\nCriminology in Crisis: Replication & Reproducibility\n(Day; UNCW CRM-495; Undergraduate)\nRecent syllabus\nAssignments for replication and reproducibility course for undergraduate seniors. Includes a crash course for conducting reproducible research using R (#1-#7) and a ‘reproducibility project’ (#8-#14) where students reproduce or conceptually replicate results from a published article using NYS data. Designed for advanced undergraduate (senior seminar) students.\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{untitled,\n  author = {},\n  title = {Replication and Reproducibility},\n  url = {https://www.reluctantcriminologists.com/rnr.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n“Replication and Reproducibility.” n.d. https://www.reluctantcriminologists.com/rnr.html."
  },
  {
    "objectID": "course-materials.html",
    "href": "course-materials.html",
    "title": "course materials",
    "section": "",
    "text": "This is a centralized location for uploading materials from various courses we have developed or our collaborators have shared. The main purpose is to have a place where we can point people if they mistakenly ask for our materials.\n\n\n\n\n\n\n\n\n\nCourse 1: Introduction to statistics in R for criminologists\n\n\nMaterials for an introductory course on frequentist statistics using R Studio & R Markdown. Course versions designed for undergraduates, graduate students, and researchers with little to no prior experience with R.\n\n\n\n\n\n\n\n\n\n\nCourse 2: Replication & reproducibility in social science\n\n\nMaterials for replication and reproducibility course. Includes assignments that provide a crash course for conducting minimally reproducible research using R Markdown and a ‘reproducibility project’ where students reproduce or conceptually replicate results from a published article. Course versions designed for graduate and advanced undergraduate (senior seminar) students."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "reluctant criminologists",
    "section": "",
    "text": "general\n\n\n\n\nYou found our repository for sharing course material and ideas. Congrats! Or condolences. Anyway, in this first post, we discuss our motives and aims for this site.\n\n\n\n\n\n\nMar 10, 2023\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\nbayesian\n\n\n\n\n\n\n\n\n\n\n\nMar 11, 2023\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\n\n\nThis post is dedicated to the intellectual contributions of our late mentor, Dr. Charles R. Tittle.\n\n\n\n\n\n\nMar 12, 2023\n\n\n30 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\n\n\nYou’ve heard the phrase ‘correlation does not imply causation.’ But does causation imply correlation?\n\n\n\n\n\n\nApr 10, 2023\n\n\n38 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#course-materials",
    "href": "index.html#course-materials",
    "title": "reluctant criminologists",
    "section": "course materials",
    "text": "course materials\n\n\n\n\n\n\n\n\n\nCourse 1: Introduction to statistics in R for criminologists\n\n\n\n\n\n\n\n\n\n\n\n\nCourse 2: Replication & reproducibility in social science"
  }
]