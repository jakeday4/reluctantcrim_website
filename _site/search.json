[
  {
    "objectID": "supp/index.html",
    "href": "supp/index.html",
    "title": "Supplementary materials",
    "section": "",
    "text": "Duplicates series\n\n\nBègue & Brauer (Forth.)\n\n\nBrauer, Day, & Kotlaja (coming soon)\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{untitled,\n  author = {},\n  title = {Supplementary Materials},\n  url = {https://www.reluctantcriminologists.com/supp},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n“Supplementary Materials.” n.d. https://www.reluctantcriminologists.com/supp."
  },
  {
    "objectID": "course-materials.html",
    "href": "course-materials.html",
    "title": "course materials",
    "section": "",
    "text": "This is a centralized location for uploading materials from various courses we have developed or our collaborators have shared. The main purpose is to have a place where we can point people if they mistakenly ask for our materials.\n\n\n\n\n\n\n\n\nCourse 1: Introduction to statistics in R for criminologists\n\n\n\nMaterials for an introductory course on frequentist statistics using R Studio & R Markdown. Course versions designed for undergraduates, graduate students, and researchers with little to no prior experience with R.\n\n\n\n\n\n\n\n\n\nCourse 2: Replication & reproducibility in social science\n\n\n\nMaterials for replication and reproducibility course. Includes assignments that provide a crash course for conducting minimally reproducible research using R Markdown and a ‘reproducibility project’ where students reproduce or conceptually replicate results from a published article. Course versions designed for graduate and advanced undergraduate (senior seminar) students."
  },
  {
    "objectID": "course-materials/intro-stats.html",
    "href": "course-materials/intro-stats.html",
    "title": "Introduction to statistics in R for criminologists",
    "section": "",
    "text": "Materials for an introductory course on frequentist statistics using R Studio & R Markdown. Course versions designed for undergraduates, graduate students, and researchers with little to no prior experience with R.\n\n\n\n\n\n\n\n\nVersion 1: archetypal lunacy (Brauer)\n\n\n\n\nTechniques of data analysis\n(Brauer; IUB CJUS-K300; Undergraduate)\nRecent syllabus\nThis is the original version created by Jon Brauer. Jon had taught previous versions of this course for many years, first by relying solely on hand-calculated statistics (at Nebraska) and then by combining hand calculations with SPSS assignments (at Indiana). For this current version, Jon continues to assign “by hand” calculations (found in Canvas assignments) but adapted the earlier SPSS assignments to R/RStudio assignments instead.\nCertain features of the course (e.g,. book selection; certain R package choices) were designed with the goal in mind of easing the transition to R for students and faculty with some prior experience using SPSS. Special shout-out to Tyeisha Fordham for helping draft the initial assignment transitions from SPSS to R.\n\n\n\n\n\n\n\n\n\n\nVersion 2: student is teacher (Ducate)\n\n\n\n\nIntroductory data analysis\n(Ducate; TAMUSA CRIM-5305; Master’s)\nRecent syllabus\nPrior to becoming a superhero professor, part of Dr. Caitlin Ducate’s origin story involved working with Jon Brauer as a graduate assistant for his statistics course at Indiana. Now, the student has become the teacher. Caitlin recently taught a modified version of Jon’s course to her Master’s students at her university and has graciously agreed to share her materials.\nChanges from original version mostly involve simplifying or adding images for clearer instructions. One notable change in this version is that Brauer’s original Assignment #3 has been split into two separate assignments (Assignments #3 and #4).\n\n\n\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "course-materials/3_ugrad_RnR/index.html",
    "href": "course-materials/3_ugrad_RnR/index.html",
    "title": "Criminology in crisis? Replication & reproducibility in criminology (Undergraduate-level)",
    "section": "",
    "text": "The struggle is real. We get it. We really do. Artwork by @allison_horst\nIn the Spring of 2022, the semester after teaching our graduate-level “Replication and Reproducibility” course, Jake was asked to teach a Senior Seminar (UNCW’s capstone course for criminology majors). He decided it would be a good opportunity to see if he could revise the course for senior-level criminology majors. Take a look at the syllabus to see how he changed the reading schedule for undergraduates. In terms of the assignments, there are two primary changes. First, he split the assignments into seven smaller chunks, including a specific assignment on creating a reproducible file structure (for which he borrowed heavily from Danielle Navarro’s “Project Structure” videos). Second, for “Replication and Reproducibility” project, he required everyone to reproduce or conceptually replicate an article using the at least one of the first seven waves of the National Youth Survey (NYS) data available on ICPSR.\nWe have included these assignments as they were assigned in Jake’s class with light editing, where necessary, for student privacy reasons. In a forthcoming blog post we will discuss what we learned from designing this course and note what we would change going forward. Jake is scheduled to teach the course again in the Fall 2023 semester, so he will have the opportunity to implement these changes."
  },
  {
    "objectID": "course-materials/3_ugrad_RnR/index.html#r-assignments",
    "href": "course-materials/3_ugrad_RnR/index.html#r-assignments",
    "title": "Criminology in crisis? Replication & reproducibility in criminology (Undergraduate-level)",
    "section": "R Assignments",
    "text": "R Assignments\n\n\n\n\n\nArtwork by @allison_horst\n\n\n\n\n\n\nR Assignment 1: Getting Started in R\nThe purpose of this first assignment is to demonstrate that you have downloaded the “R” statistical program and the “RStudio” Integrated Development Environment (IDE).\n\n\n\n\n\n\n\n\nArtwork by @allison_horst\n\n\n\n\n\n\nR Assignment 2: Introduction to R Markdown\nThe purpose of this second assignment is to introduce you to working in RMarkdown. This will be the primary file format in which you will save and present your work for this class.\n\n\n\n\n\n\n\n\nArtwork by @allison_horst\n\n\n\n\n\n\nR Assignment 3: Data Visualization\nThe purpose of this assignment is to introduce you to the powerful data visualization functionality in R and specifically the data visualization capabilities of the package “ggplot2”.\n\n\n\n\n\n\n\n\nArtwork by @allison_horst\n\n\n\n\n\n\nR Assignment 4: Reproducible File Structure\nCreating a reproducible file structure is important for efficiently working with and sharing your research and data. When you have a reproducible file structure, it will be easier for you to come back to a project after weeks or months of not working on it and pick up where you left off. Also, it will be easier for others to work directly with you, reproduce your work, and/or expand upon your work.\n\n\n\n\n\n\n\n\nArtwork by @allison_horst\n\n\n\n\n\n\nR Assignment 5: Downloading & Describing Data\nThe purpose of this assignment is to learn how to download and provide basic descriptions of data and specific variables analyzed in a published study.\n\n\n\n\n\n “Illustrations from the Openscapes blog Tidy Data for reproducibility, efficiency, and collaboration by Julia Lowndes and Allison Horst”\n\n\n\n\nR Assignment 6: Data Wrangling\nThe purpose of this assignment is to learn how to wrangle data in order to reproduce results from a published study (specifically figures 2-4 in Warr, 1993).\n\n\n\n\n\n\n\n\n\n\nR Assignment 7: Building Publishable Tables Data\nThe main purpose of this assignment is to teach you how to create publishable-ready tables entirely within the R ecosystem."
  },
  {
    "objectID": "course-materials/3_ugrad_RnR/index.html#reproducibility-project",
    "href": "course-materials/3_ugrad_RnR/index.html#reproducibility-project",
    "title": "Criminology in crisis? Replication & reproducibility in criminology (Undergraduate-level)",
    "section": "Reproducibility Project",
    "text": "Reproducibility Project\n\n\n\n\n\nA painting of teenagers taking a survey, by DALL-E\n\n\n\n\n\n\nProject Phase 1: Review NYS Data and Develop Research Topics/Questions\nThe primary purpose of this first project assignment is to familiarize yourself with the National Youth Survey (NYS) and begin to develop some ideas for research topics or questions that you will eventually examine with a replication study.\n\n\n\n\n\n\n\n\nA surrealist painting of a criminologist sharing their data, by DALL-E\n\n\n\n\n\n\nProject Phase 2: Identify Published Research on Topic/Question\nThe primary purpose of Phase 2 of the Replication and Reproducibility Project are to expose you to the academic literature surrounding your research topic and/or question. A secondary purpose of this assignment is for you to develop a sense of how (un)common it is to find research articles in the top journals in the field of Criminology for which the authors have openly shared their data and code for reproducibility purposes.\n\n\n\n\n\n\n\n\nA painting of a criminologist describing their data, by DALL-E\n\n\n\n\n\n\nProject Phase 3: Describe & Justify Reproduction or Conceptual Replication\nUnlike your previous assignments, this assignment will not be as explicitly directed or organized as previous assignments. While I will provide you with basic guidelines and things to include, this is your chance to demonstrate your own creativity and show what you have learned by crafting your own RMD file as you see fit. The final knitted file should contain the following parts: 1) Describe Article and Specific Findigs; 2) Insert Image and Description of Key Table(s) and/or Figure(s); and 3) Write Conclusion and Submit Knitted File and File Structure.\n\n\n\n\n\n\n\n\nA painting of a criminologist sharing their file structure, by DALL-E\n\n\n\n\n\n\nProject Phase 4: Identify & Describe Key Variables\nFor this assignment, you will begin the actual reproduction or replication by identifying and providing descriptive statistics for the key variables that will make up your analysis.\n\n\n\n\n\n\n\n\nA painting of a criminologist replicating a study, by DALL-E\n\n\n\n\n\n\nProject Phase 5: First Draft of Replication & Reproducibility Project\nIn this phase, you will complete a rough draft of your replication and reproducibility project.You have already drafted some of the following parts of this assignment in previous Project Assignments (e.g. Project Assignments #3 and #4). However, you should add and expand on those parts where appropriate (e.g., description of article, data source, and findings, and justification of replication or reproduction).\n\n\n\n\n\n\n\n\nA painting of a criminologist doing peer review, by DALL-E\n\n\n\n\n\n\nProject Phase 6: Peer Review\nPeer reviewers are responsible for providing detailed and constructive feedback (i.e., not just “good job!” – there are always ways we can improve our work) using a helpful and professional tone. In conducting your peer review, think about the steps you have taken so far and assess the things you have learned.\n\n\n\n\n\n\n\n\nA painting of a criminologist replicating a study, by DALL-E\n\n\n\n\n\n\nProject Phase 7: Final Replication & Reproducibility Project\nBased on feedback from your peer reviewer and instructor, submit a revised version of your replication and reproducibility project. This final version should be as polished as possible (e.g., free of grammatical, spelling, and coding errors). The computational goal is for your work to be completely reproducible (e.g., “one-click reproducibility”) while the substantive goal should be to write a well-organized, thorough, and thoughtful “article” or detailed “blog entry” replicating or reproducing an existing study."
  },
  {
    "objectID": "course-materials/1_ugrad_stats/index.html",
    "href": "course-materials/1_ugrad_stats/index.html",
    "title": "Introduction to statistics in R for criminologists",
    "section": "",
    "text": "You can do this! Artwork by @allison_horst\n\n\nThe following assignments are designed to provide a (relatively) gentle introduction to elementary foundations of frequentist statistics using R via R Studio & R Markdown. They were created for Jon’s undergraduate statistics course (CJUS K300) and, in collaboration with Tyeisha Fordham, were adapted from earlier SPSS versions.\nHere is an abridged syllabus for the course. Most of the assignments are based on exercises found in Bachman, Paternoster, & Wilson’s Statistics for Criminology & Criminal Justice, 5th Ed., which we refer to throughout as “BPW” book. When teaching the course, Jon pairs each R Assignment with a weekly Canvas assignment assessing comprehension of formulas and “by hand” statistical calculations.\nThough initially designed for undergraduate students, the course is comparable to many introductory statistics courses that graduate students take in pursuit of Masters or PhD degrees in criminology/criminal justice. Certain features of the course (e.g,. book selection; certain R package choices) were designed with the goal in mind of easing the transition to R for students and faculty with prior experience using SPSS. Hence, these R Assignments may also provide a helpful bridge for graduate students prior to taking more advanced statistics courses that use R and, likewise, may be useful for criminologists at any educational or career stages interested in learning to use R for the first time.\n\n\n\n\n\nBelieve you can do this. We do! Artwork by @allison_horst\n\n\n\n\n\n\nIntroduction: Tips, troubleshooting, and why R?\nBefore you begin the assignments below, we recommend watching this brief introductory video. In it, Dr. Caitlin Ducate explains why it is worth your time to learn data analysis skills in R/RStudio, describes basic features of the R language, highlights things you can do in R, and gives advice for troubleshooting with R.\n\n\nIntroductory video (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of here() package by @allison_horst\n\n\n\n\n\n\nAssignment 1: Getting Started in R\nThe purpose of this first assignment is to demonstrate that you have downloaded the “base R” and “RStudio” statistical programs and can open a SPSS datafile in RStudio. Additionally, you will learn how to create, edit, and knit an R Markdown file.\n\n\nVideo walkthrough for Assignment 1 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of R Markdown by @allison_horst\n\n\n\n\n\n\nAssignment 2: Navigating Data\nIn this assignment, you will create an R Markdown file in which to save and present your work for this class. Additionally, following the goals of BPW’s chapter 1, you will use R/RStudio to view variables in a data file and find information about variables, including variable names, labels, and values. This assignment should help you navigate R/RStudio and become comfortable finding basic information within data files.\n\n\nVideo walkthrough for Assignment 2 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of dplyr::mutate() by @allison_horst\n\n\n\n\n\n\nAssignment 3: Describing Data Distributions\nChapters 2 & 3 of B&P’s book focused on data distributions and displaying data with tabular or graphical representations. In this assignment, you will learn how to recode variables, generate frequency tables, and create simple graphs in R.\n\n\nVideo walkthroughs for Assignment 3 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\n\nArtwork by @allison_horst\n\n\n\n\n\n\nAssignment 4: Central Tendency\nBPW’s chapter 4 focused on measures of central tendency (e.g., mean, median, and mode,) and their advantages and disadvantages as single statistical descriptions of a data distribution. Likewise, in this assignment, you will learn how to use R to calculate measures of central tendency and other statistics (e.g., skewness; kurtosis) that us help standardize and efficiently describe the shape of a data distribution. You will also get additional practice with creating frequency tables and simple graphs in R.\n\n\nVideo walkthrough for Assignment 4 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of ggplot2() by @allison_horst\n\n\n\n\n\n\nAssignment 5: Dispersion\nBPW’s chapter 5 covered measures of dispersion, including variation ratio, range, interquartile range, variance, and standard deviation. We use measures of dispersion to summarize the “spread” (rather than central tendency) of a data distribution. Likewise, in this assignment, you will learn how to use R to calculate measures of dispersion and create boxplots that help us standardize and efficiently describe the spread of a data distribution. You will also get additional practice with creating frequency tables and simple graphs in R, and you will learn how to modify some elements (e.g., color) of a ggplot object.\n\n\nVideo walkthrough for Assignment 5 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of dplyr::filter() by @allison_horst\n\n\n\n\n\n\nAssignment 6: Probability & Cross-tabulations\nBPW’s chapter 6 provided an introduction to probability, including foundational rules of probability and probability distributions. In the current assignment, you will gain a better understanding of frequentist probability by learning to create and interpret cross-tabulations or joint frequency contingency tables and by calculating z-scores.\n\n\nVideo walkthrough for Assignment 6 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nVisualizing confidence intervals around sample statistics\n\n\n\n\n\n\nAssignment 7: Sampling Variability & Confidence Intervals\nIn this assignment, we dig deeper into the process of making statistical inferences about population parameters from sample statistics. For instance, you will learn to think about sample descriptive statistics (e.g., a sample mean or correlation coefficient) as point estimates of population parameters. Relatedly, following BPW’s chapter 7, you will learn how to calculate confidence intervals around a point estimate in R and to interpret them appropriately. Additionally, you will learn how to simulate data from a probability distribution, which should help you better understand sampling variability and the need for interval estimates.\n\n\n\n\n\n\n\n\nVisualizing a one-sample hypothesis test\n\n\n\n\n\n\nAssignment 8: One-sample Null Hypothesis Test\nFollowing BPW’s chapter 8, in this assignment you will learn how to conduct a two-tail z-test and t-test and then, given the test results and the null hypothesis, to make an appropriate inference about the population parameter by either rejecting or failing to reject the null hypothesis. Along the way, you will explore plots of data distributions from random samples drawn from simulated population data. This exploration is intended to help you visualize the sampling distribution of a sample mean, which should lead to a better understanding of the underlying mechanisms that allow us to make valid population inferences from samples with null hypothesis significance testing.\n\n\n\n\n\n\n\n\nVisualizing a Chi-squared critical value\n\n\n\n\n\n\nAssignment 9: Chi-squared Test of Independence\nAs in BPW’s chapter 9, in this assignment you will learn how to make population inferences about the relationship between two categorical variables by conducting a chi-squared test of independence on a sample contingency table (crosstab). Additionally, we will briefly introduce you to the phi-coefficient and Cramer’s V, two measures of association that can be interpreted to describe the strength of an association between variables in a crosstab.\n\n\n\n\n\n\n\n\nVisualizing a two-sample hypothesis test\n\n\n\n\n\n\nAssignment 10: Two-sample Null Hypothesis Test\nBPW’s chapter 10 focused on null hypothesis tests to make inferences about the equality of two group means or proportions using sample data. Likewise, in this assignment, you will learn how to make an inference about the (in)equality of two population group means by conducting an independent sample t-test and then determining whether to reject or fail to reject the null hypothesis of no difference in population group means. We will also use simulations to visualize the sampling distribution of sample mean differences, briefly introduce Levene’s test of equality of population group variances, and introduce the half-violin/half-dotplot as a way to visualize variable distributions and potential outliers for two (or more) groups.\n\n\n\n\n\n\n\n\nVisualizing bivariate associations where Pearson’s r=0\n\n\n\n\n\n\nAssignment 11: Correlation & Regression\nBPW’s chapter 12 explored describing the association between two continuous numeric variables using a scatterplot, Pearson’s correlation coefficient (r), and an ordinary least-squared (OLS) linear regression model. In this assignment, you will learn how to estimate the strength of a linear association between two numeric variables by calculating Pearson’s correlation coefficient (r) and predict expected values of a dependent variable (Y) from the values of a linearly correlated predictor variable (X) using a linear regression model. Additionally, you will learn to visualize the association with a scatterplot and be introduced to some tools for checking model assumptions and assessing the fit of your regression model to the data.\n\n\n\n\n\n\n\n\nRepresenting causal mediating relationships with a DAG\n\n\n\n\n\n\nExtra Credit: Causation without Correlation\nIn the last assignment, you learned how to describe associations between two continuous numeric variables using a scatterplot, Pearson’s correlation coefficient (r), and an ordinary least-squared (OLS) linear regression model. In this extra credit assignment, you have the opportunity to put your skills to the test. For this activity, you will read and reproduce all code from the Causation without correlation blog post. Then, you will be challenged to extend the blog example with new simulated data containing three mediating mechanisms and attempt to interpret the results. This assignment will push you beyond the boundaries of what you have learned. Do not let that frighten or discourage you. As extra credit, any attempt is a worthwhile success and, if you choose not to attempt it, then you only fail yourself!\n\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{brauer and tyeisha fordham,\n  author = {Brauer and Tyeisha Fordham, Jon},\n  title = {Introduction to Statistics in {R} for Criminologists},\n  url = {https://www.reluctantcriminologists.com/course-materials/1_ugrad_stats},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBrauer and Tyeisha Fordham, Jon. n.d. “Introduction to Statistics\nin R for Criminologists.” https://www.reluctantcriminologists.com/course-materials/1_ugrad_stats."
  },
  {
    "objectID": "blog-posts/[7]/modmadness-pt2.html",
    "href": "blog-posts/[7]/modmadness-pt2.html",
    "title": "Moderator Madness, Part 2",
    "section": "",
    "text": "Lemmings puzzled by 4-way total effect decomposition (with help from DALL-E)\nThis is the second of a three-part blog series on modeling moderators in criminological data. Part 1 addressed issues related to the estimation and interpretation of interaction effects in generalized linear regression models with nonlinear link functions (e.g., logistic, Poisson, and negative binomial regression). In this Part 2 entry, I use a simple example to introduce a 4-way decomposition procedure for separating a total effect into direct, indirect, and interaction components in the presence of a potential exposure-mediator interaction. Part 3 will then use more realistic simulated data to illustrate “causal mediation” analysis with the CMAverse software package in R, which relies on this 4-way potential outcomes decomposition approach to disentangle indirect and interaction effects in the presence of a potential exposure-mediator interaction.\nMy primary goals in this second post are to introduce counterfactual causality, exposure-mediator interactions, and a potential outcomes framework for conducting a four-way decomposition of a total effect into four distinct components: a controlled direct effect (CDE); a pure indirect effect (PIE); a reference interaction (INTref); and a mediated interaction (INTmed).\nReady to dip your toes into the deep end?"
  },
  {
    "objectID": "blog-posts/[7]/modmadness-pt2.html#sec-counterfac",
    "href": "blog-posts/[7]/modmadness-pt2.html#sec-counterfac",
    "title": "Moderator Madness, Part 2",
    "section": "Comprehending counterfactuals",
    "text": "Comprehending counterfactuals\nHave you ever stubbed your toe in the dark? Think back to one of those times. Did you say “ouch” or some other four letter word? What do you think caused you to stub your toe?\nLet’s add some details to this example: Imagine that you are in an unfamiliar room, at night, with blackout curtains drawn closed over a single window. With the curtains closed, the room lacks sufficient light to help you see obstacles in your path. You are tip-toing across the room in search of a light switch when suddenly - “OUCH!” - you stub your toe on what feels like the leg of a chair. Your mind suddenly and angrily turns to the curtains: “If I had just left those #&%@! curtains open, I never would have stubbed my toe!”\n\n\n\nYour thoughts communicate a causal claim about the world - that the closed window curtain caused your pain.\n\n\nThere are two important things to note about this imaginary angry thought. First, it communicates a causal belief or claim. Specifically, your momentary thought communicates a belief that the closed window curtains are (at least partly) responsible for you stubbing your toe. Put differently, you view the closed curtains as a cause of the undesired outcome - perhaps not the only cause, but a noteworthy cause nonetheless.\nSecond, the structure of this angry thought conveys an implicit view of causal claims as dependent upon contrasts between plausible “potential outcomes” across observed and “counterfactual” conditions. That is, your momentary thought contrasts an observed or factual initial condition (the closed curtain) with a counterfactual initial condition (an open curtain), and then implies a different potential outcome (i.e, a stubbed versus an unstubbed toe) might have occurred if the observed initial condition would have been changed to the counterfactual condition instead.\n\n\n\nCausal claims depend upon contrasts between “potential outcomes” across observed and counterfactual conditions.\n\n\nMany social scientific questions and claims reflect a similar counterfactual logic or, at least, can be recast in counterfactual terms:\n\nIf politicians had not campaigned on these platforms or had not signed those policies into law, then US incarceration rates would not have increased exponentially…\nIf we intervene in those neighborhoods in these ways, then crime rates in those neighborhoods will reduce…\nIf that group had those different characteristics, then they would have received better (worse) criminal justice outcomes…\n\nIf those adults had not experienced adverse childhood experiences, then they might not have participated in violent criminal behaviors…\n\nIn our earlier post on causation without correlation, we also noted that counterfactual reasoning is central to statistical tests of causal claims and even underlies justifications for randomized controlled trials themselves:\n\n“We seem to engage in counterfactual thinking naturally, as it appears central to imagination and rational agency. Pearl and Mackenzie go so far as to claim that the ability to use counterfactual thinking to make “explanation-seeking inferences reliably and repeatably” is what “most distinguishes human from animal intelligence, as well as from model-blind versions of AI and machine learning” (2018, p.33). Moreover, the belief that randomization in controlled experiments offers a valid mechanism for making causal inferences relies upon counterfactual reasoning about potential outcomes; these counterfactual justifications underlying classical statistics were proposed by pioneers Jersey Neyman and Sir Ronald Fisher a century ago! Meanwhile, principled counterfactual frameworks using potential outcomes to make causal inferences with observational data have been in use since the 1970s and represent arguably the best approach to causal identification with observational data today.”"
  },
  {
    "objectID": "blog-posts/[7]/modmadness-pt2.html#sec-potentialoutcomes",
    "href": "blog-posts/[7]/modmadness-pt2.html#sec-potentialoutcomes",
    "title": "Moderator Madness, Part 2",
    "section": "Prepare for potential outcomes notation",
    "text": "Prepare for potential outcomes notation\nWith that said, let’s recast our hypothetical toe-stubbing example into the language of counterfactuals and potential outcomes.\nIn this simple example, we have two initial “exposure” or “treatment” conditions: curtains closed and curtains open. We will denote curtains open as X=0 and curtains closed as X=1. Likewise, we have two “potential outcome” conditions: unstubbed toe, denoted as Y=0, and stubbed toe, denoted as Y=1.\nGiven these and our causal expectations, we can write two potential outcomes equations, Y(0)=0 (or Y0=0) and Y(1)=1 (or Y1=1), that respectively represent our expectation of a stubbed toe when curtains are closed and our expectation of an unstubbed toe when curtains are open. Here, I am (loosely) adopting Pearl’s do-calculus notation, where these two equations are abbreviations of longer structural equations for outcome probability expectations under different initial conditions where we do X=0 or X=1. The first equation, Y(0), is shorthand for Y(do[x=0])=0, which means that we expect the value of Y to equal “0” (i.e., we expect an unstubbed toe) when we do X=0 (i.e., when we open the curtains). Similarly, the second equation, Y(1), is shorthand for Y(do[x=1])=1, which means that we expect the value of Y to be “1” (i.e., we expect a stubbed toe) when we do X=1 (i.e., when we close the curtains). Technically, we expect the probability to be closer to zero or one when we do X=0 or X=1, respectively, but just bear with me here.\n\n\n\nWe can recast our thought experiment into the language of potential outcomes.\n\n\nAdditionally, as we have explained before, it is usually helpful to communicate our causal assumptions transparently using a causal diagram or a DAG. In the DAG below, we collapse our exposure conditions and potential outcomes into two variables connected by an arrow to represent our expectation of a causal relationship between curtains (open versus closed) and uttering a four-letter word (unstubbed versus stubbed toe).\n\n\nShow code\nlibrary(tidyverse)\nlibrary(here)\nlibrary(ggplot2)\nlibrary(dagitty)\nlibrary(ggdag)\nlibrary(ggraph)\nlibrary(gt)\n\n\n\n\nShow code\nouchDAG &lt;- dagify(\n  Ouch ~ Curtains,\n  exposure = \"Curtains\",\n  outcome = \"Ouch\",\n  coords=list(\n    x=c(Curtains=0, Ouch=2),\n    y=c(Curtains =1, Ouch=1)\n  )) %&gt;% tidy_dagitty() %&gt;% \n  dplyr::mutate(focal = ifelse(name != \"Curtains\", \"#56B4E9\", \"#CC79A7\"))\n\n\n#function to shorten arrows (edges)\n# https://stackoverflow.com/questions/65420136/how-do-you-adjust-the-arrows-in-a-ggplot-of-a-ggdag\nshorten_dag_arrows &lt;- function(tidy_dag, proportion){\n# Update underlying ggdag object\ntidy_dag$data &lt;- dplyr::mutate(tidy_dag$data, \n                             xend = (1-proportion/2)*(xend - x) + x, \n                             yend = (1-proportion/2)*(yend - y) + y,\n                             xstart = (1-proportion/2)*(x - xend) + xend,\n                             ystart = (1-proportion/2)*(y-yend) + yend)\nreturn(tidy_dag)\n}\n\nouchDAG1 &lt;- shorten_dag_arrows(ouchDAG, 0.08)\n\n\nouchDAG1 &lt;- ouchDAG1 %&gt;% ggplot(aes(x=x, y=y, xend=xend, yend=yend)) +\n  geom_dag_edges() +\n  geom_dag_text(aes(color = focal)) + \n  theme_dag() + \n  guides(fill = 'none', color = 'none') +\n  scale_color_manual(values = c(\"#56B4E9\",\"#CC79A7\")) +\n  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) +\n    #change default expansion on y-axis min & max\n  ggtitle(\"DAG1\") + \n  theme(plot.title = element_text(size = 12))\n\nouchDAG1\n\n\n\n\n\nFigure 1. Simple DAG representing causal effect of window curtains on stubbed toes (ouch!)"
  },
  {
    "objectID": "blog-posts/[7]/modmadness-pt2.html#sec-medandmod",
    "href": "blog-posts/[7]/modmadness-pt2.html#sec-medandmod",
    "title": "Moderator Madness, Part 2",
    "section": "Is your mechanism a mediator, a moderator, or both?",
    "text": "Is your mechanism a mediator, a moderator, or both?\nNow, let’s step back and revisit our causal assumptions. Do we really think the closed curtains directly caused us to stub our toes? When interrogating a causal claim, it is usually a good idea to ask “how” and “why” questions, as doing so might illuminate mechanisms that can help us better identify, predict, and explain causal relationships. For instance, why do we think the closed curtains caused us to stub our toe? How might the closed curtains have caused such an outcome to occur?\nIn this case, you probably do not think that the closed window curtains directly caused toe stubbing. Rather, you likely expect that closed curtains indirectly caused this painful outcome by blocking light from entering the room through the window. In contrast, had the window curtains been open, then there might have been more ambient light in the room and, with sufficient light, you might have been better able to see and to avoid colliding with hazardous objects.\nLet’s recast these more precise mechanistic beliefs as potential outcomes and communicate them graphically with a new DAG.\n\n\n\nSpecifying mechanisms can help us identify, predict, and explain causal relationships.\n\n\n\n\nShow code\nouchDAG2 &lt;- dagify(\n  Ouch ~ Light ,\n  Light ~ Curtains, \n  exposure = \"Curtains\",\n  outcome = \"Ouch\",\n  coords=list(\n    x=c(Curtains=0, Light=1, Ouch=2),\n    y=c(Curtains =1, Light=1, Ouch=1)\n  )) %&gt;% tidy_dagitty() %&gt;% \n  dplyr::mutate(focal = ifelse(name != \"Curtains\", \"#56B4E9\", \"#CC79A7\"))\n\n\nouchDAG2 &lt;- shorten_dag_arrows(ouchDAG2, 0.08)\n\n\nouchDAG2 &lt;- ouchDAG2 %&gt;% ggplot(aes(x=x, y=y, xend=xend, yend=yend)) +\n  geom_dag_edges() +\n  geom_dag_text(aes(color = focal)) + \n  theme_dag() + \n  guides(fill = 'none', color = 'none') +\n  scale_color_manual(values = c(\"#56B4E9\",\"#CC79A7\")) +\n  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) +\n    #change default expansion on y-axis min & max\n  ggtitle(\"DAG2\") + \n  theme(plot.title = element_text(size = 12))\n\nouchDAG2\n\n\n\n\n\nFigure 2. DAG of indirect causal effect of window curtains through light on stubbed toes\n\n\n\n\nAfter examining this DAG, many of you might immediately assume it that it displays a classic indirect causal effect or mediating relationship. However, it is worth taking a moment to ponder whether you think light really is a mediator, or instead whether it is a moderator, or perhaps both? For example, consider that opening the curtains might reduce the chances of stubbing your toes when it is light outside and, hence, when doing so lets sufficient light in the room for you to see obstacles in your path. In contrast, when it is not light outside, opening the curtains might not let sufficient light in and, in those situations, opening the curtains (i.e., doing X=0) might not reduce (i.e., cause) the probability of stubbing toes.\nPut differently, we might posit a heterogeneous causal effect of opening the curtains on the probability of toe stubbing, where the causal effect is strongest when accompanied by sufficient light but weakest or nonexistent when not accompanied by sufficient light.\nIf you are a social scientist, you might also be accustomed to seeing an intersecting arrow in a causal diagram to depict this type of conditional effect or moderating relationship, like below:\n\n\nShow code\nouchDAG2b &lt;- dagify(\n  Ouch ~ Curtains ,\n  holder ~ Light, \n  exposure = \"Curtains\",\n  outcome = \"Ouch\",\n  coords=list(\n    x=c(Curtains=0, Light=1, holder=1, Ouch=2),\n    y=c(Curtains =1, Light=0, holder=1, Ouch=1)\n  )) %&gt;% tidy_dagitty() %&gt;% \n  dplyr::mutate(focal = ifelse(name != \"Window\", \"#56B4E9\", \"#CC79A7\"))\n\n\nouchDAG2b &lt;- shorten_dag_arrows(ouchDAG2b, 0.08)\n\n\n#create factor variable to isolate edge of interest, permits specifying edge color\nouchDAG2b &lt;- ouchDAG2b %&gt;% dplyr::mutate(\n  myedge1 = if_else(ouchDAG2b$data$name == \"Light\" & ouchDAG2b$data$to == \"holder\",\n                    \"yes\", \"no\"), \n  modlinetype = ifelse(myedge1 == \"yes\", \"solid\", \"dashed\")\n  ) \n\n#plot dag\nfig3 &lt;- ouchDAG2b %&gt;% ggplot(aes(x=x, y=y, xend=xend, yend=yend)) +\n  geom_dag_edges(aes(x = xstart, y = ystart, edge_color=myedge1, \n                     edge_linetype = modlinetype), show.legend = FALSE) +\n  geom_dag_text(data = function(x) filter(x, name != \"holder\"), \n                color=\"#56B4E9\") +\n  theme_dag() + \n  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) + #change default expansion on y-axis min & max\n  scale_edge_colour_manual(values=c(\"darkgrey\", \"maroon\")) + #change second color to highlight focal myedge1 \n  # ggtitle(\"DAG w/mediation & interaction\") + \n  ggtitle(\"Classic Moderation Diagram\") + \n  theme(plot.title = element_text(size = 12))\n\nfig3 \n\n\n\n\n\nFigure 3. Causal graph of light moderating the effect of window curtains on stubbed toes\n\n\n\n\nSo, is light a mediator, or a moderator, or is it both? Well, it turns out that mediation and moderation are not always as distinguishable as one might think.\nIn fact, this potential overlap is communicated by a proper DAG of mediating and moderating relationships. As we noted in Part 1, a traditional DAG does not use intersecting arrows to depict moderation. Rather, arrows indicate information flow, while heterogeneous (moderation) effects are captured in the functional forms of the mathematical equations used to model causal relationships. Likewise, below is a DAG that illustrates the possibility of (heterogeneous) direct and indirect effects of closed curtains on stubbing toes.\n\n\nShow code\nouchDAG3 &lt;- dagify(\n  Ouch ~ Curtains + Light ,\n  Light ~ Curtains, \n  exposure = \"Curtains\",\n  outcome = \"Ouch\",\n  coords=list(\n    x=c(Curtains=0, Light=1, Ouch=2),\n    y=c(Curtains =0, Light=1, Ouch=0)\n  )) %&gt;% tidy_dagitty() %&gt;% \n  dplyr::mutate(focal = ifelse(name != \"Curtains\", \"#56B4E9\", \"#CC79A7\"))\n\n\nouchDAG3 &lt;- shorten_dag_arrows(ouchDAG3, 0.08)\n\n\nouchDAG3 &lt;- ouchDAG3 %&gt;% ggplot(aes(x=x, y=y, xend=xend, yend=yend)) +\n  geom_dag_edges() +\n  geom_dag_text(aes(color = focal)) + \n  theme_dag() + \n  guides(fill = 'none', color = 'none') +\n  scale_color_manual(values = c(\"#56B4E9\",\"#CC79A7\")) +\n  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) +\n    #change default expansion on y-axis min & max\n  ggtitle(\"DAG3\") + \n  theme(plot.title = element_text(size = 12))\n\nouchDAG3\n\n\n\n\n\nFigure 4. DAG of direct and indirect causal effects of window curtains through light on stubbed toes\n\n\n\n\nAn important takeaway message is that when we are examining causal systems that we think might involve a mediating mechanism, it is important to formally assess whether there is evidence of a non-negligible exposure-mediator interaction. An exposure-mediator interaction is a situation where the effect of the focal cause or exposure (opening or closing the curtains) on an outcome (toe stubbing) varies across the range of values of the posited mediating mechanism (ambient light levels in the room).\nOften, when testing mediation hypotheses, assessing this possibility will entail the inclusion of a multiplicative interaction term representing a potential exposure-mediator interaction (X*M) into your model, estimating marginal effects, and plotting model predictions on the outcome scale across levels of the exposure and mechanism.1 In the presence of an additive interaction, your modeling approach should account for the joint possibility of mediation and moderation. In this situation, the “causal mediation” or potential outcomes decomposition approach can help you disentangle indirect and interaction effects.2"
  },
  {
    "objectID": "blog-posts/[7]/modmadness-pt2.html#sec-fourwaydecomp",
    "href": "blog-posts/[7]/modmadness-pt2.html#sec-fourwaydecomp",
    "title": "Moderator Madness, Part 2",
    "section": "Four-way decomposition with toy example",
    "text": "Four-way decomposition with toy example\nThe first thing to note about causal mediation effect decomposition is that it generates population-average inferences about counterfactual conditions. Recall, we cannot observe counterfactual causality among individual units because we can only observe one of two (or more) possible conditions for any individual unit. In our example, either the curtains were closed or open, and either we did or did not stub our toe. If the curtains were closed and we stubbed our toe, then we cannot observe the counterfactual condition in which the curtains instead would have been open to see what might have happened to our toes. However, we can make causal inferences about potential outcomes across counterfactual conditions with sufficient data from populations, a careful research design, and a proper causal (theoretical) model. In our example, that would require many observations of mechanism states (ambient light levels in the room) and outcome occurrences (stubbed toes) in the room under both exposure and non-exposure conditions (when the curtains were open and when curtains were closed) along with some assumptions.\n\n\n\nGiven some key assumptions, we can estimate counterfactual causal effects as population-average differences in potential outcomes.\n\n\nIn Part 3 of this series, I will work through an example of effect decomposition in R using simulated crime-relevant data. First, though, I hope to build upon your intuitions about how this decomposition procedure works in this entry using some toy data based on our toe stubbing example. The goal of this example is to introduce you to key terminology and the conceptual basis for potential outcomes effect decomposition before getting into a more realistic applied example in which we will use software to perform the decomposition for us.\nNote that this first toy example is intended as a simple application of VanderWeele’s initial 4-way effect decomposition example in which exposure and mediator values are set at specific counterfactual values (setting M to 0 or 1). Later, I will briefly introduce more complex counterfactual logic (e.g., setting M at its expected value when X=0 or X=1), which will be required for estimating and interpreting “natural” direct and indirect effects found in CMAverse output in Part 3. For more and better resources on this topic, I recommend reading VanderWeele’s 2014 paper itself, as well as his tutorials and short video course on causal mediation, all of which are available on his website.\n\nShow code\nouchdat &lt;- tribble(\n~CurtainClosed, ~AmpleLight, ~StubToe,\n1,  0,  1,\n1,  0,  1,\n1,  0,  1,\n1,  0,  1,\n1,  0,  1,\n1,  0,  0,\n1,  0,  0,\n1,  0,  0,\n1,  0,  0,\n1,  0,  0,\n1,  1,  0,\n0,  1,  1,\n0,  1,  0,\n0,  1,  0,\n0,  1,  0,\n0,  1,  0,\n0,  1,  0,\n0,  1,  0,\n0,  1,  0,\n0,  0,  1,\n0,  0,  0,\n)\n\nhead(ouchdat,n=11) %&gt;% gt()\ntail(ouchdat,n=10) %&gt;% gt()\n\n\n\n\n\n\n\nX=1 {#tbl-anonymous-8237139-1}\n\n\nCurtainClosed\nAmpleLight\nStubToe\n\n\n\n\n1\n0\n1\n\n\n1\n0\n1\n\n\n1\n0\n1\n\n\n1\n0\n1\n\n\n1\n0\n1\n\n\n1\n0\n0\n\n\n1\n0\n0\n\n\n1\n0\n0\n\n\n1\n0\n0\n\n\n1\n0\n0\n\n\n1\n1\n0\n\n\n\n\n\n\n\n\n\nX=0 {#tbl-anonymous-8237139-2}\n\n\nCurtainClosed\nAmpleLight\nStubToe\n\n\n\n\n0\n1\n1\n\n\n0\n1\n0\n\n\n0\n1\n0\n\n\n0\n1\n0\n\n\n0\n1\n0\n\n\n0\n1\n0\n\n\n0\n1\n0\n\n\n0\n1\n0\n\n\n0\n0\n1\n\n\n0\n0\n0\n\n\n\n\n\n\n\n\nToy toe-stubbing data\n\n\n\nThese data represent n = 21 curtains, light, and toe stubbing observations. In approximately half of the cases, the curtains were closed (CurtainClosed = 1; n = 11); in the other cases, the curtains were open (CurtainClosed = 0; n = 10). The overall probability of stubbing toes, or P(Y), is 0.33 (StubToe = 1; n = 7/21). We will use these hypothetical “observed” probabilities to represent (counterfactual) expectations.\nY0 and Y1\nThe probability of stubbing toes varies across exposure conditions. The probability of stubbing toes given the curtains were open, denoted by P(Y|do[X=0]) or abbreviated to Y0, is 0.2. That is, we stubbed our toes in 2 out of 10 cases in which curtains were open. In contrast, we stubbed our toes in 5 out of 11 cases in which curtains were closed, which means that P(Y|do[X=1]), or Y1, is equal to 0.45.\n\n\n\nY0 and Y1\n\n\n\nTotal effect (TE)\nIn this example, we can calculate the total effect (TE) simply as the difference between the outcome probabilities across exposed and unexposed conditions. The estimated total effect of closing curtains on toe stubbing is Y1 - Y0, or 0.455 - 0.2, which equals 0.255. Put differently, opening curtains reduces the predicted probability of toe stubbing by about 26 percentage points (from ~45.5% to 20%).\n\n\n\nTotal effect (TE) = Y1 - Y0\n\n\nM0 and M1\nWhat about our mechanism? The probability of experiencing sufficient ambient light in the room to be able to see obstacles is P(M) = 0.43, since 9 out of 21 cases had a AmpleLight value = 1. Like stubbing our toes, the probability of experiencing sufficient light also varied across exposure conditions. The probability of sufficient light given the curtains were open, denoted by P(M|do[X=0]) or abbreviated to M0, is 0.80 (i.e., 8/10). In contrast, there was sufficient light in the room in only 1 out of 11 cases in which the curtains were closed, which means that P(M|do[X=1]) or M1 = 0.09.\n\n\n\nM0 and M1\n\n\nNow, let’s consider jointly how the probability of stubbing our toes changes given different combinations of exposure and mediator conditions, or given that we open or close curtains and simultaneously observe the presence or absence of sufficient ambient light in the room.\nY00\nLet’s start with the probability of stubbing toes given open curtains and the absence of sufficient light, which we will denote as P(Y|do[X=0],do[M=0]) and abbreviate to Y00. Given some assumptions, this quantity represents the expected probability of stubbing our toes if we do X=0 (i.e., if we open the curtains) and if we were able to set the mechanism to absent, or M=0. In other words, we are setting the room to insufficient light, or AmpleLight = 0, with the curtains open. There were 2 observed cases in which X=0 and M=0. Perhaps these cases represented especially dark nights during which the open window curtains were not effective in increasing the amount of ambient light in the room. In half of these cases (1/2), we stubbed our toes, meaning Y00 = 0.5.\n\n\n\nY00\n\n\nY10\nNow, imagine we do X=1 instead (i.e., we close the curtains) and we continue hold the mechanism constant at the value of “0”. That is, we set the room to insufficient light, or AmpleLight = 0, with the curtains closed. There are ten observed cases in which the curtains were closed and there was insufficient ambient light in the room. We stubbed our toes in five of these ten cases, meaning P(Y|do[X=1],do[M=0]) or Y10 = 0.5.\n\n\n\nY10\n\n\n\n\nControlled direct effect (CDE)\nWith the quantities above, we now have enough information to calculate the controlled direct effect, or CDE, of X on Y. Conceptually, the CDE of an exposure is the expected effect that an exposure would have on the outcome if the mechanism (M) were fixed at a specific value (m). Here is the potential outcomes equation for the CDE:\nCDE = Y1m - Y0m, where we set M to a specific value “m”\nCommonly, we might wish to estimate the controlled direct effect when the mediator is equal to zero. In this case, the CDE of an exposure is the expected effect that an exposure would have on the outcome if the mechanism were removed or fixed at M=0. Here, when we set M to m=0, the CDE is equivalent to the difference between Y10 and Y00, or the estimated effect on Y of doing X in the absence of the mechanism:\nCDE(M=0) = Y10 - Y00\n= 0.5 - 0.5\n= 0.0\nIn essence, this value of 0.0 indicates that doing X = 1 (i.e., closing the curtains) instead of doing X = 0 is expected to have no effect on the probability of toe stubbing once we remove from the equation the effect that opening curtains has on the mechanism (ie., letting sufficient ambient light into the room). Put differently, closing the window curtains is not expected to have a direct effect on stubbing toes above and beyond any indirect effects it has on the ambient light levels in the room.\nThink of it this way: You are in a dark room with curtains closed (do[X=1],do[M=0]) and, after opening the curtains, the room remained just as dark as it was before (do[X=0],do[M=0]). A CDE = 0 indicates that the probability of stubbing your toes would remain unchanged in that situation, where opening or closing the curtains does not add any ambient light into the dark room (Y10 - Y00 = 0). Either way, it is dark, and you are predicted to have a coinflip’s chance (Y10 = Y00 = .50) of stubbing your toes.\n\n\n\nControlled direct effect (CDE) = Y1m - Y0m\n\n\nY01\nIn addition to Y10 and Y00, there are additional quantities we can estimate that will help us further decompose the total effect into other meaningful components like the CDE. For instance, what if we were to open the curtains (do[X=0]) while also holding constant a sufficient amount of ambient light in the room (do[M=1])? In our toy data, there were eight observations in which the curtains were open and we experienced sufficient ambient light in the room that allowed us to see. We stubbed our toe in only one of these eight cases (1/8), so P(Y|do[X=0],do[M=1]) or Y01 = 0.125.\n\n\n\nY01\n\n\nY11\nNow, imagine instead we close the curtains (do[X=1]) and continue holding a sufficient amount of ambient light in the room constant (do[M=1]). There is only one observation in these toy data with X=1 and M=1. Perhaps a hall light was on, or perhaps we used our cell phone backlight to provide ambient light when the curtains were closed. In any case, we did not stub our toe in this one instance (0/1), so P(Y|do[X=1],do[M=1]) or Y11 = 0.0.\n\n\n\nY11\n\n\n\n\nTE = CDE + INTref + INTmed + PIE\nWith the various quantities calculated above (e.g., M0; M1; Y00; Y10; Y01; Y11), now we have enough information to decompose the total effect of X on Y into four different components. Specifically, the total effect, or TE, is a composite value representing the sum of the controlled direct effect (CDE); reference interaction (INTref); mediated interaction (INTmed); and the pure indirect effect (PIE). I already covered the CDE above. Below, I will describe the remaining three components: INTref, INTmed, and PIE.\n\n\nReference interaction (INTref)\nWhen we observe a nonzero total effect of an exposure on an outcome, a common thing to do is to test whether the exposure operates indirectly through a posited mediating mechanism(s). However, an observed total effect might wholly (or partly) reflect the operation of an additive interaction between the exposure and a mechanism rather than (or in addition to) a mediation process as is often assumed.\nYes, you read that right. An observed total effect of an exposure on an outcome might (only) reflect the presence of an interaction effect, and failure to account for this when testing indirect effect hypotheses using traditional mediation tests might result in erroneously attributing moderation to mediation, or vice versa. Moderator madness indeed! If you cannot recall learning about this in your graduate stats courses, then you are not alone.\nAt this point, you can probably guess that we account for this possibility by decomposing the total effect into its various possible constituent parts. As implied here, one of the components that may comprise a total effect is the reference interaction (INTref), which is an additive interaction that operates only if mediator is present in the absence of the exposure. As VanderWeele explains (p.750), the reference interaction component is nonzero when “the effect on the outcome of setting both the exposure and the mediator to present differs from the sum of the effect of having only the exposure present and the effect of having only the mediator present.”\nThough that might sound confusing, this is essentially a classic interaction effect. Do you find yourself preferring our probability notation yet? Either way, let’s use it to calculate INTref.\nThe INTref component is nonzero when [P(Y|do[X=1],do[M=1]) - P(Y|do[X=0],do[M=0])] is not equal to [(P(Y|do[X=1]) - P(Y|do[X=0])] + [(P(Y|do[M=1]) - P(Y|do[M=0])]. Let’s check this with our toy data, using our abbreviated notation for quantities that we have already calculated:\nY11 - Y00\n= 0.0 - 0.5\n= -0.5\n[Y1 - Y0] + [(P(Y|do[M=1]) - P(Y|do[M=0])]\n= [0.45 - 0.2] + [.11 - 0.5]\n= -0.25 + -0.39\n= -0.64\nSince -0.5 is not equal to -0.64, we would expect a nonzero INTref estimate.\nWe can use the quantities calculated earlier to estimate the reference interaction using the equations provided in VanderWeele’s Table 1 on p.751:\nINTref = (Y11 - Y10 - Y01 + Y00)(M0)\n= (0.0 - 0.5 - 0.125 + 0.5)(0.8)\n= (-.125)(0.8)\n= -0.1\nHere, our toy data show a small reference interaction. What does this mean and where did it come from? Well, first remember that a reference interaction is an additive interaction that operates only if mediator is present in the absence of the exposure. Likewise, we observed the mechanism (sufficient ambient light) when the curtains were open and when they were closed, so a nonzero reference interaction estimate is possible. The logic here, which mirrors that of a classic interaction, is that we must be able to assess the effect of doing X=1 (versus X=0) both in the absence and in the presence of the mechanism. Then, if the estimated effect of doing X=1 differs across those conditions (or across levels of the mechanism), we would have a nonzero exposure-mediator “reference interaction.”\n\n\n\nA reference interaction is not what it sounds like. Well, maybe it is, if it sounds like an additive interaction effect that operates only if mediator is present in the absence of the exposure. (DALL-E)\n\n\nNow, recall that we did not stub our toes in that one time we observed closed curtains and the mechanism present (Y11 = 0/1 = 0.0). However, we did stub our toe in one of the eight instances with open curtains and the mechanism present (Y01 = 1/8 = 0.125). Meanwhile, the probability of stubbing our toes was equal across exposure conditions in the absence of the mediator (Y10 = 5/10 = 0.5; Y00 = 1/2 = 0.5).\nFrom these comparisons, it appears that doing X=1 instead of X=0 (closing curtains) slightly reduced the probability of toe stubbing with the mechanism present (Y11 - Y01 = 0.0 - 0.125 = -.125), whereas doing X=1 instead of X=0 had no effect on the probability of toe stubbing with the mechanism absent (Y10 - Y00 = 0.5 - 0.5 = 0). In the equation above, we essentially used these same comparisons and then weighted the resulting difference-in-differences value by the expectation of observing the mediator in the absence of exposure (i.e., M0 = probability of observing M=1 given we do[X=0]).3\nStrong caveat: If these were real data, I would strongly recommend against making any inferences from this INTref estimate given it was generated using a very small sample (e.g., only n=1 observation for one of the cells). Unfortunately, such noisy and unreliable inferences are all too common in criminology. But, that is an entry for another day.\nOne final point about the INTref component: As VanderWeele explains (p.755), the INTref “requires the mediator to operate, but the effect does not come about by the exposure changing the mediator — it simply requires that the mediator is present even when the exposure is absent; the effect is ‘unmediated,’ in the sense that it does not operate by the exposure changing the mediator, but it requires the presence of the mediator nonetheless.” In contrast, the remaining two components (PIE and INTmed) both involve mediation such that doing X (i.e., the exposure) affects the outcome at least partly by changing the mediator. Now, let’s move to the next component.\n\n\nPure indirect effect (PIE)\nAs noted above, when we observe a total effect of an exposure on an outcome, that total effect might also reflect an indirect effect of the exposure operating through a specific mediating mechanism(s). In this four-way decomposition, the “pure indirect effect” (PIE) component is the analogue of this classic indirect effect. Formally, the PIE component represents the effect of the mediator in the absence of the exposure, and it is non-zero only if: (1) the exposure itself affects mediator and (2) the mediator affects the outcome when the exposure is absent.\nHere, closing curtains decreases light in the room, and light reduces the chances of stubbing toes when the curtains are open. Using the equations in VanderWeele’s Table 1, we can estimate the PIE component using the quantities calculated earlier by estimating the effect of doing M in the absence of X (Y01 - Y00) and then weighting this contrast by the effect of doing X on the mediator (M1-M0):\nPIE = (Y01 - Y00)(M1 - M0)\n= (0.125 - 0.5)(0.09 - 0.8)\n= (-0.375)(-0.71)\n= 0.266\nRecall, the total effect of closing the curtains on toe stubbing was 0.255. Closing curtains primarily increases our chances of stubbed toes indirectly by blocking light out of the room. In this case, the indirect effect estimate is quite close to the total effect estimate (0.266 versus 0.255). However, it does not always work out this way. In fact, as we will see, the only reason it worked out this way in our toy example is because the other two nonzero components, INTref and INTmed, were of approximately equal magnitude with opposite signs, so they cancel each other out when summing for the total effect.\nThis is an important point. If we had relied strictly on the total effect, or on traditional mediation test procedures, to make inferences about the exposure’s effect on the outcome via the primary mediating mechanism, then we would have been close to accurately estimating the indirect effect. However, we would have done so only by luck or accident, and we would have missed completely the other two nonzero interaction components.\n\n\n\nPure indirect effects: As American as apple PIE? (DALL-E)\n\n\nSpeaking of those other two interaction components, we already discussed INTref; now, let’s move on to INTmed, our fourth component.\n\n\nMediated interaction (INTmed)\nSo far, we have discussed controlled direct effects, reference interaction effects, and pure indirect effects. Each of these is analogous (in certain situations) to well-known direct effects, interaction effects (moderation), and indirect effects (mediation), though their empirical connections as distinct components of a total effect may be less widely appreciated or understood.\nThis is good time to introduce the most important use cases for decomposition: When there is no exposure-mediator interaction (and strong causal assumptions hold), then traditional approaches to detecting interaction effects or testing indirect effects are often reliable and decomposition procedures may be unnecessary. However, when there is a nonzero exposure-mediator interaction, then traditional approaches become problematic, decomposition is essential, and the constituent components comprising a total effect become more complex - and potentially more numerous. For instance, in such situations, we may find a fourth nonzero component also contributes to the total effect - the “mediated interaction” or INTmed.\nThe “mediated interaction” or INTmed component represents an additive interaction that operates only if the exposure has an effect on the mechanism. As VanderWeele explains (p.750), when the INTmed component is nonzero, this means that “the exposure causes the mediator, and the presence of the mediator is itself necessary for the exposure to have an effect on the outcome.”\nIn our toy example, the probability of stubbing our toes varies across values of X (i.e., whether curtains are open or closed); that is, P(Y|do[X=x],do[M=1]) varies across do[X=0] and do[X=1]. Given the presence of the mechanism (sufficient ambient light), the probability of stubbing toes is higher when the exposure is “absent” (X=0, or curtains open) than it is when the exposure is present (X=1, or curtains closed). We can check this with our data:\nCurtains open: P(Y|do[X=0],do[M=1]) = Y01 = 1/8 = 0.125\nCurtains closed: P(Y|do[X=1],do[M=1]) = Y11 = 0/1 = 0.0\nWe can also use the quantities estimated earlier to calculate the INTmed component. Like the INTref component, we are essentially generating a weighted difference-in-difference contrast. Like the PIE component, we are weighting that contrast by the effect of doing X on the mediator (M1 - M0):\nINTmed = (Y11 - Y10 - Y01 + Y00)(M1 - M0)\n= (0.0 - 0.5 - 0.125 + 0.5)(0.09 - 0.8)\n= (-0.125)(-0.71)\n= 0.089\nRecall, when the mechanism was present in this toy example (i.e., AmpleLight=1), toe stubbing was less likely when the curtains were closed (Y11 = 0.0) than when they were open (Y01 = 0.125). In other words, closing the curtains (do[X=1]) reduced the probability of toe stubbing in the presence of the mechanism. However, this effect was only observed in the presence of the mechanism; when AmpleLight=0, the probability of toe stubbing was the same whether the curtains were open (Y00 = 0.5) or closed (Y10 = 0.5). Moreover, closing the curtain reduced the probability of observing the mechanism (M1 - M0 = 0.09 - 0.80 = -0.71). So, the exposure causes this conditional effect, meaning it is a mediated interaction (INTmed).\n\n\n\nA mediated interaction is not what it sounds like either. Unless it sounds like an additive interaction that operates only if the exposure has an effect on the mechanism. (DALL-E)\n\n\nPut differently, since opening the curtains increases light in the room, and opening the curtains appears to increase toe stubbing when light is present, then the exposure actually increases risks of toe stubbing by increasing the conditions (light) under which it amplifies the risks of the outcome occurring. Again, this is a mediated interaction.\nAnother caveat: I strongly caution against such real world inferences when data are so sparse; like our INTref, this mediated interaction is based on a comparison generated from n=1 observation in one of the cells! If we had more (and real) data, I highly doubt we would observe a negative effect of closing curtains on toe stubbing in the presence of the mechanism. Still, despite the implausibility of this toy example, I hope it helps you better understand the components that comprise a total effect.\n\n\nRevisiting TE\nBefore moving on to a simulated example, I want to revisit the total effect (TE) that we just decomposed into four component parts. Recall earlier how we calculated the total effect of X on Y as the difference between the outcome probabilities across exposed and unexposed conditions (Y1 - Y0)?\nTE = Y1 - Y0\n= 0.455 - .20\n= 0.255\nWell, after decomposing these four constituent components of the total effect, we can also calculate the total effect by summing these four components. This is a good way to check that our calculations were correct!\nTE = CDE + INTref + INTmed + PIE\n= 0 + (-0.1) + 0.089 + 0.266\n= 0.255\nIt worked! Whew.\n\n\n\nYou were worried. I wasn’t worried."
  },
  {
    "objectID": "blog-posts/[7]/modmadness-pt2.html#sec-intermission2",
    "href": "blog-posts/[7]/modmadness-pt2.html#sec-intermission2",
    "title": "Moderator Madness, Part 2",
    "section": "Second intermission",
    "text": "Second intermission\nAt this point, I am hoping the toy example above helped build your intuitions about the 4-way total effect decomposition and that you feel ready to move on to a somewhat more realistic use case with simulated data.\nIn the next post (Part 3), I will illustrate how to use the CMAverse package in R to conduct causal mediation analysis, which relies on potential outcomes decomposition to disentangle indirect and interaction effects in the presence of a potential exposure-mediator interaction. Part 3 will also introduce the important assumptions required to interpret results as estimates of causal effects."
  },
  {
    "objectID": "blog-posts/[7]/modmadness-pt2.html#footnotes",
    "href": "blog-posts/[7]/modmadness-pt2.html#footnotes",
    "title": "Moderator Madness, Part 2",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn a linear model, if the multiplicative interaction coefficient departs from zero, then you should typically acccount for the possibility of an exposure-mediator interaction. However, do NOT rely on statistical significance of the interaction coefficient to make this determination as those tests are notoriously underpowered. Things get more complicated with nonlinear models, as a substantial additive exposure-mediator interaction on the outcome scale might exist even if the interaction coefficient is near-zero in magnitude on the estimation scale. Recall, this is because nonlinear models are fundamentally interactive: A linear effect of the exposure on the model estimation scale quite often implies a heterogeneous effect of the exposure on the outcome scale across covariate (e.g., mechanism) levels irrespective of the magnitude or significance of the interaction term on the linear estimation scale. I discussed this issue in Part 1 of this series, and I will provide another example of a substantial exposure-mediator interaction accompanied by a near-zero interaction coefficient in Part 3, the next post in the series.↩︎\nAt this point, you might be wondering: “Do I really need to do this? The [insert] theory I am testing does not predict such an interaction!” Well, failure to examine and adjust for the possibility of an exposure-mediator interaction is equivalent to forcing your model of the data generating process to conform to a strong and potentially incorrect theoretical assumption about underlying data generating processes. In SEM parlance, it is equivalent to “fixing” the effect of X on Y through M to be the same at all values of M. In situations where the effect of X on Y indeed varies across strata of M, failure to account for it could result in biased or incomplete inferences. In contrast, allowing for and decomposing a potential exposure-mediator interaction is, in SEM terms, akin to “freeing” that parameter, thus permitting a test of that strong theoretical assumption. In situations where no such interaction exists, the magnitude of the interaction will approach zero, and traditional and “causal” mediation approaches (e.g., “controlled” and “natural” effect estimates) will converge to the same values. In those situations, decomposition would be unnecessary yet nonetheless informative. In short, there is substantial upside and little downside apart from learning the skills to testing and accounting for exposure-mediator interactions whether or not one exists, yet there are potentially substantial inferential risks to not doing so when one exists. So, just how a priori confident are you in that likely imprecise and discursive theory of yours?↩︎\nAre you wondering what the (Y11 - Y10 - Y01 + Y00) term represents? Well, you can think of it as contrasting the effect of X (i.e., doing X=1 - doing X=0) in the mechanism’s presence (M=1) versus its absence (M=0). Alternatively, you can also think of it as contrasting the effect of M (i.e,. doing M=1 - doing M=0) in the exposure’s presence (X=1) versus its absence (X=0). Let’s use the latter to show our work:\n(Effect of M | X=1) - (Effect of M | X=0)\n= (Y11 - Y10) - (Y01 - Y00)\nFrom here, we just do a bit of basic algebra:\n= Y11 - Y10 + (-1)(Y01 - Y00)\n= Y11 - Y10 - Y01 + Y00↩︎"
  },
  {
    "objectID": "blog-posts/[5]/colliders.html",
    "href": "blog-posts/[5]/colliders.html",
    "title": "Are you afraid of colliders?",
    "section": "",
    "text": "Collider: The rancor in your regression"
  },
  {
    "objectID": "blog-posts/[5]/colliders.html#sec-afraid",
    "href": "blog-posts/[5]/colliders.html#sec-afraid",
    "title": "Are you afraid of colliders?",
    "section": "Are you afraid of colliders? You will be… You will be.",
    "text": "Are you afraid of colliders? You will be… You will be.\nIn our previous post on causation without correlation, we concluded with a brief caution about how an otherwise fun fishing trip for indirect effects might be spoiled by the collider monster in your modeling closet. We referenced Julia Rohrer’s blog entry on hunting for indirect effects, then noted the following:\n\nHer example beautifully, or frighteningly, illustrates how a collider can produce an erroneous inference about an indirect effect. You might be wondering to yourself: what the heck is a collider? Great question. To us, it is the scary monster in our statistical modeling closet that keeps us up at night; neither of us have ever really seen the monster, but we’ve read enough stories about it to be convinced that it is there. We’ll try tackling that one another time…\n\nIf you’d prefer a crime-relevant analogy, colliders also have been referred to as the mass murderer of interpretable statistical analyses. Rohrer has another excellent post introducing these modeling monsters. However, the first time we can remember encountering a systematic discussion of colliders and the problems they pose for our statistical models was in our initial reading of Richard McElreath’s Statistical Rethinking book. In keeping with the theme here, McElreath discusses colliders in chapter six of the current edition, which he titled The Haunted DAG and the Causal Terror.\nWe think such fear-inspired collider analogies are apt as, once you understand them, it is hard not to fear, loathe, and respect them. In fact, after our initial reading of McElreath’s book (and watching his lectures), we came away pretty terrified that all our prior analyses were potentially misspecified. Yet, after that first encounter, we had not gotten a full glimpse of the villain - we lacked a full understanding and appreciation of how much they may be affecting the criminological literature (and our own previous work). Now that we have seen them, we think a collider is like a rancor - the terrifying and destructive monster from the Star Wars universe - that has been set loose to wreak havoc on your regression model.\n\nWho should care about colliders?\nBefore going any deeper, we should note that colliders and collider bias are relevant to anyone using any type of regression model to estimate the causal effect of a variable on an outcome - or to determine whether one variable has an “influence” on another variable - irrespective of the functional form (e.g., linear; logistic; negative binomial), complexity, estimation method (e.g., OLS; ML; Bayes), or statistical program you use. Also, if you ever add covariates to your regression models to “adjust” for coefficient bias or “control” for alternative explanations - that is, if you use “control variables” in your regression models - then you really need to know about colliders and collider bias.\nAlso, if you are relatively new to the topic of colliders, then we wrote this blog for you. That does not mean we think you will understand colliders by the end of our post. We have been reading and thinking about colliders for years now, and we still find ourselves trying to get a firm grip on them. Our hope is to introduce you to colliders and to help you develop a healthy fear of them. We also hope to convince you of the importance of reading more about colliders and related topics like DAGs, adjustment sets, and the backdoor criterion; we link to many excellent and free resources on these topics throughout this post. So, by the end of our post, if you feel fearful and confused, then rest assured you are not alone! You are taking the first of many steps on a challenging but worthwhile journey with us. Now, grab some popcorn and turn on the lights for our version of a sci-fi stats thriller mashup.\n\n\nSelection effects, causal force, and DAG-sabers\nPerhaps without knowing it, you’ve likely encountered discussions of collider bias before in the form of selection bias. It’s probably safe to say that most social scientists get exposed to the problems with selection effects at some point in their graduate training. Indeed, it’s been at the center of high profile debates within criminology (e.g., peer influence; turning points; sentencing; specialty courts; and police use of force). On some level, we often treat selection effects as a known limitation and perhaps even a minor nuisance. However, once you comprehend that selection effects often are caused by restricting on levels of a collider or a causal descendant of a collider (and other times by selecting on an effect moderator) then, like us, you too might begin to develop a healthy fear of colliders. You might also find yourself on a quest to master the transparent use of structural causal models or directed acyclic graphs (DAGs).\nCausal assumptions are the force from which our modeling power flows and that binds our scientific claims together. The transparent causal model or DAG is a powerful ally in the force that can shed light on hidden causal assumptions. They help us make essential design, modeling, and interpretive decisions with reason rather than intuition or emotion. If we (okay, this part is all Jon - IYKYK) have not yet stretched this extended Star Wars metaphor past its breaking point already, then let’s do it now. Fear (of colliders) is the path to the dark side. Confronting fear is the destiny of a Jedi (scientist). Your destiny. Below, we will face our fear of colliders and learn to overcome it with DAGs, the elegant weapon of a Jedi scientist.\n\n\n\nLearn to fear colliders, then learn how to confront them with DAGs."
  },
  {
    "objectID": "blog-posts/[5]/colliders.html#sec-colliders",
    "href": "blog-posts/[5]/colliders.html#sec-colliders",
    "title": "Are you afraid of colliders?",
    "section": "What is a collider?",
    "text": "What is a collider?\nOk, so what exactly is a collider? To answer that, we should first specify a causal estimand of interest - say, the causal effect or “average marginal effect” of X on outcome Y. Once we’ve determined what exactly we are trying to estimate using data, then we might start thinking about other things - like colloquially named “third variables” - that might be related to or potentially bias our estimate of the quantity of interest.\nIn our experience, most criminologists understand confounding bias and immediately think of confounders when asked about “third variables” that might affect causal effect estimation. Most also seem to have reasonable intuitions regarding what to do about confounders (e.g., adjust or “control” for them to block their “backdoor” causal paths). Additionally, many criminologists are familiar with mediation - a type of “third variable” related to causal estimation that we discussed in our last post on causation without correlation. In that post, we demonstrated how adjusting for a mediator M removes part of the total causal effect of X on Y - specifically, it isolates the indirect effect of X through M - from our causal estimate.\nLike confounders and mediators of the X/Y relationship, colliders have been described as another type of “third variable” that is relevant to causal effect estimation. However, unlike confounders and mediators, we get the sense that many in our field do not understand and perhaps have never even heard of colliders. So, what are they?\nWell, most of the sources that we have read explicitly or implicitly define colliders as a type of third variable is caused by both X and Y. The causal diagram depicted in the figure below represents the quintessential collider example.\n\n\nShow code\nlibrary(tidyverse)\nlibrary(here)\nlibrary(simstudy)\n  # https://cran.r-project.org/web/packages/simstudy/vignettes/simstudy.html\n  # https://kgoldfeld.github.io/simstudy/articles/simstudy.html\nlibrary(ggplot2)\nlibrary(patchwork)\n# library(psych) #detach to ensure alpha works with ggplot\n  # library(devtools)\n  # install_github(\"jtextor/dagitty/r\")\nlibrary(dagitty)\nlibrary(ggdag)\nlibrary(truncnorm)\nlibrary(see)\n  # devtools::install_github(\"strengejacke/strengejacke\")\nlibrary(\"sjPlot\")\nlibrary(\"ggthemes\")\nlibrary(\"margins\")\nlibrary(\"ggdist\")\nlibrary(gt)\nlibrary(gtsummary)\n\nhauntedDAG1 &lt;- dagify(\n  Z ~ X + Y,\n  exposure = \"X\",\n  outcome = \"Y\",\n  coords=list(\n    x=c(X=1, Z=1.5, Y=2),\n    y=c(X=0, Z=.5, Y=0)\n  )) %&gt;% tidy_dagitty() %&gt;% \n  dplyr::mutate(collider = ifelse(name != \"Z\", \"#56B4E9\", \"#CC79A7\"))\n\nhauntedDAG1p &lt;- hauntedDAG1 %&gt;% ggplot(aes(x=x, y=y, xend=xend, yend=yend)) +\n  geom_dag_point(aes(color = collider)) +\n  geom_dag_edges() +\n  geom_dag_text() +\n  theme_dag() + \n  guides(fill = 'none', color = 'none') +\n  scale_color_manual(values = c(\"#56B4E9\",\"#CC79A7\")) +\n  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) +\n    #change default expansion on y-axis min & max\n  ggtitle(\"Example 1\") + \n  theme(plot.title = element_text(size = 12))\n\nhauntedDAG1p \n\n\n\n\n\nFigure 1. DAG of classic three-variable example of a collider (Z)\n\n\n\n\n\nColliders are like trick shots\nWhile this common definition usefully describes some colliders, we do not think it sufficiently captures all types of colliders. Assuming you have specified an estimand and then summarized relevant causal relationships in a DAG of the theorized data generating process connecting X and Y, then a more general definition of a collider might be any node in the DAG that you can trace along a path between X and Y, irrespective of directionality, where two or more arrows meet head-to-head. Judea Pearl similarly describes colliders as follows:\n\n“By a”path” we mean any consecutive sequence of edges, disregarding their directionalities. By “unblocked path” we mean a path that can be traced without traversing a pair of arrows that collide “head-to-head”. In other words, arrows that meet head-to-head do not constitute a connection for the purpose of passing information, such a meeting will be called a “collider”.”\n\n\n\n\nColliders are like trick shots where arrows meet head to head (in a DAG)\n\n\nWe have provided some example DAGs below in which the variable Z is a collider in a path between X and Y. As you will see, the collider Z is not always caused (directly or as a descendent) by the outcome Y.1 Likewise, in this blog post, we have attempted to deviate from the typical three-variable models (e.g., DAG Example 1, where X and Y cause collider Z) that we often encounter in collider explanations. Instead, we aimed to specify colliders and illustrate potential collider biases that might routinely occur from conditioning on a collider that is not necessarily an effect or a descendant of the outcome variable (Y).\n\n\nShow code\nhauntedDAG2 &lt;- dagify(\n  Y ~ X,\n  A ~ X, \n  B ~ Y,\n  Z ~ A + B,\n  exposure = \"X\",\n  outcome = \"Y\",\n  coords=list(\n    x=c(X=1, A=1.5, Z=2, B=2.5, Y=3),\n    y=c(X=-.5, A=0, Z=.5, B=0, Y=-.5)\n  )) %&gt;% tidy_dagitty() %&gt;% \n  dplyr::mutate(collider = ifelse(name != \"Z\", \"#56B4E9\", \"#CC79A7\"))\n\nhauntedDAG2p &lt;- hauntedDAG2 %&gt;% ggplot(aes(x=x, y=y, xend=xend, yend=yend)) +\n  geom_dag_point(aes(color = collider)) +\n  geom_dag_edges() +\n  geom_dag_text() +\n  theme_dag() + \n  guides(fill = 'none', color = 'none') +\n  scale_color_manual(values = c(\"#56B4E9\",\"#CC79A7\"))+\n  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) +\n    #change default expansion on y-axis min & max\n  ggtitle(\"Example 2\") + \n  theme(plot.title = element_text(size = 12))\n\n\nhauntedDAG3 &lt;- dagify(\n  Y ~ X + M + C,\n  Z ~ X + M, \n  M ~ X + C,\n  exposure = \"X\",\n  outcome = \"Y\",\n  coords=list(\n    x=c(X=1, M=1.5, Y=2, Z=1, C=2),\n    y=c(X=0, M=.5, Y=0, Z=1, C=1)\n  )) %&gt;% tidy_dagitty() %&gt;% \n  dplyr::mutate(collider = ifelse(name != \"Z\", \"#56B4E9\", \"#CC79A7\"))\n\nhauntedDAG3p &lt;- hauntedDAG3 %&gt;% ggplot(aes(x=x, y=y, xend=xend, yend=yend)) +\n  geom_dag_point(aes(color = collider)) +\n  geom_dag_edges() +\n  geom_dag_text() +\n  theme_dag() + \n  guides(fill = 'none', color = 'none') +\n  scale_color_manual(values = c(\"#56B4E9\",\"#CC79A7\")) +\n  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) +\n    #change default expansion on y-axis min & max\n  ggtitle(\"Example 3\") + \n  theme(plot.title = element_text(size = 12))\n\n\nhauntedDAG4 &lt;- dagify(\n  Z ~ X + C,\n  Y ~ X + C, \n  X ~ C,\n  exposure = \"X\",\n  outcome = \"Y\",\n  coords=list(\n    x=c(Z=.5, X=1, C=1.5, Y=2),\n    y=c(Z=.5, X=0, C=.5, Y=0)\n  )) %&gt;% tidy_dagitty() %&gt;% \n  dplyr::mutate(collider = ifelse(name != \"Z\", \"#56B4E9\", \"#CC79A7\"))\n\nhauntedDAG4p &lt;- hauntedDAG4 %&gt;% ggplot(aes(x=x, y=y, xend=xend, yend=yend)) +\n  geom_dag_point(aes(color = collider)) +\n  geom_dag_edges() +\n  geom_dag_text() +\n  theme_dag() + \n  guides(fill = 'none', color = 'none') +\n  scale_color_manual(values = c(\"#56B4E9\",\"#CC79A7\")) +\n  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) +\n    #change default expansion on y-axis min & max\n  ggtitle(\"Example 4\") + \n  theme(plot.title = element_text(size = 12))\n\n(hauntedDAG1p + hauntedDAG2p) / (hauntedDAG3p + hauntedDAG4p)\n\n\n\n\n\nFigure 2. Examples of colliders (Z) in four different DAGs"
  },
  {
    "objectID": "blog-posts/[5]/colliders.html#sec-whycare",
    "href": "blog-posts/[5]/colliders.html#sec-whycare",
    "title": "Are you afraid of colliders?",
    "section": "Why should we care about colliders?",
    "text": "Why should we care about colliders?\nSo, how do colliders affect attempts to estimate the causal effect of X on Y? Well, when a causal system includes a collider in a path between X and Y, then X and Y are connected in such a way that, similar to mediators and confounders, we can expect the “passing” of empirical information (statistical dependence) between variables under certain conditions. Yet, paths between X and Y that contain confounders and mediators begin as unblocked and, therefore, causal estimates of the effect of X on Y will contain information from these types of third variables unless we stratify or condition on them to block their empirical information from passing between X and Y. In symmetric contrast, a path containing a collider begins as blocked, meaning that causal estimates of the effect of X on Y do not initially contain information about colliders. However, stratifying or conditioning on a collider unblocks this path, allowing information to flow through the collider and, therefore, biasing estimates of the causal effect of X on Ys. Likewise, in reference to colliders, Pearl states:\n\n“When we measure a common effect of two independent causes, the causes becomes dependent, because finding the truth of one makes the other less likely (or”explained away”), and refuting one implies the truth of the other.”\n\nDAGs are extremely useful, then, in helping us identify all paths through which information might flow between X and Y and, likewise, in figuring out which variables we should be including in our models to adjust for confounding bias and which variables we should not include in our models to avoid removing indirect causal effects and/or introducing collider bias.\nFor instance, using the fourth example above, we can identify all paths between X and Y and identify appropriate adjustment sets automatically using ggdag::ggdag_paths() and ggdag::ggdag_adjustment_set(). You will note below that the path from X -&gt; Y and X &lt;- C -&gt; Y are open or unblocked paths, but the path from X -&gt; Z &lt;- C -&gt; Y is not an open path - unless we open it by conditioning on Z and, in turn, bias our estimate of the effect of X on Y. Likewise, the appropriate adjustment set for Example 4 contains only C, meaning we should control for C but not Z (or C and Z).\n\n\nShow code\nEx4paths &lt;- ggdag_paths(hauntedDAG4) +\n  theme_dag() + \n  ggtitle(\"Example 4 unblocked paths\") + \n  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) +\n  theme(plot.title = element_text(size = 12))\n\nEx4adj &lt;- ggdag_adjustment_set(hauntedDAG4, shadow = TRUE) +\n  theme_dag() +\n  ggtitle(\"Example 4 adjustment set\") + \n  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) +\n  theme(plot.title = element_text(size = 12))\n\nEx4paths / Ex4adj\n\n\n\n\n\nFigure 3. Unblocked paths (top) & adjustment set (bottom) from Example 4 DAG above\n\n\n\n\nHopefully, it is clear by now that conditioning on a collider (and other issues) can inadvertently occur when we do not have clear causal reasons for selecting control variables in our models. Yet, depending upon the research question & estimand of interest, conditioning on a collider can also happen when we analyze data collected via research designs involving known selection on variables related to causal processes of interest. This might pose particular challenges for criminologists investigating certain types of questions with popular data sources comprising samples of responses from youth with known criminal histories (e.g. Pathways to Desistance), or incarcerated samples, or even college student samples.\nWe will present examples of biases caused by conditioning on a collider with both methods (over-control & selection) using simulated and real-world data. The first two examples will use simulated data that were generated in a way that resembles some key features of real-world criminological data. The third example will rely on comparisons of real-world data collected from a college student sample and from a similarly-aged online sample."
  },
  {
    "objectID": "blog-posts/[5]/colliders.html#sec-SATdag",
    "href": "blog-posts/[5]/colliders.html#sec-SATdag",
    "title": "Are you afraid of colliders?",
    "section": "Causal model (DAG) for simulated data",
    "text": "Causal model (DAG) for simulated data\nMany existing examples of collider bias are in different fields & use toy examples with only a few variables and, at least for us, do not always clearly represent the types of problems we face in criminology. Thus, if you’re like us, upon learning about collider bias, you may develop a fear of the problem, but you have difficulty imagining how such issues might affect analyses in criminology. So, a key goal in the examples below is realism. We want to present a scenario that many of us have or will encounter in the criminological wild.\nIn our first example, we will explore how colliders might bias estimation of the causal effects of high self-control and weak moral beliefs on delinquency.\nThe core causal structure underlying this part of the DAG we use to simulate data is inspired by theory and research on Situational Action Theory (SAT). Specifically, we will focus on modeling the theory’s posited interaction between moral beliefs and self-control in predicting delinquent or criminal behavior.\n\n\n\nFigure 4: Stick figures depicting SAT’s perception-choice process\n\n\nSAT’s basic claim is that most people refrain from crime for moral, not rational, reasons: Those who strongly believe that a criminal behavior is morally wrong generally will not perceive that crime as morally viable situational action alternative and, likewise, will not engage in that behavior - irrespective of their levels of self-control (i.e., executive functioning capacities). However, those with weaker moral beliefs might perceive a criminal behavior as a situational action alternative and, in such situations, their levels of self-control may become causally relevant to decision-making. As Wikstrom & Treiber explain:\n\n“…the primary reason for individuals’ law abidance is strong moral beliefs (and moral habits) that correspond to the moral rules of the law, rather than their ability to exercise self-control…” (p.250)\n\n\n“…this implies that morality is the fundamental individual characteristic in the explanation of crime and that an individual’s ability to exercise self-control plays a far more limited role…” (p.251, emphasis in original)\n\nWhile SAT actually implies a complex causal structure involving a three-way (or more) interaction between moral beliefs, moral context, and self-control, we will specify a simpler DAG for the purposes of illustrating collider biases. Instead, we will aim to specify a causal structure and simulate data that builds upon the logic of many tests of SAT, which often regress delinquency or crime on self-control, moral beliefs, and their multiplicative interaction, as well as include gender and “controls” for other (presumably independent) variables.\nSpecifically, we will aim to generate data that resembles the interactive relationships found in such tests, like those Svensson and colleagues documented across three international samples:\n\n\n\nFigure 5: Self-control and morality interact to predict delinquency\n\n\nYet, as we think is true in tests of most criminological theories, empirical tests of SAT often explicitly consider only a limited set of causal relationships within a data source generated by a much larger connection of complex interlinked causal processes. So, we will add a bit of plausible complexity to the DAG to illustrate how colliders might bias estimation of theorized causal effects.\n\nDAG of causal structure underlying simulated data\nBelow is our DAG of a simple causal structure describing a plausible (if simplified) data generating process used to simulate data for our first two examples. We highlighted the focal estimand of interest (effect of self-control on delinquency) for our first simulation example with a red arrow.\n\n\nShow code\ncollideDAG &lt;- dagitty('dag{\n  Male -&gt; {SelfControl MoralBeliefs Delinquency PriorFelony}\n  SelfControl -&gt; {Delinquency PriorFelony QualityEmploy College}\n  MoralBeliefs -&gt; {Delinquency PriorFelony QualityEmploy College}\n  PriorFelony -&gt; QualityEmploy\n  SES -&gt; {QualityEmploy College}\n  College -&gt; QualityEmploy\n   }')\ncoordinates( collideDAG ) &lt;-\n    list( x=c(PriorFelony=1, QualityEmploy=1, SelfControl=2, Male=2, MoralBeliefs=2, SES=2, Delinquency=3, College=3),\n        y=c(PriorFelony=0, SelfControl=1, QualityEmploy=2,Male=0, MoralBeliefs=-1, SES=2, Delinquency=0, College=1) )\n\n# plot(collideDAG)\n\n\n#function to shorten arrows (edges)\n# https://stackoverflow.com/questions/65420136/how-do-you-adjust-the-arrows-in-a-ggplot-of-a-ggdag\nshorten_dag_arrows &lt;- function(tidy_dag, proportion){\n# Update underlying ggdag object\ntidy_dag$data &lt;- dplyr::mutate(tidy_dag$data, \n                             xend = (1-proportion/2)*(xend - x) + x, \n                             yend = (1-proportion/2)*(yend - y) + y,\n                             xstart = (1-proportion/2)*(x - xend) + xend,\n                             ystart = (1-proportion/2)*(y-yend) + yend)\nreturn(tidy_dag)\n}\n\n\ncollideDAGalt &lt;- dagify(\n  Delinquency ~ MoralBeliefs + Male + SelfControl,\n  PriorFelony ~ MoralBeliefs + Male + SelfControl, \n  MoralBeliefs ~ Male, \n  SelfControl ~ Male,\n  College ~ MoralBeliefs + SelfControl + SES, \n  QualityEmploy ~ MoralBeliefs + SelfControl + College + SES + PriorFelony, \n  # labels = c(\"Delinquency\" = \"Delinquency\",\n  #                 \"MoralBeliefs\" = \"Moral\\nBeliefs\",\n  #                 \"Male\" = \"Male\",\n  #                 \"SelfControl\" = \"Self-\\nControl\",\n  #                 \"PriorFelony\" = \"Prior\\nFelony\",\n  #                 \"College\" = \"Attend\\nCollege\",\n  #                 \"SES\" = \"SES\",\n  #                 \"QualityEmploy\" = \"Quality\\nEmploy\"),\n  exposure = \"SelfControl\",\n  outcome = \"Delinquency\",\n  coords=list(\n    x=c(PriorFelony=1, QualityEmploy=1, SelfControl=2, Male=2, \n        MoralBeliefs=2, SES=2, Delinquency=3, College=3),\n    y=c(PriorFelony=0, SelfControl=-1, QualityEmploy=-2, Male=0, \n        MoralBeliefs=1, SES=-2, Delinquency=0, College=-1)\n  )) %&gt;% tidy_dagitty() %&gt;% \n  dplyr::mutate(collider = ifelse(name %in% c(\"PriorFelony\", \"QualityEmploy\", \"College\"), \"#CC79A7\", \"#56B4E9\"))\n\n\n#function to shorten arrows - set percentage to shorten\ncollideDAGaltp &lt;- shorten_dag_arrows(collideDAGalt, 0.08)\n\n# ggdag(collideDAGaltp, \n#              use_labels = \"label\", text = FALSE)\n\n\n#if using label in geom_dag_text, arrange data by name then match labels to order of names in data!\n#print(collideDAGalt$data$name)\n\n#create factor variable to isolate edge of interest, permits specifying edge color\ntestdat &lt;- collideDAGaltp %&gt;% dplyr::mutate(\n  myedge1 = if_else(collideDAGaltp$data$name == \"SelfControl\" & collideDAGaltp$data$to == \"Delinquency\",\n                    \"yes\", \"no\")\n  ) \n\n#try filtering plot data for only edge of interest & adding colored layer?\nlibrary(ggraph)\ncollideDAGaltp2 &lt;- testdat %&gt;% ggplot(aes(x=x, y=y, xend=xend, yend=yend)) +\n  #geom_dag_point(aes(color = collider)) +\n  # geom_dag_edges(data = function(x) filter(x, name == \"SelfControl\" & to == \"Delinquency\"), \n  #                aes(x = xstart, y = ystart), color=\"maroon\") +\n  geom_dag_edges(aes(x = xstart, y = ystart, edge_color=myedge1)) +\n  geom_dag_text(label=c(\"Attend\\nCollege\", \"   Delinquency\", \"Male\", \"Moral\\nBeliefs\",\n                  \"Prior\\nFelony\", \"Quality\\nEmploy\", \"SES\", \"Self-\\nControl\"), \n                aes(color = collider)) + # add labels\n  # geom_dag_label_repel(\n  #   aes(label=collideDAGalt$data$label), \n  #       # fill=\"green\",\n  #       show.legend = FALSE) + \n  theme_dag() + \n  guides(fill = 'none', color = 'none', edge_color = 'none') +\n  scale_color_manual(values = c(\"#56B4E9\",\"#CC79A7\")) +\n  scale_edge_colour_manual(values=c(\"darkgrey\", \"red\")) + #change second color to highlight focal myedge1 \n  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) +\n    #change default expansion on y-axis min & max\n  ggtitle(\"Data-generating DAG\") + \n  theme(plot.title = element_text(size = 12))\n\n# how to change text names in DAG nodes \n# https://www.r-bloggers.com/2019/10/how-to-use-math-symbols-with-ggdag/\n\n# how to change color of all edges\n# geom_dag_edges(edge_color = \"steelblue\") +\n\ncollideDAGaltp2\n\n\n\n\n\nFigure 6. Causal diagram (DAG) used to generate simulated data\n\n\n\n\nAs suggested, even this DAG is simplified for clarity purposes. It ignores, for instance, all other potential measured (e.g., race/ethnicity) and unmeasured confounders that might affect selection into delinquent behavior, criminal justice contact and subsequent felony conviction, and participation in a survey. Still, an important first step in analyzing data should be to precisely and transparently specify causal assumptions. Even if the causal model is wrong (as all likely are), we can learn from it because a precisely and transparently reported causal model clearly communicates the assumptions underlying our interpretation of the data and, in turn, allows others to critique, test, and challenge our causal model with alternatives.\nPut differently, DAGs force the researcher to make choices, and these choices are ultimately testable. For example, in the above DAG, there is no arrow going directly from prior felony to delinquency. Thus, this DAG explicitly assumes that any empirically observed statistical dependence between prior felony and delinquency is expected to be entirely caused by other factors in the model (i.e., morality, sex, and self-control). If you think other factors than those in the DAG are important (e.g., crime as a collateral consequence of official labeling or the pains of punishment), then you can modify the DAG and examine the empirical implications of doing so. For now, we think this DAG will suit our purposes of illustrating some consequences of conditioning on colliders in three different examples using simulated yet realistic (examples 1 & 2) and real-world (example 3) criminological data.\nIn our first example, we will estimate the moderated effects of self-control on delinquency at different levels of moral beliefs in two samples: (1) a sample drawn at random from a “general” population with known (simulated) parameters; and (2) a “restricted” sample selected at random from the same population only after limiting the sampling frame to those with criminal felony records. This second restricted sample was motivated by the Pathways to Desistance study, a commonly used data source in criminology.\nIn the second example, we will use these simulated data to examine whether conditioning on a collider might bias estimates of the null effect of SES on delinquency.\nIn the third example, we will briefly illustrate how conditioning on a collider might impact causal estimates using real-world data from college students and MTurk workers.\nNow let’s simulate some data.\n\n\n\nBecause, you know, addressing collider bias in messy real data is “just like the simulations.”"
  },
  {
    "objectID": "blog-posts/[5]/colliders.html#sec-simdata",
    "href": "blog-posts/[5]/colliders.html#sec-simdata",
    "title": "Are you afraid of colliders?",
    "section": "Simulating data for examples 1 & 2",
    "text": "Simulating data for examples 1 & 2\nFor simplicity, we will assume random normal distributions for socioeconomic status (SES), employment status/quality, and self-control. We will assume Poisson distributed morality and delinquency scales. Morality’s continuous Poisson distribution is rounded down to nearest integer and truncated so negative values are recoded as zero. Delinquency’s continuous Poisson distribution is rounded to the nearest integers. These rounding procedures add a bit more noise to the data and also make these variable more comparable to the types of highly skewed, ordinal, Likert-type measures we see in our field.\nFor realism, the magnitudes of key simulated causal effects for the first example are relatively consistent with published correlation matrices.\nFor the second example, we will assume no total effect of SES on delinquency association (for rationale, see our previous blog on causation without correlation). However, we will assume a hypothetical positive effect of SES and negative effect of felony convictions on employment status/quality.\n\n\nShow code\noptions(scipen=0, digits = 3)\n\nset.seed(1138)\nn &lt;- 6100 #want approx n=1350 with felonies selecting into final sample (Pathways: n=1354)\n\ndef &lt;- defData(varname = \"Male\", dist = \"binary\", formula = 0,\n    link = \"logit\")\ndef &lt;- defData(def, varname = \"SES\", dist = \"normal\",\n    formula = \"0\", variance = 1)\ndef &lt;- defData(def, varname = \"HighSC\", dist = \"normal\",\n    formula = \"0 + (-.21)*Male\", variance = 1)\ndef &lt;- defData(def, varname = \"LowMoral\", dist = \"poisson\",\n    formula = \"-.3 + 0.36*Male\", link = \"log\")\n# simpop &lt;- simpop %&gt;% mutate(LowMoral = ifelse(LowMoral &gt; 5, 5, LowMoral)) #truncate LowMoral (0-5) 0\ndef &lt;- defData(def, varname = \"Delinquency\", dist = \"poisson\",\n    formula = \"-.7 + .20*Male + (-.05)*HighSC + .68*LowMoral + (-.21)*HighSC*LowMoral\", link = \"log\")\ndef &lt;- defData(def, varname = \"Felony\", dist = \"binary\", \n    formula = \"-3.5 + 2.2*Male + (-.09)*HighSC + (.62)*LowMoral + (-.20)*HighSC*LowMoral\", link = \"logit\")\ndef &lt;- defData(def, varname = \"QualityEmploy\", dist = \"normal\",\n    formula = \"0 + .5*SES + .3*HighSC + (-.3)*LowMoral + (-2)*Felony\", variance = 1)\nsimpop &lt;- genData(n, def)\n\n# cap LowMoral at 5 (0-5 item) - randomly replace n=3 oob values with values in bounds \ninds &lt;- simpop$LowMoral &gt; 5\nsimpop$LowMoral[inds] &lt;- sample(0:5, sum(inds), replace = TRUE)\n\n# cap Delinquency at 7 (0-7 item) - randomly replace oob values with in bounds values\ninds &lt;- simpop$Delinquency &gt; 7\nsimpop$Delinquency[inds] &lt;- sample(0:7, sum(inds), replace = TRUE)\n\nsimpop &lt;- simpop %&gt;% \n  mutate(Felonysamp = as.character(Felony))\n# simpop\nsimsamp &lt;- simpop %&gt;% filter(Felony==\"1\") \n# simsamp\n\n# table(simsamp$Male) #approx .85 in sample\n\n\nMaleplot &lt;- simpop %&gt;% ggplot(aes(x=Male, y=..density..,\n                                  fill = Felonysamp, colour = Felonysamp)) +\n  geom_histogram(alpha=.5, position=\"identity\") + \n  scale_color_manual(values = c(\"#E69F00\", \"#009E73\")) + \n  scale_fill_manual(values = c(\"#E69F00\", \"#009E73\")) + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"Male\", y=NULL)\n\nSESplot &lt;- simpop %&gt;% ggplot(aes(x=SES, y=..density.., \n                                   fill = Felonysamp, colour = Felonysamp)) +\n  geom_histogram(alpha=.5, position=\"identity\", \n                 breaks = seq(-4, 4, by = 1)) + \n  scale_color_manual(values = c(\"#E69F00\", \"#009E73\")) + \n  scale_fill_manual(values = c(\"#E69F00\", \"#009E73\")) + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"SES\", y=NULL)\n\nHighSCplot &lt;- simpop %&gt;% ggplot(aes(x=HighSC, y=..density.., \n                                   fill = Felonysamp, colour = Felonysamp)) +\n  geom_histogram(alpha=.5, position=\"identity\", \n                 breaks = seq(-4, 4, by = 1)) + \n  scale_color_manual(values = c(\"#E69F00\", \"#009E73\")) + \n  scale_fill_manual(values = c(\"#E69F00\", \"#009E73\")) + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"High self-control\", y=NULL)\n\nLowMoralplot &lt;- simpop %&gt;% ggplot(aes(x=LowMoral, y=..density.., \n                                      fill = Felonysamp, colour = Felonysamp)) +\n  geom_histogram(alpha=.5, position=\"identity\") + \n  scale_color_manual(values = c(\"#E69F00\", \"#009E73\")) + \n  scale_fill_manual(values = c(\"#E69F00\", \"#009E73\")) + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"Low morality\", y=NULL)\n\nDelqplot &lt;- simpop %&gt;% ggplot(aes(x=Delinquency, y=..density.., \n                                      fill = Felonysamp, colour = Felonysamp)) +\n  geom_histogram(alpha=.5, position=\"identity\") + \n  scale_color_manual(values = c(\"#E69F00\", \"#009E73\")) + \n  scale_fill_manual(values = c(\"#E69F00\", \"#009E73\")) + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"Delinquency\", y=NULL)\n\nFelonyplot &lt;- simpop %&gt;% ggplot(aes(x=Felony, y=..density..,\n                                  fill = Felonysamp, colour = Felonysamp)) +\n  geom_histogram(alpha=.5, position=\"identity\") + \n  scale_color_manual(values = c(\"#E69F00\", \"#009E73\")) + \n  scale_fill_manual(values = c(\"#E69F00\", \"#009E73\")) + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"Felonysamp\", y=NULL)\n\nEmployplot &lt;- simpop %&gt;% ggplot(aes(x=QualityEmploy, y=..density.., \n                                   fill = Felonysamp, colour = Felonysamp)) +\n  geom_histogram(alpha=.5, position=\"identity\", \n                 breaks = seq(-4, 4, by = 1)) + \n  scale_color_manual(values = c(\"#E69F00\", \"#009E73\")) + \n  scale_fill_manual(values = c(\"#E69F00\", \"#009E73\")) + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"Employment status/quality\", y=NULL)\n\n\nMaleplot + SESplot + HighSCplot + \n  LowMoralplot + Delqplot + Felonyplot + Employplot +\n  guide_area() + plot_layout(guides = 'collect')\n\n\n\n\n\n\n\n\n\nLet’s examine the bivariate correlations between our variables in the simulated “general” sample.\n\n\nShow code\n# https://r-coder.com/correlation-plot-r/  \n\ntrimpop &lt;- simpop %&gt;% dplyr::select(-id)\n\npsych::pairs.panels(trimpop,\n             smooth = FALSE,      # If TRUE, draws loess smooths\n             scale = FALSE,      # If TRUE, scales the correlation text font\n             density = TRUE,     # If TRUE, adds density plots and histograms\n             ellipses = FALSE,    # If TRUE, draws ellipses\n             method = \"pearson\", # Correlation method (also \"spearman\" or \"kendall\")\n             pch = 21,           # pch symbol\n             lm = TRUE,         # If TRUE, plots linear fit rather than the LOESS (smoothed) fit\n             cor = TRUE,         # If TRUE, reports correlations\n             jiggle = FALSE,     # If TRUE, data points are jittered\n             factor = 2,         # Jittering factor\n             hist.col = 3,       # Histograms color\n             stars = TRUE,       # If TRUE, adds significance level with stars\n             ci = TRUE)          # If TRUE, adds confidence intervals\n\n\n\n\n\n\n\n\n\nNow, let’s examine the bivariate correlations between our variables in the simulated “restricted” sample in which participants are selected based upon felony conviction status.\n\n\nShow code\n# https://r-coder.com/correlation-plot-r/  \n\ntrimsamp &lt;- simsamp %&gt;% dplyr::select(-c(id, Felony, Felonysamp))\n\npsych::pairs.panels(trimsamp,\n             smooth = FALSE,      # If TRUE, draws loess smooths\n             scale = FALSE,      # If TRUE, scales the correlation text font\n             density = TRUE,     # If TRUE, adds density plots and histograms\n             ellipses = FALSE,    # If TRUE, draws ellipses\n             method = \"pearson\", # Correlation method (also \"spearman\" or \"kendall\")\n             pch = 21,           # pch symbol\n             lm = TRUE,         # If TRUE, plots linear fit rather than the LOESS (smoothed) fit\n             cor = TRUE,         # If TRUE, reports correlations\n             jiggle = FALSE,     # If TRUE, data points are jittered\n             factor = 2,         # Jittering factor\n             hist.col = 3,       # Histograms color\n             stars = TRUE,       # If TRUE, adds significance level with stars\n             ci = TRUE)          # If TRUE, adds confidence intervals\n\n\n\n\n\n\n\n\n\nEven a brief examination of the bivariate correlation matrices foreshadows some of the problems we face when our research design invokes selection on a collider into the sample. For instance, imagine one group of researchers estimates gender gaps in self-control (r=-0.09), weak moral beliefs (r=0.17), and delinquency (r=0.18) using the general sample and then another group replicates their analysis using the felony sample (r=-0.01, 0.05, and 0.05, respectively). How might conclusions differ across these two studies?"
  },
  {
    "objectID": "blog-posts/[5]/colliders.html#sec-ex1",
    "href": "blog-posts/[5]/colliders.html#sec-ex1",
    "title": "Are you afraid of colliders?",
    "section": "Example 1: Estimating causal effect of self-control on delinquency",
    "text": "Example 1: Estimating causal effect of self-control on delinquency\nLet’s not get ahead of ourselves. Instead, let’s illustrate in detail with our first example. We begin by estimating a generalized linear model predicting delinquency in the simulated general sample and in the restricted sample that is selected on felony convictions. In both models, we specify a Poisson distribution with a log link for our delinquency outcome. Though we should also account for ordinal nature of predictors (e.g., model monotonic effects with cumulative logit link function), we will save that for a future blog entry.\n\n\nShow code\n#nonlinear models predicting delinquency in pop & sample\nglm1a &lt;- glm(Delinquency ~ Male + HighSC * LowMoral , data=simpop, family=\"poisson\")\n# summary(glm1a)\nglm1b &lt;- glm(Delinquency ~ Male + HighSC * LowMoral , data=simsamp, family=\"poisson\")\n# summary(glm1b)\n\n# Set table theme\ntheme_gtsummary_compact()\n\n# function for custom p-values\nroundp &lt;- function(x) {\n    if_else(\n      is.na(x), \n      NA_character_,\n      if_else(x &lt; 0.001, format(x, digits = 3, scientific = TRUE), format(round(x, 3), scientific = F))\n    )\n  } \n\n# function for reg output w/custom p-values\nregsum &lt;- function(mymod) {\n  tbl_regression(mymod, intercept=TRUE, pvalue_fun = roundp) %&gt;%\n  add_significance_stars(\n        hide_se = FALSE,\n        hide_ci = FALSE,\n        hide_p = FALSE\n      )\n}\n\nregsum(glm1a) %&gt;%\n  as_gt() %&gt;%\n  gt::tab_header(title = \"Example 1: Poisson model 1a, General sample\")\n\n\n\n\n\n\n\n\nExample 1: Poisson model 1a, General sample\n\n\nCharacteristic\nlog(IRR)1,2\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n-0.50***\n0.022\n-0.55, -0.46\n4.51e-115\n\n\nMale\n0.17***\n0.024\n0.12, 0.22\n4.22e-13\n\n\nHighSC\n-0.23***\n0.018\n-0.26, -0.19\n2.27e-35\n\n\nLowMoral\n0.50***\n0.010\n0.48, 0.52\n0.00e+00\n\n\nHighSC * LowMoral\n-0.01\n0.009\n-0.03, 0.00\n0.133\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 IRR = Incidence Rate Ratio, SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\nShow code\nregsum(glm1b) %&gt;%\n  as_gt() %&gt;%\n  gt::tab_header(title = \"Example 1: Poisson model 1b, Felony sample\")\n\n\n\n\n\n\n\n\nExample 1: Poisson model 1b, Felony sample\n\n\nCharacteristic\nlog(IRR)1,2\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n-0.29***\n0.069\n-0.43, -0.16\n3.02e-05\n\n\nMale\n0.11\n0.062\n-0.01, 0.23\n0.071\n\n\nHighSC\n-0.32***\n0.039\n-0.40, -0.24\n3.07e-16\n\n\nLowMoral\n0.44***\n0.018\n0.41, 0.48\n5.18e-136\n\n\nHighSC * LowMoral\n0.04**\n0.016\n0.01, 0.08\n0.006\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 IRR = Incidence Rate Ratio, SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\nShow code\n#use min (0), mean, and +2d low moral beliefs in felony sample to plot interaction  \n# mean(simsamp$LowMoral)\n# mean(simsamp$LowMoral) + 2*sd(simsamp$LowMoral)\n\nplot_glm1a &lt;- plot_model(glm1a, type = \"pred\",  terms = c(\"HighSC\", \"LowMoral [0,1.46,3.76]\")) + \n  theme_minimal() + coord_cartesian(xlim=c(-4,4), ylim=c(0,11)) + scale_colour_colorblind() + \n  scale_fill_colorblind() + labs(x=\"High self-control\", y=\"Delinquency\", title=\"General sample\")  \n\n\nplot_glm1b &lt;- plot_model(glm1b, type = \"pred\", terms = c(\"HighSC\", \"LowMoral [0,1.46,3.76]\")) + \n  theme_minimal() + coord_cartesian(xlim=c(-4,4), ylim=c(0,11)) + scale_colour_colorblind() + \n  scale_fill_colorblind() + labs(x=\"High self-control\", y=\"Delinquency\", title=\"Felony sample\")    \n\nplot_glm1a + plot_glm1b + plot_layout(guides = 'collect')\n\n\n\n\n\n\n\n\n\nSuccess! The plot on the left confirms that our simulation recreated the moderated effects of self-control on delinquency across levels of moral beliefs as documented in earlier research (e.g., see Figure 5 above, though note our x-axis is reversed and we specified a nonlinear functional form).\n\nDetour: On interactions in nonlinear models, psychoastronomy, & posterity\nBefore moving on, let’s take a brief detour. Note the interaction coefficient between high self-control and low morality is not statistically significant in the general sample (model 1a). Yet, we know there is an interaction in that sample because we simulated it to be there! Likewise, the nonparallel lines in the general sample’s plot confirm the existence of the exact interaction on the outcome scale that we intended to simulate.\nMeanwhile, notice the interaction coefficient is statistically significant in the felony sample (model 1b). However, the outcome scale plot shows estimated effects of self-control on delinquency are nearly parallel (i.e., little to no interaction) across the minimum, mean, and +2SD values of low moral beliefs. At the very least, these plots imply a much stronger interaction on the outcome scale in the general sample compared to the felony sample, which is the exact opposite conclusion one might draw from a naive interpretation of the magnitude and statistical significance of the model’s linear interaction coefficients.\n\n\n\nBeware naive interpretations of interaction terms in models with nonlinear link functions - it’s a trap!\n\n\nHence, these simulated results help illustrate an important lesson: Never rely on the statistical significance test results of an interaction term in a generalized linear model with a nonlinear link function (e.g., logistic; Poisson; negative binomial) to determine whether there is a significant interaction.2 Instead, we recommend estimating and plotting the potential interaction on the outcome probability or count scale and calculating predicted marginal contrasts when estimating and interpreting these types of models.\nThis is not simply an issue of preferences, nor is it an insignificant concern - and no, simply reporting odds ratios or risk ratios does not solve the problem either. Rather, the issue stems from fundamental yet oft-misunderstood differences between linear and generalized linear models. We are diving deeper into this issue with additional examples in an upcoming blog post. For now, we do not expect you to just take our word for it. Here are recent editors of American Sociological Review offering guidelines on the same issue:\n\n“The case is closed: don’t use the coefficient of the interaction term to draw conclusions about statistical interaction in categorical models such as logit, probit, Poisson, and so on.”\n\nYes, we know that many of us in our field were trained to rely on the presence or absence of stars3 next to an interaction coefficient to make inferences about the existence and nature of “significant” effects from regression models - including interaction effects in generalized linear models. Likewise, we know that the prospect of reading and learning new methods can be overwhelming - not to mention academia’s structural disincentives to do so. Have no fear - there are other alternatives to stepping up to this challenge! For instance, we can just skip all the hassle of collecting expensive data, building appropriate models, and correctly interpreting results and, instead, use a magic 8-ball or a coin-flip algorithm to make inferences. After all, though unreliable and lacking any evidentiary value, such random methods might be less biased than many statistical decision-making procedures. Or, if you do not want to risk subjecting your desired findings to the whims of chance, you could just ask ChatGPT to make up the results for you!4\nIf you have read this far, we think it is likely that you care about science, like to learn, and want to do careful work. If we are right, then please do not use p-values and significance stars to make inferences about interaction terms in generalized linear models with nonlinear link functions. Also, please do not use p-values and significance stars to make decisions about which variables to include as controls in your models. Rather, use theory to generate a plausible causal model (DAG), then choose which variables to include - and which variables to exclude - based on your estimand of interest and implications derived from your transparent causal model. Again, do not just take our word for it - listen to McElreath’s 2023 lecture on good and bad controls. At around the 42:15 mark, he states:\n\n“There are lots of heuristics that are taught in the sciences for choosing control variables and unfortunately most of them are simply wrong and damaging. One of the approaches of course is to just add everything in the spreadsheet and see what’s significant. This is the YOLO strategy. There is no statistical framework that justifies this at all but it is a great way to get published because you can farm asterisks and publish them and leave a trail of damage through the scientific literature that can last for decades. Not the posterity we should aspire to.”\n\n\n\n\nSo you want your research to change the world - for the better, right?\n\n\n\n\nSelection biases are not always easy to predict\nOk, let’s get back on track. So far, we have seen some evidence that selecting on felony status when collecting data might bias inferences about important substantive questions in criminology. First, a quick glance at bivariate correlations revealed that the magnitude of estimated gender differences in delinquency, self-control, moral beliefs, and even employment outcomes are substantially biased towards zero in the restricted felony sample. Second, a theoretically expected interaction between self-control and delinquency that exists in the general sample was not clearly observed in the felony sample.\nSpecifically, those with the strongest moral beliefs constraining delinquency (i.e., LowMoral == 0) are not expected to engage in delinquency and, therefore, self-control should be unimportant to (i.e., have no effect on) delinquency since there is little to no temptation to resist. This is exactly what we see in the general sample plot. However, in the felony sample plot, self-control is predicted to have a negative effect on delinquency of similar magnitude for respondents with strong (==0), average, and weak (+2SD) moral beliefs.\nNote, too, that the truncated variation from selection bias did not simply result in attenuated effect estimates in the felony sample. In fact, the magnitude of the estimated average marginal effect of self-control on delinquency is upwardly biased in the felony sample. Below, we plot the average marginal effect (AME) of self-control on delinquency in both samples, alongside a plot of the predicted delinquency count at each value of self-control in both samples.\n\n\nShow code\n#marginal effect of self-control plots\n\n#plot 1 - AME of self-control (on response) in both samples \n  #NEED TO EXTRACT & CREATE PLOT\name_scpop &lt;- summary(margins(glm1a, variables = \"HighSC\"))\name_scpop &lt;- ame_scpop %&gt;% mutate(\n  Felonysamp = 0\n)\name_scsamp &lt;- summary(margins(glm1b, variables = \"HighSC\"))\name_scsamp &lt;- ame_scsamp %&gt;% mutate(\n  Felonysamp = 1\n)\n\ndat &lt;- bind_rows(ame_scpop, ame_scsamp) %&gt;% \n  mutate(Felonysamp = as.factor(Felonysamp))\n\ncoefplot &lt;- ggplot(data = dat,\n       aes(x = AME, y = reorder(Felonysamp, desc(Felonysamp)), xmin = lower, xmax = upper, \n           fill = Felonysamp, col = Felonysamp)) +\n  geom_pointrange() + \n  scale_color_manual(values = c(\"#E69F00\", \"#009E73\")) +\n  scale_fill_manual(values = c(\"#E69F00\", \"#009E73\")) +\n  geom_vline(xintercept = 0, linetype=\"dotted\") +\n  coord_cartesian(xlim=c(-.55,.1)) +\n  theme_minimal() + \n  labs(x=\"Average Marginal Effect of Self-control\", y=\"Sample\") + \n  theme(legend.position = \"none\")\n\n\n#plot 2 - predicted delinquency count by self-control in both samples \nplot_glm1c &lt;- plot_model(glm1a, type = \"pred\", terms = \"HighSC\") + \n  theme_minimal() + coord_cartesian(xlim=c(-4,4), ylim=c(0,5)) + scale_colour_colorblind() + \n  scale_fill_colorblind() + labs(x=\"High self-control\", y=\"Delinquency\", title=\"General sample\")  \n\nplot_glm1d &lt;- plot_model(glm1b, type = \"pred\", terms = \"HighSC\") + \n  theme_minimal() + coord_cartesian(xlim=c(-4,4), ylim=c(0,5)) + scale_colour_colorblind() + \n  scale_fill_colorblind() + labs(x=\"High self-control\", y=\"Delinquency\", title=\"Felony sample\")    \n\n# plot_glm1c + plot_glm1d + plot_layout(guides = 'collect')\n\n#Extract lineribbon data & combine plots into one custom plot\n\n# Create own plot instead of plot_model()\nplot_glm1cd &lt;- ggplot() +\n  geom_jitter(data=simpop, aes(y=Delinquency,x=HighSC, fill = Felonysamp, color = Felonysamp), \n              alpha=.2, shape=21, linewidth=2, width=.2, height=.2) +\n  scale_color_manual(values = c(\"#E69F00\", \"#009E73\")) +\n  scale_fill_manual(values = c(\"#E69F00\", \"#009E73\")) +\n  geom_line(data=plot_glm1c$data, aes(x=x, y=predicted), \n                  color=\"#E69F00\", size=1.5) +\n  geom_ribbon(data=plot_glm1c$data, aes(x=x, ymin=conf.low, ymax=conf.high), \n                  fill=\"#E69F00\", alpha=.2) +\n  geom_line(data=plot_glm1d$data, aes(x=x, y=predicted), \n                  color=\"#009E73\", size=1.5) +\n  geom_ribbon(data=plot_glm1d$data, aes(x=x, ymin=conf.low, ymax=conf.high), \n                  fill=\"#009E73\", alpha=.2) +\n  theme_minimal() +\n  theme(axis.text.y=element_blank(),\n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"High self-control\", y=\"Delinquency\")\n\ncoefplot + plot_glm1cd \n\n\n\n\n\n\n\n\n\nThis may be surprising to some of you. After all, it is quite common for researchers to incorrectly defend against charges of selection bias by claiming that, with truncated distributions, the documented associations are likely attenuated and hence conservative estimates. In fact, we have made such claims ourselves,5 before we learned about collider bias and came to realize that predicting the nature, extent, or direction of bias is not always as simple as it may seem.\n\n\n\nDon’t use Jedi mind tricks. State causal assumptions (in a DAG), then identify your estimand and adjustment set."
  },
  {
    "objectID": "blog-posts/[5]/colliders.html#sec-ex2",
    "href": "blog-posts/[5]/colliders.html#sec-ex2",
    "title": "Are you afraid of colliders?",
    "section": "Example 2: Estimating noncausal effect of SES on delinquency",
    "text": "Example 2: Estimating noncausal effect of SES on delinquency\nLet’s move onto our second example, where we illustrate how improperly “controlling for” (i.e., conditioning on) a collider can bias causal estimation using our simulated general population and felony sample data. Here, we are estimating the noncausal effect of SES on delinquency. Of course, since our DAG and simulations specified no such causal effect, we should expect a near-zero estimate for the coefficient.\nLet’s start with a model that includes male and employment (i.e., QualityEmploy) as control variables Why? Well, because employment might be related to SES and to delinquency, and because everyone throws in demographic controls like sex, right? I know just said that this is not how one should select controls; however, in this example, we are trying to illustrate what might happen when people DO select controls in this way.\n\n\nShow code\n#generalized linear model, effect of SES on delinquency in pop, strat on employment \nglm2a &lt;- glm(Delinquency ~ Male + SES + QualityEmploy, data=simpop, family=\"poisson\")\n# summary(glm2a)\n\nregsum(glm2a) %&gt;%\n  as_gt() %&gt;%\n  gt::tab_header(title = \"Example 2: Model 2a, General sample, Collider\")\n\n\n\n\n\n\n\n\nExample 2: Model 2a, General sample, Collider\n\n\nCharacteristic\nlog(IRR)1,2\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n-0.09***\n0.019\n-0.13, -0.05\n1.82e-06\n\n\nMale\n0.24***\n0.024\n0.19, 0.29\n1.35e-23\n\n\nSES\n0.10***\n0.012\n0.08, 0.12\n2.85e-17\n\n\nQualityEmploy\n-0.22***\n0.008\n-0.23, -0.20\n1.02e-171\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 IRR = Incidence Rate Ratio, SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\nShow code\nplot_glm2a &lt;- plot_model(glm2a, type = \"pred\", terms = \"SES\") + \n  theme_minimal() + coord_cartesian(xlim=c(-4,4), ylim=c(0,4)) + \n  labs(x=\"SES\", y=\"Delinquency\", title=\"General sample, Stratify on employ\")  \nplot_glm2a\n\n\n\n\n\n\n\n\n\nUh oh. We simulated data to have no (i.e., null or “0”) effect of SES on delinquency, but our model estimated a positive effect of SES on delinquency in the population. By now, it should be clear that this is caused by inappropriately conditioning on the collider employment QualityEmploy.\nWhy? Well, to risk overextending another analogy, think of your focal estimand (SES -&gt; delinquency) as your room and a collider (employment) as the rancor monster in your closet that, if left unattended, will destroy your room (bias your effect estimate). Adjusting for a collider risks opening the closet door - aka, “backdoor paths” in your model - and letting the monster out. So, you need to check your DAG to be sure that the closet door is closed (the collider paths are blocked) from the outset and, if the closet door is opened (by conditioning on a collider), then you need to identify an adjustment that will close the door (block the path) to stop the monster (biasing information) from escaping.\nTo add another layer of complexity, a closer look at our DAG will reveal that the SES -&gt; Delinquency estimand is not the only potential relationship depicted for which adjusting for employment threatens to bias estimates due to conditioning on a collider. Below, we also briefly discuss nonfocal coefficients in our SES -&gt; delinquency models (e.g., for male and employment) to help illustrate how conditioning on a collider can wreak havok on an entire model and other relevant alternative models by opening backdoor paths and letting out biasing information. However, before we do this, we want to issue a strong cautionary plea:\nDo not try this at home or, worse, in scientific papers. It is typically a bad idea to interpret nonfocal coefficients as if they are effect estimates for alternative estimands like we are doing in this section. We plan to explain why in more detail in a later post about the Table 2 fallacy. Here, we know that our DAG accurately reflects the causal processes that generated our simulated data, so we have a better understanding of what is happening in our models than one typically would in real world data analytic contexts. If you really feel it is necessary, then use your DAG and specify the nonfocal variable as the exposure to identify whether the variables in the model sufficiently adjust for potential bias (more on this soon).\nWith that cautionary statement in place, we ill-advisedly point your attention to the negative coefficient for employment in the model above. We know this should not be there, since we did not specify a causal relationship between them in our DAG and, therefore, we did not simulate a causal relationship between them. In this case, the biased coefficient arises because both employment and delinquency “listen to” (in this case, are caused by) common mechanisms, namely moral beliefs and self-control (see Pearl & Mackenzie for explanation & more on the “listens to” metaphor).\nIn more specific terms, tracing employment to delinquency reveals confounding paths (forks) involving self-control and moral beliefs that are not blocked by the male or SES variables. For example:\n\nEmployment &lt;- Self-control -&gt; Delinquency\nEmployment &lt;- Moral beliefs -&gt; Delinquency\nEmployment &lt;- Prior felony &lt;- Self-control -&gt; Delinquency\nEmployment &lt;- Prior felony &lt;- Moral beliefs -&gt; Delinquency\n\nOf course, if we had not simulated the data ourselves or had a reliable DAG to communicate our causal assumptions - which is exactly the situation most researchers find themselves in - then we might simply assume that the SES and employment coefficients are accurate causal estimates and then proceed to tell a story about them in a paper for publication.\nScared yet? Face your fears, then be empowered to overcome them.\nNow, let’s illustrate what happens if we remove employment, the collider in our SES -&gt; delinquency estimate, from our model.\n\n\nShow code\n#generalized linear model, effect of SES on delinquency in pop, drop employment \nglm2b &lt;- glm(Delinquency ~ Male + SES , data=simpop, family=\"poisson\")\n# summary(glm2b)\n\nregsum(glm2b) %&gt;%\n  as_gt() %&gt;%\n  gt::tab_header(title = \"Example 2: Model 2b, General sample, No collider\")\n\n\n\n\n\n\n\n\nExample 2: Model 2b, General sample, No collider\n\n\nCharacteristic\nlog(IRR)1,2\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n0.02\n0.018\n-0.01, 0.06\n0.210\n\n\nMale\n0.43***\n0.023\n0.38, 0.47\n1.43e-77\n\n\nSES\n-0.01\n0.011\n-0.03, 0.01\n0.515\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 IRR = Incidence Rate Ratio, SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\nShow code\nplot_glm2b &lt;- plot_model(glm2b, type = \"pred\", terms = \"SES\") +\n  theme_minimal() + coord_cartesian(xlim=c(-4,4), ylim=c(0,4)) +\n  labs(x=\"SES\", y=\"Delinquency\", title=\"General sample, Drop collider\")  \n\nplot_glm2a + plot_glm2b\n\n\n\n\n\n\n\n\n\nOur estimate of the causal effect of SES on delinquency is now near-zero and negligible, with zero falling well within the 95% confidence interval.\nWhat would happen if we continue to condition on employment in our other simulated sample that also essentially conditions on felony status, or a key (simulated) cause of employment quality/status? Let’s re-estimate our two models using the simulated felony sample to see.\n\n\nShow code\n#generalized linear model, effect of SES on delinquency in pop, stratify employment \nglm2c &lt;- glm(Delinquency ~ Male + SES + QualityEmploy, data=simsamp, family=\"poisson\")\n\n# regsum(glm2a) %&gt;%\n#   as_gt() %&gt;%\n#   gt::tab_header(title = \"Example 2: Model 2a, General sample, with Collider\")\n\nregsum(glm2c) %&gt;%\n  as_gt() %&gt;%\n  gt::tab_header(title = \"Example 2: Model 2c, Felony sample, with Collider\")\n\n\n\n\n\n\n\n\nExample 2: Model 2c, Felony sample, with Collider\n\n\nCharacteristic\nlog(IRR)1,2\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n-0.03\n0.076\n-0.18, 0.11\n0.666\n\n\nMale\n0.17**\n0.062\n0.05, 0.29\n0.006\n\n\nSES\n0.15***\n0.022\n0.10, 0.19\n1.58e-11\n\n\nQualityEmploy\n-0.22***\n0.018\n-0.26, -0.19\n4.42e-37\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 IRR = Incidence Rate Ratio, SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\nShow code\nplot_glm2c &lt;- plot_model(glm2c, type = \"pred\", terms = \"SES\") +\n  theme_minimal() + coord_cartesian(xlim=c(-4,4), ylim=c(0,4)) +\n  labs(x=\"SES\", y=\"\", title=\"Felony sample, Stratify on employ\")  \n\n#generalized linear model, effect of SES on delinquency in pop, drop collider \nglm2d &lt;- glm(Delinquency ~ Male + SES, data=simsamp, family=\"poisson\")\n\nregsum(glm2d) %&gt;%\n  as_gt() %&gt;%\n  gt::tab_header(title = \"Example 2: Model 2d, Felony sample, no Collider\")\n\n\n\n\n\n\n\n\nExample 2: Model 2d, Felony sample, no Collider\n\n\nCharacteristic\nlog(IRR)1,2\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n0.56***\n0.058\n0.44, 0.67\n4.49e-22\n\n\nMale\n0.17**\n0.062\n0.05, 0.29\n0.005\n\n\nSES\n0.03\n0.020\n-0.01, 0.07\n0.100\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 IRR = Incidence Rate Ratio, SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\nShow code\nplot_glm2d &lt;- plot_model(glm2d, type = \"pred\", terms = \"SES\") +\n  theme_minimal() + coord_cartesian(xlim=c(-4,4), ylim=c(0,4)) +\n  labs(x=\"SES\", y=\"\", title=\"Felony sample, Drop collider\")  \n\n\n(plot_glm2a + plot_glm2b) / (plot_glm2c + plot_glm2d)\n\n\n\n\n\n\n\n\n\nWhen conditioning on a collider (employment), SES is incorrectly estimated to have a positive effect on delinquency in the simulated general sample and a positive effect of even larger magnitude on the outcome scale in the restricted felony sample.\nWhat about those nonfocal estimates? Let’s plug our noses and check. First, employment has a sizeable negative coefficient in both the general and felony samples, despite a lack of causal connection or direct simulated correlation between them. A review of our DAG helps us understand why this is the case: again, we did not adjust for self-control and moral beliefs, two confounders of the employment/delinquency relationship. As such, these backdoor paths remain open, resulting in a biased estimate.\nFinally, a large, positive coefficient for male on delinquency is observed in the general sample, whereas a smaller positive coefficient is observed in the felony sample. This is because, due to our DAG and simulation, being male is causally related to self-control and moral beliefs. Thus, in the general sample, being male has a positive association due to its unblocked indirect effects on delinquency through these mediators. In contrast, in the felony sample, we are letting biasing information from these indirect effects into our estimate of the total Male -&gt; delinquency effect by conditioning on a collider (e.g., felony).\nAgain, if you must interpret nonfocal estimates in your model, then we recommend specifying the nonfocal variable as the exposure and using your DAG (and a program like DAGitty) to trace the paths and identify sufficient adjustment sets to determine whether the coefficient might be biased in the model - which is likely, since you built the model to identify the causal effect of a different (i.e., the focal) variable.\n\n\n\nDestroy collider bias with the force. Or, you know, with a DAG and a sufficient adjustment set.\n\n\n\nAvoid being clever with DAG adjustment sets\nThough this collider business may be new to many of us, we all learned in early statistics classes that one way to unbias an empirical estimate of a causal in observational research (i.e., without randomization) is by adjusting for confounders. Well, it turns out that we can often do that to mitigate collider bias as well!\nOne of the cool things about the DAG framework is that it follows systematic and logically coherent rules that, though perhaps daunting at first, can be learned and applied formulaically. In fact, given you commit to a particular model of the world and specify it in a DAG, you do not have to rely on being clever when deciding what to adjust for in your statistical models.6\nSpecifically, for any theoretical estimand you want to empirically estimate from the data, you can start by designing your DAG with a program like “DAGitty” and identifying the exposure (cause) and outcome. Then, you can have the program automatically identify the various adjustment sets that would give you the unbiased estimate based on your theoretical model as specified in the DAG. The DAGitty User’s Manual explains a sufficient adjustment set as:\n\n“a set of covariates such that adjustment, stratification, or selection (e.g. by restriction or matching) will minimize bias when estimating the causal effect of the exposure on the outcome (assuming that the causal assumptions encoded in the diagram hold)…. One can understand adjustment sets graphically… as a set [of covariates] that closes all biasing paths while keeping desired causal paths open…” (p.9, bold emphasis added)\n\nLet’s do that with our SES -&gt; Delinquency example above.\n\n\nShow code\ncollideDAG_adjust &lt;- adjustmentSets(collideDAG, \"SES\", \"Delinquency\", type = \"all\")\ncollideDAG_adjust\n\n\n {}\n{ Male }\n{ MoralBeliefs }\n{ Male, MoralBeliefs }\n{ PriorFelony }\n{ Male, PriorFelony }\n{ MoralBeliefs, PriorFelony }\n{ Male, MoralBeliefs, PriorFelony }\n{ SelfControl }\n{ Male, SelfControl }\n{ MoralBeliefs, SelfControl }\n{ College, MoralBeliefs, SelfControl }\n{ Male, MoralBeliefs, SelfControl }\n{ College, Male, MoralBeliefs, SelfControl }\n{ PriorFelony, SelfControl }\n{ Male, PriorFelony, SelfControl }\n{ MoralBeliefs, PriorFelony, SelfControl }\n{ College, MoralBeliefs, PriorFelony, SelfControl }\n{ Male, MoralBeliefs, PriorFelony, SelfControl }\n{ College, Male, MoralBeliefs, PriorFelony, SelfControl }\n{ Male, MoralBeliefs, QualityEmploy, SelfControl }\n{ College, Male, MoralBeliefs, QualityEmploy, SelfControl }\n{ MoralBeliefs, PriorFelony, QualityEmploy, SelfControl }\n{ College, MoralBeliefs, PriorFelony, QualityEmploy, SelfControl }\n{ Male, MoralBeliefs, PriorFelony, QualityEmploy, SelfControl }\n{ College, Male, MoralBeliefs, PriorFelony, QualityEmploy, SelfControl\n  }\n\n\nAbove you see the various combinations of variables that you could include in your model to get an “unbiased” estimate of the total (non)effect of SES on delinquency based on the structural causal model described above. Note that there are a lot of valid adjustment sets in this case but none of these include just male and employment - the covariates in our model - as a sufficient adjustment set, which is why our earlier estimates were biased.\nOne of these sets does include adjusting only for male without employment in the model. In fact, you might be surprised to see that, in the case of the SES -&gt; Delinquency relationship, the minimal and arguably most sensible of the valid adjustment sets includes adjusting for nothing at all (“{}”)! There is an important lesson here: Depending on the DAG, it might be better to do quite literally nothing at all (i.e., include no control variables in a model) than to do the wrong thing (i.e., include bad controls).\n\n\n\nTry not to control. Use your DAG, then control you do. Or do not. There is no try.\n\n\nInterestingly, of the 26 identified adjustment sets for accurately estimating the total (null) effect of SES on delinquency, only six of them include the collider “QualityEmploy.” So, given you include “QualityEmploy” in your model, you would also have to adjust for one of the following sets of variables to accurately estimate the null noncausal effect from your statistical model:\n\n{ Male, MoralBeliefs, QualityEmploy, SelfControl }\n{ College, Male, MoralBeliefs, QualityEmploy, SelfControl }\n{ MoralBeliefs, PriorFelony, QualityEmploy, SelfControl }\n{ College, MoralBeliefs, PriorFelony, QualityEmploy, SelfControl }\n{ Male, MoralBeliefs, PriorFelony, QualityEmploy, SelfControl }\n{ College, Male, MoralBeliefs, PriorFelony, QualityEmploy, SelfControl }\n\nThis might seem like a random list but it is actually generated using formulaic rules for determining adjustment sets - that’s why a program like DAGitty can do it for us! For instance, in this particular case, the reason we would be better off controlling for nothing is because there are no forks (confounders) or pipes (mediators) between SES and delinquency - as we trace our way from SES to delinquency, we immediately encounter colliders.\nMeanwhile, given this DAG and the SES -&gt; Delinquency estimand, we can basically control for any combination of variables that is not one of the two colliders to which SES is causally related (employment or college), as the rest are essentially superfluous controls for our estimand. However, if we do open a path by conditioning on a collider, then we have to block it with something else between the collider and the outcome.\nSo, given we decide to control for male and employment in our model, then there are four adjustment sets that include both male and employment that should effectively block the path we open by conditioning on a collider (employment). “College” isn’t in the simulated data - it is common to lack key variables in a DAG in real world data - so that leaves us with two adjustment sets that we could use to block the open collider path with the data at hand. Let’s estimate those models and confirm that we get the correct “null” estimate.\n\n\nShow code\nglm2e &lt;- glm(Delinquency ~ Male + SES + QualityEmploy + LowMoral + HighSC, data=simpop, family=\"poisson\")\n\nglm2f &lt;- glm(Delinquency ~ Male + SES + QualityEmploy + LowMoral + HighSC + Felony, data=simpop, family=\"poisson\")\n\nregsum(glm2e) %&gt;%\n  as_gt() %&gt;%\n  gt::tab_header(title = \"Example 2: Model 2e, General sample, Adj.Set #25\")\n\n\n\n\n\n\n\n\nExample 2: Model 2e, General sample, Adj.Set #25\n\n\nCharacteristic\nlog(IRR)1,2\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n-0.51***\n0.021\n-0.55, -0.47\n2.77e-124\n\n\nMale\n0.17***\n0.024\n0.12, 0.21\n5.74e-12\n\n\nSES\n0.00\n0.012\n-0.03, 0.02\n0.858\n\n\nQualityEmploy\n-0.01\n0.009\n-0.02, 0.01\n0.502\n\n\nLowMoral\n0.51***\n0.010\n0.48, 0.53\n0.00e+00\n\n\nHighSC\n-0.25***\n0.012\n-0.27, -0.22\n1.04e-95\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 IRR = Incidence Rate Ratio, SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\nShow code\nregsum(glm2f) %&gt;%\n  as_gt() %&gt;%\n  gt::tab_header(title = \"Example 2: Model 2f, General sample, Adj.Set #26\")\n\n\n\n\n\n\n\n\nExample 2: Model 2f, General sample, Adj.Set #26\n\n\nCharacteristic\nlog(IRR)1,2\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n-0.51***\n0.022\n-0.55, -0.47\n2.93e-123\n\n\nMale\n0.17***\n0.025\n0.12, 0.22\n4.50e-11\n\n\nSES\n0.00\n0.013\n-0.03, 0.02\n0.877\n\n\nQualityEmploy\n-0.01\n0.011\n-0.03, 0.02\n0.569\n\n\nLowMoral\n0.51***\n0.010\n0.48, 0.53\n0.00e+00\n\n\nHighSC\n-0.25***\n0.012\n-0.27, -0.22\n1.68e-95\n\n\nFelony\n0.00\n0.036\n-0.07, 0.07\n0.951\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 IRR = Incidence Rate Ratio, SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\nAs you can see, these adjustment sets resulted in the same coefficient estimates and, more importantly, they removed the collider bias from our causal estimates! We have more to say about alternative models, variable selection, and Table 2 fallacy, but it will have to wait for a later entry. For now, let’s move on to one last example of collider bias caused by sample selection in real data."
  },
  {
    "objectID": "blog-posts/[5]/colliders.html#sec-ex3",
    "href": "blog-posts/[5]/colliders.html#sec-ex3",
    "title": "Are you afraid of colliders?",
    "section": "Example 3: Conditioning on a collider through selection in real data",
    "text": "Example 3: Conditioning on a collider through selection in real data\nFor our final example, we present results of an analysis of pilot survey data collected to explore the relationship between volunteering, moral behaviors, and moral attitudes in two samples: a university student sample (n=152 valid responses), and a similarly aged sample of respondents recruited online through Amazon Mechanical Turk (n=164 valid responses). Data collection was conducted by Miriam Northcutt Bohmert (Principal Investigator) in collaboration with Theresa Ochoa and Jon Brauer. We owe a special thanks to Miriam Northcutt Bohmert for granting us permission to use the data for this post, as well as to Indiana University’s Social Science Research Funding Program for financially supporting the data collection.\nIn this example, we focus solely on a basic bivariate association: the relationship between moral beliefs and delinquent (criminal) behavior. Self-reported measures of one’s moral beliefs about crime are among the strongest and most consistent correlates of criminal behavior. Hence, we would expect to see similarly strong correlations in both the MTurk and university samples. Failure to see such correlations might raise concerns about the data.\nIn particular, we anticipate that selection into the University sample might introduce collider biases for estimates of various causal estimands of interest to criminologists. Of course, we communicated this expectation in our initial DAG used to simulate data, which we present again for convenience (see Figure 7 below).\n\n\nShow code\ncollideDAGalt2 &lt;- dagify(\n  Delinquency ~ MoralBeliefs + Male + SelfControl,\n  PriorFelony ~ MoralBeliefs + Male + SelfControl, \n  MoralBeliefs ~ Male, \n  SelfControl ~ Male,\n  College ~ MoralBeliefs + SelfControl + SES, \n  QualityEmploy ~ MoralBeliefs + SelfControl + College + SES + PriorFelony, \n  exposure = \"MoralBeliefs\",\n  outcome = \"Delinquency\",\n  coords=list(\n    x=c(PriorFelony=1, QualityEmploy=1, SelfControl=2, Male=2, \n        MoralBeliefs=2, SES=2, Delinquency=3, College=3),\n    y=c(PriorFelony=0, SelfControl=-1, QualityEmploy=-2, Male=0, \n        MoralBeliefs=1, SES=-2, Delinquency=0, College=-1)\n  )) %&gt;% tidy_dagitty() %&gt;% \n  dplyr::mutate(collider = ifelse(name %in% c(\"PriorFelony\", \"QualityEmploy\", \"College\"), \"#CC79A7\", \"#56B4E9\"))\n\n\n#function to shorten arrows - set percentage to shorten\ncollideDAGalt2p &lt;- shorten_dag_arrows(collideDAGalt2, 0.08)\n\n#create factor variable to isolate edge of interest, permits specifying edge color\ntestdat2 &lt;- collideDAGalt2p %&gt;% dplyr::mutate(\n  myedge1 = if_else(collideDAGalt2p$data$name == \"MoralBeliefs\" & collideDAGaltp$data$to == \"Delinquency\",\n                    \"yes\", \"no\")\n  ) \n\n#try filtering plot data for only edge of interest & adding colored layer?\nlibrary(ggraph)\ncollideDAGalt2p2 &lt;- testdat2 %&gt;% ggplot(aes(x=x, y=y, xend=xend, yend=yend)) +\n  geom_dag_edges(aes(x = xstart, y = ystart, edge_color=myedge1)) +\n  geom_dag_text(label=c(\"Attend\\nCollege\", \"   Delinquency\", \"Male\", \"Moral\\nBeliefs\",\n                  \"Prior\\nFelony\", \"Quality\\nEmploy\", \"SES\", \"Self-\\nControl\"), \n                aes(color = collider)) + # add labels\n  # geom_dag_label_repel(\n  #   aes(label=collideDAGalt$data$label), \n  #       # fill=\"green\",\n  #       show.legend = FALSE) + \n  theme_dag() + \n  guides(fill = 'none', color = 'none', edge_color = 'none') +\n  scale_color_manual(values = c(\"#56B4E9\",\"#CC79A7\")) +\n  scale_edge_colour_manual(values=c(\"darkgrey\", \"red\")) + #change second color to highlight focal myedge1 \n  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) +\n    #change default expansion on y-axis min & max\n  ggtitle(\"Data-generating DAG\") + \n  theme(plot.title = element_text(size = 12))\n\ncollideDAGalt2p2\n\n\n\n\n\nFigure 7. Causal diagram (DAG), highlighting Example 3 estimand\n\n\n\n\nFor our purposes here, note that we are assuming the MTurk sample is more akin to a “general” sample that is not subject to the same collider biases for our estimand and, as such, it provides a useful point of comparison for visualizing the extent of the problem. However, we recognize this is a strong assumption that may be untenable for many research questions; likewise, consider that any differences we see between these two samples may be distorting the true extent to which collider biases are affecting our estimates.\nImportant caveats aside, let’s get to the results. Below, we skip the coefficient tables this time and instead jump straight to prediction plots in the outcome scale (like our previous plots). These plots are visualizations of posterior estimates generated by Bayesian bivariate negative binomial regression models predicting a criminal behavior variety index in each sample (integer counts ranging from min=0 to max=11).7\nWe start by presenting sample-specific results in separate plots.\n\n\nShow code\n# Restore RDS data to object\ndat.mturk.epred &lt;- readRDS(here(\"blog-posts\", \"[5]\", \"dat_mturk.rds\"))\ndat.univ.epred &lt;- readRDS(here(\"blog-posts\", \"[5]\", \"dat_univ.rds\"))\ndat.ssrfp &lt;- readRDS(here(\"blog-posts\", \"[5]\", \"dat_ssrfp.rds\")) \n\n\n# Figure 3A: Pile of lines & Shaded 95CI Plot, CrmBehavVI by zMoralBlfIRT, mturk only\nfig3a &lt;- dat.ssrfp %&gt;%\n  ggplot(aes(x = zMoralBlfIRT, y=CrmBehavVI)) +\n  geom_line(data=dat.mturk.epred, aes(y = .epred, group = .draw), alpha = 0.5, color=\"grey60\") +\n  stat_lineribbon(data=dat.mturk.epred, aes(y = .epred), .width = 0, color=\"black\") +\n  stat_lineribbon(data=dat.mturk.epred, aes(y = .epred), .width = .95, alpha = 0.2, color=\"darkgrey\") +\n  geom_hline(yintercept=11, linetype=\"dashed\", color = \"darkgrey\") +\n  guides(color = FALSE, fill = FALSE) +\n  geom_jitter(data=subset(dat.ssrfp, mturk==1), width = 0.1, height = 0.1, color = \"darkgreen\", alpha = 0.5) +\n  scale_fill_brewer(palette=\"Greens\") + \n  coord_cartesian(ylim = c(0, 15), xlim = c(-3.9, 1.5), expand = FALSE) + \n  labs(x=\"Strong Moral Beliefs\", y = \"Criminal Behaviors\") +  \n       theme(axis.title.x = element_text(size = 12, family = \"serif\")) + \n       theme(axis.title.y = element_text(size = 12, family = \"serif\")) + \n  ggtitle(\"3A. Posterior Fitted Curves, MTurk\") + \n  theme_minimal() +\n  theme(plot.title.position = \"plot\",\n        plot.title = element_text(size = 12, family = \"serif\"))\n\n# Figure 3B: Pile of lines & Shaded 95CI Plot, CrmBehavVI by zMoralBlfIRT, univ onlydat.univ %&gt;%\nfig3b &lt;- dat.ssrfp %&gt;%\n  ggplot(aes(x = zMoralBlfIRT, y=CrmBehavVI)) +\n  geom_line(data=dat.univ.epred, aes(y = .epred, group = .draw), alpha = 0.5, color=\"grey60\") +\n  stat_lineribbon(data=dat.univ.epred, aes(y = .epred), .width = 0, color=\"black\") +\n  stat_lineribbon(data=dat.univ.epred, aes(y = .epred), .width = .95, alpha = 0.2, color=\"darkgrey\") +\n  geom_hline(yintercept=11, linetype=\"dashed\", color = \"darkgrey\") +\n  guides(color = FALSE, fill = FALSE) +\n  geom_jitter(data=subset(dat.ssrfp, mturk==0), width = 0.1, height = 0.1, color = \"darkblue\", alpha = 0.5) +\n  scale_fill_brewer() + \n  coord_cartesian(ylim = c(0, 15), xlim = c(-3.9, 1.5), expand = FALSE) + \n  labs(x=\"Strong Moral Beliefs\", y = \"Criminal Behaviors\") +  \n       theme(axis.title.x = element_text(size = 12, family = \"serif\")) + \n       theme(axis.title.y = element_text(size = 12, family = \"serif\")) + \n  ggtitle(\"3B. Posterior Fitted Curves, University\") + \n  theme_minimal() + \n  theme(plot.title.position = \"plot\",\n        plot.title = element_text(size = 12, family = \"serif\"))\n\nfig3a + fig3b \n\n\n\n\n\n\n\n\n\nIn case it is easier to visualize the selection thresholds, we also overlay both plots on the same grid below.\n\n\nShow code\nfig3c &lt;- dat.ssrfp %&gt;%\n  ggplot(aes(x = zMoralBlfIRT, y=CrmBehavVI)) +\n  # geom_line(data=dat.mturk.epred, aes(y = .epred, group = .draw), alpha = 0.5, color=\"grey60\") +\n  stat_lineribbon(data=dat.mturk.epred, aes(y = .epred), .width = 0, color=\"darkgreen\") +\n  stat_lineribbon(data=dat.mturk.epred, aes(y = .epred), .width = .95, alpha = 0.1, fill=\"darkgreen\") +\n  geom_jitter(data=subset(dat.ssrfp, mturk==1), width = 0.1, height = 0.1, color = \"darkgreen\", alpha = 0.5) +\n  # scale_fill_brewer(palette=\"Greens\") + \n  # geom_line(data=dat.univ.epred, aes(y = .epred, group = .draw), alpha = 0.5, color=\"grey60\") +\n  stat_lineribbon(data=dat.univ.epred, aes(y = .epred), .width = 0, color=\"darkblue\") +\n  stat_lineribbon(data=dat.univ.epred, aes(y = .epred), .width = .95, alpha = 0.1, fill=\"darkblue\") +\n  geom_hline(yintercept=11, linetype=\"dashed\", color = \"darkgrey\") +\n  guides(color = FALSE, fill = FALSE) +\n  geom_jitter(data=subset(dat.ssrfp, mturk==0), width = 0.1, height = 0.1, color = \"darkblue\", alpha = 0.5) +\n  # scale_fill_brewer() + \n  coord_cartesian(ylim = c(0, 15), xlim = c(-3.9, 1.5), expand = FALSE) + \n  labs(x=\"Strong Moral Beliefs\", y = \"Criminal Behaviors\") +  \n       theme(axis.title.x = element_text(size = 12, family = \"serif\")) + \n       theme(axis.title.y = element_text(size = 12, family = \"serif\")) + \n  ggtitle(\"3C. Posterior Fitted Curves, MTurk + University\") + \n  theme_minimal() + \n  theme(plot.title.position = \"plot\",\n        plot.title = element_text(size = 12, family = \"serif\"))\n\nfig3c\n\n\n\n\n\n\n\n\n\nNow, what is happening here? Well, if our DAG is correct, then we conditioned on a collider when selecting a sample of university students to survey about moral beliefs and crime.\nLet’s check our sufficient adjustment sets.\n\n\nShow code\ncollideDAG_adjust2 &lt;- adjustmentSets(collideDAG, \"MoralBeliefs\", \"Delinquency\", type = \"all\")\ncollideDAG_adjust2\n\n\n{ Male }\n{ Male, SES }\n{ Male, SelfControl }\n{ College, Male, SelfControl }\n{ Male, PriorFelony, SelfControl }\n{ College, Male, PriorFelony, SelfControl }\n{ Male, QualityEmploy, SelfControl }\n{ College, Male, QualityEmploy, SelfControl }\n{ Male, PriorFelony, QualityEmploy, SelfControl }\n{ College, Male, PriorFelony, QualityEmploy, SelfControl }\n{ Male, SES, SelfControl }\n{ College, Male, SES, SelfControl }\n{ Male, PriorFelony, SES, SelfControl }\n{ College, Male, PriorFelony, SES, SelfControl }\n{ Male, QualityEmploy, SES, SelfControl }\n{ College, Male, QualityEmploy, SES, SelfControl }\n{ Male, PriorFelony, QualityEmploy, SES, SelfControl }\n{ College, Male, PriorFelony, QualityEmploy, SES, SelfControl }\n\n\nAgain assuming our DAG is correct, then the first thing to note is that a bivariate model is insufficient for estimating the causal effect of moral beliefs on delinquency (or criminal behavior). At the very least, we need to adjust for Male sex to remove its potential confounding bias.\nNext, notice that a single adjustment for College is not listed among the sufficient adjustment sets. Given we condition on College, then at the very least we would also need to remove the confounding bias of Male sex and adjust for Self-control to block the path we opened that allowed the collider College to bias our causal estimate.\nIn this case, though, model-based adjustments are unlikely to help us very much. After all, we did not simply condition on the collider College by adding it as a “bad control” in our regression model. Rather, we systematically selected out observations from our data through our sampling design. Adding in the appropriate model-based adjustments will not magically make those truncated observations appear in our data. So, what do we do now?\nWell, fellow Jedi Padawan Scientists, we heed the advice of OG Jedi Master Yoda: “Mind what you have learned. Save you it can.”\n\n\n\nMind what you have learned. Save you it can."
  },
  {
    "objectID": "blog-posts/[5]/colliders.html#footnotes",
    "href": "blog-posts/[5]/colliders.html#footnotes",
    "title": "Are you afraid of colliders?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you traced all the paths from X to Y and applied the general definition of a collider that we provided above, then you might have noticed the mediator M is also a collider in the Example 3 DAG.↩︎\nNote we are not saying here that you should abandon statistical significance altogether. That is a different issue, albeit one with which we strongly sympathize. However, we also recognize the error control utility of significance testing given specific circumstances, such as transparent theoretical assumptions about data generating processes, a precise hypothesis, and an appropriate research design. Perhaps we can try to tackle these issues in a future blog post…↩︎\nIn The Nurture Assumption (footnote, p.18), Judith Rich Harris cleverly describes this process as follows: “The significant correlations are easy to spot, nicely marked with asterisks by the statistics software. It’s a technique known as ‘psychoastronomy’: looking for the stars.”↩︎\nLiability caveat: If it is not obvious to all, we are being facetious here. Do learn new things. Do not waste scientific resources on data and then subject them to methods that routinely deliver unreliable, random, or biased inferences. Do not make up data yourself, and do not have an ever-expanding super-intelligent AI overlord do it for you.↩︎\nFor example, Jake is guilty of this type of claim in his published work on race inequality in the college football coaching profession (see Day, 2015). To offer what is in hindsight an embarrassing quote: “…given that Black coaches are more likely to leave the profession, by examining predictors of racial differences in promotions to executive positions (in retrospective data), the present study offers a conservative test of the relationship between job-level, task-based,segregation and racial disparities in career outcomes (pg. 435).” To again paraphrase Richard McElreath], upon learning about DAGs, collider bias, and a host of other issues, I have often found myself experiencing “a profound sense of regret for (my) previous analyses.”↩︎\n“Avoid being clever” is another McElreath motto. You’re probably picking up on a pattern with all of our McElreath references. Seriously, do yourself a favor and read his book and watch his lectures.↩︎\nStrong moral beliefs is measured as a standardized item response theory (IRT) score scale. It is similar to measures found in existing criminological literature and, like our simulated moral beliefs variable above, is assumed to capture an underlying latent continuous dimension theoretically ranging from endorsement of strong pro-crime moral beliefs (min=-3.84) to strong anti-crime moral beliefs (max=1.18). We also specify weakly informative priors for the beta coefficient; we hope to write more about specification of prior distributions in such models in a later post.↩︎"
  },
  {
    "objectID": "blog-posts/[3]/charles-memorial.html",
    "href": "blog-posts/[3]/charles-memorial.html",
    "title": "Dr. Charles R. Tittle’s intellectual contributions",
    "section": "",
    "text": "Dr. Charles R. Tittle\nThe comments below were delivered in one of two tribute panels dedicated to Dr. Charles R. Tittle’s intellectual and interpersonal contributions to criminology at the 2021 American Society of Criminology annual meeting in Chicago. While others contributed additional comments on the spot, the following include only those formally scheduled comments delivered about Charles’ intellectual contributions to the field. Click on a panel topic below to expand and view its contents:\nCharles R. Tittle Tribute I: Intellectual Contributions to Criminology\nFor additional reflections about Charles from a few of his former students and colleagues, see Washington State University’s wonderful Remembering Charles Tittle memorial tribute."
  },
  {
    "objectID": "blog-posts/[3]/charles-memorial.html#sec-charles_international",
    "href": "blog-posts/[3]/charles-memorial.html#sec-charles_international",
    "title": "Dr. Charles R. Tittle’s intellectual contributions",
    "section": "Contributions to International Criminology",
    "text": "Contributions to International Criminology\nby Katya Botchkovar\nKatya gave us permission to share the recorded video of her presentation, which was delivered remotely for the ASC tribute session:"
  },
  {
    "objectID": "blog-posts/[3]/charles-memorial.html#sec-charles_measurement",
    "href": "blog-posts/[3]/charles-memorial.html#sec-charles_measurement",
    "title": "Dr. Charles R. Tittle’s intellectual contributions",
    "section": "Contributions to Measurement and Theory Testing",
    "text": "Contributions to Measurement and Theory Testing\nby Carter Hay\n\nIntroduction\nCarter gave us permission to share the written notes for his comments delivered for the ASC tribute session:\nThank you Jon, and thank you for all of your organizing these sessions that allow us to reflect on Charles as such an important scholar and person for the field of criminology but also in our lives. My areas to cover are measurement and theory testing, and it was a wonderful idea to put those two together because when we look at Charles’s research in broad strokes, those two are inherently linked. I think of it in this way:\n\nCharles was as theoretical as they come — he approached each issue with a deep concern for theory.\nBut he also was immensely empirical; analyzing data and testing hypotheses are the core of his research activities.\nBut a third thing: He commonly used data that he had some part in collecting, which meant that he wasn’t having to rely on the measures available in secondary data; instead, he played a role in shaping new novel measures of theoretical concepts.\n\nThis ultimately translated into extraordinary number of novel creative tests—studies that are among the best and most influential tests of a given theory, and this often was due in part to measurement.\nAnd he did this for MANY different theories — by my count, it’s at 10 different theories not just that Charles was able to test, but that he was able to test with original data that enabled he and his co-authors to design their own measures:\n\nDifferential association theory\nSelf-control theory\nDeterrence theory\nReintegrative shaming and labeling theory\nStrain theory, including general strain theory\nSituational action theory\nColvin’s social support/coercion theory\n\nAnd then there also are theoretical topics that cut across multiple theories, including innovative work on:\n\ncriminal motivations\nmorality and crime and religiosity and crime.\n\nIt’s not possible talk about all of those areas where Charles had a big impact with respect to measurement and empirical testing. I’m instead going to discuss two of those areas—deterrence and self-control—in some detail as illustrations of his general approach and his lasting influence.\n\n\nDeterrence\nSo the first area I want to focus on is deterrence. Charles’s work in this area most clearly begins with the Tittle (1969) article that used official data for the 50 states to reveal that the certainty of punishment—as indicated by the probability of imprisonment—was associated with lower crime and that severity (the length of prison sentences) also could reduce crime when certainty was at high levels. Charles’s key point in that article and in several others that followed in the 1970s was that deterrence needed to be taken seriously; it had been dismissed, but this wasn’t because good testing or good data had found problems; instead, he saw biases in play along with a tendency to go along with the conventional wisdom even when it wasn’t on firm ground.\nCharles wasn’t in favor of deterrence theory, he wasn’t opposed to it—he wanted to test it effectively.\nAnd his ideas on how best to test deterrence evolved fairly quickly and they would help shape the field. In 1972, Charles gets an NSF grant of $100,000 to fund a survey approach to testing deterrence theory. The results of that work were published in the book Sanctions and Social Deviance was published in 1980 and in some other articles published around that time.\nEarly in the book, he makes the case for studying deterrence with surveys, which of course, was quite different than his 1969 test that attracted so much attention—he expressed some real doubts that the macro-level research could ever explicitly reveal fear of sanctions as the operative mechanism, and this was crucial for distinguishing deterrence from other mechanisms by which punishment can affect crime.\nAlso, Charles felt that causal order issues would be tough to parse out because of how legal systems are embedded in complicated social contexts where history looms large. Even with sophisticated analyses, it was difficult to determine whether low certainty was leading to high crime, or conversely, whether high crime was leading to low certainty.\nSo he set out to try to address these two issues with a survey of roughly 2,000 adults randomly selected from three states: Iowa, Oregon, and New Jersey.\nSo on that first issue, Charles’s created an comprehensive measure of fear of sanctions. He identified multiple indicators of fear that were used for a multitude of different rule violations, with these capturing:\n\nthe chances that people would find out?\nwould those be people you know?\nwould lots of people in the community find out?\nwould there be a loss of respect?\nwould it produce an arrest?\nwould produce jail?\n\nAnd then scores were further adjusted based on the person’s peer deviance—if most of the people that someone knew engaged in deviance, then them finding out probably shouldn’t be seen as increasing sanction fear.\nNow, I’ll emphasize that Charles was not the only one pursuing this survey approach at this time (Waldo, Chiricos, Anderson), but his comprehensive approach to measurement was unique and his attention to scaling was meticulous.\n\nAnd let me mention something in connection to that — when you go to Charles’s CV, you see that 4 of his first 6 publications were explicitly measurement-oriented methodological pieces — measurement and scaling were the explicit priorities of the paper. This included articles or research notes from 1966-68 in American Journal of Sociology, Public Opinion Quarterly, Sociometry, and Social Forces. Collectively, they were cited more than 600 times and often re-printed.\nThese articles precede the articles in criminology that we think of regarding Charles’s career, and they dealt with things like political activity and bureaucratization, but there’s some foreshadowing that innovation and rigor in the area of measurement would be central to his work.\n\nBut the scope of his survey-based approach to deterrence theory also was unique—it was a big project drawing a very diverse set of subjects from 3 states to ensure big variations in social contexts—which is critical to testing deterrence theory—a convenience sample taken from a group of people in the same social context simply isn’t the best test.\nSo that’s innovation #1 — taking the most rigorous approach possible to get at that mechanism of fear.\nThe second innovation dealt with this causal order issue, which had its own problems when using the survey approach. In cross-sectional studies, perceived certainty, severity, or fear of sanctions is measured at the time of the survey and offending is measured for the prior 6 or 12 months creating an obvious causal order concern in which offending precede perceptions of sanctions.\nNow longitudinal panel data could be used but that’s difficult to come by and it creates the problem of lags—current perceptions are being used to predict future behavior, but what if perceptions of sanctions change and those current perceptions being measured at the time of the survey become outdated.\nSo Charles had an interesting fix for this — he measured projected deviance.\nHe asked this question: “If you were in a situation tomorrow where you had an extremely strong desire or need to [fill in the blank on the behavior], what are the chances that you would actually do it?”\nSo he used current perceptions of punishment to predict this measure of projected deviance, but he also measured prior deviance — it could be used as a conditioning variable or a control variable, and this measurement advance created much stronger causal inferences, especially in light of the later research that would show that projections of future deviance often were strongly correlated with actual deviance.\nAnd this approach becomes the basis for many criminological studies that in some way make use of projected deviance or crime, intentions to offend, willingness to offend, and the vignette studies. These studies go beyond deterrence theory—studies on strain theory, differential association theory, self-control theory, and so on. In many instances, they cite Tittle’s earlier work—that’s especially true for the people in this room because there are a lot of us who have used these measures—but even when Tittle wasn’t cited, they typically lean on the same basic rational that Charles drew attention to more than 40 years ago:\nthe desire to use cross-sectional data to examine contemporaneous or short-term effects (rather than lagged effects) and to do so with stronger causal inferences.\nTaking these two innovations together, what did Charles find? Findings that are very close to the current state of knowledge today. He found that:\n\nSanction fear reduces offending but fairly modestly.\nPerceived informal sanctions tends to matter more than perceived formal sanctions.\nAnd sanction fear generally has smaller effects than other theoretical variables, including moral commitments, social bonding, and differential associations.\n\nAnd Charles discovered lots of contingencies. His findings on this are immensely valuable; they laid the groundwork for interesting work to come on the idea of differential deterrability — with sanction fear operating more for some people and under some circumstances than others.\n\n(Mark Stafford on deterrence)\nAnd this issue of contingencies is something that Mark Stafford emphasized in comments that he sent me. Mark had a family issue arise and he wasn’t able to travel to Chicago, but I wanted to share with you his comments on this issue:\n\nMost deterrence researchers have paid lip-service to the idea that the threat of legal punishment probably interacts with other variables to affect the likelihood of crime. However, few have followed through on it, and no one as much as Charles. This was a central theme in his Sanctions and Social Deviance: The Question of Deterrence. A brief perusal of his deterrence studies over the years reveals that he looked at interactions between punishment threats and age, gender, informal punishments, self-control, and morality.\n\n\nProbably my favorite deterrence research by Charles focused on the possible interaction between punishment threats and motivation to commit crime. When I was a graduate student at the University of Arizona, I remember students (Mark Warr, Kirk Williams, Joe Rankin, and I) drinking with faculty (Jack Gibbs, Maynard Erickson, and Gary Jensen) on many occasions and discussing the obvious that punishment threats could not deter unless people were motivated to commit crime. We concluded, however, that motivation was too complex to capture in a simple measure. Move ahead decades later and that is exactly what Charles did – he measured motivation, and by simply asking people how much they wanted to commit crime. It turned out that this measure interacted with punishment threats to form a strong predictor of crime. Charles had a real talent of taking complex ideas and reducing them to their basics. What was too complex for the rest of us was easy for Charles. As a consequence, deterrence research is decades ahead of where it would have been without Charles. Perhaps it is hyperbole to compare Charles with Bentham and Beccaria, but I bet they would have liked to pick Charles’ brain about deterrence, and I bet Charles would tell them many things they got wrong.\n\n\n\n\nSelf-control theory—many innovations here\nLet me pivot now to self-control theory, which is an area where Charles’s contributions are immense. Many of the things we know about this theory are things we learned from Charles’s work.\nIf you look at Charles’s book reviews and commentaries on Gottfredson and Hirschi’s self-control theory, along with comments he’d make, three things were clear: (1) he saw some shortcomings in the theory, (2) he was nevertheless impressed by the case they made for self-control being an important neglected variable, and (3) he knew the theory would attract a lot of attention and testing.\nAnd a question has occurred to me, one that I wished I’d asked him: In 1991, when Charles published one of the first reviews of Gottfredson and Hirschi’s book, did he anticipate that he himself would become so central to the empirical testing of the theory? I don’t know; maybe some of you do.\nBut his centrality is unquestioned.\nIt begins obviously with the Grasmick et al. self-control scale, which of course never gets referred to by the more long-winded label of the Grasmick, Tittle, Bursik, and Arneklev scale. But I do know that Charles was quite involved in the development of that scale because he once described the painstaking process he went through to try to identify items from the California Psychological Inventory, along with the recognition at various points that newly invented items also would be needed.\nThat resulting scale they came up with was examined with new data from the Oklahoma City Survey in one the first tests of the theory, and that scale or subsets of it of it have been used in scores of studies. And their original study also has been cited more than 2600 times. The bottom line is that this scale is in many ways the gold standard for measuring self-control in criminology, and the meticulous attention to its scaling has inspired further research into not just this measure but possible limitations in Gottfredson and Hirschi’s initial conceptualization of self-control.\nAnother notable innovation of Charles’s in this area involves the distinction between self-control ability and self-control interest, along with his creative attempts to empirically distinguish them. This 2004 article with Grasmick and Ward really displays Charles’s skill in getting at the interplay between theoretical creativity and measurement. This study went beyond the arguments of the theory to consider something new, but rather than just making an interesting argument, he used data and creative measurement to test it.\nThe argument was this: self-control theory and research had been really centered on the idea that people differ in the ABILITY (or capacity) to exercise self-control—some people have that ability, some people don’t. Charles’s point was that there also could be variation in self-control INTEREST. Here’s what he said:\n\nsome people may have a strong capacity for self-control but may not always want to exercise it, while others may have weak self-control ability but have such a keen interest in controlling their deviant impulses that they end up conforming.\n\nSo these two things—ability and interest—can both be consequential and maybe they even interact with each other. Maybe the effect that one has on crime depends on how much of the other they possess.\n\nAnd he also raises this interesting possibility: self-control interest could be distinct from ability in being especially responsive to social stimuli. Maybe self-control ability is pretty stable in the way that the theory predicts, but interest—do you feel like exercising the self-control you really do possess or do you not feel like it?—is probably a much more situationally-fluid variable.\n\nSo in this study, using Oklahoma City Survey data, they construct a measure of self-control interest, and they do so with items that place a person in a situation in which they have the option of REFRAINING from some deviant action, and they ask might come from refraining—\n\nwould it allow them to feel proud?\nto earn praise from others?\nto avoid losing the respect of people they care about?\nto avoid feeling guilty?\n\nIf they say yes to these things, that’s an interest in exercising self-control.\nAnd very quickly on the findings:\n\nThey found that items measuring self-control interest coalesced nicely, loading on the same factor and not loading on a 2nd factor that including the traditional self-control ABILITY items.\nSelf control interest and self-control ability BOTH affected offending, often similarly, but when differences did emerge, it was INTEREST having the greater effect\nThere was some evidence of interaction such that self-control ability mattered less when a person was really INTERESTED in exercising self-control.\n\nNow there are other innovations that Charles had on self-control research, including measurement, but I’m running out of time. And there are other areas beyond deterrence and self-control theory that I would have liked to discuss. In particular, Charles’s research with Jon Brauer on Colvin’s social support and coercion theory in my mind provides a similar gold standard for testing that theory and measuring its concepts in both global and domain-specific ways.\nBut there’s not time, so I’ll just conclude by saying that the lasting influence of Charles’s research on theory testing and measurement comes back to a simple premise that seemed to always guide him, and we should be inspired to have it guide us as well. I believe that premise that really guided Charles was this:\n\nBefore reaching a conclusion on something, get the highest quality evidence you can, even if doing that is really hard. And it probably will be really hard. Press on and do it anyway."
  },
  {
    "objectID": "blog-posts/[3]/charles-memorial.html#sec-charles_science",
    "href": "blog-posts/[3]/charles-memorial.html#sec-charles_science",
    "title": "Dr. Charles R. Tittle’s intellectual contributions",
    "section": "Advocate for Theoretical Science in Criminology",
    "text": "Advocate for Theoretical Science in Criminology\nby Jon Brauer\n\nIntroduction\nAs my colleagues have described, Charles’ scholarship advanced so many areas of criminological inquiry, including: (1) several important substantive debates in criminology; (2) concept measurement & theory testing using survey research; (3) and assessment of the generality of criminological patterns & theories across international contexts. As scholars, many of us would love to make meaningful contributions to any single issue within one of these broad areas. The breadth, magnitude, and consistency of his contributions cements Charles Tittle’s status as one of the brightest stars in our criminological universe.\nThroughout all this work, one would be hard-pressed to find a theory of crime or deviance that was popular or that emerged during his illustrious 55+ year career that Charles had not read, reviewed, and even directly tested himself. Think about that a moment. He did not devote his time to becoming a specialist in any one theory or any particular area of inquiry. Rather, he devoted his time to becoming a specialist in countless theories and interdisciplinary areas relevant to his vast domain of inquiry – human behavior. That is, Charles embodied a generalist or Renaissance model of scholarship that seems all too rare in today’s knowledge silos, perpetuated by narrow training specializations, focused research funding and accomplishments, and exponential growth in short, quick-hitting publications.\nCharles’ varied contributions stemmed directly from his philosophy of science. He was not simply jumping from latest fad to latest fad. He was not an opportunist doggedly seeking to aim his crosshairs at every emergent idea from other hard-working scholars. He was not just publishing because that is what we do. No, Charles had much loftier aims with his research and writing. Individually and in their totality, his publications reflect his deep commitment to the health and vibrancy of the field of criminology. In fact, to Charles, the health and vibrancy of a scientific field is tantamount to the health and vibrancy of theoretical development in that field.\nLikewise, Charles devoted his entire career – and such a massive portion of his precious hours spent on this Earth – to trying to improve our theories: by reading them, thinking about them, testing them, critiquing them, developing them, and by advocating for and training others to do the same.\n\n\nCharles’ Philosophy & The Mansion of Science\nCharles was not known as someone who spent much time writing explicitly about philosophy of science. Yet, he certainly had a coherent working scientific philosophy – his belief in and advocacy for the centrality of theories to scientific progress was a cornerstone – and while his scientific philosophy was readily apparent to those who knew him well, it also emanated from his teachings and writings.\nIn the introductory lecture to one of his foundational graduate theory courses, Charles would begin by describing the “mansion of science” as having many rooms, with these rooms divided into blocks representing different paradigms or models of science. After describing other complementary or competing models of science, such as descriptive, vehrstehen, engineering, critical, nihilistic approaches, and the like, Charles would then endorse the “theoretical science” model, which he viewed as the most efficient, reliable means of fostering scientific progress. He would also pointedly profess that the theoretical science model occupied the most rooms and held the best real estate in the mansion of science.\nIn this regard, Charles views were heavily influenced by works such as Richard Braithwaite’s classic 1953 book, Scientific Explanation, and by Paul Reynolds’ 1971 book, A Primer in Theory Construction. Reynolds’ book was particularly influential to Charles’ working scientific philosophy.\nLike Reynolds, Charles viewed the goals of science and scientific activity as:\n\nproviding typologies, or identification and organization of phenomena into conceptual categories of similar and different things;\npermitting the accurate prediction of future phenomena;\nproviding accurate explanations for past phenomena; and\nproviding people a sense of understanding about how and why phenomena occur via full articulation of the causal mechanisms linking changes in some concepts (causes) with changes in other concepts (effects).\n\n(Many would add the potential for control of phenomena as a secondary consequence of accurate explanation and prediction, though Charles was infamously resistant to making the jump from is-based knowledge to ought-based control or policy prescriptions given the state of our evidence, to which I will return soon.)\nIf these indeed are the primary goals of scientific activity, then theory development is central to science. Theories provide our typologies, or our conceptual categories and shared language about phenomena. Theories are our explanations of phenomena, and we use them to generate and test predictions. Likewise, theories are our (variably) formalized answers to why and how things occur and, as such, they do, or they fail to, provide us with a sense of understanding about – or potential for effective control of – phenomena. So, for Charles, science goes as our theories go. Also, like Reynolds, Charles viewed scientific progress or the successful pursuit of these goals as occurring most efficiently through what is reminiscent of a Lakatosian process involving:\n\nObserving, describing, & making initial empirical generalizations about phenomena -&gt;\nDeveloping initial hypotheses, or what Charles endearingly called “simple theories,” that explain some of those descriptive patterns or empirical generalizations -&gt;\nRigorous testing of these (often numerous, varied, & competing) hypotheses or “simple theories” -&gt;\nSlow accumulation of knowledge from these tests; identification of additional generalizations & negative cases; and, ultimately, the development of new theories that better account for patterns observed in accumulated knowledge base through processes such as theoretical invention, elaboration, or integration.\n\nCharles most explicitly outlines his adherence to this philosophy in one of my favorite pieces of his – a chapter in Gilbert Geis & Mary Dodge’s wonderful 2002 book, Lessons of Criminology (see p.32-3), entitled “Confessions of a Reluctant but Committed Criminologist.” In it, he describes the eventual development of adequate theories ultimately is what will permit “explanation, prediction, and sometimes control of criminal/deviant or other human behavior.” He warns, a la Lakatos, that “[t]he whole process, however, is long and tedious, with knowledge growing in a cumulative process. One study means nothing; collections of large numbers and varieties of progressively more refined studies are required.” (p.33).\n\n\nLessons of a Reluctant but Committed Criminologist\nIn that Reflections chapter, Charles also described the first four important lessons of his academic career, which crystallized during his time on the faculty at Washington State University. Those are that:\n\nOur body of verified scientific knowledge is exceptionally weak\n[Theoretical] Science is the best model for criminological work\nBias is pervasive in social science, including criminology, & is an archenemy of knowledge\nRecommendations or guidelines from criminologists for social policy should be delayed until there is a strong scientific base of relevant knowledge\n\nCharles then states: “…to fully comprehend their import [of these four lessons] one must share certain definitions and orientations about the meaning of science.” That is, one must share a view of science as ideally involving the slow process of knowledge construction through careful observation, empirical generalization, explanation, testing, evolution of community consensus about the adequacy an explanation following accumulation of supporting and challenging test results, development of refined explanations under more general explanatory schemes or adequate theories, and rinse and repeat.\nCharles worked with intention according to these lessons. His strong dedication to theory development always involved frequent testing of others’ ideas; ultimately, these efforts also culminated in his magnum opus, Control Balance: Toward a General Theory of Deviance. His advocacy for theoretical science was readily apparent in his book, in his reactions to critics of the book, and in his later published refinements to control balance theory.\n\n\nCulmination in His Magnum Opus, Control Balance\nIn the first sentence of his published reply in Theoretical Criminology to John Braithwaite’s review of Control Balance, Charles summarized the dual aims of his book:\n\n“Control Balance… tries to do two things. One is to set forth a paradigm for theory building and the other is to present an exemplar to be used as a starting point for the application of that paradigm. An important theme contained within the paradigm is that theory must represent the collective efforts of the community of scholars. No specific theoretical effort should be owned by anybody, a specific formulation is always tentative, and theory cumulates and improves as many individuals add their ideas and the results of research to the enterprise…”\n\nThe paradigm he envisions here is a theoretical science of criminology oriented toward the collective, collaborative construction of causal process theories. The first half of Control Balance described this paradigm in detail. He started by illustrating both the utility and deficiencies inherent in existing “simple theories” of crime and deviance, thereby convincingly highlighting the need for a new paradigm such as his – and likely disaffecting at least as many readers as he convinced in the process. He then described core features of an adequate theory, calling for criminologists to work towards developing theories with sufficient breadth, comprehensiveness, precision, and depth. He subsequently argued that integration around central causal processes or mechanisms, as opposed to invention or elaboration, holds the greatest promise for collaborative efforts at effective theory development.\nI am convinced our field would benefit from widely disseminating these initial chapters as a touchstone by which we judge our ideas and organize our efforts. In particular, I think we really need collective commitment to improving the precision of our causal predictions – to “identifying the conditions that influence exactly when and to what degree causal processes will unfold, the nature of the causal effects, the time interval between the proposed causes and expected effects” (or timing, magnitude, and functional form), and other contingencies that specify the scope or conditions under which the causal processes and predictions are expected to vary.\nAdditionally, Charles thought our best chance at accumulating a meaningful body of scientific knowledge in criminology was for us to build a community of like-minded scholars dedicated to the same cause. Toward this end, foreshadowing post-replication crisis movements, Charles put forth provocative suggestions for a more collaborative peer review system (in The Criminologist), and he advocated for changes to our incentive structures and training regimes to foster theoretical science pursuits. For instance, in his 2002 Reflections chapter, Charles stated (p.33):\n\n“For science to operate and to produce the desired outcomes, it must be supported by a community of scholars dedicated to the scientific enterprise. This community of scholars must structure itself to reward those who follow its dictates and ignore those who do not, and it must socialize new members in the values and methods of science. Those values include dedication to: (1) knowledge gained through the scientific method, (2) objectivity, (3) the search for truth, (4) open discussion and sharing of information, and (5) skepticism and mutual criticism. Science, therefore, is not value free. It is absolutely committed to a value system – the values of science. Moreover, science is a jealous master, insisting that other values (ideology and personal commitments) be rejected or overcome, at least when attempting to do science.”\n\nCharles also insisted that, this being a difficult task, we scientists organize our community to check competing values by “insisting on review by demanding critics, rewarding those who work against their own personal interests and values, and granting prestige to those who most fully exhibit the ideals of science while stigmatizing those who betray the cause.” If we meet these ideals, Charles asserted that “science can lead to knowledge that is more reliable, satisfying, and useful than any other paradigm by which people seek to understand human behavior and social organization.” However, “practicing science is difficult, especially for those who study social phenomena.” So, “the best that we criminologists can do is to practice science to the fullest extent possible, recognizing that our work often falls short and being cautious in our claims.”\n\n\nBack to the Mansion\nHow did Charles think we criminologists are doing in this regard? Well, remember that mansion of science? I will refrain from elaborating on our self-derogatory conversations about which floors (or subfloors) our fields – sociology, criminology, & criminal justice – took up in the mansion. What I will say, though, is that over their final several years attending ASC, Charles and his close friend Jim Short would frequently lament about the diminishing number of ASC panels devoted specifically to theory compared to the burgeoning number of panels representing work within those other paradigms. Moreover, in our last conversations, Charles expressed much pessimism about the health of criminology and the future of theoretical development in our field.\nI certainly empathized with his viewpoint – much more so than I let him know in those conversations. However, I also pointed to various developments – such as emerging theoretical solutions to the replication crisis; advances in formal modeling; sophisticated theorizing and prediction in the Bayesian movement; and theoretical advancements tied to the counterfactual causal revolution – that I think hold much promise for interdisciplinary social science. He was also encouraged when I summarized Proctor & Niemeyer’s new book, Mechanistic Criminology, which (I think) in many ways represents a new generation of criminologists carrying Charles’ paradigmatic torch into exciting unexplored theoretical territory and, likewise, holds much promise for our field.\nMost importantly, across more than a half-century of scholarship, Charles practiced science to the fullest extent possible, he never failed to recognize that his work often fell short, and likewise he was consistently cautious in his claims. In doing so, he was perhaps most effective as a relentless advocate for theoretical science in criminology in leading us by example. His writings will live on in the scholarly record – with each of his individual studies meaning nothing on their own but, collectively, each contributing as “grist for the mill” of science in the long and tedious process of cumulative knowledge production. Additionally, likely without explicitly intending to do so, he built a community of like-minded scholars – including many of you in this room – who share his pursuit and, in doing so, make his journey and his immense sacrifices on the alter of science meaningful.\n\n\nCommunity Building by Example\nFinally, as a last testament to his advocacy and community building by example, I would like to close with quotes from a few students of Charles’ students – these are young scholars, a generation removed, most of whom never had the pleasure of meeting the man, the myth, the legend in black jeans and cowboy boots.\nAs these excerpts come from a list of longer quotes that I collected for a different purpose – to read to Charles as he neared the end – I have kept the authors’ names anonymous here. They are a small sample, but I think these effectively represent the legacy of influence that Charles Tittle has left with his students and colleagues.\nFirst, two assistant professors who never met Charles but had read Control Balance in a graduate course state that reading Control Balance theory reminded them:\n\n“of the creativity, effort, and time it takes to actually put forth a theory. Your review of previous criminological theories and their weaknesses to even set up Control Balance Theory shows how meticulous you were in theory building approach. In today’s race to publish, it is easy to lose sight of the difficulty and time it takes to develop a comprehensive framework for thinking about crime.”\n\nAn advanced doctoral student states that “Dr. Charles Tittle was the first scholar who was able to convince me of the value and power of theory and” that reading Control Balance “was, in the deepest sense of the word, enlightening.” After reading it, this student says:\n\n“I now think theory development and testing are some of the most important scientific endeavors social scientists can and should engage in–moreover, I find them the most intellectually satisfying! It turns out I love theory. His book, his articles, and even discussions with his former students influenced by his work have certainly shaped my trajectory as a student and a scholar. And I am certain that echoes of his influence will continue to shape the rest of my academic career.”\n\nAn advanced graduate student states that:\n\n“Control Balance had a tremendous influence on me… in illustrating and breaking down all the complexities that go into theory building and integration. We all know human behavior is a complicated phenomenon, but the way Control Balance looks at the integration of theories to build a general theory of crime and how it connects the numerous converging variables, which each exists on their own continuum, is just artistry. Dr. Tittle’s work really stuck with me in enumerating how much work we have ahead of us in our field (and in many other fields) to truly understanding the nature of crime and deviance. His call for the continued elaboration on his work really sets a precedence for how we as scholars should approach and encourage critiques, elaboration, and hopefully integration on our own work instead of falling into the time-old tradition of pure competition.”\n\nA newer doctoral student says that prior to reading Control Balance for a course:\n\n“I had not, in fact, taken any interest in theory construction or debate, believing it to be outside of my level of comprehension. Upon reading Control Balance, I realized that theory is not a tool that one can afford to overlook out of fear of dissonance and ambiguity. As an individual who has only just begun to break into the world of theoretical science…, your book could not have come to me at a better time. For that, I thank you and proudly take up your call toward better theory, debate, and collaboration…”\n\nFinally, an advanced doctoral student explains various lessons learned from Charles work:\n\n“…your [Reflections chapter] taught me that it is important to be nice in the work that we do (from your conversation with Dr. Short), that it is okay to do science for the sake of science, and not to be supremely concerned with policy relevance. Along similar lines, your article The Arrogance of Public Sociology taught me to employ healthy skepticism regarding research that is primarily public/policy driven. Additionally, your work on Control Balance Theory has helped me see where existing theories are deficient, how they can potentially be improved, and how complex it is to formulate a grand theory of deviant/criminal behavior.”\n\nThis student also reflected on how Charles’ legacy of mentorship was indirectly influential in teaching the importance of:\n\n“…increasing methodological rigor in research methodology/statistical analysis, creating a more transparent and cumulative science, being honest about things we do not know in the field, and an appreciation for the importance of testing and refining criminological theory. … I am forever grateful to you and cannot wait to pass on these principles to students of my own one day.”\n\nI could not have said that better myself. Thank you, Charles."
  },
  {
    "objectID": "blog-posts/[1]/welcome-blog.html",
    "href": "blog-posts/[1]/welcome-blog.html",
    "title": "Welcome to the reluctant criminologists",
    "section": "",
    "text": "Reluctant criminologists logo"
  },
  {
    "objectID": "blog-posts/[1]/welcome-blog.html#why-are-we-doing-this",
    "href": "blog-posts/[1]/welcome-blog.html#why-are-we-doing-this",
    "title": "Welcome to the reluctant criminologists",
    "section": "Why are we doing this?",
    "text": "Why are we doing this?\nFirst, this site is intended primarily as a central repository for conveniently sharing our course material and preliminary ideas with students and colleagues. It allows us to simply point people to a website rather than sending large html files via email or proliferating dropbox links. If it serves only this purpose effectively, we will be happy.\nSecond, this site is a direct consequence of our recent efforts to re-tool our approaches to doing science. We think this site will serve as evidence for how much we have learned - and likely as even stronger evidence of how much more we have yet to learn.\nOf course, this begs the question: Why have we been re-tooling our approaches to science? Well, answering that question requires a longer conversation with multiple threads, and we anticipate weaving some of those threads into our future blog posts. For now, it may be clear from our posted materials that we are motivated to act in response to increasing concerns about replication failures across multiple scientific disciplines and awareness of subsequent reforms. We are also motivated by the perception that our academic disciplines of sociology and criminology, with some exceptions, may be lagging behind other fields like psychology in self-reflection on these important issues and widespread adoption of potentially effective reforms. Likewise, we are moved by our own experiences with reproducing high-profile work and attempting to raise awareness through the traditional academic peer-review publication process about concerns regarding underpowered null hypothesis significance tests and common misinterpretations of null findings from such tests.\nIt is also fair to say that this site is indicative of early-mid-career crises of sorts brought on by other factors such as post-tenure malaise and serious reflections about what we are doing with our limited time in the aftermath of the global COVID-19 pandemic.\nIn fact, the initial idea for the blog emerged during the height of the pandemic in a long email thread between Jon and Jake. In a somewhat typical exchange, Jake was asking Jon to explain a relatively complex statistical topic (e.g., latent variable modeling in SEM vs. multilevel modeling). Jon was sharing resources, summarizing debates, and explaining issues that have been published on the topic across disparate statistical literatures over the years. Jake thought putting these types of discussions into a blog might be beneficial for multiple reasons. First, rather than burying this writing in emails, others might also appreciate such reviews or tutorials if they were available in a free, public-facing blog. Second, Jon seemed reluctant to write traditional academic articles on such topics since, from his perspective, they would be redundant - the reviews and debates are already out there, you just need to go read them (often in other fields). Meanwhile, Jon was receptive to the idea of a blog; he thought Jake should write more, and a blog might be a good way for both of them to spill ink and “try out” ideas under a critical public eye while perhaps even helping some students and colleagues along the way. So, here we are."
  },
  {
    "objectID": "blog-posts/[1]/welcome-blog.html#how-we-were-inspired-by-charles",
    "href": "blog-posts/[1]/welcome-blog.html#how-we-were-inspired-by-charles",
    "title": "Welcome to the reluctant criminologists",
    "section": "How we were inspired by Charles",
    "text": "How we were inspired by Charles\nThe name of our site pays homage to our late mentor and friend, Dr. Charles R. Tittle. It is meant to be a cheeky reference to his chapter entitled “Reflections of a Reluctant but Committed Criminologist” in Gilbert Geis and Mary Dodge’s Lessons of Criminology (pp.23-45).\nThis is one of our favorite pieces written by Charles. Our perspectives on the field of criminology and criminal justice were heavily shaped by Charles and are thus quite comparable to the views he presents in that chapter. Here is how that chapter starts (p.23):\n\n\n“I didn’t intend to become a criminologist. Rather, happenstance led me to investigate certain sociological problems that resulted in my being labeled a criminologist (Tittle, 1991). After a while the reactions of others had the effects that symbolic interactionist theory would predict - I began to think of myself as a criminologist, although one with a larger allegiance. In fact, one of the first conclusions I drew as a criminologist is that criminology ought not be thought of as a discipline. Disciplines have unifying perspectives; criminology does not. Criminology is an umbrella term encompassing diverse studies of crime and crime-relevant phenomena undertaken from many disciplinary points of view. It makes sense to speak of an economic perspective, a political perspective, a historical perspective, or a sociological perspective. It makes no sense to speak of a criminological, a criminal justice, or a criminal perspective (at least not in an academic context). In my mind, the best criminology is done by those with a firm grounding in some discipline, or by those with an appreciation of several different disciplines, the insights of which are then brought to bear on criminological issues.”\n\nThe chapter then proceeds to introduce several lessons that Charles learned throughout his illustrious career, which he later summarized as follows (pp.40-41):\n\n\nCriminology is not a discipline but a topical area dependent on a variety of disciplines and that criminological knowledge is best pursued and dispensed within the context of a liberal arts education\nOur methods of identifying and recruiting new scholars must be improved\nEvidence concerning most important issues having to do with crime and crime-relevant phenomena is weak; success requires that we commit ourselves to a long-range mission of improving that situation\nThings are more complicated than our extant theories show, calling for improved theories specifying contingent and interactive effects\nThe most effective criminology demands that we be aware of and committed to the goal of developing general explanatory schemes refined through test and feedback\nScience is the best model to follow in developing criminological knowledge\nWeak science, which is likely to continue to characterize criminology for some time, is hardly a basis for policy\nThe barriers to, and distractions from, good scientific criminology, especially the widespread practice of ad hoc work and the intrusion of personal biases and larger ideologies, must be countered\nCivility within the scholarly community is necessary for maximum collective effort\n\n\nIf you are interested in learning more about some of Charles Tittle’s intellectual contributions, check out our blog post on the topic, which contains comments delivered in a tribute panel for Charles at the 2021 American Society of Criminology annual meetings. To be clear, as we also note on our About page, we were inspired by Charles but he did not endorse this project in any way; in fact, he likely would have thought it was a waste of time better spent contributing in more traditional ways to scientific theory development and testing. We think it’s safe to say that we are both more “reluctant” and less “committed” criminologists than Charles was."
  },
  {
    "objectID": "blog-posts/[1]/welcome-blog.html#but-really-why-are-we-doing-this",
    "href": "blog-posts/[1]/welcome-blog.html#but-really-why-are-we-doing-this",
    "title": "Welcome to the reluctant criminologists",
    "section": "But really, why are we doing this?",
    "text": "But really, why are we doing this?\nIf we have a loftier aim for our site, it is to answer the call expressed in Charles’ lessons above by contributing modestly to the advancement of scientific criminology. In other words, this site is an attempt to help improve upon, even if just a little, what we perceive are systemic shortcomings in our respective fields.\nOf course, we are not alone - scholars raise similar concerns in other social scientific disciplines, including psychology, marketing, and evolutionary anthropology to name a few. Likewise, we benefit immensely from the contributions in blogs and bookdown projects shared freely for the collective good by so many people from various disciplinary perspectives working within and outside academia. We encourage you to check out our favorite links post for some excellent examples. Our hope is that this site might offer a comparable (derivative, bargain-basement) version that enriches conversations in our fields about how we can collectively strengthen our science through concerted efforts to improve our theories and the methods we use to generate knowledge about them.\nIn our own academic careers and scholarly pursuits, we continually try to improve our understanding of philosophies of science, substantive theories of crime and deviance, and quantitative methods used to test social scientific theories. Rather than solely bothering seemingly uninterested authors about these issues in the reviews we write for journals (we both now sign our reviews but the editors often take our names off), we thought we might as well put our thoughts out in public and subject them to criticism. Of course, we recognize the most likely outcome is that our thoughts, like in many of the reviews we write, will simply be (justifiably?) ignored. But we expect our own thinking on these matters will be strengthened by forcing ourselves to write them down and, ideally, by then accounting for your feedback.\nSo welcome to our blog! We’ll try to keep the navel gazing to a minimum from here on out."
  },
  {
    "objectID": "blog-posts/[11]/modmadness-pt3.html",
    "href": "blog-posts/[11]/modmadness-pt3.html",
    "title": "Moderator Madness, Part 3",
    "section": "",
    "text": "Two lemmings confused by exposure-mediator interactions (with help from DALL-E)\nThis is the third and final entry in a three-part blog series on modeling moderators in criminological data. In Part 1, I covered issues related to estimating and interpreting interaction effects with binary or skewed count outcome variables. In Part 2, I introduced counterfactual causality, exposure-mediator interactions, and a potential outcomes framework for conducting a four-way decomposition of a total effect into controlled direct effect (CDE), pure indirect effect (PIE), reference interaction (INTref), and mediated interaction (INTmed) components.\nIn this final entry, I illustrate how to use the CMAverse software package in R to conduct “causal mediation” analysis, which relies on the 4-way potential outcomes decomposition introduced in Part 2 to disentangle indirect and interaction effects in the presence of a potential exposure-mediator interaction. Along the way, I will also introduce the important assumptions required to interpret “causal mediation” results as estimates of causal effects."
  },
  {
    "objectID": "blog-posts/[11]/modmadness-pt3.html#do-i-really-need-to-learn-this",
    "href": "blog-posts/[11]/modmadness-pt3.html#do-i-really-need-to-learn-this",
    "title": "Moderator Madness, Part 3",
    "section": "Do I really need to learn this?",
    "text": "Do I really need to learn this?\nDo you ever examine interaction effects? If so, is it ever plausible that the hypothesized moderator also mediates the effect of the exposure (i.e., treatment or focal causal variable)?\nDo you ever test for indirect effects? If so, is it ever plausible that the hypothesized mediator also interacts with the exposure (treatment or focal causal) variable? In other words, is it possible that the exposure variable’s effect could differ across levels of the mediator, or is it possible that the mediator’s effect could differ across exposed and unexposed groups?\nDo you work with data (e.g., crime or delinquency counts) for which nonlinear modeling approaches (e.g., Poisson regression) are more appropriate than traditional linear regression procedures? When testing indirect effects with such data, do you find yourself making concessions (e.g., dichotomizing data or using linear models anyway) because the software programs you use to test for mediation are restricted to a limited set of specific (e.g., linear; logistic) distributions?\nIf you answered “YES” to any of the above questions, then you should probably learn about causal mediation procedures. If you said “NO” to the first two questions, consider the following footnote that I included in Part 2 of this series:\n\n“At this point, you might be wondering: ‘Do I really need to do this? The [insert] theory I am testing does not predict such an interaction!’ Well, failure to examine and adjust for the possibility of an exposure-mediator interaction is equivalent to forcing your model of the data generating process to conform to a strong and potentially incorrect theoretical assumption about underlying data generating processes.\nIn SEM parlance, it is equivalent to ‘fixing’ the effect of X on Y through M to be the same at all values of M. In situations where the effect of X on Y indeed varies across strata of M, failure to account for it could result in biased or incomplete inferences. In contrast, allowing for and decomposing a potential exposure-mediator interaction is, in SEM terms, akin to ‘freeing’ that parameter, thus permitting a test of that strong theoretical assumption. In situations where no such interaction exists, the magnitude of the interaction will approach zero, and traditional and ‘causal’ mediation approaches (e.g., ‘controlled’ and ‘natural’ effect estimates) will converge to the same values. In those situations, decomposition would be unnecessary yet nonetheless informative.\nIn short, there is substantial upside and little downside apart from learning the skills to testing and accounting for exposure-mediator interactions whether or not one exists, yet there are potentially substantial inferential risks to not doing so when one exists. So, just how a priori confident are you in that likely imprecise and discursive theory of yours?”\n\nIf you ever test moderation or mediation hypotheses, then it is generally a good idea to incorporate the evaluation of exposure-mediator interactions into your research workflow. The “causal mediation” approach I describe in this post is well-suited for this task. It is also generally applicable to a wide variety of data analytic situations and distributional types for exposures, mediators, and outcomes. For example, the CMAverse package in R introduced below can be applied to various combinations of continuous, binary, count, nominal, ordinal, and survival data."
  },
  {
    "objectID": "blog-posts/[11]/modmadness-pt3.html#sec-readfirst",
    "href": "blog-posts/[11]/modmadness-pt3.html#sec-readfirst",
    "title": "Moderator Madness, Part 3",
    "section": "Have you read Parts 1 and 2?",
    "text": "Have you read Parts 1 and 2?\nAt this point, I am assuming you read the first two entries in this series. In particular, I assume you understand the issues discussed in Part 1 pertaining to the conditional or “interactive” nature of model coefficients when nonlinear link functions are specified in generalized linear models. I also assume you understand the four-way total effect decomposition components (CDE; PIE; INTref; INTmed) described in Part 2.\nIf so, then you are ready to move on to a more realistic example of total effect decomposition using simulated data in R. For this example, I will rely primarily on the CMAverse package, which adopts a causal mediation approach to disentangling indirect and interaction effects in the presence of an exposure-mediator interaction. Though we took a long and winding road to arrive here, as I explained at the beginning of my Moderator Madness, Part 1 post, this is the goal that initially motivated the three-part blog series.\nBefore diving in, I should also explain that I wrote this example with social scientists in mind that already have some familiarity with “traditional” (e.g., Baron & Kenny steps; product of ab path coefficients) approaches to modeling mediation processes and are looking for a basic introduction to the less well known yet generally preferred “causal mediation” methods. If you find yourself in the position of testing or estimating indirect effects and unaware of the causal mediation approach, then I strongly encourage you to read more on the topic. There are lots of excellent summaries, overviews of software alternatives, and introductory primers on causal mediation and on CMAverse specifically. Additionally, the CMAverse quickstart website itself is a great place to start. If nothing else, I hope this entry serves as a segue for folks curious about advancing beyond traditional mediation tests by learning about causal mediation approaches.\nWithout further ado, let’s get to it!"
  },
  {
    "objectID": "blog-posts/[11]/modmadness-pt3.html#sec-DAG",
    "href": "blog-posts/[11]/modmadness-pt3.html#sec-DAG",
    "title": "Moderator Madness, Part 3",
    "section": "DAG of simulated data-generating processes",
    "text": "DAG of simulated data-generating processes\nFor this illustration, I will generate simulated data that are very similar to those found in Example 2 from my “Moderator Madness: Part 1” post. In that post, I stated:\n\nIn the second example, I assume that the true data generating process underlying both imaginary papers (i.e., “paper 1” and “paper 2” in our example above) is an integrated causal model in which moral beliefs is both a mediating and moderating mechanism. That is, in the simulated data for the second example, there is a true indirect effect of parental support on delinquency through strong moral beliefs as well as a direct effect of parental support on delinquency that varies systematically across levels of (i.e., “interacts with”) strong moral beliefs.\n\nThus, the simulated data here contain the same three focal variables. The exposure, parental support practices, is conceptualized as a variable measure of parental intervention(s) on youth attitudes and behaviors; it is generated here as a continuous, normally distributed, mean-centered variable. The mechanism, youths’ strong moral beliefs, is generated as a negatively skewed ordinal variable ranging from 0 to 5, which was created by reverse-scoring a truncated Poisson-distributed weak moral beliefs variable. The outcome, delinquency, is a positively skewed, Poisson-distributed event count variable ranging from 0 to a truncated theoretical maximum of 7.\nAgain, the simulated data will be generated using the following hypothetical causal mediation and moderation assumptions: Parental support practices are a somewhat effective cause of youth’s internalization of strong moral beliefs, and strong moral beliefs effectively cause fewer delinquent behavior events (i.e., they constrain temptations, promote resistance to, or encourage selection out of delinquency). Thus, the data generating processes include causal mediation or indirect effects of an exposure through a mechanism.\nAdditionally, parental support directly discourages or reduces involvement in youth delinquency.1 However, this effect varies across levels of the mechanism. Specifically, parental support’s negative effect on youth delinquency is most pronounced among youth with weak moral beliefs (i.e., low strong moral beliefs index scores); these youth are most at risk of engaging in delinquency, so effective parental interventions have the greatest potential to enact behavioral change among these youth. In contrast, youth with strong moral beliefs are highly unlikely to engage in delinquency irrespective of the degree of parental support they experience; therefore, parental support is largely ineffective among youth with the highest strong moral beliefs index scores. Since the effect of parental support on delinquency varies across levels of a mechanism (e.g., across youth with weak versus strong moral beliefs), then the data generating processes include moderation or interaction effects.\nMoreover, since parental support both operates indirectly through and interacts with youth’s strong moral beliefs, I expect the operation of an underlying exposure-mediator interaction in the data generating process. Recall, when we expect the existence of an additive exposure-mediator interaction, then part of the total effect of parental support might be attributable to a reference interaction, which involves an additive interaction that would occur when the mediator is observed even the absence of the exposure (e.g., if some youth internalize strong moral beliefs even in the absence of high parental support). Additionally, since parental support also partly causes strong moral beliefs, then parental support may be partly responsible for setting the very levels across which it variably or conditionally affects delinquency. Thus, part of the total effect of parental support on delinquency also might be attributable to a mediated interaction.2\nNow that the key variables and their underlying causal relationships have been discursively described, it is a good idea to generate a directed acyclic graph or DAG that concisely and formally communicates the causal assumptions about the data generating processes underlying our data simulation.\n\n\nShow code\n#|echo=FALSE\n\n#explicitly set graphics device to png(type=cairo) to knit ggblend plots properly\nknitr::opts_chunk$set(dev = \"png\", dev.args = list(type = \"cairo-png\"))\n\n\n\n\nShow code\nlibrary(tidyverse)\nlibrary(here)\nlibrary(simstudy)\n  # https://cran.r-project.org/web/packages/simstudy/vignettes/simstudy.html\n  # https://kgoldfeld.github.io/simstudy/articles/simstudy.html\nlibrary(ggplot2)\nlibrary(patchwork)\n# library(psych) #detach to ensure alpha works with ggplot\n  # library(devtools)\n  # install_github(\"jtextor/dagitty/r\")\nlibrary(dagitty)\nlibrary(ggdag)\nlibrary(truncnorm)\nlibrary(see)\n  # devtools::install_github(\"strengejacke/strengejacke\")\nlibrary(\"sjPlot\")\nlibrary(\"ggthemes\")\nlibrary(\"margins\")\nlibrary(\"ggdist\")\nlibrary(gt)\nlibrary(gtsummary)\nlibrary(ggraph)\nlibrary(CMAverse)\nlibrary(ggExtra)\nlibrary(ggeffects)\nlibrary(ggblend)\n\n\n\n\nShow code\n#function to shorten arrows (edges)\n# https://stackoverflow.com/questions/65420136/how-do-you-adjust-the-arrows-in-a-ggplot-of-a-ggdag\nshorten_dag_arrows &lt;- function(tidy_dag, proportion){\n# Update underlying ggdag object\ntidy_dag$data &lt;- dplyr::mutate(tidy_dag$data, \n                             xend = (1-proportion/2)*(xend - x) + x, \n                             yend = (1-proportion/2)*(yend - y) + y,\n                             xstart = (1-proportion/2)*(x - xend) + xend,\n                             ystart = (1-proportion/2)*(y-yend) + yend)\nreturn(tidy_dag)\n}\n\n# modified from Valeri & VanderWeele 2013, Fig.2 \n\n# causalDAG2 &lt;- dagify(\n#   Y ~ A + M + C1 + C2,\n#   M ~ A + C1 + C2,\n#   A ~ C1,\n#   exposure = \"A\",\n#   outcome = \"Y\",\n#   coords=list(\n#     x=c(A=1, M=1.5, Y=2, C1=1.5, C2=1.9),\n#     y=c(A=1, M=2, Y=1, C1=1.4, C2=1.75)\n#   )) %&gt;% tidy_dagitty() \n\n# change to simplified version from \n  # https://bs1125.github.io/CMAverse/articles/quickstart.html\n\ncausalDAG2 &lt;- dagify(\n  Y ~ A + M + C,\n  M ~ A + C,\n  A ~ C,\n  exposure = \"A\",\n  outcome = \"Y\",\n  coords=list(\n    x=c(A=1, M=1.5, Y=2, C=1.5),\n    y=c(A=1, M=2, Y=1, C=3)\n  )) %&gt;% tidy_dagitty()\n\n\n#shorten edges\ncausalDAG2p &lt;- shorten_dag_arrows(causalDAG2, 0.08)\n\n#create factor variable to isolate edge of interest, permits specifying edge color\ncausalDAG2p &lt;- causalDAG2p %&gt;% dplyr::mutate(\n  myedge1 = if_else(causalDAG2p$data$name == \"C\", \"yes\", \"no\"),\n  # myedge1 = if_else(causalDAG2p$data$name == \"C1\" | causalDAG2p$data$name == \"C2\",\n  #                   \"yes\", \"no\"), \n  modlinetype = ifelse(myedge1 == \"yes\", \"solid\", \"solid\") #change 2nd \"solid\" to \"dashed\" if desired\n  ) \n\n\n#plot dag\nfig4 &lt;- causalDAG2p %&gt;% ggplot(aes(x=x, y=y, xend=xend, yend=yend)) +\n  geom_dag_edges(aes(x = xstart, y = ystart, edge_color=myedge1, \n                     edge_linetype = modlinetype), show.legend = FALSE) +\n  geom_dag_text(label=c(\"A\\n(Parental\\nSupport)\", \"C\\n(Measured Confounders\\nNot Affected by Exposure)\", \"M\\n(Moral\\nBeliefs)\", \"Y\\n(Delinquency)\"), \n                color=\"#56B4E9\") +\n  theme_dag() + \n  guides(fill = 'none', color = 'none') +\n  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) +\n    #change default expansion on y-axis min & max\n  # ggtitle(\"Modified Figure 2 from Valeri & VanderWeele 2013\") + \n  scale_edge_colour_manual(values=c(\"darkgrey\", \"maroon\")) + \n  theme(plot.title = element_text(size = 12))\n\n\n\n\n\n\n\nFigure 1. DAG illustrating simulated data-generating process and ‘no unmeasured confounding’ assumptions underlying causal mediation. (Modified from Fig.2 in Valeri & VanderWeele 2013)"
  },
  {
    "objectID": "blog-posts/[11]/modmadness-pt3.html#sec-assumptions",
    "href": "blog-posts/[11]/modmadness-pt3.html#sec-assumptions",
    "title": "Moderator Madness, Part 3",
    "section": "“Causal mediation” assumptions",
    "text": "“Causal mediation” assumptions\nThe DAG above is a modified version of Part 1’s basic DAG, with a couple notable changes. First, I added common “causal mediation” notations to variable names, such as exposure label “A” to “Parental Support” variable. Second, I added “measured confounders” to the DAG. I made this change with the hopes of reminding readers that making causal inferences from results of “causal mediation” models (and from traditional mediation models) requires important, and perhaps untenable, assumptions about the lack of unmeasured sources of confounding of the X-M, M-Y, or X-Y relationships.3 Valeri and VanderWeele (2013) succinctly describe these essential assumptions:\n\n“…controlled direct effects require (a) no unmeasured treatment– outcome confounding and (b) no unmeasured mediator–outcome confounding. Natural direct and indirect effects require these assumptions and also (c) no unmeasured treatment-mediator confounding and (d) no mediator–outcome confounder affected by treatment.” (p.140)\n\nThey also describe a (regularly overlooked) challenge with meeting these assumptions even in randomized controlled trials:\n\n“It is important to note that randomizing the treatment is not enough to rule out confounding issues in mediation analysis. This is because randomization of the treatment rules out the problem of treatment–outcome and treatment-mediator confounding but does not guarantee that the assumption of no confounding of mediator– outcome relationship holds. This is because even if the treatment is randomized, the mediator generally will not be.” (p.140)\n\nResearch designs in criminology often violate some or all of these assumptions, thereby calling into question the appropriateness of causal interpretations of results. At the very least, I think we owe it to readers to routinely acknowledge such necessary causal assumptions and to transparently identify those assumptions that we think may be plausibly violated in our research designs. Beyond this, researchers can also consider conducting sensitivity analyses to determine the robustness of conclusions to assumption violations.\nIn this entry, I will not illustrate confounding adjustments or sensitivity checks. My primary goal here is to simply introduce the causal mediation approach as a generally preferred option over traditional (e.g., product of coefficients) approaches in situations where researchers have already decided that a mediation (or moderation) analysis is appropriate. Given these aims, the simulated example below is sufficiently complex for an introductory tutorial without also including confounding of the modeled relationships. However, once one is familiar with CMAverse code, terminology, and interpretation of results, it is pretty straightforward to extend this example by including and adjusting for measured confounders, and the various resources I have linked throughout will also provide readers with additional information about recommended sensitivity checks.4"
  },
  {
    "objectID": "blog-posts/[11]/modmadness-pt3.html#sec-terms",
    "href": "blog-posts/[11]/modmadness-pt3.html#sec-terms",
    "title": "Moderator Madness, Part 3",
    "section": "Terminology",
    "text": "Terminology\nBefore getting to the simulation, it is probably a good idea to introduce some minor changes in terminology and basic notation that you will encounter when using CMAverse to perform effect decomposition.\n\nVariables\nFirst, the focal variables are labeled as follows:\nExposure == A (Alternatively referred to as “X” in Part 2)\nMediator == M\nOutcome == Y\nConfounders == C (Ignored here, but choose wisely)\nThough I do not include confounders in this example, two types of outcome confounders are sometimes distinguished as C1 (exposure-outcome confounders) and C2 (mediator-outcome confounders). Note that there may also be potential confounding of the exposure-mediator relationship.\n\n\nControlled versus natural effects\nSecond, depending upon the model and options selected, the CMAverse output may contain terms that do not exactly match the four-way total effect decomposition components described in Part 2. I recommend reviewing those four components (CDE; PIE; INTref, INTmed) if needed as they are foundational to understanding CMAverse’s effect decomposition.\nDirect Effects: You should recognize the controlled direct effect (CDE). However, the CMAverse output may also contain estimates for a pure natural direct effect (PNDE) and a total natural direct effect (TNDE).\nIndirect Effects: Instead of encountering a pure indirect effect (PIE) estimate, the output might instead contain estimates for a pure natural indirect effect (PNIE) and a total natural indirect effect (TNIE).\nRecall, controlled direct effects hold the mediator constant at a specific value (M=m). For example, a controlled direct effect (CDE) might contrast expected outcomes across A=0 and A=1 while holding the mechanism constant at a specific value like M=0.\nUnderstanding natural effects requires comprehending and extending upon the counterfactual contrasts underlying the CDE described in Part 2. Remember that, in the presence of mediation, the mediator is expected to change as the exposure changes. So, setting the mediator to a constant value (e.g., M=0) may not provide a realistic or “natural” contrast. Natural effects allow the mediator to vary as it “naturally” would across exposure conditions, and they are then estimated by holding the mediator constant at specific counterfactual values that the mediator would be expected to take under specified exposure conditions.\nFor example, we might estimate a (pure) natural direct effect as a contrast in Y across exposure levels A=0 and A=1 when M is set to the level it is expected to be when we do[A=0] (i.e., M0). Modifying the notation used above, we can summarize this contrast as Y(do[A=1],do[MA=0]) - Y(do[A=0],do[MA=0]), or Y10 - Y00. You might notice that this overlaps with the notation presented in Part 2; however, that post presented simplified “natural” contrasts for the sake of clarity in explaining the basic decomposition components. It is important to realize, though, that do[MA=0] is not necessarily the same as setting M to m=0, unless the mechanism is expected to equal “0” when A=0.5\n\n\n\n“Natural” effects are estimated by allowing the mediator to vary as it naturally would across exposure conditions and then setting it to specific counterfactual values.\n\n\nYou can find more detailed descriptions elsewhere of the differences between controlled and natural effects. Once you wrap your head around these important distinctions between counterfactual contrasts and their relations to natural and controlled effects, then you may find yourself beginning to comprehend other important issues underlying mediation, moderation, and total effect decomposition.\nFirst, in a linear model without interactions (i.e., where INTref=0 and INTmed=0), the CDE estimates will not change across different values of M. Additionally, in such models, controlled and natural direct effects will converge on the same estimates. This is because doing A=1 (versus A=0) will have the same effect on Y at all values of M, so doing M=0 or doing MA=0 will generate the same direct effect estimate. This should become apparent in the examples using simulated data below.\nSecond, as you have probably figured out by now, things are not as straightforward in more complex models with nonlinear link functions or exposure-mediator interactions. For instance, when the effect of the exposure varies across levels of the mechanism, as it would in the presence of an exposure-mediator interaction, controlled (Y1m - Y0m) and natural (e.g., Y10 - Y00) direct effect estimates may vary as well. This, too, should become apparent in the examples below.\nThird, when there are nonlinearities or exposure-mediator interactions, one could conceivably estimate a different CDE for every possible value of M! This makes it impossible to perform effect decomposition in the presence of an interaction using controlled effects. However, the counterfactual contrasts underlying natural direct and indirect effect estimates are uniquely defined so there is a single value even in the presence of nonlinearities and exposure-mediator interactions. This permits us to perform effect decomposition even in those situations involving more complex causal relationships.\nPut differently, given the same exposure contrasts (e.g., setting astar=0 and a=1 in CMAverse models), changing the mediator value (e.g, from mval = list(0) to mval = list(1)) may result in different controlled direct effect estimates, but it will not change natural direct effect estimates. This may not be apparent in the examples below, but you can easily test it yourself (e.g., by copying my code, setting mval to different mediator values, and comparing results).\n\n\nPure versus total effects\nI just told you that there is only one natural direct and natural indirect effect. Yet, your CMAverse output will probably show more than one natural direct and indirect effect estimate! Do not lose trust in me just yet. It is more accurate to say that there is only one “pure” natural direct effect, and there is only one “total” natural direct effect estimate. So, what is the difference between “pure” and “total” effects?\nUltimately, the difference between “pure” and “total” effects comes down to the nonzero “mediated interaction” or INTmed estimate that we may find when there is an exposure-mediator interaction. Recall, the INTmed estimate describes how, in the presence of both mediation and moderation, we can contribute some differences in the effect of X on Y across different levels of M to the fact that X causes different levels of M. Well, when we decompose mediation and moderation components, should we attribute INTmed effects to mediation processes or to moderation processes?\nThat is, are INTmed effects best thought of as indirect effects, or are they best thought of as interaction effects? The secret to understanding the difference between “pure” and “total” effect estimates, and which specific ones you will want to interpret, lies in your answer to that question.\n\n\n\nWhen interpreting “pure” and “total” effects, remember the “total” cat won the fight over the INTmed component.\n\n\nFundamentally, INTmed effects are simultaneously indirect and interaction effects. However, depending upon your research question and estimand of interest, you may wish to attribute that INTmed component to the “direct” effect of X on Y at specific counterfactual values of M (i.e., absorbed into heterogeneous estimates of direct effects across values of M) or, instead, to the “indirect” effect of X on Y through M. In any case, there are a few important points to remember when interpreting these effects.\nFirst, “pure” effects do not include the INTmed component, whereas “total” effects do include the INTmed component. So, for instance, a “pure direct effect” does not contain any mediation components; rather, it purely summarizes the effect of X on Y that is due to its controlled direct effect (CDE) and any heterogeneity across M that is not due to mediation (i.e. attributed to INTref but not INTmed). Meanwhile, a “total indirect effect” contains all indirect effect sources, including the “pure” indirect effect (PIE) of X on Y through M and any interaction component that is due to mediation (i.e., INTmed).\nSecond, we always pair the following effect estimates:\n\nPure natural direct effect & total natural indirect effect (PNDE & TNIE)\nTotal natural direct effect & pure natural direct effect (TNDE & PNIE)\n\nThese pairings ensure that: (1) all mediation and moderation components (CDE; PIE; INTref; INTmed) are accounted for in the given pair, and (2) that the INTmed component is always counted once and only once, either in the (total) direct effect estimate or in the (total) indirect effect estimate. The table below shows which of the four decomposition components are included in each of the pure and total direct and indirect effect estimates.\n\n\n\nRelationship between 4-way effect decomposition and CMAverse effect estimates. Modified from Table 4 in Vanderweele 2014\n\n\nThird, since all four components of a total effect are accounted for in each of these two pairings of pure and total effects, each paired direct and indirect effect estimate essentially sums to the total effect of an exposure on an outcome. In fact, in a linear model, the PNDE + TNIE estimates quite literally will sum to the same value as the TNDE + PNIE estimates, and each of these pairs will sum to the total effect estimate. The pair you choose to interpret, then, depends upon your research question, goals, and estimand of interest.\nFourth, in the absence of an exposure-mediator interaction - such as when the interaction term equals zero or when you ignore a nonzero interaction term by not including it in the model - then the CDE, TNDE, and PNDE estimates all will converge to the same value. This is because the INTref and INTmed components are essentially fixed to zero in these situations, either by the data or by the researcher.\nThat’s enough talking. Let’s start walking with a simulation."
  },
  {
    "objectID": "blog-posts/[11]/modmadness-pt3.html#sec-simulate",
    "href": "blog-posts/[11]/modmadness-pt3.html#sec-simulate",
    "title": "Moderator Madness, Part 3",
    "section": "Simulate data",
    "text": "Simulate data\nI start by simulating n=3,000 observations, which should allow us to generate relatively precise estimates of each estimated component. We have more than enough going on; we do not need to deal simultaneously with issues related to particularly noisy estimates.\n\n\nShow code\n#|message=FALSE \n\noptions(scipen=0, digits = 3)\n\n# Simulate data (Sim.2)\n\nset.seed(1138)\nn &lt;- 3000\n\ndef2 &lt;- defData(varname = \"ParentSupport\", dist = \"normal\", \n               formula = 0, variance = 1)\ndef2 &lt;- defData(def2, varname = \"WeakMoralBlfs\", dist = \"poisson\",\n    formula = \"-.3 + (-.3)*ParentSupport\", link = \"log\")\ndef2 &lt;- defData(def2, varname = \"Delinquency\", dist = \"poisson\",\n    formula = \"-.7 + (-.25)*ParentSupport + .4*WeakMoralBlfs + \n    (-.15)*ParentSupport*WeakMoralBlfs\", link = \"log\")\ndef2 &lt;- defData(def2, varname = \"Delinquency2\", dist = \"poisson\",\n    formula = \"-.7 + (-.25)*ParentSupport + .4*WeakMoralBlfs + \n    (-.15)*ParentSupport*WeakMoralBlfs\", link = \"log\")\nsimdat2 &lt;- genData(n, def2)\n  #NOTE: Simulated alternative \"Delinquency2\" variable to illustrate interaction \n  # on linear estimation scale in nonlinear model\n\n# simdat2 %&gt;% sjPlot::view_df()\n# simdat2 %&gt;% \n#   ggplot(aes(x=WeakMoralBlfs, y=Delinquency)) +\n#   geom_point()\n\n# cap LowMoral at 5 (0-5 item) - randomly replace oob values with values in bounds \ninds2 &lt;- simdat2$WeakMoralBlfs &gt; 5\nsimdat2$WeakMoralBlfs[inds2] &lt;- sample(0:5, sum(inds2), replace = TRUE)\nsimdat2$StrgMoralBlfs &lt;- 5 - simdat2$WeakMoralBlfs\n\n# cap Delinquency at 7 (0-7 item) - randomly replace oob values with in bounds values\ninds2 &lt;- simdat2$Delinquency &gt; 7\nsimdat2$Delinquency[inds2] &lt;- sample(0:7, sum(inds2), replace = TRUE)\n\n# inds3 &lt;- simdat2$Delinquency2 &gt; 7\n# simdat2$Delinquency2[inds3] &lt;- sample(0:7, sum(inds3), replace = TRUE)\n  # Truncation minimizes relative interaction, so not truncate Delinquency2 \n  # increases relative differences on outcome scale for viz in final example\n\n# simdat2 %&gt;% sjPlot::view_df()\n# simdat2 %&gt;%\n#   ggplot(aes(x=WeakMoralBlfs, y=Delinquency)) +\n#   geom_point()\n\n#Even with n=10k, need to consider collapsing low values for StrgMoralBlfs and recenter to min=0\n#Raise points re: rare events & skewed data\n    # out of n=10k, 18.1% of cases have StrgMoralBlfs &lt;=3 \n      # (nrow(subset(simdat2, StrgMoralBlfs &lt;=3))/10000)*100\n    # out of n=10k, 1.02% (n=102) of cases have StrgMoralBlfs &lt;=1 \n      # (nrow(subset(simdat2, StrgMoralBlfs &lt;=1))/10000)*100\n    # out of n=10k, 0.17% (n=17) of cases have StrgMoralBlfs &lt;=0 \n      # (nrow(subset(simdat2, StrgMoralBlfs &lt;=1))/10000)*100\n\n#Collapse [0,1] values & recenter StrgMoralBlfs from 0-4\nsimdat3 &lt;- simdat2 %&gt;% \n  mutate(\n    StrgMoralBlfs = if_else(\n      StrgMoralBlfs &lt;= 1, 1, StrgMoralBlfs), \n    StrgMoralBlfs = StrgMoralBlfs - 1\n    )\n# summary(simdat3$StrgMoralBlfs)\n\np &lt;- ggplot(simdat3, aes(x = ParentSupport, y = StrgMoralBlfs)) +\n  geom_point(color=\"#E69F00\") +\n  theme_minimal()\n\n# Densigram\nggMarginal(p, type = \"densigram\", \n           fill=\"#E69F00\")\n\n\n\n\n\n\n\n\n\nThe plot above shows the joint distribution of the exposure (A=ParentSupport) and mechanism (M=StrgMoralBlfs). Notice the lack of observations in the bottom right of the plot, at the highest values of parental support (A&gt;2) and lowest values of strong moral beliefs (M=0). This pattern might be expected given the existence of mediation processes; that is, high parental support causes strong moral beliefs, so we might not expect to observe the lowest values of the mechanism at the highest exposure levels.\nNote, too, that there are observations with high mechanism values (e.g., strong moral beliefs, or M=4) across a wide range of exposure levels (e.g., from -2SD to +3SD levels of parent support). This means a nonzero INTref component is possible, since a nonzero reference interaction requires that the mechanism be present even in the absence (or, in this case, at low levels) of the exposure.\nFinally, there are relatively few observations at the lowest value (M=0) of the skewed, Poisson-distributed mechanism across the range of exposure levels. One consequence is that estimates of the causal effect of the exposure generated at the highest mechanism levels will be much noisier and more uncertain than those generated at the lowest mechanism levels. This is the case despite simulating a relatively large sample of n=3,000 observations. Assuming distributions of variables like moral beliefs and delinquency tend to be similarly skewed in the real world (and they are), you can imagine how much noisier and more uncertain such estimates might be in smaller real-world criminological samples."
  },
  {
    "objectID": "blog-posts/[11]/modmadness-pt3.html#sec-plots",
    "href": "blog-posts/[11]/modmadness-pt3.html#sec-plots",
    "title": "Moderator Madness, Part 3",
    "section": "Regressions & interaction plots",
    "text": "Regressions & interaction plots\nNow that I have simulated data resembling real-world self-reported criminological data, my next step will be to build regression models and then estimate and plot marginal effects of parental support on delinquency at different levels of strong moral beliefs to visualize any exposure-mediator interactions in these data.\nAs I explained in Part 1, I will want to build a generalized linear model with a nonlinear link function that can flexibly describe the data generating processes causing the skewed distributions and nonlinearities observed in the simulated data. Additionally, I will want to add an interaction term to that model to account for the possibility of an exposure-mediator interaction on the estimation scale.\nYet, I will start by presenting results from a simple linear interaction model. Why? Well, because so many researchers in our field seem to be most comfortable, if not outright obsessed, with simple linear models. What else explains our field’s collective unwillingness to move on from them?\n\n\nShow code\n#|message=FALSE \n\n# Sim.2 linear model\nlm2 &lt;- lm(Delinquency ~ ParentSupport * StrgMoralBlfs, data=simdat3)\n\n# Sim.2 nonlinear model\nglm2 &lt;- glm(Delinquency ~ ParentSupport * StrgMoralBlfs, data=simdat3, family=\"poisson\")\n\n\n# function for custom p-values\nroundp &lt;- function(x) {\n    if_else(\n      is.na(x), \n      NA_character_,\n      if_else(x &lt; 0.001, format(x, digits = 3, scientific = TRUE), format(round(x, 3), scientific = F))\n    )\n  } \n\n# function for reg output w/custom p-values\nregsum &lt;- function(mymod) {\n  tbl_regression(mymod, intercept=TRUE, pvalue_fun = roundp) %&gt;%\n  add_significance_stars(\n        hide_se = FALSE,\n        hide_ci = FALSE,\n        hide_p = FALSE\n      )\n}\n\n# Regression output\n\nEx2tab1 &lt;- regsum(lm2) %&gt;%\n  as_gt() %&gt;%\n  gt::tab_header(title = \"Linear regression predicting delinquency values\")\n\nEx2tab2 &lt;- regsum(glm2) %&gt;%\n  as_gt() %&gt;%\n  gt::tab_header(title = \"Poisson regression predicting delinquency event rates\")\n\n#Plot interactions \n  #plot at all four values: minimum (0), (1), median (2), and maximum (3) strong moral beliefs\n  #show x-axis from approx -2sd to 2sd parental support\nplot_lm2 &lt;- plot_model(lm2, type = \"pred\", show.data = FALSE,   \n                       terms = c(\"ParentSupport\", \"StrgMoralBlfs [0,2,4]\")) + \n  geom_hline(yintercept=7, linetype=\"dashed\") +\n  theme_minimal() + coord_cartesian(xlim=c(-2,2), ylim=c(-1,8)) +\n  scale_colour_colorblind() +\n  scale_fill_colorblind() +\n  labs(x=\"Parental Support\", \n       y=\"Delinquency\",\n       title=\"Predicted conditional marginal effects of parent support on delinquency\", \n       subtitle=\"Plotted at minimum (0), scale midpoint (2), & maximum (4) strong moral beliefs\\n(Linear regression, n=3k simulated observations)\")  \n\nplot_glm2 &lt;- plot_model(glm2, type = \"pred\",  show.data=FALSE,\n                       terms = c(\"ParentSupport\", \"StrgMoralBlfs [0,2,4]\")) + \n  geom_hline(yintercept=7, linetype=\"dashed\") +\n  theme_minimal() + coord_cartesian(xlim=c(-2,2), ylim=c(-1,8)) + \n  scale_colour_colorblind() +\n  scale_fill_colorblind() +\n  labs(x=\"Parental Support\", \n       y=\"Delinquency\",\n       title=\"Predicted conditional marginal effects of parent support on delinquency\", \n       subtitle=\"Plotted at minimum (0), scale midpoint (2), & maximum (4) strong moral beliefs\\n(Poisson regression, n=3k simulated observations)\")"
  },
  {
    "objectID": "blog-posts/[11]/modmadness-pt3.html#general-linear-interaction-model",
    "href": "blog-posts/[11]/modmadness-pt3.html#general-linear-interaction-model",
    "title": "Moderator Madness, Part 3",
    "section": "General linear interaction model",
    "text": "General linear interaction model\n\nGeneral linear interaction model resultsPrediction plotsPrediction plots with dataPrediction plots (min-to-max ParentSupport)Prediction plots with data (M=0 only)\n\n\n\n\nShow code\nEx2tab1\n\n\n\n\n\n\n\n\nLinear regression predicting delinquency values\n\n\nCharacteristic\nBeta1\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n2.1***\n0.068\n2.0, 2.3\n1.11e-190\n\n\nParentSupport\n-1.2***\n0.063\n-1.3, -1.1\n1.46e-72\n\n\nStrgMoralBlfs\n-0.42***\n0.020\n-0.46, -0.38\n9.17e-91\n\n\nParentSupport * StrgMoralBlfs\n0.26***\n0.019\n0.23, 0.30\n9.07e-43\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n#|message=FALSE \n\nplot_lm2\n\n\n\n\n\n\n\n\n\nShow code\n# plot_lm2 & \n#   theme(legend.position = 'bottom',\n#         legend.direction = 'horizontal') \n\n\n\n\n\n\nShow code\n#|message=FALSE \n\n\n#dev = \"png\" \n#dev.args = list(type = \"cairo-png\")\n\n#use ggeffects::ggpredict() to save plot_model data for use in ggplot \nlm2df &lt;- ggpredict(lm2, terms = c(\"ParentSupport\", \"StrgMoralBlfs [0,2,4]\"))\n\n#save subsets of simdat3 to plot observations where StrgMoralBlfs in (0,2,4)\nsimdat3sub &lt;- simdat3 %&gt;%\n  filter(StrgMoralBlfs %in% c(0,2,4)) %&gt;%\n  mutate(\n    StrgMoralBlfs = as_factor(StrgMoralBlfs))\n\n# prediction plot with data subset - use ggblend to improve overlap viz\npredplot1 &lt;- ggplot(data=simdat3sub, aes(x=ParentSupport, y=Delinquency, \n                            color=StrgMoralBlfs, group=StrgMoralBlfs)) + \n  geom_hline(yintercept=7, linetype=\"dashed\") +\n  # geom_point(data=simdat3sub[simdat3sub$StrgMoralBlfs == 0], alpha=0.4)  +\n  # geom_point(data=simdat3sub[simdat3sub$StrgMoralBlfs %in% c(2,4)], alpha=0.1) +\n  geom_point() |&gt; partition(vars(StrgMoralBlfs)) |&gt; blend(\"lighten\") |&gt;\n  blend(\"multiply\", alpha = 0.4)+\n  scale_colour_colorblind() +\n  scale_fill_colorblind() +\n  theme_minimal() + coord_cartesian(xlim=c(-2,2), ylim=c(-1,8)) + \n  geom_line(data=lm2df, aes(x=x, y=predicted,\n                             linetype=group, color=group), inherit.aes=FALSE) +  \n  geom_ribbon(data=lm2df, aes(x=x, y=predicted, \n                               ymin=conf.low, ymax=conf.high, fill=group), \n              alpha=0.3, inherit.aes=FALSE) +\n  scale_linetype_manual(values = c(\"solid\", \"solid\", \"solid\")) + \n  guides(linetype=\"none\", fill=\"none\") + \n  labs(x=\"Parental Support\",\n       y=\"Delinquency\",\n       title=\"Predicted conditional marginal effects of parent support on delinquency\", \n       subtitle=\"Plotted at minimum (0), scale midpoint (2), & maximum (4) strong moral beliefs\\n(Poisson regression, n=3k simulated observations)\") \n\npredplot1\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n#|message=FALSE \n\nplot_lm2 + \n  coord_cartesian(xlim=c(min(simdat3$ParentSupport), max(simdat3$ParentSupport)), \n                  ylim=c(-3,9)) + \n  labs(x=\"Parental Support\",\n       y=\"Delinquency\",\n       title=\"Predicted conditional marginal effects of parent support on delinquency\", \n       subtitle=\"Plotted across full range (min-to-max) of parental support values and\\nat minimum (0), scale midpoint (2), & maximum (4) strong moral beliefs\\n(Poisson regression, n=3k simulated observations)\") \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n#|message=FALSE\n\nggplot(data=simdat3sub, aes(x=ParentSupport, y=Delinquency, \n                            color=StrgMoralBlfs, group=StrgMoralBlfs)) + \n  geom_hline(yintercept=7, linetype=\"dashed\") +\n  geom_point(data=simdat3sub[simdat3sub$StrgMoralBlfs == 0], alpha=0.4)  +\n  scale_colour_colorblind() +\n  scale_fill_colorblind() +\n  theme_minimal() + coord_cartesian(xlim=c(-2,2), ylim=c(-1,8)) + \n  geom_line(data=lm2df, aes(x=x, y=predicted,\n                             linetype=group, color=group), inherit.aes=FALSE) +  \n  geom_ribbon(data=lm2df, aes(x=x, y=predicted, \n                               ymin=conf.low, ymax=conf.high, fill=group), \n              alpha=0.3, inherit.aes=FALSE) +\n  scale_linetype_manual(values = c(\"solid\", \"solid\", \"solid\")) + \n  guides(linetype=\"none\", fill=\"none\") + \n  labs(x=\"Parental Support\",\n       y=\"Delinquency\",\n       title=\"Predicted conditional marginal effects of parent support on delinquency\", \n       subtitle=\"Plotted at minimum (0) strong moral beliefs\\n(Poisson regression, n=3k simulated observations)\")\n\n\n\n\n\n\n\n\n\n\n\n\nHey, the linear interaction model detected a substantial interaction between parental support and moral beliefs! So far, so good, right? Not so fast. How well do you think the linear regression slopes describe the data and underlying data generating processes?\nI attempt to visualize this in the second figure above (third tab, entitled “Prediction Plots with Data”), which overlays the marginal effect prediction lines with a scatterplot of the relevant data (i.e., a subset of Strong Moral Beliefs values equal to “0”, “2”, and “4”). Close examination of this figure appears to reveal some areas of poor fit between the model’s linear predictions and the underlying data. Of particular concern are some out of bounds predictions below “0” on predicted delinquency counts (bottom right side of the plot). Of course, you expected some problems with a linear model because you read Part 1 entry.\nYet, what would happen if I were to use this particular linear interaction model to make predictions about delinquency values at higher exposure levels? After all, our maximum observed ParentSupport score is 3.6, but we are only plotting from about -2SD to +2SD values on this variable in the first figure. You can see what happens when I extend the prediction plot to the full observed (minimum to maximum) range of ParentSupport scores in the third figure (fourth tab) above.\nPerhaps unsurprisingly, the crossover interaction appears even more pronounced in this version of the plot. With the exception of predictions at the highest mechanism values (M=4), this model predicts negative delinquency counts at high observed exposure levels; of course, negative outcome scores were not observed and are not even logically possible in this case. As discussed in Part 1, these sorts of problematic model predictions are routinely generated as artifacts of inappropriately applying a linear model to nonlinear data.\nSpeaking of model issues, I often think regression results like these convey an illusory degree of precision around model-based estimates and predictions. To illustrate, check out the fourth figure (fifth tab) above, which overlays marginal predictions with a scatterplot of only the subset of observations for which M=0.\nIn this plot, notice the relative lack of observations at M=0 despite a relatively large sample (n=3,000 total)? I referenced this issue earlier after simulating the data. Now, look at the spread of the relatively sparse observations where M=0 (black dots), and compare the confidence interval bands for the M=0 prediction line (black line). Given the scarcity of data at this mechanism level and the fit of that line to the data points in the scatterplot, do you feel that these confidence bands effectively communicate the degree of uncertainty we should have with the predictions implied by that line? Perhaps you do, and I am simply a curmudgeon. In any case, this is another topic for a different entry.\nNow, let’s compare these results with those generated by a generalized linear model specifying a Poisson distributed outcome with a log link (aka, a “nonlinear” model)."
  },
  {
    "objectID": "blog-posts/[11]/modmadness-pt3.html#generalized-linear-poisson-nonlinear-interaction-model",
    "href": "blog-posts/[11]/modmadness-pt3.html#generalized-linear-poisson-nonlinear-interaction-model",
    "title": "Moderator Madness, Part 3",
    "section": "Generalized linear Poisson (“nonlinear”) interaction model",
    "text": "Generalized linear Poisson (“nonlinear”) interaction model\n\nNonlinear interaction model resultsPrediction plotsPrediction plots with dataPrediction plots with data (M=0 only)\n\n\n\n\nShow code\nEx2tab2\n\n\n\n\n\n\n\n\nPoisson regression predicting delinquency event rates\n\n\nCharacteristic\nlog(IRR)1,2\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n0.99***\n0.064\n0.86, 1.1\n9.75e-54\n\n\nParentSupport\n-0.38***\n0.047\n-0.47, -0.29\n1.08e-15\n\n\nStrgMoralBlfs\n-0.42***\n0.021\n-0.46, -0.38\n1.88e-90\n\n\nParentSupport * StrgMoralBlfs\n0.00\n0.016\n-0.03, 0.03\n0.963\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 IRR = Incidence Rate Ratio, SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n#|message=FALSE \n\nplot_glm2\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n#|message=FALSE \n\n#use ggeffects::ggpredict() to save plot_model data for use in ggplot \nglm2df &lt;- ggpredict(glm2, terms = c(\"ParentSupport\", \"StrgMoralBlfs [0,2,4]\"))\n\n#prediction plot with data subset & ggblend\npredplot2 &lt;- ggplot(data=simdat3sub, aes(x=ParentSupport, y=Delinquency, \n                            color=StrgMoralBlfs, group=StrgMoralBlfs)) + \n  geom_hline(yintercept=7, linetype=\"dashed\") +\n  # geom_point(data=simdat3sub[simdat3sub$StrgMoralBlfs == 0], alpha=0.4)  +\n  # geom_point(data=simdat3sub[simdat3sub$StrgMoralBlfs %in% c(2,4)], alpha=0.1) +\n  geom_point() |&gt; partition(vars(StrgMoralBlfs)) |&gt; blend(\"lighten\") |&gt;\n  blend(\"multiply\", alpha = 0.4) +\n  scale_colour_colorblind() +\n  scale_fill_colorblind() +\n  theme_minimal() + coord_cartesian(xlim=c(-2,2), ylim=c(-1,8)) + \n  geom_line(data=glm2df, aes(x=x, y=predicted,\n                             linetype=group, color=group), inherit.aes=FALSE) +  \n  geom_ribbon(data=glm2df, aes(x=x, y=predicted, \n                               ymin=conf.low, ymax=conf.high, fill=group), \n              alpha=0.4, inherit.aes=FALSE) +\n  scale_linetype_manual(values = c(\"solid\", \"solid\", \"solid\")) + \n  guides(linetype=FALSE, fill=FALSE) + \n  labs(x=\"Parental Support\",\n       y=\"Delinquency\",\n       title=\"Predicted conditional marginal effects of parent support on delinquency\", \n       subtitle=\"Plotted at minimum (0), scale midpoint (2), & maximum (4) strong moral beliefs\\n(Poisson regression, n=3k simulated observations)\") \n\npredplot2\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n#|message=FALSE \n\n#prediction plot with data subset & ggblend\npredplot2b &lt;- ggplot(data=simdat3sub, aes(x=ParentSupport, y=Delinquency, \n                            color=StrgMoralBlfs, group=StrgMoralBlfs)) + \n  geom_hline(yintercept=7, linetype=\"dashed\") +\n  geom_point(data=simdat3sub[simdat3sub$StrgMoralBlfs == 0], alpha=0.4)  +\n  scale_colour_colorblind() +\n  scale_fill_colorblind() +\n  theme_minimal() + coord_cartesian(xlim=c(-2,2), ylim=c(-1,8)) + \n  geom_line(data=glm2df, aes(x=x, y=predicted,\n                             linetype=group, color=group), inherit.aes=FALSE) +  \n  geom_ribbon(data=glm2df, aes(x=x, y=predicted, \n                               ymin=conf.low, ymax=conf.high, fill=group), \n              alpha=0.4, inherit.aes=FALSE) +\n  scale_linetype_manual(values = c(\"solid\", \"solid\", \"solid\")) + \n  guides(linetype=FALSE, fill=FALSE) + \n  labs(x=\"Parental Support\",\n       y=\"Delinquency\",\n       title=\"Predicted conditional marginal effects of parent support on delinquency\", \n       subtitle=\"Plotted at minimum (0) strong moral beliefs\\n(Poisson regression, n=3k simulated observations)\") \n\npredplot2b\n\n\n\n\n\n\n\n\n\n\n\n\nThe first thing you might notice is that the results tables show a statistically non-significant interaction term that is near-zero in magnitude on the estimation scale (logged delinquency event rates) in this model. Of course, after reading Part 1, you know better than to rely on the sign and significance of an interaction term from a generalized regression model with a nonlinear link function to draw inferences about model predictions on the outcome scale. Rather, you know it is a good idea to estimate and plot marginal effects, which I also do here.\nSecond, as with the linear model results, examination of marginal prediction plots appears to reveal an additive interaction pattern on the outcome scale (delinquency event rates). However, unlike the linear model results, the greater flexibility and appropriateness of the nonlinear functional form specified in this model permits a better fit between the marginal predictions and the data while also avoiding illogical negative delinquency predictions. The model is not perfect; for instance, we might wish to account for a threshold effect or censoring at the highest delinquency observations. Still, this model should be good enough for our purposes here."
  },
  {
    "objectID": "blog-posts/[11]/modmadness-pt3.html#sec-indirect",
    "href": "blog-posts/[11]/modmadness-pt3.html#sec-indirect",
    "title": "Moderator Madness, Part 3",
    "section": "Whither the indirect effect?",
    "text": "Whither the indirect effect?\nNow, for some in our field, documenting an additive interaction like this, whether generated with linear or nonlinear model specifications, would be deemed sufficient grounds for declaring a contribution to existing literature and for publishing a manuscript in a peer-reviewed journal. (Remember the hypothetical paper #2 from Part 1?)\n\nPart 1’s “Imaginary Paper #2”\nYet, note that this model does not seem to account for the possibility of an indirect effect of parental support on delinquency through the moderating mechanism. Moreover, since the exposure causes the mechanism, is the observed interaction an example of a “mediated interaction” (INTmed)? Or, is this an example of a reference interaction (INTref), or perhaps both? We will use CMAverse to answer this question soon, but you might be able to intuit the answer from prediction plots and with an understanding of what these two components represent that you gained from the toe-stubbing example in Part 2.\nBefore using CMAverse, I want to first illustrate a “traditional” approach to testing for indirect effects. Commonly, researchers in our field might use what is popularly known as the classic “Baron and Kenny” (1986) causal steps approach to detecting indirect effects. This “traditional” approach to testing mediation hypotheses usually involves estimating a series of regression models and then, depending upon the specific procedures adopted, estimating a “difference in coefficients” or “product of coefficients” representing causal path estimates (e.g., ab paths) paired with a test of significance. (See MacKinnon and colleagues’ 2002 paper, and especially their Table 1, for a summary of these traditional approaches).6\nFor this illustration, I will use psych::mediate() to estimate “traditional” direct and indirect effects of parental support on delinquency through moral beliefs. This package by default relies upon the “product of coefficients” estimation approach with bootstrapped standard errors, which is a very popular method in social sciences due perhaps to its status for years as the default method for testing indirect effects in SEM programs like Mplus as well as the increasing popularity of PROCESS modeling."
  },
  {
    "objectID": "blog-posts/[11]/modmadness-pt3.html#sec-traditional",
    "href": "blog-posts/[11]/modmadness-pt3.html#sec-traditional",
    "title": "Moderator Madness, Part 3",
    "section": "Traditional (ab) linear mediation model",
    "text": "Traditional (ab) linear mediation model\nTraditional product of coefficients approach\n\n\nShow code\npsych::mediate(Delinquency ~ ParentSupport + (StrgMoralBlfs), data = simdat3, n.iter = 2000) %&gt;% print(short = TRUE)\n\n\n\n\n\n\n\n\n\n\nMediation/Moderation Analysis \nCall: psych::mediate(y = Delinquency ~ ParentSupport + (StrgMoralBlfs), \n    data = simdat3, n.iter = 2000)\n\nThe DV (Y) was  Delinquency . The IV (X) was  ParentSupport . The mediating variable(s) =  StrgMoralBlfs .\n\nTotal effect(c) of  ParentSupport  on  Delinquency  =  -0.43   S.E. =  0.02  t  =  -21.6  df=  2998   with p =  9.9e-97\nDirect effect (c') of  ParentSupport  on  Delinquency  removing  StrgMoralBlfs  =  -0.33   S.E. =  0.02  t  =  -17.7  df=  2997   with p =  1.5e-66\nIndirect effect (ab) of  ParentSupport  on  Delinquency  through  StrgMoralBlfs   =  -0.1 \nMean bootstrapped indirect effect =  -0.1  with standard error =  0.01  Lower CI =  -0.12    Upper CI =  -0.08\nR = 0.53 R2 = 0.28   F = 580 on 2 and 2997 DF   p-value:  4.04e-297 \n\n To see the longer output, specify short = FALSE in the print statement or ask for the summary\n\n\nResults from the “traditional” mediation analysis show an indirect effect estimate of -0.10. You can calculate the indirect effect estimate yourself from the path diagram by multiplying the so-called a and b path coefficients, or (0.20)x(-0.48) = -0.10, hence the “product of coefficients” terminology.\nThe estimate is also statistically significant. Of course, with a simulated sample size of n=3,000, even modest non-zero estimates will be significant. You will rarely find us pointing to statistical significance as a useful information signal in our blog entries; that is a topic for another time.\nTo me, a better question here might be whether, given a causal indirect effect of this estimated magnitude, a change in exposure (e.g., from “0” to “1”) would be predicted to generate differences of substantively meaningful magnitudes on the outcome scale indirectly through a mechanistic change in the mediator. You might notice that our interaction plots above depicting predicted marginal effects provide us substantially greater leverage for answering this type of question.\nStill, we are on a mission here, so I will avoid the temptation to embark on a yet another tangent, this time about effect sizes. Instead, I will simply note that this indirect effect output and path diagram might be viewed as sufficient in our field to declare another contribution and submit yet another paper to the publication pile. (Remember hypothetical paper #1 from Part 1?)\n\nPart 1’s “Imaginary Paper #1”\nLet’s move to CMAverse, starting with a simple linear mediation model that reproduces key results from the “traditional” mediation approach."
  },
  {
    "objectID": "blog-posts/[11]/modmadness-pt3.html#sec-CMAlin-noint",
    "href": "blog-posts/[11]/modmadness-pt3.html#sec-CMAlin-noint",
    "title": "Moderator Madness, Part 3",
    "section": "Linear CMA model, no EMint",
    "text": "Linear CMA model, no EMint\nBelow, I use the cmest() function from the CMAverse R package. Specifying the mediator and outcome distributions (mreg and yreg) as “linear” and setting the exposure-mediator coefficient (EMint) to “FALSE” makes this model equivalent to the traditional mediation model above.\n\n\nShow code\nset.seed(1138)\nest2 &lt;- cmest(data = simdat3, model = \"rb\", outcome = \"Delinquency\", exposure = \"ParentSupport\",\n                mediator = \"StrgMoralBlfs\", EMint = FALSE,\n                mreg = list(\"linear\"), yreg = \"linear\",\n                astar = 0, a = 1, mval = list(0),\n                estimation = \"imputation\", inference = \"bootstrap\", nboot = 20)\n\n\n\nResults: linear no EMintDefault plot: linear no EMintFull output: linear no EMint\n\n\n\n\nShow code\nest2dat &lt;- as.data.frame(est2$effect.pe) %&gt;% rownames_to_column(\"CMA_est\") \n\n\nest2dattab &lt;- est2dat %&gt;%\n  add_column(\n    trad_est = c(\"direct\", \"--\", \"--\", \"indirect\", \"--\", \"total\", \"prop_med\"), \n    estimate = c(-.33, NA, NA, -.10, NA, -.43, .23)) %&gt;%\n  rename(\"linear_noEM\" = \"est2$effect.pe\") %&gt;% \n  relocate(trad_est, estimate) \n\nest2dattab %&gt;%\n  gt() %&gt;% \n    tab_spanner(label = html(\"CMAverse&lt;br&gt;(linear)\"), columns = c(\"CMA_est\", \"linear_noEM\")) %&gt;%\n    tab_spanner(label = html(\"Traditional&lt;br&gt;(linear)\"), columns = c(\"trad_est\",\"estimate\")) %&gt;%\n    cols_add('blank' = '', .after = 'estimate') %&gt;%\n    cols_label('blank' = md('&emsp;&emsp;&emsp;'),\n               trad_est = \"effect\", \n               CMA_est = \"effect\",\n               estimate = \"estimate\",\n               linear_noEM = html(\"No_EMint&lt;br&gt;estimate\")\n               )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraditional\n(linear)\n   \nCMAverse\n(linear)\n\n\neffect\nestimate\neffect\nNo_EMint\nestimate\n\n\n\n\ndirect\n-0.33\n\ncde\n-0.327\n\n\n--\nNA\n\npnde\n-0.327\n\n\n--\nNA\n\ntnde\n-0.327\n\n\nindirect\n-0.10\n\npnie\n-0.101\n\n\n--\nNA\n\ntnie\n-0.101\n\n\ntotal\n-0.43\n\nte\n-0.428\n\n\nprop_med\n0.23\n\npm\n0.235\n\n\n\n\n\n\n\n\n\n\n\nShow code\nggcmest(est2) +\n  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 30, vjust = 0.8)) \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\nsummary(est2)\n\n\nCausal Mediation Analysis\n\n# Outcome regression:\n\nCall:\nglm(formula = Delinquency ~ ParentSupport + StrgMoralBlfs, family = gaussian(), \n    data = getCall(x$reg.output$yreg)$data, weights = getCall(x$reg.output$yreg)$weights)\n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     2.4282     0.0668    36.4   &lt;2e-16 ***\nParentSupport  -0.3273     0.0185   -17.7   &lt;2e-16 ***\nStrgMoralBlfs  -0.4890     0.0200   -24.4   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.969)\n\n    Null deviance: 4028.6  on 2999  degrees of freedom\nResidual deviance: 2904.8  on 2997  degrees of freedom\nAIC: 8425\n\nNumber of Fisher Scoring iterations: 2\n\n\n# Mediator regressions: \n\nCall:\nglm(formula = StrgMoralBlfs ~ ParentSupport, family = gaussian(), \n    data = getCall(x$reg.output$mreg[[1L]])$data, weights = getCall(x$reg.output$mreg[[1L]])$weights)\n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     3.2145     0.0164   195.9   &lt;2e-16 ***\nParentSupport   0.2061     0.0165    12.5   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.807)\n\n    Null deviance: 2546.9  on 2999  degrees of freedom\nResidual deviance: 2420.6  on 2998  degrees of freedom\nAIC: 7876\n\nNumber of Fisher Scoring iterations: 2\n\n\n# Effect decomposition on the mean difference scale via the regression-based approach\n \nDirect counterfactual imputation estimation with \n bootstrap standard errors, percentile confidence intervals and p-values \n \n     Estimate Std.error  95% CIL 95% CIU  P.val    \ncde  -0.32727   0.02071 -0.35504  -0.285 &lt;2e-16 ***\npnde -0.32727   0.02071 -0.35504  -0.285 &lt;2e-16 ***\ntnde -0.32727   0.02071 -0.35504  -0.285 &lt;2e-16 ***\npnie -0.10078   0.01025 -0.11819  -0.084 &lt;2e-16 ***\ntnie -0.10078   0.01025 -0.11819  -0.084 &lt;2e-16 ***\nte   -0.42805   0.02439 -0.46258  -0.371 &lt;2e-16 ***\npm    0.23545   0.01995  0.20332   0.275 &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(cde: controlled direct effect; pnde: pure natural direct effect; tnde: total natural direct effect; pnie: pure natural indirect effect; tnie: total natural indirect effect; te: total effect; pm: overall proportion mediated)\n\nRelevant variable values: \n$a\n[1] 1\n\n$astar\n[1] 0\n\n$mval\n$mval[[1]]\n[1] 0\n\n\n\n\n\nFirst, looking at the results, you will notice that all the CMAverse direct effect estimates are equivalent (i.e., CDE = PNDE = TNDE), and that both indirect effect estimates are equivalent as well (PNIE = TNIE). This is because we set EMint=FALSE, which means we did not specify an exposure-mediator interaction. Of course, this does not mean there is no exposure-mediator interaction in the data. On the contrary, we simulated the data to include one! Rather, it just means we ignored the possibility by essentially fixing the exposure-mediator interaction parameter to equal “0” in our model.\nThis is also what happens by default in the traditional “product of coefficients” mediation approach. In fact, you can see the estimates from both approaches converge in this case; that is, the “traditional” direct, indirect, and total effect estimates are equivalent to the comparable CDE, PNIE, and TE effect estimates from the CMAverse model.\nThe “pm” or “prop_med” estimates refer to “proportion mediated” or the proportion of the total effect attributable to mediation. Though they are included here to show equivalence across traditional and CMAverse output, as explained later, I will not focus much on proportion measures in this entry.\nAlso, with an exposure variable with more than two levels, note that I could have defined different meaningful contrasts (e.g., -1SD vs. 1SD; max vs. min). Recall that ParentSupport is simulated as a standardized exposure variable, so by setting astar=0 and a=1, I am specifying the exposure contrast as the predicted difference in Y at mean parental support values (ParentSupport=0) and +1SD parental support values (ParentSupport=1). The setting mval = list(0) indicates that I want controlled direct effect estimates to be calculated at m=0 (StrgMoralBlfs=0).\nYou might also wonder why confidence intervals are asymmetric around point estimates in these tables and plots. This is because “bootstrap” is the default inference method for estimating standard errors and confidence intervals in CMAverse. Unlike the well-known “delta” method (available for some models), which calculates confidence intervals using approximations to a normal distribution, this method estimates percentile-based confidence intervals using the standard deviations of estimates from bootstrapped samples. Since indirect effect estimators (e.g., ab product term or potential outcomes resampling procedures) are known to generate non-normally distributed estimates, bootstrapped confidence intervals are generally preferred in mediation tests because they better represent the asymptotic distributions generated by indirect effect estimators."
  },
  {
    "objectID": "blog-posts/[11]/modmadness-pt3.html#sec-CMAlin-int",
    "href": "blog-posts/[11]/modmadness-pt3.html#sec-CMAlin-int",
    "title": "Moderator Madness, Part 3",
    "section": "Linear CMA model, with EMint",
    "text": "Linear CMA model, with EMint\nNow, let’s estimate another linear model in CMAverse but instead allow for the possibility of an exposure-mediator interaction by setting EMint=TRUE.\n\n\nShow code\nset.seed(1138)\nest3 &lt;- cmest(data = simdat3, model = \"rb\", outcome = \"Delinquency\", exposure = \"ParentSupport\",\n                mediator = \"StrgMoralBlfs\", EMint = TRUE,\n                mreg = list(\"linear\"), yreg = \"linear\",\n                astar = 0, a = 1, mval = list(0),\n                estimation = \"imputation\", inference = \"bootstrap\", nboot = 20)\n\n\n\nResults: linear with EMintDefault plot: linear with EMintCustom plot: linear with EMintFull output: linear with EMint\n\n\n\n\nShow code\nest3dat &lt;- as.data.frame(est3$effect.pe) %&gt;% rownames_to_column(\"CMA_est\") \n\nest3dattab &lt;- full_join(est2dattab, est3dat, by=\"CMA_est\") %&gt;%\n  rename(\"linear_EM\" = \"est3$effect.pe\") %&gt;%\n  filter(!CMA_est %in% c(\"cde(prop)\", \"intref(prop)\", \"intmed(prop)\", \n                          \"pnie(prop)\", \"pm\", \"int\", \"pe\")) %&gt;%\n  mutate(\n    trad_est = if_else(is.na(trad_est), \"--\", trad_est)\n  )\n\nest3dattab %&gt;%\n  gt() %&gt;% \n    tab_spanner(label = html(\"CMAverse&lt;br&gt;(linear)\"), \n                columns = c(\"CMA_est\", \"linear_noEM\", \"linear_EM\")) %&gt;%\n    tab_spanner(label = html(\"Traditional&lt;br&gt;(linear)\"), columns = c(\"trad_est\",\"estimate\")) %&gt;%\n    cols_add('blank' = '', .after = 'estimate') %&gt;%\n    cols_label('blank' = md('&emsp;&emsp;&emsp;'),\n               trad_est = \"effect\", \n               CMA_est = \"effect\",\n               estimate = \"estimate\",\n               linear_noEM = html(\"No_EMint&lt;br&gt;estimate\"),\n               linear_EM = html(\"EMint&lt;br&gt;estimate\")\n               )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraditional\n(linear)\n   \nCMAverse\n(linear)\n\n\neffect\nestimate\neffect\nNo_EMint\nestimate\nEMint\nestimate\n\n\n\n\ndirect\n-0.33\n\ncde\n-0.327\n-1.1747\n\n\n--\nNA\n\npnde\n-0.327\n-0.3325\n\n\n--\nNA\n\ntnde\n-0.327\n-0.2784\n\n\nindirect\n-0.10\n\npnie\n-0.101\n-0.0864\n\n\n--\nNA\n\ntnie\n-0.101\n-0.0322\n\n\ntotal\n-0.43\n\nte\n-0.428\n-0.3647\n\n\n--\nNA\n\nintref\nNA\n0.8422\n\n\n--\nNA\n\nintmed\nNA\n0.0541\n\n\n\n\n\n\n\n\n\n\n\nShow code\nggcmest(est3) +\n  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 30, vjust = 0.8)) \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n#save estimates and intervals data\nest3dat &lt;- as.data.frame(est3[9:12]) %&gt;%\n  rownames_to_column(\"CMA_est\")\n\n\n# drop proportion estimates\nest3dat %&gt;%\n  filter(!CMA_est %in% c(\"pm\", \"pe\", \"pnie(prop)\", \"intref(prop)\",\"intmed(prop)\",\"cde(prop)\", \"int\")) %&gt;%\n  mutate(CMA_est = factor(CMA_est, levels=c(\"intmed\", \"intref\", \"te\", \"tnie\", \"pnie\", \"tnde\", \"pnde\", \"cde\"))) %&gt;%\n  # reorder the coefficients so that the largest is at the top of the plot\n  # mutate(term = fct_reorder(CMA_est, effect.pe)) %&gt;%\n  ggplot(aes(effect.pe, CMA_est)) +\n  geom_point() + \n  geom_errorbarh(aes(xmin = effect.ci.low, xmax = effect.ci.high), height = .1) +\n  # add in a dotted line at zero\n  geom_vline(xintercept = 0, lty = 2) +\n  labs(\n    x = \"Estimated effects on linear difference scale\",\n    y = NULL,\n    title = \"Effect estimates from causal mediation decomposition\"\n  ) + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\nsummary(est3)\n\n\nCausal Mediation Analysis\n\n# Outcome regression:\n\nCall:\nglm(formula = Delinquency ~ ParentSupport + StrgMoralBlfs + ParentSupport * \n    StrgMoralBlfs, family = gaussian(), data = getCall(x$reg.output$yreg)$data, \n    weights = getCall(x$reg.output$yreg)$weights)\n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                   2.1496     0.0678    31.7   &lt;2e-16 ***\nParentSupport                -1.1747     0.0634   -18.5   &lt;2e-16 ***\nStrgMoralBlfs                -0.4190     0.0200   -20.9   &lt;2e-16 ***\nParentSupport:StrgMoralBlfs   0.2626     0.0189    13.9   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.911)\n\n    Null deviance: 4028.6  on 2999  degrees of freedom\nResidual deviance: 2728.2  on 2996  degrees of freedom\nAIC: 8239\n\nNumber of Fisher Scoring iterations: 2\n\n\n# Mediator regressions: \n\nCall:\nglm(formula = StrgMoralBlfs ~ ParentSupport, family = gaussian(), \n    data = getCall(x$reg.output$mreg[[1L]])$data, weights = getCall(x$reg.output$mreg[[1L]])$weights)\n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     3.2145     0.0164   195.9   &lt;2e-16 ***\nParentSupport   0.2061     0.0165    12.5   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.807)\n\n    Null deviance: 2546.9  on 2999  degrees of freedom\nResidual deviance: 2420.6  on 2998  degrees of freedom\nAIC: 7876\n\nNumber of Fisher Scoring iterations: 2\n\n\n# Effect decomposition on the mean difference scale via the regression-based approach\n \nDirect counterfactual imputation estimation with \n bootstrap standard errors, percentile confidence intervals and p-values \n \n              Estimate Std.error   95% CIL 95% CIU  P.val    \ncde          -1.174713  0.111557 -1.393855  -1.036 &lt;2e-16 ***\npnde         -0.332465  0.016572 -0.354123  -0.297 &lt;2e-16 ***\ntnde         -0.278356  0.013193 -0.295906  -0.252 &lt;2e-16 ***\npnie         -0.086354  0.007336 -0.098157  -0.074 &lt;2e-16 ***\ntnie         -0.032245  0.006340 -0.037651  -0.018 &lt;2e-16 ***\nte           -0.364710  0.014081 -0.380222  -0.331 &lt;2e-16 ***\nintref        0.842248  0.099992  0.722433   1.046 &lt;2e-16 ***\nintmed        0.054109  0.008268  0.042002   0.067 &lt;2e-16 ***\ncde(prop)     3.220949  0.264090  2.949594   3.800 &lt;2e-16 ***\nintref(prop) -2.309362  0.249934 -2.851880  -2.049 &lt;2e-16 ***\nintmed(prop) -0.148362  0.020618 -0.180025  -0.120 &lt;2e-16 ***\npnie(prop)    0.236775  0.018755  0.209000   0.273 &lt;2e-16 ***\npm            0.088413  0.018417  0.047611   0.107 &lt;2e-16 ***\nint          -2.457724  0.267019 -3.026326  -2.169 &lt;2e-16 ***\npe           -2.220949  0.264090 -2.800203  -1.950 &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(cde: controlled direct effect; pnde: pure natural direct effect; tnde: total natural direct effect; pnie: pure natural indirect effect; tnie: total natural indirect effect; te: total effect; intref: reference interaction; intmed: mediated interaction; cde(prop): proportion cde; intref(prop): proportion intref; intmed(prop): proportion intmed; pnie(prop): proportion pnie; pm: overall proportion mediated; int: overall proportion attributable to interaction; pe: overall proportion eliminated)\n\nRelevant variable values: \n$a\n[1] 1\n\n$astar\n[1] 0\n\n$mval\n$mval[[1]]\n[1] 0\n\n\n\n\n\nFirst, a comparison of the tabled results reveals substantial differences in estimates across the linear models with and without an “EMint” term. This is a signal that there is a non-negligible exposure-mediator interaction in these simulated data. Recall, the initial EMint=FALSE specification forced our model to fit a constant effect of parental support on delinquency across all values of moral beliefs. In contrast, specifying EMint=TRUE made the model more flexible by permitting it to fit different conditional average linear effects of parental support on delinquency across values of strong moral beliefs. If no such differences in effects had existed in the data, the linear interaction term would have been near zero, and both sets of linear model results would have converged.7\nSecond, when we ignored the exposure-mediator interaction (i.e, by using traditional ab method or by setting EMint=FALSE in CMAverse), the “proportion mediated” estimate was about 24%. After allowing for the possibility of a nonzero exposure-mediator interaction (with EMint=TRUE), the proportion mediated estimate dropped to 7.2%. What happened? Did the indirect effect shrink after including the interaction term?\nTo understand what is happening here, recall the “TNIE” component, which represents the “total” indirect effect of X on Y through M, is a composite measure of the total indirect effect comprised of both the “pure” indirect effect component (PNIE) and the part of an exposure-mediator interaction that is due to mediation (INTmed). Now, check out the PNIE and INTmed effect estimates, which are similar in magnitude but in opposite directions. As a result, these two indirect effect components largely cancel each other out (-0.09 vs. 0.06), resulting in a very small “total” natural indirect effect estimate (TNIE) and, likewise, a small proportion mediated estimated (PM = TNIE/TE). Meanwhile, the proportion of the total effect that is due to the pure indirect effect (PNIE) remains approximately 24%.\nSimilarly, the results also show negative direct effect estimates (CDE; PNDE) and a positive reference interaction (INTref) effect. The presence of such non-monotonic effect estimates, or effects operating in different directions, undermines the utility of “proportion mediated” estimates. While proportion mediated estimators can be useful for interpreting relative contributions of components under certain assumptions and conditions (e.g., no opposite-signed direct or indirect effects), too often those assumptions are untenable and, when they are, the properties of these estimators become unreliable. For this reason and others,8 I will exclude most proportion estimates (except proportion mediated or PM) in custom tables and plots and will largely avoid discussing proportion estimates moving forward.\nThird, notice that the CDE(M=0) estimate is much larger and is no longer equivalent to the PNDE or TNDE estimates in the linear model with EMint=TRUE. This is because the effect of parental support varies across values of the mediator, and we estimated the CDE at M=0, or at the lowest value of strong moral beliefs, where the effect of parental support is strongest. You can see this in the regression prediction plots presented earlier. In fact, if you look closely at the linear prediction plot, you will notice that the slope of the “M=0” line is equivalent to the CDE estimate from this model (CDE = -1.17); that is, with a ParentSupport change from “0” to “1” units, delinquency is predicted to change by -1.17 units. To help visualize this, I regenerated the linear prediction plot from earlier and added lines to help visualize the slope of this CDE estimate.\n\n\nShow code\n#|message=FALSE \n\nsegdat &lt;- data.frame(x1 = 0, x2 = 1, x3 = .55, x4 = .05, \n                     y1 = .8, y2 = 2.03, y3 = 2.45, y4 = 1.6)\n\nplot_lm2 +\n  geom_segment(aes(x = segdat$x1, y = segdat$y1, xend = segdat$x2, yend = segdat$y1), \n               color = \"maroon\", linewidth = 1.5) + \n  geom_segment(aes(x = segdat$x1, y = segdat$y1, xend = segdat$x1, yend = segdat$y2),\n               col = \"maroon\", linewidth = 1.5) + \n  geom_segment(aes(x = segdat$x3, y = segdat$y3, xend = segdat$x4, yend = segdat$y4),\n               col = \"maroon\", linewidth = .5) + \n  annotate(\"text\", x=.6, y=2.5, label= \"CDE(M=0) = -1.17\", col = \"maroon\", \n           fontface = \"bold\", hjust=0) \n\n\n\n\n\n\n\n\n\nLooking at this plot, I am hoping it is clear that the magnitude of the CDE estimate would have been much smaller or even negligible if we had instead estimated it at a different level of strong moral beliefs (e.g., M=4).\nUnlike the CDE, the PNDE estimate remains largely unchanged across the linear models that do and do not specify an exposure-mediator interaction. Substantively, the PNDE indicates that doing a=1 instead of astar=0, or increasing from mean levels of parental support to one-SD unit above the mean levels of parental support, is predicted to reduce delinquency by -0.33 units on the linear difference scale in the absence of the exposure. However, recall that PNDE is estimating Y1MA=0 - Y0MA=0 or setting M to value it is expected to be when A=0. So, changing the exposure contrast, say, to astar=-1 and a=0, would change the PNDE because it would change the value at which M is set (e.g., estimating Y1MX=-1 - Y0MX=-1 instead); in contrast, changing the exposure contrast would have no effect on the CDE(M=0) in a linear model.\nFourth, recall that in a linear model, the sum of PIE and TNIE estimates should equal the sum of the TNDE and PNIE estimates, and each of these sums should equal to the total effect (TE) estimate. I explained this before; you can check to see that it holds true here.\nFifth, notice how small in magnitude the pure indirect (PNIE) and mediated interaction (INTmed) components are relative to the pure natural direct (PNDE) and reference interaction (INTref) components. Though there is some evidence of mediation in these simulated data, it would seem that parental support primarily causes delinquency directly and conditionally via unmediated interaction with strong moral beliefs.\nFinally, I hope one lesson is apparent by now: If you wish to interpret any of these estimates, or indirect and interaction effects generally, then it is important to know precisely what each estimate means,9 which causal contrasts you do (and do not) wish to make, and what assumptions your model and you are making if interpreting them as causal effects. Such determinations require an understanding of the various decomposition components described earlier and careful consideration of which components align best with your causal estimand of interest."
  },
  {
    "objectID": "blog-posts/[11]/modmadness-pt3.html#sec-CMAnonlin-noint",
    "href": "blog-posts/[11]/modmadness-pt3.html#sec-CMAnonlin-noint",
    "title": "Moderator Madness, Part 3",
    "section": "Nonlinear CMA model, no EMint",
    "text": "Nonlinear CMA model, no EMint\nNow, we already know the linear model does not provide a good approximation for the data generating processes underlying these simulated data. This is frequently the case when analyzing real-world criminological data as well. Yet, given the familiarity that many readers will likely have with linear models, my hope is that the relatively poor-fitting linear models above will help ease the transition to better-fitting but more complex nonlinear models.\nBelow, I conclude by briefly presenting CMAverse models with and without EM interactions again but, this time, I will specify a Poisson distribution for the outcome variable. This means that the predicted contrasts will be described on the event rate ratio scale instead of the linear difference scale.10 As you will soon see, the output and interpretations get a bit more complicated with nonlinear models due to changes in the outcome scale (and related issues like noncollapsibility of certain estimates).\n\n\nShow code\nset.seed(1138)\nest4 &lt;- cmest(data = simdat3, model = \"rb\", outcome = \"Delinquency\", exposure = \"ParentSupport\",\n                mediator = \"StrgMoralBlfs\", EMint = FALSE,\n                mreg = list(\"linear\"), yreg = \"poisson\",\n                astar = 0, a = 1, mval = list(0),\n                estimation = \"imputation\", inference = \"bootstrap\", nboot = 20)\n\n\n\nResults: nonlinear no EMintDefault plot: nonlinear no EMintFull output: nonlinear no EMint\n\n\n\n\nShow code\nest4dat &lt;- as.data.frame(est4$effect.pe) %&gt;% rownames_to_column(\"CMA_est2\") %&gt;%\n  mutate(CMA_est = if_else(CMA_est2==\"Rcde\",\"cde\",CMA_est2),\n         CMA_est = if_else(CMA_est2==\"Rpnde\",\"pnde\",CMA_est), \n         CMA_est = if_else(CMA_est2==\"Rtnde\",\"tnde\",CMA_est),\n         CMA_est = if_else(CMA_est2==\"Rpnie\",\"pnie\",CMA_est),\n         CMA_est = if_else(CMA_est2==\"Rtnie\",\"tnie\",CMA_est),\n         CMA_est = if_else(CMA_est2==\"Rte\",\"te\",CMA_est)\n  )\n\nest4dattab &lt;- left_join(est3dattab, est4dat, join_by(\"CMA_est\")) %&gt;%\n  rename(\"nonlin_noEM\" = \"est4$effect.pe\") %&gt;%\n  mutate(\n    CMA_est2 = if_else(is.na(CMA_est2), \"--\", CMA_est2)\n  )\n  \n\nest4dattab %&gt;%\n  gt() %&gt;% \n    tab_spanner(label = html(\"CMAverse&lt;br&gt;(nonlinear)\"), \n                columns = c(\"CMA_est2\", \"nonlin_noEM\")) %&gt;%\n    tab_spanner(label = html(\"CMAverse&lt;br&gt;(linear)\"), \n                columns = c(\"CMA_est\", \"linear_noEM\", \"linear_EM\")) %&gt;%\n    tab_spanner(label = html(\"Traditional&lt;br&gt;(linear)\"), columns = c(\"trad_est\",\"estimate\")) %&gt;%\n    cols_add('blank' = '', .after = 'estimate') %&gt;%\n    cols_label('blank' = md('&emsp;&emsp;&emsp;')) %&gt;%\n    cols_add('blank2' = '', .before = 'CMA_est2') %&gt;%\n    cols_label('blank2' = md('&emsp;&emsp;&emsp;'), \n               trad_est = \"effect\", \n               CMA_est = \"effect\",\n               CMA_est2 = \"effect\",\n               estimate = \"estimate\",\n               linear_noEM = html(\"No_EMint&lt;br&gt;estimate\"),\n               linear_EM = html(\"EMint&lt;br&gt;estimate\"),\n               nonlin_noEM = html(\"No_EMint&lt;br&gt;estimate\")\n               )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraditional\n(linear)\n   \nCMAverse\n(linear)\n   \nCMAverse\n(nonlinear)\n\n\neffect\nestimate\neffect\nNo_EMint\nestimate\nEMint\nestimate\neffect\nNo_EMint\nestimate\n\n\n\n\ndirect\n-0.33\n\ncde\n-0.327\n-1.1747\n\nRcde\n0.683\n\n\n--\nNA\n\npnde\n-0.327\n-0.3325\n\nRpnde\n0.683\n\n\n--\nNA\n\ntnde\n-0.327\n-0.2784\n\nRtnde\n0.683\n\n\nindirect\n-0.10\n\npnie\n-0.101\n-0.0864\n\nRpnie\n0.917\n\n\n--\nNA\n\ntnie\n-0.101\n-0.0322\n\nRtnie\n0.917\n\n\ntotal\n-0.43\n\nte\n-0.428\n-0.3647\n\nRte\n0.626\n\n\n--\nNA\n\nintref\nNA\n0.8422\n\n--\nNA\n\n\n--\nNA\n\nintmed\nNA\n0.0541\n\n--\nNA\n\n\n\n\n\n\n\n\n\n\n\nShow code\nggcmest(est4) +\n  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 30, vjust = 0.8))\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\nsummary(est4)\n\n\nCausal Mediation Analysis\n\n# Outcome regression:\n\nCall:\nglm(formula = Delinquency ~ ParentSupport + StrgMoralBlfs, family = poisson(), \n    data = getCall(x$reg.output$yreg)$data, weights = getCall(x$reg.output$yreg)$weights)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     0.9880     0.0540    18.3   &lt;2e-16 ***\nParentSupport  -0.3816     0.0202   -18.9   &lt;2e-16 ***\nStrgMoralBlfs  -0.4178     0.0175   -23.8   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 4367.7  on 2999  degrees of freedom\nResidual deviance: 3219.5  on 2997  degrees of freedom\nAIC: 6788\n\nNumber of Fisher Scoring iterations: 5\n\n\n# Mediator regressions: \n\nCall:\nglm(formula = StrgMoralBlfs ~ ParentSupport, family = gaussian(), \n    data = getCall(x$reg.output$mreg[[1L]])$data, weights = getCall(x$reg.output$mreg[[1L]])$weights)\n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     3.2145     0.0164   195.9   &lt;2e-16 ***\nParentSupport   0.2061     0.0165    12.5   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.807)\n\n    Null deviance: 2546.9  on 2999  degrees of freedom\nResidual deviance: 2420.6  on 2998  degrees of freedom\nAIC: 7876\n\nNumber of Fisher Scoring iterations: 2\n\n\n# Effect decomposition on the rate ratio scale via the regression-based approach\n \nDirect counterfactual imputation estimation with \n bootstrap standard errors, percentile confidence intervals and p-values \n \n      Estimate Std.error  95% CIL 95% CIU  P.val    \nRcde  0.682781  0.013782 0.664411   0.711 &lt;2e-16 ***\nRpnde 0.682781  0.013782 0.664411   0.711 &lt;2e-16 ***\nRtnde 0.682781  0.013782 0.664411   0.711 &lt;2e-16 ***\nRpnie 0.917494  0.006533 0.906926   0.928 &lt;2e-16 ***\nRtnie 0.917494  0.006533 0.906926   0.928 &lt;2e-16 ***\nRte   0.626448  0.013760 0.607616   0.654 &lt;2e-16 ***\npm    0.150804  0.012626 0.131287   0.177 &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Rcde: controlled direct effect rate ratio; Rpnde: pure natural direct effect rate ratio; Rtnde: total natural direct effect rate ratio; Rpnie: pure natural indirect effect rate ratio; Rtnie: total natural indirect effect rate ratio; Rte: total effect rate ratio; pm: overall proportion mediated)\n\nRelevant variable values: \n$a\n[1] 1\n\n$astar\n[1] 0\n\n$mval\n$mval[[1]]\n[1] 0\n\n\n\n\n\nIt should be immediately apparent that the estimates from this model look different from the estimates reported with the linear models - each estimate is now designated with an “R” prefix (e.g., “Rcde”). This is because the nonlinear model estimates describe relative effects on the rate ratio scale (or risk ratio for logistic outcome models) instead of effects on the linear difference scale.\nYou can find various accessible discussions of interpreting risk and rate ratio estimates online; for a couple examples, see here, here, and here. Briefly, rate ratio estimates less than one indicate negative effects; estimates equal to one indicate null effects; and estimates greater than one indicate positive effects.\nSo, this model predicts a moderate direct effect of parental support on delinquency; increasing parental support from its mean (astar=0) to one standard deviation above its mean (a=1) is predicted to directly reduce delinquency to 0.68 times the rate at the mean (i.e., at astar=0). In comparison, the model predicts a modest indirect effect of parental support on delinquency through moral beliefs; similarly increasing parental support from astar=0 to a=1 is predicted to indirectly reduce delinquency to 0.92 times the rate at the mean (i.e., at astar=0).\nThough the outcome scale and resulting estimates changed, some patterns should be familiar by now. For instance, all the direct effect estimates are equivalent (i.e., CDE = PNDE = TNDE), as are the indirect effect estimates (PNIE = TNIE). Also, the results lack any INTmed or INTref estimates. Again, these patterns are expected because we set EMint=FALSE, which means we constrained the model to ignore any exposure-mediator interaction by essentially fixing the interaction parameter to zero. In the final model below, I relax this constraint by specifying EMint = TRUE to include an exposure-mediator interaction term on the estimation scale."
  },
  {
    "objectID": "blog-posts/[11]/modmadness-pt3.html#sec-CMAnonlin-int",
    "href": "blog-posts/[11]/modmadness-pt3.html#sec-CMAnonlin-int",
    "title": "Moderator Madness, Part 3",
    "section": "Nonlinear CMA model, with EMint",
    "text": "Nonlinear CMA model, with EMint\n\n\nShow code\nset.seed(1138)\nest5 &lt;- cmest(data = simdat3, model = \"rb\", outcome = \"Delinquency\", exposure = \"ParentSupport\",\n                mediator = \"StrgMoralBlfs\", EMint = TRUE,\n                mreg = list(\"linear\"), yreg = \"poisson\",\n                astar = 0, a = 1, mval = list(0),\n                estimation = \"imputation\", inference = \"bootstrap\", nboot = 20)\n\n\n\nResults: nonlinear with EMintDefault plot: nonlinear with EMintRisk ratio plot: nonlinear with EMintExcess risk plot: nonlinear, with EMintFull output: nonlinear with EMint\n\n\n\n\nShow code\nest5dat &lt;- as.data.frame(est5$effect.pe) %&gt;% rownames_to_column(\"CMA_est2\") %&gt;%\n  mutate(CMA_est = if_else(CMA_est2==\"Rcde\",\"cde\",CMA_est2),\n         CMA_est = if_else(CMA_est2==\"Rpnde\",\"pnde\",CMA_est), \n         CMA_est = if_else(CMA_est2==\"Rtnde\",\"tnde\",CMA_est),\n         CMA_est = if_else(CMA_est2==\"Rpnie\",\"pnie\",CMA_est),\n         CMA_est = if_else(CMA_est2==\"Rtnie\",\"tnie\",CMA_est),\n         CMA_est = if_else(CMA_est2==\"Rte\",\"te\",CMA_est)\n  )\n\nest5dattab &lt;- full_join(est4dattab, est5dat, join_by(\"CMA_est2\")) %&gt;%\n  rename(\"nonlin_EM\" = \"est5$effect.pe\",\n         \"CMA_est\" = \"CMA_est.x\") %&gt;%\n  select(!CMA_est.y) %&gt;% \n  filter(!CMA_est2 %in% c(\"ERcde(prop)\", \"ERintref(prop)\", \"ERintmed(prop)\", \n                          \"ERpnie(prop)\", \"pm\", \"int\", \"pe\")) %&gt;% \n  mutate(\n    trad_est = if_else(is.na(trad_est), \"--\", trad_est), \n    CMA_est = if_else(is.na(CMA_est), \"--\", CMA_est)\n  )\n\nest5dattab %&gt;%\n  gt() %&gt;% \n    tab_spanner(label = html(\"CMAverse&lt;br&gt;(nonlinear)\"), \n                columns = c(\"CMA_est2\", \"nonlin_noEM\", \"nonlin_EM\")) %&gt;%\n    tab_spanner(label = html(\"CMAverse&lt;br&gt;(linear)\"), \n                columns = c(\"CMA_est\", \"linear_noEM\", \"linear_EM\")) %&gt;%\n    tab_spanner(label = html(\"Traditional&lt;br&gt;(linear)\"), columns = c(\"trad_est\",\"estimate\")) %&gt;%\n    cols_add('blank' = '', .after = 'estimate') %&gt;%\n    cols_label('blank' = md('&emsp;&emsp;&emsp;')) %&gt;%\n    cols_add('blank2' = '', .before = 'CMA_est2') %&gt;%\n    cols_label('blank2' = md('&emsp;&emsp;&emsp;'), \n               trad_est = \"effect\", \n               CMA_est = \"effect\",\n               CMA_est2 = \"effect\",\n               estimate = \"estimate\",\n               linear_noEM = html(\"No_EMint&lt;br&gt;estimate\"),\n               linear_EM = html(\"EMint&lt;br&gt;estimate\"),\n               nonlin_noEM = html(\"No_EMint&lt;br&gt;estimate\"),\n               nonlin_EM = html(\"EMint&lt;br&gt;estimate\")\n               )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraditional\n(linear)\n   \nCMAverse\n(linear)\n   \nCMAverse\n(nonlinear)\n\n\neffect\nestimate\neffect\nNo_EMint\nestimate\nEMint\nestimate\neffect\nNo_EMint\nestimate\nEMint\nestimate\n\n\n\n\ndirect\n-0.33\n\ncde\n-0.327\n-1.1747\n\nRcde\n0.683\n0.6841\n\n\n--\nNA\n\npnde\n-0.327\n-0.3325\n\nRpnde\n0.683\n0.6827\n\n\n--\nNA\n\ntnde\n-0.327\n-0.2784\n\nRtnde\n0.683\n0.6826\n\n\nindirect\n-0.10\n\npnie\n-0.101\n-0.0864\n\nRpnie\n0.917\n0.9174\n\n\n--\nNA\n\ntnie\n-0.101\n-0.0322\n\nRtnie\n0.917\n0.9173\n\n\ntotal\n-0.43\n\nte\n-0.428\n-0.3647\n\nRte\n0.626\n0.6262\n\n\n--\nNA\n\nintref\nNA\n0.8422\n\n--\nNA\nNA\n\n\n--\nNA\n\nintmed\nNA\n0.0541\n\n--\nNA\nNA\n\n\n--\nNA\n\n--\nNA\nNA\n\nERcde\nNA\n-1.1268\n\n\n--\nNA\n\n--\nNA\nNA\n\nERintref\nNA\n0.8094\n\n\n--\nNA\n\n--\nNA\nNA\n\nERintmed\nNA\n0.0261\n\n\n--\nNA\n\n--\nNA\nNA\n\nERpnie\nNA\n-0.0826\n\n\n\n\n\n\n\n\n\n\n\nShow code\nggcmest(est5) +\n  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 30, vjust = 0.8))\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n#save estimates and intervals data\nest5dat &lt;- as.data.frame(est5[9:12]) %&gt;%\n  rownames_to_column(\"CMA_est\")\n\n\n# drop proportion estimates\nest5dat %&gt;%\n  filter(!CMA_est %in% c(\"pm\", \"pe\", \"ERpnie(prop)\", \"ERintref(prop)\",\n                         \"ERintmed(prop)\",\"ERcde(prop)\", \"int\", \n                         \"ERpnie\", \"ERintmed\", \"ERintref\", \"ERcde\")) %&gt;%\n  mutate(CMA_est = factor(CMA_est, levels=c(\"Rte\", \"Rtnie\", \"Rpnie\", \"Rtnde\", \"Rpnde\", \"Rcde\"))) %&gt;%\n  # reorder the coefficients so that the largest is at the top of the plot\n  # mutate(term = fct_reorder(CMA_est, effect.pe)) %&gt;%\n  ggplot(aes(effect.pe, CMA_est)) +\n  geom_point() + \n  geom_errorbarh(aes(xmin = effect.ci.low, xmax = effect.ci.high), height = .1) +\n  # add in a dotted line at zero\n  geom_vline(xintercept = 1, lty = 2) +\n  labs(\n    x = \"Estimated effects on risk ratio scale\",\n    y = NULL,\n    title = \"Effect estimates from causal mediation decomposition (risk ratios)\"\n  ) + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# drop proportion estimates\nest5dat %&gt;%\n  filter(!CMA_est %in% c(\"pm\", \"pe\", \"ERpnie(prop)\", \"ERintref(prop)\",\n                         \"ERintmed(prop)\",\"ERcde(prop)\", \"int\", \n                         \"Rte\", \"Rtnie\", \"Rpnie\", \"Rtnde\", \"Rpnde\", \"Rcde\")) %&gt;%\n  mutate(CMA_est = factor(CMA_est, levels=c(\"ERpnie\", \"ERintmed\", \"ERintref\", \"ERcde\"))) %&gt;%\n  # reorder the coefficients so that the largest is at the top of the plot\n  # mutate(term = fct_reorder(CMA_est, effect.pe)) %&gt;%\n  ggplot(aes(effect.pe, CMA_est)) +\n  geom_point() + \n  geom_errorbarh(aes(xmin = effect.ci.low, xmax = effect.ci.high), height = .1) +\n  # add in a dotted line at zero\n  geom_vline(xintercept = 0, lty = 2) +\n  labs(\n    x = \"Estimated effects on excess risks scale\",\n    y = NULL,\n    title = \"Effect estimates from causal mediation decomposition (excess risks)\"\n  ) + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\nsummary(est5)\n\n\nCausal Mediation Analysis\n\n# Outcome regression:\n\nCall:\nglm(formula = Delinquency ~ ParentSupport + StrgMoralBlfs + ParentSupport * \n    StrgMoralBlfs, family = poisson(), data = getCall(x$reg.output$yreg)$data, \n    weights = getCall(x$reg.output$yreg)$weights)\n\nCoefficients:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                  0.989580   0.064119   15.43  &lt; 2e-16 ***\nParentSupport               -0.379579   0.047346   -8.02  1.1e-15 ***\nStrgMoralBlfs               -0.418358   0.020744  -20.17  &lt; 2e-16 ***\nParentSupport:StrgMoralBlfs -0.000758   0.016197   -0.05     0.96    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 4367.7  on 2999  degrees of freedom\nResidual deviance: 3219.5  on 2996  degrees of freedom\nAIC: 6790\n\nNumber of Fisher Scoring iterations: 5\n\n\n# Mediator regressions: \n\nCall:\nglm(formula = StrgMoralBlfs ~ ParentSupport, family = gaussian(), \n    data = getCall(x$reg.output$mreg[[1L]])$data, weights = getCall(x$reg.output$mreg[[1L]])$weights)\n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     3.2145     0.0164   195.9   &lt;2e-16 ***\nParentSupport   0.2061     0.0165    12.5   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.807)\n\n    Null deviance: 2546.9  on 2999  degrees of freedom\nResidual deviance: 2420.6  on 2998  degrees of freedom\nAIC: 7876\n\nNumber of Fisher Scoring iterations: 2\n\n\n# Effect decomposition on the rate ratio scale via the regression-based approach\n \nDirect counterfactual imputation estimation with \n bootstrap standard errors, percentile confidence intervals and p-values \n \n                Estimate Std.error   95% CIL 95% CIU  P.val    \nRcde            0.684149  0.037105  0.598769   0.725 &lt;2e-16 ***\nRpnde           0.682662  0.013715  0.665171   0.712 &lt;2e-16 ***\nRtnde           0.682556  0.014239  0.662567   0.713 &lt;2e-16 ***\nRpnie           0.917396  0.006654  0.906475   0.930 &lt;2e-16 ***\nRtnie           0.917253  0.008195  0.905841   0.935 &lt;2e-16 ***\nRte             0.626174  0.014402  0.605906   0.657 &lt;2e-16 ***\nERcde          -1.126777  0.112203 -1.376355  -1.018 &lt;2e-16 ***\nERintref        0.809439  0.109402  0.698336   1.050 &lt;2e-16 ***\nERintmed        0.026115  0.002870  0.021995   0.031 &lt;2e-16 ***\nERpnie         -0.082604  0.006654 -0.093525  -0.070 &lt;2e-16 ***\nERcde(prop)     3.014176  0.318260  2.663009   3.694 &lt;2e-16 ***\nERintref(prop) -2.165285  0.311553 -2.828061  -1.814 &lt;2e-16 ***\nERintmed(prop) -0.069860  0.007046 -0.080692  -0.060 &lt;2e-16 ***\nERpnie(prop)    0.220968  0.016263  0.195328   0.251 &lt;2e-16 ***\npm              0.151108  0.014391  0.122961   0.174 &lt;2e-16 ***\nint            -2.235145  0.316424 -2.901838  -1.875 &lt;2e-16 ***\npe             -2.014176  0.318260 -2.693672  -1.663 &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Rcde: controlled direct effect rate ratio; Rpnde: pure natural direct effect rate ratio; Rtnde: total natural direct effect rate ratio; Rpnie: pure natural indirect effect rate ratio; Rtnie: total natural indirect effect rate ratio; Rte: total effect rate ratio; ERcde: excess relative rate due to controlled direct effect; ERintref: excess relative rate due to reference interaction; ERintmed: excess relative rate due to mediated interaction; ERpnie: excess relative rate due to pure natural indirect effect; ERcde(prop): proportion ERcde; ERintref(prop): proportion ERintref; ERintmed(prop): proportion ERintmed; ERpnie(prop): proportion ERpnie; pm: overall proportion mediated; int: overall proportion attributable to interaction; pe: overall proportion eliminated)\n\nRelevant variable values: \n$a\n[1] 1\n\n$astar\n[1] 0\n\n$mval\n$mval[[1]]\n[1] 0\n\n\n\n\n\nBy this point, we have covered most everything you should need to know to be able to interpret results of this final causal mediation model. I will only make a couple additional points.\nFirst, along with the rate ratio measures (“R” prefix, e.g., Rcde), these results include a new set of estimates with an “ER” prefix (e.g., ERcde), or the “excess rate ratio” (or “excess risk ratio” in logistic regressions) attributable to particular components of a total effect. The sign or direction of an excess relative rate or risk estimate can be helpful for determining the direction of an interaction and, in particular, for inferring which group might be especially affected by an intervention. However, caution is warranted if attempting to interpret the magnitude of estimates on an excess relative rate or risk scale because estimation of excess rates depends upon baseline rates. The issue here is that baseline rates often vary across groups, but the estimates themselves do not communicate those baseline rates. As such, it is easy to misinterpret magnitudes of excess relative risk estimates unless interpretations also specifically reference associated differences in baseline and absolute rates or risks.\nThis raises a more general issue about relative rate or risk estimates. Though they are widely used to describe effects in nonlinear models, any estimate of relative rates or risks is potentially susceptible to misinterpretation or misleading inferences if not also paired with corresponding information about differences in baseline and absolute rates or risks. This is another reason why I recommend also estimating and plotting marginal effects on the outcome scale, as it can help with identifying, communicating, and visualizing these important differences on an absolute scale. In combination, a thorough understanding of the decomposition of a total effect into its constituent components can help you communicate precisely what information is being conveyed in specific relative effect estimates and may help you better comprehend and communicate about your marginal effect estimates and plots as well.\nFor more information about relative excess ratio estimates, see VanderWeele and Tchetgen Tchetgen (2014). Additionally, VanderWeele and Knol’s 2014 tutorial on interaction is especially helpful on this topic (see especially p.39 and footnote #1). That manuscript also contains a wealth of information that may be new to readers in our field about estimating and interpreting interactions, including distinctions between concepts such as statistical, mechanistic, and sufficient cause interactions.\nAs a final point, compare results from the CMAverse nonlinear interaction model with those from the CMAverse linear interaction model. Recall, the linear model suggested the existence of a substantial exposure-mediator interaction, which we were clued into by the notable differences in estimates across the two linear models with and without an EM interaction term. In contrast, the nonlinear model does not appear to show a sizeable exposure mediator interaction; again, we can infer this from an EM interaction coefficient of negligible magnitude and from the fact that the estimates barely changed after including the EMint term.\nRecall, the additive interaction in the data is on the outcome scale, or delinquency event rates, which is also the scale of estimation for the linear model. However, this is not the estimation scale for the nonlinear model, which generates estimates on the logged delinquency event rate scale. Put differently, the linear model shows a statistically significant nonzero interaction term because its predictions are on the linear outcome scale, so the interaction term grants the model flexibility to fit conditional exposure effects on delinquency event rates that potentially vary across levels of the mechanism.\nMeanwhile, the estimates from a generalized linear model with a Poisson-distributed outcome and log link function (aka, a nonlinear model) already are conditional on covariates. That is, these estimates already build conditional variability across mechanism levels into the model, so they are flexible enough to capture a similar additive interaction on the delinquency event rate outcome scale without the need for an interaction on estimation scale.\nIf there had been a non-negligible exposure-mediator interaction in the nonlinear model, such that estimates changed when we switched from EMint = FALSE to EMint = TRUE, then this would have signaled the existence of an interaction on the estimation scale, or in logged delinquency rates and differences in relative effects across mechanism levels. Plotting such changes in predicted effects on the outcome scale might have shown, for instance, a growth or a reduction across mechanism levels in the predicted differences in delinquency rates attributed to the exposure’s effect.11\nWhen simulating the data, I actually included an alternative outcome variable (Delinquency2) to provide an example of such a non-negligible interaction on the logged delinquency rate scale. If you are curious, click the expandable link below to view tabled results and plots from nonlinear models predicting this alternative variable. In particular, the prediction plots (second tab) help visualize how this specific interaction on the estimation scale translates into differences in the relative magnitude of the exposure effect across mechanism levels on the delinquency rate outcome scale.\n\n\nExample interaction in nonlinear model\n\n\n\nShow code\n# Sim.2 nonlinear model (alt DV)\nglm3 &lt;- glm(Delinquency2 ~ ParentSupport * StrgMoralBlfs, data=simdat3, family=\"poisson\")\n\nEx2tab3 &lt;- regsum(glm3) %&gt;%\n  as_gt() %&gt;%\n  gt::tab_header(title = \"Poisson regression predicting delinquency2 event rates\")\n\nset.seed(1138)\nest6 &lt;- cmest(data = simdat3, model = \"rb\", outcome = \"Delinquency2\", exposure = \"ParentSupport\",\n                mediator = \"StrgMoralBlfs\", EMint = TRUE,\n                mreg = list(\"linear\"), yreg = \"poisson\",\n                astar = 0, a = 1, mval = list(0),\n                estimation = \"imputation\", inference = \"bootstrap\", nboot = 20)\n\n\n\nGLM: ResultsGLM: Prediction plot with dataCMA: Results (nonlinear; EMint; alt DV)CMA: Default plot (nonlinear; EMint; alt DV)CMA: Risk ratio plot (nonlinear; EMint; alt DV)CMA: Excess risk plot (nonlinear; EMint; alt DV)Full output: nonlinear with EMint\n\n\n\n\nShow code\n# Sim.2 nonlinear model (alt DV)\n\nEx2tab3\n\n\n\n\n\n\n\n\nPoisson regression predicting delinquency2 event rates\n\n\nCharacteristic\nlog(IRR)1,2\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n0.79***\n0.065\n0.66, 0.91\n1.57e-33\n\n\nParentSupport\n-1.1***\n0.036\n-1.2, -1.0\n2.15e-209\n\n\nStrgMoralBlfs\n-0.37***\n0.021\n-0.41, -0.33\n4.87e-69\n\n\nParentSupport * StrgMoralBlfs\n0.20***\n0.013\n0.17, 0.22\n1.81e-54\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 IRR = Incidence Rate Ratio, SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n#|message=FALSE \n\n#use ggeffects::ggpredict() to save plot_model data for use in ggplot \nglm3df &lt;- ggpredict(glm3, terms = c(\"ParentSupport\", \"StrgMoralBlfs [0,2,4]\"))\n\n#prediction plot with data subset & ggblend\npredplot3 &lt;- ggplot(data=simdat3sub, aes(x=ParentSupport, y=Delinquency2, \n                            color=StrgMoralBlfs, group=StrgMoralBlfs)) + \n  geom_point() |&gt; partition(vars(StrgMoralBlfs)) |&gt; blend(\"lighten\") |&gt;\n  blend(\"multiply\", alpha = 0.4) +\n  scale_colour_colorblind() +\n  scale_fill_colorblind() +\n  theme_minimal() + \n  # geom_hline(yintercept=7, linetype=\"dashed\") +\n  coord_cartesian(xlim=c(-2,2), ylim=c(-1,8)) +\n  geom_line(data=glm3df, aes(x=x, y=predicted,\n                             linetype=group, color=group), inherit.aes=FALSE) +  \n  geom_ribbon(data=glm3df, aes(x=x, y=predicted, \n                               ymin=conf.low, ymax=conf.high, fill=group), \n              alpha=0.4, inherit.aes=FALSE) +\n  scale_linetype_manual(values = c(\"solid\", \"solid\", \"solid\")) + \n  guides(linetype=FALSE, fill=FALSE) + \n  labs(x=\"Parental Support\",\n       y=\"Delinquency2\",\n       title=\"Predicted conditional marginal effects of parent support on delinquency2\", \n       subtitle=\"Plotted at minimum (0), scale midpoint (2), & maximum (4) strong moral beliefs\\n(Poisson regression, n=3k simulated observations)\") \n\npredplot3\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\nest6dat &lt;- as.data.frame(est6$effect.pe) %&gt;% rownames_to_column(\"CMA_est2\") %&gt;%\n  mutate(CMA_est = if_else(CMA_est2==\"Rcde\",\"cde\",CMA_est2),\n         CMA_est = if_else(CMA_est2==\"Rpnde\",\"pnde\",CMA_est), \n         CMA_est = if_else(CMA_est2==\"Rtnde\",\"tnde\",CMA_est),\n         CMA_est = if_else(CMA_est2==\"Rpnie\",\"pnie\",CMA_est),\n         CMA_est = if_else(CMA_est2==\"Rtnie\",\"tnie\",CMA_est),\n         CMA_est = if_else(CMA_est2==\"Rte\",\"te\",CMA_est)\n  )\n\nest6dattab &lt;- est6dat %&gt;%\n  rename(\"nonlin_EM\" = \"est6$effect.pe\") %&gt;%\n  select(!CMA_est) %&gt;% \n  filter(!CMA_est2 %in% c(\"ERcde(prop)\", \"ERintref(prop)\", \"ERintmed(prop)\", \n                          \"ERpnie(prop)\", \"pm\", \"int\", \"pe\")) \n\nest6dattab %&gt;%\n  gt() %&gt;% \n    tab_spanner(label = html(\"CMAverse&lt;br&gt;(nonlinear, alt DV)\"), \n                columns = c(\"CMA_est2\", \"nonlin_EM\")) %&gt;%\n    cols_label(CMA_est2 = \"effect\",\n               nonlin_EM = html(\"EMint&lt;br&gt;estimate\")\n               )\n\n\n\n\n\n\n\n\n\n\n\n\nCMAverse\n(nonlinear, alt DV)\n\n\neffect\nEMint\nestimate\n\n\n\n\nRcde\n0.3338\n\n\nRpnde\n0.5997\n\n\nRtnde\n0.6244\n\n\nRpnie\n0.9272\n\n\nRtnie\n0.9654\n\n\nRte\n0.5790\n\n\nERcde\n-2.0461\n\n\nERintref\n1.6458\n\n\nERintmed\n0.0520\n\n\nERpnie\n-0.0728\n\n\n\n\n\n\n\n\n\n\n\nShow code\nggcmest(est6) +\n  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 30, vjust = 0.8))\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n#save estimates and intervals data\nest6dat &lt;- as.data.frame(est5[9:12]) %&gt;%\n  rownames_to_column(\"CMA_est\")\n\n\n# drop proportion estimates\nest6dat %&gt;%\n  filter(!CMA_est %in% c(\"pm\", \"pe\", \"ERpnie(prop)\", \"ERintref(prop)\",\n                         \"ERintmed(prop)\",\"ERcde(prop)\", \"int\", \n                         \"ERpnie\", \"ERintmed\", \"ERintref\", \"ERcde\")) %&gt;%\n  mutate(CMA_est = factor(CMA_est, levels=c(\"Rte\", \"Rtnie\", \"Rpnie\", \"Rtnde\", \"Rpnde\", \"Rcde\"))) %&gt;%\n  # reorder the coefficients so that the largest is at the top of the plot\n  # mutate(term = fct_reorder(CMA_est, effect.pe)) %&gt;%\n  ggplot(aes(effect.pe, CMA_est)) +\n  geom_point() + \n  geom_errorbarh(aes(xmin = effect.ci.low, xmax = effect.ci.high), height = .1) +\n  # add in a dotted line at zero\n  geom_vline(xintercept = 1, lty = 2) +\n  labs(\n    x = \"Estimated effects on risk ratio scale\",\n    y = NULL,\n    title = \"Effect estimates from causal mediation decomposition (risk ratios)\"\n  ) + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# drop proportion estimates\nest6dat %&gt;%\n  filter(!CMA_est %in% c(\"pm\", \"pe\", \"ERpnie(prop)\", \"ERintref(prop)\",\n                         \"ERintmed(prop)\",\"ERcde(prop)\", \"int\", \n                         \"Rte\", \"Rtnie\", \"Rpnie\", \"Rtnde\", \"Rpnde\", \"Rcde\")) %&gt;%\n  mutate(CMA_est = factor(CMA_est, levels=c(\"ERpnie\", \"ERintmed\", \"ERintref\", \"ERcde\"))) %&gt;%\n  # reorder the coefficients so that the largest is at the top of the plot\n  # mutate(term = fct_reorder(CMA_est, effect.pe)) %&gt;%\n  ggplot(aes(effect.pe, CMA_est)) +\n  geom_point() + \n  geom_errorbarh(aes(xmin = effect.ci.low, xmax = effect.ci.high), height = .1) +\n  # add in a dotted line at zero\n  geom_vline(xintercept = 0, lty = 2) +\n  labs(\n    x = \"Estimated effects on excess risks scale\",\n    y = NULL,\n    title = \"Effect estimates from causal mediation decomposition (excess risks)\"\n  ) + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\nsummary(est6)\n\n\nCausal Mediation Analysis\n\n# Outcome regression:\n\nCall:\nglm(formula = Delinquency2 ~ ParentSupport + StrgMoralBlfs + \n    ParentSupport * StrgMoralBlfs, family = poisson(), data = getCall(x$reg.output$yreg)$data, \n    weights = getCall(x$reg.output$yreg)$weights)\n\nCoefficients:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                   0.7882     0.0653    12.1   &lt;2e-16 ***\nParentSupport                -1.0971     0.0355   -30.9   &lt;2e-16 ***\nStrgMoralBlfs                -0.3666     0.0209   -17.6   &lt;2e-16 ***\nParentSupport:StrgMoralBlfs   0.1958     0.0126    15.5   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 7750.2  on 2999  degrees of freedom\nResidual deviance: 4249.6  on 2996  degrees of freedom\nAIC: 7832\n\nNumber of Fisher Scoring iterations: 5\n\n\n# Mediator regressions: \n\nCall:\nglm(formula = StrgMoralBlfs ~ ParentSupport, family = gaussian(), \n    data = getCall(x$reg.output$mreg[[1L]])$data, weights = getCall(x$reg.output$mreg[[1L]])$weights)\n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     3.2145     0.0164   195.9   &lt;2e-16 ***\nParentSupport   0.2061     0.0165    12.5   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.807)\n\n    Null deviance: 2546.9  on 2999  degrees of freedom\nResidual deviance: 2420.6  on 2998  degrees of freedom\nAIC: 7876\n\nNumber of Fisher Scoring iterations: 2\n\n\n# Effect decomposition on the rate ratio scale via the regression-based approach\n \nDirect counterfactual imputation estimation with \n bootstrap standard errors, percentile confidence intervals and p-values \n \n                Estimate Std.error   95% CIL 95% CIU  P.val    \nRcde            0.333837  0.035640  0.276100   0.399 &lt;2e-16 ***\nRpnde           0.599703  0.050694  0.535054   0.683 &lt;2e-16 ***\nRtnde           0.624391  0.053477  0.557103   0.715 &lt;2e-16 ***\nRpnie           0.927231  0.008316  0.916611   0.944 &lt;2e-16 ***\nRtnie           0.965403  0.009502  0.954753   0.984 &lt;2e-16 ***\nRte             0.578955  0.046486  0.520907   0.659 &lt;2e-16 ***\nERcde          -2.046113  0.181242 -2.454288  -1.776 &lt;2e-16 ***\nERintref        1.645817  0.198858  1.336259   2.069 &lt;2e-16 ***\nERintmed        0.052021  0.004102  0.044078   0.058 &lt;2e-16 ***\nERpnie         -0.072769  0.008316 -0.083389  -0.056 &lt;2e-16 ***\nERcde(prop)     4.859609  0.788595  3.891345   6.695 &lt;2e-16 ***\nERintref(prop) -3.908887  0.805974 -5.772869  -2.911 &lt;2e-16 ***\nERintmed(prop) -0.123552  0.019938 -0.167576  -0.098 &lt;2e-16 ***\nERpnie(prop)    0.172829  0.036256  0.119480   0.237 &lt;2e-16 ***\npm              0.049278  0.020259  0.019565   0.084 &lt;2e-16 ***\nint            -4.032438  0.821021 -5.929947  -3.017 &lt;2e-16 ***\npe             -3.859609  0.788595 -5.695418  -2.891 &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Rcde: controlled direct effect rate ratio; Rpnde: pure natural direct effect rate ratio; Rtnde: total natural direct effect rate ratio; Rpnie: pure natural indirect effect rate ratio; Rtnie: total natural indirect effect rate ratio; Rte: total effect rate ratio; ERcde: excess relative rate due to controlled direct effect; ERintref: excess relative rate due to reference interaction; ERintmed: excess relative rate due to mediated interaction; ERpnie: excess relative rate due to pure natural indirect effect; ERcde(prop): proportion ERcde; ERintref(prop): proportion ERintref; ERintmed(prop): proportion ERintmed; ERpnie(prop): proportion ERpnie; pm: overall proportion mediated; int: overall proportion attributable to interaction; pe: overall proportion eliminated)\n\nRelevant variable values: \n$a\n[1] 1\n\n$astar\n[1] 0\n\n$mval\n$mval[[1]]\n[1] 0"
  },
  {
    "objectID": "blog-posts/[11]/modmadness-pt3.html#sec-curtaincall",
    "href": "blog-posts/[11]/modmadness-pt3.html#sec-curtaincall",
    "title": "Moderator Madness, Part 3",
    "section": "Curtain call",
    "text": "Curtain call\nI hope this three-part series has helped you better appreciate the challenges of analyzing moderation processes with criminological data and the importance of checking for exposure-mediator interactions and, where they exist, of decomposing total effects into its constituent interaction and indirect effect components.\nIn closing, the next time you stub your toe, I hope I have not caused you to think of me. Blame the curtains instead.\n\n\n\nThat’s all folks!"
  },
  {
    "objectID": "blog-posts/[11]/modmadness-pt3.html#footnotes",
    "href": "blog-posts/[11]/modmadness-pt3.html#footnotes",
    "title": "Moderator Madness, Part 3",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOf course, in many situations, a “direct effect” estimate itself may (and likely does) represent an aggregate or composite summary of other indirect effects operating through unmeasured mechanisms.↩︎\nIn causal mediation decomposition using potential outcomes, the mediated interaction component is typically attributed variously to quantities representing the direct effect of the exposure or, instead, to quantities representing the indirect effect through the mechanism. The specific estimates that a researcher chooses to report will depend upon one’s focal research questions and estimand of interest. I will try to explain this partitioning of the mediated interaction component (out of “pure” or into “total” effect estimates) in more detail later.↩︎\nAgain, traditional and causal mediation approaches both rest upon similar confounding assumptions. In addition to these assumptions, there are lots of other considerations as well when deciding whether a mediation model is appropriate for your situation. Too often, a mediation model may not be appropriate, but researchers use them anyway. Still, even in situations where the appropriateness of their assumptions are dubious, I think most social scientific research would benefit from careful thinking about and transparent statements of the assumptions required to make causal inferences from data - whether those causal inferences are from mediation models or otherwise. Likewise, reading more about causal mediation methods may help towards these ends, as the explicit and formal statement of assumptions necessary to generate valid causal inferences from mediation models is an important area of emphasis in the causal mediation literature.↩︎\nGiven these aims, I also do not address other detailed issues or advanced modeling options here, such as differences between regression-based, weighting-based, g-formula, or other estimation methods available in CMAverse. However, note that some available methods may be better suited for your particular modeling situation, and some choices may be better than others depending upon your specific causal estimand of interest.↩︎\nNote, too, that the Y(do[A=1],do[MA=0]) may be an unobservable counterfactual condition (e.g., in the presence of mediation). We cannot in fact simultaneously observe Y with X set to =1 and M set to equal its expected value when A=0. After all, if we do A=1 and X has an effect on M, then M would also change to its (population average) value at A=1; M would not stay at its expected value when A=0! These slides (especially slide 12) offer a concise description of this issue.↩︎\nIf you have not read it yourself, then you might be unaware that Baron & Kenny’s (1986) classic paper was actually about distinguishing between mediation and moderation concepts, with an emphasis on testing indirect and interaction hypotheses in the same analysis. You might also be surprised to learn that Judd and Kenny’s (1981) classic mediation paper outlined the core causal assumptions necessary for valid mediation analysis and explicitly discussed exposure-mediator interactions. So, in some important ways, this entry is trying help get our field caught up to leading mediation advice published over 40 years ago. Unfortunately, for decades, researchers following the “Baron and Kenny” causal steps approach to mediation largely have ignored Judd and Kenny’s earlier discussions of causal assumptions pertaining to confounding or exposure-mediator interactions. David Kenny suggests this might be partly due (among other important reasons) to the fact that Baron and Kenny’s highly cited paper “does not even mention confounding as an assumption”; rather, that paper did “discuss reliability and interaction” and it “suggests to the reader to consult Judd and Kenny (1981a) for more information about assumptions.” Sadly, you might not be surprised to learn that, according to Kenny, the “initial submission did discuss confounding, but the editor suggested cutting that section and unfortunately the authors complied.” Let’s focus on improving our analytic approaches to mediation and moderation for now, then work on problematic reviewer, editor, and publisher practices at a later date.↩︎\nUpon close inspection of the full output for the EMint=TRUE model, you might also notice that the outcome model regression coefficients are equivalent to those generated by the linear interaction model used earlier to create prediction plots. This is because essentially the same underlying linear interaction model is used to estimate indirect effects and conduct total effect decomposition.↩︎\nInvalid proportion estimates extending beyond expected bounds of 0 to 1 also can mess up axis scales when plotting; you can see this in some of the CMAverse “default” plots. Additionally, even in situations where proportion estimates are valid, I am skeptical that the proportion of a total effect that is attributable to specific underlying component is likely to be a very useful estimand of interest.↩︎\nTable 1 here provides descriptions of the various effect estimates generated by CMAverse in linear decomposition models.↩︎\nSee Table 2 here for descriptions of the various causal estimates on the ratio scale that are output by CMAverse, and see the cmest documentation for descriptions of which causal estimates are generated under different modeling specifications.↩︎\nTo echo my recommendation from Part 1, Trenton Mize’s (2019) paper is an excellent resource for better understanding interactions in nonlinear models.↩︎"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "reluctant criminologists",
    "section": "",
    "text": "My job is to introduce a little tension into an otherwise harmonious system.\n— Charles Tittle in “The Arrogance of Public Sociology”\nWelcome to our site! We are Jon Brauer and Jake Day, aka the “reluctant criminologists.”\nWe created this site to publicly share course materials and musings about scientific theory and methods. In particular, we provide course materials containing crime-relevant examples to help interested scholars in our field learn to use R and to improve the reproducibility of their workflows. Additionally, we will post occasional blog entries about topics in our areas of interest, including philosophy of science, criminology theory, and statistical techniques (e.g., ordinal modeling; Bayesian estimation; data visualization). We are also open to the idea of collaborating with or posting others’ course materials and topical blog posts, so feel free to contact us with your ideas.\nWith respect to philosophy of science and criminology theory, we were both heavily influenced by the late Dr. Charles R. Tittle. The name of our site is meant to be a cheeky reference to one of our favorite pieces written by Charles: “Reflections of a Reluctant but Committed Criminologist” in Gilbert Geis and Mary Dodge’s Lessons of Criminology (pp.23-45). You can read more about how he directly inspired our site’s name (“Reluctant Criminologists”) in our welcome blog. However, we wish to make it clear that although we were influenced and inspired by him, Charles in no way endorsed the project, and he likely would have thought it was a waste of time better spent contributing (in more traditional ways) to scientific theory development and testing. We think it’s safe to say that we are both more “reluctant” and less “committed” criminologists than Charles was.\nIn sharing course content and posts containing R code, we are committing to the practice of coding in public. Likewise, we expect to learn more than we teach through readers’ constructive feedback on our innumerable coding inefficiencies and inevitable errors. So, please do reach out with suggestions or corrections.\nFinally, if we contribute anything of value on this site, undoubtedly someone else - one or more of our many countless scientific heroes who tirelessly publish through traditional scientific outlets and/or share scientific information and resources via their own blogs, bookdowns, and videos - deserve the lion’s share of credit for it. To borrow again from Charles Tittle (and specifically his preface to Control Balance), none of these people contributed to the errors or other shortcomings found in any materials that we post on this site."
  },
  {
    "objectID": "about.html#about-the-reluctant-criminologists",
    "href": "about.html#about-the-reluctant-criminologists",
    "title": "reluctant criminologists",
    "section": "about the reluctant criminologists",
    "text": "about the reluctant criminologists"
  },
  {
    "objectID": "blog-posts/[12]/RRR_mediation.html",
    "href": "blog-posts/[12]/RRR_mediation.html",
    "title": "RRR: Mediation Makes My Head Hurt!",
    "section": "",
    "text": "Mediation makes my head hurt"
  },
  {
    "objectID": "blog-posts/[12]/RRR_mediation.html#motivation",
    "href": "blog-posts/[12]/RRR_mediation.html#motivation",
    "title": "RRR: Mediation Makes My Head Hurt!",
    "section": "Motivation",
    "text": "Motivation\nAt times, we find ourselves wanting to publish a brief or “quick hitting” entry with a brief comment or coding example but do not have the time for a formal blog post. So, we decided to pilot a new type of entry. For lack of a better term, we’ll call this a “Reluctantly Rapid Response” (RRR for short). We are generally reluctant to post anything and doubly reluctant to post anything rapidly, so the name seems fitting to us.\nThis RRR entry provides code and output from a simple simulation motivated by Brier Gallihugh’s question on X about a mediation issue.\n\n\n\nA mediation mystery unfolds\n\n\nThe following simulation, plots, and analysis provide one example situation in which changes in a mediator (ChgM) are positively correlated with changes in an outcome (ChgY) within two groups A & B, yet Group A membership is estimated as having a negative indirect effect on changes in the outcome (ChgY) via changes in the mediator (ChgM). In this example, the total negative indirect effect is generated by a small negative “pure” indirect (PNIE) effect combined with a small “mediated interaction” (INTmed) effect.\nI am not claiming that this is what is happening in the original poster’s (BG’s) data. In fact, one apparent and important difference is that BG stated in a later tweet that “Group A shows higher rates of their mediator compared to Group B AND lower rates of the outcome compared to Group B as well.”\n\n\n\nThe probability plot thickens\n\n\nIf “rates” refer to initial status at Time 1 (not changes), then perhaps we could generate comparable data. Yet, if “rates” refers to the change scores themselves, then it seems we may still have an unsolved problem on our hands. In the simulation below, changes in the mediator are positively correlated with changes in the outcome in both Groups A and B, and Group A has lower outcome change scores on average; however, specification of marginally lower mediator change scores on average for Group A contribute to the negative indirect effect estimates.\nPlease feel free to reach out on X or via email if you see errors or have other suggestions!"
  },
  {
    "objectID": "blog-posts/[12]/RRR_mediation.html#load-libraries",
    "href": "blog-posts/[12]/RRR_mediation.html#load-libraries",
    "title": "RRR: Mediation Makes My Head Hurt!",
    "section": "Load libraries",
    "text": "Load libraries\n\n\nShow code\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(psych)\n# library(devtools)\n# install_github(\"jtextor/dagitty/r\")\nlibrary(dagitty)\nlibrary(CMAverse)"
  },
  {
    "objectID": "blog-posts/[12]/RRR_mediation.html#basic-dag",
    "href": "blog-posts/[12]/RRR_mediation.html#basic-dag",
    "title": "RRR: Mediation Makes My Head Hurt!",
    "section": "Basic DAG",
    "text": "Basic DAG\n\n\nShow code\nSimpsonDAG &lt;- dagitty(\"dag{\n  GroupA -&gt; ChgM -&gt; ChgY\n  GroupA -&gt; ChgY\n   }\") \ncoordinates(SimpsonDAG) &lt;- list(\n  x=c(GroupA=1, ChgM=2, ChgY=3),\n  y=c(GroupA=2, ChgM=1, ChgY=2) )\n\nplot(SimpsonDAG)"
  },
  {
    "objectID": "blog-posts/[12]/RRR_mediation.html#simulate-data",
    "href": "blog-posts/[12]/RRR_mediation.html#simulate-data",
    "title": "RRR: Mediation Makes My Head Hurt!",
    "section": "Simulate data",
    "text": "Simulate data\n\n\nShow code\nset.seed(1138)\nn &lt;- 500\nGroupA&lt;-rbinom(n=1000,size=1,prob=0.50)\nChgM &lt;- -.1*GroupA + rnorm(n)\nChgY &lt;- .5*ChgM + -.5*GroupA + .4*GroupA*ChgM + rnorm(n)\nsimdata &lt;- tibble(GroupA, ChgM, ChgY)\n\nsimdata\n\n\n# A tibble: 1,000 × 3\n   GroupA   ChgM    ChgY\n    &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1      0 -0.358  0.687 \n 2      0 -0.490 -2.07  \n 3      0 -0.115  0.895 \n 4      1 -0.451 -1.65  \n 5      1 -0.588 -1.31  \n 6      0 -0.961  0.371 \n 7      1 -0.732 -1.51  \n 8      1  0.294 -0.344 \n 9      0 -0.249  0.0797\n10      1 -2.42  -2.25  \n# ℹ 990 more rows\n\n\n\n\nShow code\nGroupAplot &lt;- simdata %&gt;% ggplot() +\n  geom_bar(aes(x=GroupA),\n                 color=\"#1fa187\", fill=\"#4ac16d\", alpha=.7,\n                 position=\"identity\") + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"GroupA\", y=NULL)\n\nChgMplot &lt;- simdata %&gt;% ggplot() +\n  geom_histogram(aes(x=ChgM, y=..density..),\n                 color=\"#1fa187\", fill=\"#4ac16d\", alpha=.7,\n                 position=\"identity\", \n                 breaks = seq(-4, 4, by = 1)) + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"ChgM\", y=NULL)\n\nChgYplot &lt;- simdata %&gt;% ggplot() +\n  geom_histogram(aes(x=ChgY, y=..density..),\n                 color=\"#1fa187\", fill=\"#4ac16d\", alpha=.7,\n                 position=\"identity\") + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"ChgY\", y=NULL)\n\n\nGroupAplot + ChgMplot + ChgYplot"
  },
  {
    "objectID": "blog-posts/[12]/RRR_mediation.html#bivariate-corrs",
    "href": "blog-posts/[12]/RRR_mediation.html#bivariate-corrs",
    "title": "RRR: Mediation Makes My Head Hurt!",
    "section": "Bivariate corrs",
    "text": "Bivariate corrs\n\nFull sample\nPositive correlation between ChgM and ChgY in full sample.\n\n\nShow code\npairs.panels(simdata,\n             smooth = FALSE,      # If TRUE, draws loess smooths\n             scale = FALSE,      # If TRUE, scales the correlation text font\n             density = TRUE,     # If TRUE, adds density plots and histograms\n             ellipses = FALSE,    # If TRUE, draws ellipses\n             method = \"pearson\", # Correlation method (also \"spearman\" or \"kendall\")\n             pch = 21,           # pch symbol\n             lm = TRUE,         # If TRUE, plots linear fit rather than the LOESS (smoothed) fit\n             cor = TRUE,         # If TRUE, reports correlations\n             jiggle = FALSE,     # If TRUE, data points are jittered\n             factor = 2,         # Jittering factor\n             hist.col = 3,       # Histograms color\n             stars = TRUE,       # If TRUE, adds significance level with stars\n             ci = TRUE)          # If TRUE, adds confidence intervals\n\n\n\n\n\n\n\n\n\n\n\nGroup A only\nPositive correlation between ChgM and ChgY within Group A.\n\n\nShow code\nsimdataA &lt;- simdata %&gt;% filter(GroupA==1) %&gt;% select(-GroupA)\npairs.panels(simdataA, density = TRUE, method = \"pearson\", pch = 21, \n             lm = TRUE, cor = TRUE, hist.col = 3, stars = TRUE, ci = TRUE)  \n\n\n\n\n\n\n\n\n\n\n\nGroup B only\nPositive correlation between ChgM and ChgY within Group B.\n\n\nShow code\nsimdataB &lt;- simdata %&gt;% filter(GroupA==0) %&gt;% select(-GroupA)\npairs.panels(simdataB, density = TRUE, method = \"pearson\", pch = 21, \n             lm = TRUE, cor = TRUE, hist.col = 3, stars = TRUE, ci = TRUE)"
  },
  {
    "objectID": "blog-posts/[12]/RRR_mediation.html#scatterplot-by-group",
    "href": "blog-posts/[12]/RRR_mediation.html#scatterplot-by-group",
    "title": "RRR: Mediation Makes My Head Hurt!",
    "section": "Scatterplot by group",
    "text": "Scatterplot by group\nNotice inconsistent or heterogeneous effect of ChgM on ChgY across Groups.\n\n\nShow code\nggplot(data = simdata, aes(x = ChgM, y = ChgY)) +\n        geom_point(aes(shape = factor(GroupA))) +\n        geom_point(aes(color = factor(GroupA))) +\n        geom_smooth(method = \"lm\", \n                    se = FALSE, \n                    aes(color = factor(GroupA)))"
  },
  {
    "objectID": "blog-posts/[12]/RRR_mediation.html#simple-mediation-model",
    "href": "blog-posts/[12]/RRR_mediation.html#simple-mediation-model",
    "title": "RRR: Mediation Makes My Head Hurt!",
    "section": "Simple mediation model",
    "text": "Simple mediation model\nNegative indirect effect of GroupA on ChgY via ChgM.\n\n\nShow code\nmediate(ChgY ~ GroupA + (ChgM), data = simdata, n.iter = 10000) %&gt;% print(short = TRUE)\n\n\n\n\n\n\n\n\n\n\nMediation/Moderation Analysis \nCall: mediate(y = ChgY ~ GroupA + (ChgM), data = simdata, n.iter = 10000)\n\nThe DV (Y) was  ChgY . The IV (X) was  GroupA . The mediating variable(s) =  ChgM .\n\nTotal effect(c) of  GroupA  on  ChgY  =  -0.62   S.E. =  0.08  t  =  -8.07  df=  998   with p =  2e-15\nDirect effect (c') of  GroupA  on  ChgY  removing  ChgM  =  -0.53   S.E. =  0.06  t  =  -8.47  df=  997   with p =  8.5e-17\nIndirect effect (ab) of  GroupA  on  ChgY  through  ChgM   =  -0.08 \nMean bootstrapped indirect effect =  -0.08  with standard error =  0.04  Lower CI =  -0.17    Upper CI =  0\nR = 0.61 R2 = 0.37   F = 289.17 on 2 and 997 DF   p-value:  5.13e-135 \n\n To see the longer output, specify short = FALSE in the print statement or ask for the summary"
  },
  {
    "objectID": "blog-posts/[12]/RRR_mediation.html#mediation-model-accounting-for-exposure-mediator-interaction",
    "href": "blog-posts/[12]/RRR_mediation.html#mediation-model-accounting-for-exposure-mediator-interaction",
    "title": "RRR: Mediation Makes My Head Hurt!",
    "section": "Mediation model accounting for exposure-mediator interaction",
    "text": "Mediation model accounting for exposure-mediator interaction\nTotal negative indirect effect (PNIE + INTmed) estimate is larger after accounting for exposure-mediator interaction.\n\n\nShow code\nset.seed(1138)\nest &lt;- cmest(data = simdata, model = \"rb\", outcome = \"ChgY\", exposure = \"GroupA\",\n                mediator = \"ChgM\", EMint = TRUE,\n                mreg = list(\"linear\"), yreg = \"linear\",\n                astar = 0, a = 1, mval = list(0),\n                estimation = \"imputation\", inference = \"bootstrap\", nboot = 20)\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |======================================================================| 100%\n\n\nShow code\nsummary(est)\n\n\nCausal Mediation Analysis\n\n# Outcome regression:\n\nCall:\nglm(formula = ChgY ~ GroupA + ChgM + GroupA * ChgM, family = gaussian(), \n    data = getCall(x$reg.output$yreg)$data, weights = getCall(x$reg.output$yreg)$weights)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.03308    0.04337   0.763    0.446    \nGroupA      -0.51010    0.06229  -8.190 7.97e-16 ***\nChgM         0.53021    0.04329  12.248  &lt; 2e-16 ***\nGroupA:ChgM  0.34764    0.06259   5.554 3.58e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.9610836)\n\n    Null deviance: 1559.35  on 999  degrees of freedom\nResidual deviance:  957.24  on 996  degrees of freedom\nAIC: 2804.2\n\nNumber of Fisher Scoring iterations: 2\n\n\n# Mediator regressions: \n\nCall:\nglm(formula = ChgM ~ GroupA, family = gaussian(), data = getCall(x$reg.output$mreg[[1L]])$data, \n    weights = getCall(x$reg.output$mreg[[1L]])$weights)\n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) -0.006556   0.043905  -0.149   0.8813  \nGroupA      -0.120841   0.062786  -1.925   0.0546 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.9850333)\n\n    Null deviance: 986.71  on 999  degrees of freedom\nResidual deviance: 983.06  on 998  degrees of freedom\nAIC: 2826.8\n\nNumber of Fisher Scoring iterations: 2\n\n\n# Effect decomposition on the mean difference scale via the regression-based approach\n \nDirect counterfactual imputation estimation with \n bootstrap standard errors, percentile confidence intervals and p-values \n \n              Estimate Std.error   95% CIL 95% CIU  P.val    \ncde          -0.510101  0.073753 -0.651063  -0.410 &lt;2e-16 ***\npnde         -0.514441  0.074196 -0.638106  -0.410 &lt;2e-16 ***\ntnde         -0.556449  0.076406 -0.692366  -0.431 &lt;2e-16 ***\npnie         -0.064071  0.034397 -0.126845  -0.011 &lt;2e-16 ***\ntnie         -0.106080  0.056820 -0.194148  -0.019 &lt;2e-16 ***\nte           -0.620520  0.089392 -0.778236  -0.465 &lt;2e-16 ***\nintref       -0.004339  0.015854 -0.029367   0.025    0.8    \nintmed       -0.042009  0.025189 -0.095535  -0.008 &lt;2e-16 ***\ncde(prop)     0.822054  0.068527  0.730253   0.935 &lt;2e-16 ***\nintref(prop)  0.006993  0.025298 -0.042487   0.047    0.8    \nintmed(prop)  0.067700  0.035646  0.017009   0.143 &lt;2e-16 ***\npnie(prop)    0.103254  0.047652  0.021586   0.183 &lt;2e-16 ***\npm            0.170953  0.078667  0.038596   0.283 &lt;2e-16 ***\nint           0.074693  0.031196  0.022878   0.120 &lt;2e-16 ***\npe            0.177946  0.068527  0.064943   0.270 &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(cde: controlled direct effect; pnde: pure natural direct effect; tnde: total natural direct effect; pnie: pure natural indirect effect; tnie: total natural indirect effect; te: total effect; intref: reference interaction; intmed: mediated interaction; cde(prop): proportion cde; intref(prop): proportion intref; intmed(prop): proportion intmed; pnie(prop): proportion pnie; pm: overall proportion mediated; int: overall proportion attributable to interaction; pe: overall proportion eliminated)\n\nRelevant variable values: \n$a\n[1] 1\n\n$astar\n[1] 0\n\n$mval\n$mval[[1]]\n[1] 0"
  },
  {
    "objectID": "blog-posts/[2]/favorite_links.html",
    "href": "blog-posts/[2]/favorite_links.html",
    "title": "Check out some of our favorite sites",
    "section": "",
    "text": "Melting heart of statistics in Salvadore Dali’s surrealist style, by DALL-E\nWe have learned so much from blogs, bookdowns, and videos openly shared by others. Here, we compiled a list of some of our favorite resources.\nThis list is far from exhaustive; there are too many influential sources to recall and credit as deserved. Nonetheless, we felt it would be helpful to pull together some of those that we routinely find ourselves revisiting and recommending to others."
  },
  {
    "objectID": "blog-posts/[2]/favorite_links.html#statistics-especially-bayesian-approaches-and-more",
    "href": "blog-posts/[2]/favorite_links.html#statistics-especially-bayesian-approaches-and-more",
    "title": "Check out some of our favorite sites",
    "section": "statistics, especially Bayesian approaches, and more",
    "text": "statistics, especially Bayesian approaches, and more\nAndrew Gelman’s blog is perhaps our favorite place to go for musings on all things statistics, especially Bayesian inference, frequentist evaluation, causal inference, multilevel modeling, uncertainty, and reproducibility. We also appreciate the frequent attention paid to philosophy of science issues throughout many posts. Bonus: if you browse long enough, you might even stumble upon an answer to the question that perennially motivates a career crisis for us: The social sciences are useless, so why do we even study them?.\nSpeaking of Andrew Gelman - do you want to learn regression or Bayesian modeling? Gelman and colleagues’ books and accompanying websites are excellent resources on these topics. However, our go-to resource for learning statistics from a Bayesian framework is Richard McElreath’s Rethinking Statistics (2nd Ed.). All code from the book and a corresponding R package (rethinking) are openly shared online, and McElreath’s brilliant video lectures on YouTube, which he routinely updates, simply are without equal. Seriously - stop reading our site now and go work your way through those lectures and associated code.\nAs much as we love McElreath’s book and lectures for learning a Bayesian approach to data analysis, we usually rely on Paul Bürkner’s “Bayesian regression models using Stan,” or brms(), R package for everyday Bayesian modeling tasks. In addition to the brms() package, we recommend checking out Bürkner’s research projects and publications. In particular, we especially appreciate his work on modeling and visualizing uncertainty in (Bayesian) model comparison and his efforts to incorporate cumulative link functions for modeling monotonic effects of ordinal predictors in Bayesian regression models. Meanwhile, we are particularly fond of Bürkner’s brms vignettes, especially those on multivariate (i.e., multiple response variables) models and monotonic effects. You can also watch his talk on multilevel modeling in brms for free courtesy of @GenerableHQ.\nSo, what if you want to learn Bayesian analysis from McElreath’s book and lectures, yet you also want to follow along with his examples using the brms() package? Enter Solomon Kurz, the data science hero we need but do not deserve. Kurz has dedicated an unfathomable amount of energy to developing Bayesian translations of some of our favorite statistics books into R language and the brms() package, then sharing these valiant efforts in open-access bookdown projects. Specifically, here are Kurz’s translations of the first edition and second edition of McElreath’s book. Additionally, many years agom Jake and I initially learned longitudinal data analysis in the SAS program using Singer and Willett’s (2003) now-classic book; Kurz actually offers a free tidyverse and brms translation of their book as well! Likewise, he has similarly translated two other favorites of ours: Kruschke’s Doing Bayesian Data Analysis and Hayes’ Introduction to Mediation, Moderation, and Conditional Process Analysis. If you make it through all that free content, then we suggest heading over to his informative blog on data analysis in R for more useful content.\nThere are so many others worth mentioning in this section but, in respect of your time, we will simply share the rest in list format:\n\nMatthew Kay’s site for inspiration on communicating and visualizing uncertainty with tidybayes and ggdist. In particular, we recommend Kay’s various package vignettes, such as this one on using tidy data with Bayesian models and this one on slab + interval stats and geoms with ggdist. Also, you can watch Kay’s talk on visualizing uncertainty courtesy of @GenerableHQ.\n\nAndrew Heiss’s blog, especially entries on different types of posterior predictions, marginal effects terminology, and conditional and marginal effects in multilevel models\nAki Vehtari’s work, especially that on model selection, model checking and cross-validation, and posterior stacking. Also, be sure to check out his various videos, like this one on Bayesian workflow or his open access course videos on Bayesian data analysis.\nMichael Betancourt’s writing and videos on probabilistic modeling in Stan, and especially those on adopting a principled Bayesian workflow.\nThe 100% CI is a newer favorite. We are especially fond of Julia Rohrer’s (one of the site’s authors) various writing related to causal inference, like these on directed acyclic graphs, collider bias, and what can go wrong with nonrepresentative samples.\nThe Data Colada blog offers great analysis on various topics. For instance, they write about replication, conduct preregistered replications, and even offer an R package (groundhog) for improving reproducibililty of code. They also have interesting things to say about meta-analysis and problems with common techniques such as funnel plots and trim and fill “corrections”.\nDan Quintana, co-host of the Everything Hertz podcast, also has a blog containing great resources for meta-analysis and more in R.\n\nDaniel Lakens’ blog, the 20% statistician, is rife with useful posts about two of our favorite topics - statistics and philosophy of science. Some of our favorites include posts about p-values, power and observed power, the smallest effect size of interest, or whether philosophy of science matters in practice (we think it does a lot in criminology). Several of his lecture videos are also available online, including this one that corresponds to another favorite post discussing why more of us should seriously consider whether we are really ready to test a hypothesis in our research. Lakens has combined and expanded on a lot of these materials in his open access book, Improving Your Statistical Inferences and his free coursera course of the same name.\n\nOf all the podcasts we enjoy, the Quantitude podcast deserves a special shout-out for its highly informative yet quirky and accessible introduction to all sorts of important issues in statistics. Now, if only the hosts would join the Bayesian dark side.\nJacob Kaplan has multiple resources related to R that are geared specifically to Criminologists. Perhaps most notably is a free online book Crime by the Numbers: A Criminologist’s Guide to R. Kaplan has great programming skills and, as such, many of his examples rely on base R functionality more so than ours do."
  },
  {
    "objectID": "blog-posts/[2]/favorite_links.html#learning-data-science-with-r",
    "href": "blog-posts/[2]/favorite_links.html#learning-data-science-with-r",
    "title": "Check out some of our favorite sites",
    "section": "learning data science with R",
    "text": "learning data science with R\nWhile there is so much to learn from resources found at the links shared above, those are not the first places we send our students and friends that are interested in learning data science skills in R, yet that lack any R programming experience. We find the following links to be especially useful for these purposes - so much so that they deserve their own dedicated section! Of course, we also hope our course materials might be useful in this regard to some of you.\nDanielle Navarro’s blog is as delightful as it is informative. The blog is a model for reproducible R programming and showcases Danielle’s inspiring art throughout the site (see more of Danielle’s computational art here). The newest version of the blog often focuses on technical posts addressing issues beyond our range of program expertise. However, we love various topical essays from earlier blog renditions, like this one on preregistration, and we strongly recommend Danielle’s Data Science with R course and associated video tutorials for R beginners or those interested in leveling up their R skills.\nAllison Hill’s blog is a great place to find resources for learning to do as well as to teach R-related topics. For instance, we especially appreciate her post on teaching R Markdown, which was influential in creating our own courses, as well as her post on transitioning to Quarto, which was helpful to us in creating our blog.\nThe psyTeachR website is a phenomenal repository of resources for learning and teaching reproducible research using R. They offer a wealth of open access courses and tutorials for undergraduate and graduate levels.\nThe easystats collection of R packages is a great place for those new to R to learn basic skills related to modeling, visualization, and reporting within a relatively unified framework. Those new Unlike curated nature of R and package conflicts Those transitioning from curated statistical packages to R’s open-source environment, with its a la carte format and associated challenges (e.g., package conflicts), may find the easystats suite of packages especially helpful.\nOf course, we also love creating data visualizations with ggplot2 in R, so we owe a huge shout out to Hadley Wickham for all his R programming efforts and clear tutorials and foundational texts, which you can learn more about and freely access via his website."
  },
  {
    "objectID": "blog-posts/[2]/favorite_links.html#creating-a-website",
    "href": "blog-posts/[2]/favorite_links.html#creating-a-website",
    "title": "Check out some of our favorite sites",
    "section": "creating a website",
    "text": "creating a website\nIf you want to learn to create your own website or blog using R, we recommend checking out Andrew Rapp’s ultimate guide to creating a Quarto blog, Beatriz Mills’ guide to creating a blog with Quarto in 10 steps, Samantha Csik’s tutorial on adding a blog to your existing Quarto website, and Ezekiel Ekunola’s instructions for setting up a personalized domain address for your site.\nIn addition to R-based visualizations, we relied heavily upon Allison Horst’s website, where she freely shares amazing data science, statistics, and R themed artwork, to help improve our site’s aesthetics. We also had fun generating custom images and art using the artificial intelligence system DALL-E."
  },
  {
    "objectID": "blog-posts/[4]/causation-no-corr.html",
    "href": "blog-posts/[4]/causation-no-corr.html",
    "title": "Causation without Correlation?",
    "section": "",
    "text": "Empty Easter egg, or countervailing causation?"
  },
  {
    "objectID": "blog-posts/[4]/causation-no-corr.html#sec-ladder",
    "href": "blog-posts/[4]/causation-no-corr.html#sec-ladder",
    "title": "Causation without Correlation?",
    "section": "Thinking up the ladder of causation",
    "text": "Thinking up the ladder of causation\nI have taught a version of my undergraduate introductory course on theories of crime and deviance (CJUS-P 200 at Indiana University) nearly every semester for the past 15 years and across three different universities. In each of those courses, my second lecture has always been devoted to teaching principles of causality.\nI start that segment with a thought question and class discussion about what it means to say that something “causes” something else. Most of the time, students start with correlational descriptions of causality, such as “X causes Y means that when X changes, Y tends to change.” Such answers are what Pearl & Mackenzie refer to as a “rung one” observation on the ladder of causation. In contrast, it is much rarer for students to intuit with minimal prompting a counterfactual or “rung three” description of causality, such as “if X caused Y, then Y might not have changed if X had not changed.”\nAt first glance, this may be a bit unexpected. We seem to engage in counterfactual thinking naturally, as it appears central to imagination and rational agency. Pearl and Mackenzie go so far as to claim that the ability to use counterfactual thinking to make “explanation-seeking inferences reliably and repeatably” is what “most distinguishes human from animal intelligence, as well as from model-blind versions of AI and machine learning” (2018, p.33). Moreover, the belief that randomization in controlled experiments offers a valid mechanism for making causal inferences relies upon counterfactual reasoning about potential outcomes; these counterfactual justifications underlying classical statistics were proposed by pioneers Jersey Neyman and Sir Ronald Fisher a century ago! Meanwhile, principled counterfactual frameworks using potential outcomes to make causal inferences with observational data have been in use since the 1970s and represent arguably the best approach to causal identification with observational data today.\nYet, counterfactuals also are weird and can be difficult to comprehend, particularly when using formal statistical notation. So, I still start with a discussion of the three basic criteria for establishing causal claims found in most sociology and criminology textbooks (correlation; nonspuriousness; temporal order). From there, I very briefly introduce students to some more advanced ideas, such as simple versus complex causality, causal chains, causal mechanisms and mediation, effect heterogeneity and moderation, and, of course, counterfactual causality. In doing so, I often tell students that, while they might know that correlation does not necessarily imply causation, they may be surprised to learn that causation may exist even in the absence of observed correlation."
  },
  {
    "objectID": "blog-posts/[4]/causation-no-corr.html#sec-reasons",
    "href": "blog-posts/[4]/causation-no-corr.html#sec-reasons",
    "title": "Causation without Correlation?",
    "section": "Causation without correlation",
    "text": "Causation without correlation\n\n\n\nPop art portrait of someone very confused, by DALL-E\n\n\nTo say students are surprised by this claim is an understatement - many seem confused or downright skeptical when I state it. After all, didn’t we just discuss how a basic criteria for establishing that X causes Y is observing a correlation between X and Y? Anticipating this confusion, I provide an example involving multiple mediation.\nIn fact, there are a number of reasons why two variables, X & Y, can be causally related despite the lack of an observed bivariate or conditional (partial) correlation between them that have nothing to do with multiple mediation. Many of these reasons involve a failure to detect a correlation where one is expected to exist due to an existing causal relationship (notice the counterfactual reasoning again?). Examples include poor measurement and insufficient statistical power of a test to detect an effect, or improper modeling of nonlinear (e.g., parabolic) functional relationships, or sample selection bias. Interestingly, it is possible to fail to observe a correlation between two variables even when in situations where there is nearly perfect functional causality (see advanced example at end here).\nWhile it is certainly important to understand how and why we might sometimes fail to statistically detect a correlation between X & Y where one might be causally expected, the example I use draws from a different situation in which one would not even expect the existence of a statistical correlation between X & Y even with precise measurement, sufficient power, careful sampling, and so on, and despite a reasonable belief in the existence of causal processes or mechanisms connecting X & Y. Examples of this situation might include counteracting direct and indirect effects or multiple countervailing mediators.\nThe statistical literature on mediation was particularly formative for my thinking on this topic. For example, consider the following excerpt from Andrew Hayes’ (2009, p.413) article, Beyond Baron & Kenny: Statistical Mediation Analysis in the New Millennium, which was published around the time I first started teaching my theories of crime course and in the same year that I published my very first article, which included a “test” of a mediation hypothesis using the old school Baron & Kenny method:\n\nCan Effects that Don’t Exist be ‘Mediated’?\n If a mediator is a variable, M, that is causally between X and Y and that accounts at least in part for the association between X and Y, then by definition X and Y must be associated in order for M to be a mediator of that effect. According to this logic, if there is no evidence that X affects Y, then how can X’s effect on Y be mediated and so what is the point of estimating indirect and direct effects? But it is possible for M to be causally between X and Y even if X and Y aren’t associated. In this case, some prefer to avoid the term mediator when describing M and instead refer simply to X’s indirect effect on Y through M…\n The distinction between mediation and indirect effect is not always made by users of the Baron and Kenny method, who may prematurely end the hunt for evidence of indirect effects if there is no evidence that X and Y are associated. If the size of c [path coefficients] constrained the size of a and b and therefore their product, this logic would make sense. Unfortunately, no such constraints exist, and it is easy to show that the claim that X can’t affect Y indirectly in the absence of a detectable total effect is false.\n\nIn this excerpt, Hayes first expresses the common sentiment that X & Y must be correlated if they are causally connected through a mediator, then proceeds to inform us that this view has been debunked as a myth. Yet, despite this being a well-established fact in the mediation/indirect effect literature for many years, I was surprised to find very few accessible examples online to which I could point students and colleagues for a more detailed illustration of the type of situation I regularly describe to them. So, I did what any nerd who recently learned R would do - I simulated some data to help my students better visualize an example. Then, I thought that others also might be uninformed or confused about the issue, and here we are."
  },
  {
    "objectID": "blog-posts/[4]/causation-no-corr.html#sec-ai",
    "href": "blog-posts/[4]/causation-no-corr.html#sec-ai",
    "title": "Causation without Correlation?",
    "section": "AI to the rescue?",
    "text": "AI to the rescue?\n\n\n\nCartoon person seeking wisdom from a computer oracle, by DALL-E\n\n\nBefore transforming my simulation example for students into a blog entry, I sought the wisdom of the artificial intelligence oracle ChatGPT, thinking it might lead me to existing examples that I was missing. I realize that, at present, ChatGPT is not particularly well-suited for causal reasoning, as Pearl himself has documented and the AI oracle itself has humbly admitted, though it also notes some ability to extract, mimic, or make guesses from data containing information about causal relations. Nonetheless, I asked the oracle: “Is it possible to have causation without correlation?”\nFor those interested in such things, I have included the full conversation with ChatGPT in the expandable link below.\n\n\nConversation with ChatGPT (4/5/2023, 12:20am)\n\n\n\n\nJon Brauer  Is it possible to have causation without correlation?\n\n\nChatGPT  Yes, it is possible to have causation without correlation. While causation and correlation are often related, they are not the same thing.\nCorrelation refers to a statistical relationship between two variables, where a change in one variable tends to be associated with a change in the other variable. However, correlation does not necessarily imply causation, because there could be other factors at play that influence both variables. For example, there is a correlation between the number of ice cream cones sold and the number of drownings each year, but this does not mean that ice cream causes drownings.\nCausation, on the other hand, refers to a relationship where one event (the cause) brings about another event (the effect). A causal relationship can exist even if there is no correlation between the two variables, because the relationship is not dependent on a statistical pattern. For example, smoking causes lung cancer, but not everyone who smokes gets lung cancer, and not everyone with lung cancer smokes.\nIn summary, while correlation and causation are often linked, they are not the same thing, and it is possible to have causation without correlation.\n\n\nJon Brauer  In your smoking example, if smoking causes lung cancer, wouldn’t there also be a statistical relationship (i.e., a correlation) between smoking and lung cancer? The statement that “not everyone who smokes gets lung cancer, and not everyone with lung cancer smokes” does not rule out the possibility (or the likelihood) of a statistical relationship - it only rules out the possibility of a perfect correlation.\n\n\nChatGPT  You are correct that in the case of smoking causing lung cancer, there is typically a statistical relationship (i.e., a correlation) between smoking and lung cancer. In fact, smoking is one of the strongest risk factors for developing lung cancer, and studies have consistently shown a strong correlation between smoking and lung cancer.\nMy previous statement about not everyone who smokes getting lung cancer and not everyone with lung cancer smoking was intended to highlight the fact that while there is a strong correlation between smoking and lung cancer, it is not a perfect correlation. In other words, there are some people who smoke and do not develop lung cancer, and there are some people who develop lung cancer even though they have never smoked.\nSo while a correlation between smoking and lung cancer does exist, it is not a one-to-one relationship, and it is possible for some smokers to avoid lung cancer and for some non-smokers to develop lung cancer. However, this does not negate the fact that smoking is a significant risk factor for developing lung cancer, and the statistical relationship between the two remains strong.\n\n\nJon Brauer  Yes, but the question was whether it is possible to have causation without correlation. You gave an example of causation with correlation.\n\n\nChatGPT  You are correct, my apologies for any confusion. The smoking example I gave was indeed an example of causation with correlation.\nTo provide an example of causation without correlation, imagine a scenario where a scientist discovers that a specific gene mutation causes a rare disease that affects only a small portion of the population. In this case, there may not be a statistical relationship or correlation between the gene mutation and the disease in the general population, because the disease is so rare and the gene mutation is only found in a small portion of the population. However, there is a clear causal relationship between the gene mutation and the disease.\nSo, to answer the original question more accurately, it is possible to have causation without a statistically significant correlation between the two variables in the general population, as in the rare disease example described above.\n\n\nJon Brauer  In that example, again, there is a correlation between the gene mutation and the disease. I did not ask about whether there could be causation without a statistically significant correlation - statistical significance depends on power of the test. So, in this causal example, if you had a sufficiently large sample, the correlation would also be detected, making it another example of causation with correlation.\n\n\nChatGPT  You are correct, and I apologize for the confusion. In the scenario I described, there is indeed a correlation between the gene mutation and the rare disease, even though it may not be statistically significant in the general population due to the low prevalence of the disease.\nIt is true that statistical significance depends on the power of the test and the sample size, and it is possible that a correlation between two variables could become statistically significant with a larger sample size. Therefore, in this case, with a larger sample size, the correlation between the gene mutation and the rare disease would likely be detected, and it would be an example of causation with correlation.\nThank you for pointing out this mistake in my previous responses, and I hope this clarification is helpful.\n\n\nJon Brauer  So, can you think of another example of causation without correlation that does not involve an insufficiently powered test for detecting correlation?\n\n\nChatGPT  Yes, I can provide another example of causation without correlation that does not involve an insufficiently powered test for detecting correlation.\nConsider the example of a person who takes a medication that causes a significant reduction in their symptoms of a medical condition. In this case, there is a clear causal relationship between taking the medication and the improvement in symptoms, but there may not be a statistical correlation between the two variables in the general population.\nThis lack of correlation could be due to a number of factors, such as individual differences in the severity or type of the medical condition, or differences in the dosage or timing of the medication. Additionally, the relationship between the medication and the symptoms could be confounded by other factors, such as the person’s diet, exercise habits, or stress levels.\nSo, in this scenario, while there may not be a statistically significant correlation between taking the medication and the improvement in symptoms in the general population, there is a clear causal relationship between the two variables in the individual person who experienced the improvement in symptoms.\n\n\nJon Brauer  This example again leverages a lack of statistical significance, which I am unmoved by such arguments. For instance, here, there is causation and likely correlation - but the correlation is not detectable due to improper modeling due to issues like heterogeneity in the strength of the effect, confounding, poor measurement, or inadequately specifying dosage and time. Can you think of any other examples that are different from these?\n\n\nChatGPT  Thank you for the feedback and clarification. I will provide another example of causation without correlation that is different from the previous examples.\nConsider the example of a person who develops a fear of flying after experiencing a traumatic event on a plane, such as severe turbulence or an emergency landing. In this case, the traumatic event on the plane is the direct cause of the person’s fear of flying.\nHowever, there may not be a statistical correlation between traumatic events on planes and the development of a fear of flying in the general population. This is because not everyone who experiences a traumatic event on a plane will develop a fear of flying, and some people may develop a fear of flying for other reasons unrelated to traumatic events.\nTherefore, in this scenario, there is a clear causal relationship between the traumatic event on the plane and the person’s fear of flying, but there may not be a statistically significant correlation between the two variables in the general population.\n\n\nJon Brauer  Interesting. If it was a singular event, then would there not be a perfect correlation between flight exposure and fear of flying since there are two data points (pre-exposure level of fear & post-exposure levels of fear)? If it is not a singular event and there is some proportion of the population that develops fear of flying after exposure to flying, then again we are back to the rare genetic cause of disease example - with sufficient data, we would be able to detect this causally driven correlation in the population. Any other ideas?\n\n\nChatGPT  You make a good point, and I apologize for any confusion. The example I provided may not be a good example of causation without correlation.\nAnother example of causation without correlation could be the case of a person who develops an allergic reaction to a specific food after consuming it for the first time. In this case, the food is the direct cause of the allergic reaction, but there may not be a statistically significant correlation between consuming the food and developing an allergic reaction in the general population.\nThis lack of correlation could be due to individual differences in genetics or immune system function, or differences in the amount or preparation of the food consumed. Additionally, the relationship between the food and the allergic reaction could be confounded by other factors, such as the person’s age or other underlying health conditions.\nTherefore, in this scenario, while there may not be a statistically significant correlation between consuming the food and developing an allergic reaction in the general population, there is a clear causal relationship between the two variables in the individual person who experienced the allergic reaction.\n\n\nJon Brauer  Again, this example seems to have a very similar logical structure and empirical implications of your previous examples. I am going to write a blog entry on causation without correlation that covers a different type of example. I will share the idea with you in case it helps you answer questions like this. Another reason there might be causation without correlation is that an exposure affects multiple mechanisms that have countervailing effects on an outcome. For instance, the exposure might be causally related to the mediators and correlated with the mediators, but and the mediators are causally related to the outcome and correlated with the outcome but in opposite directions, thereby resulting in a null (negated or cancelled out) correlation in the population. There would still be causation, though, since one could imagine intervening on one mediating pathway to hold it constant, then the exposure would cause change the outcome - and be correlated with the outcome - through the other mediating pathway. Have you encountered any examples like this before?\n\n\nChatGPT  Thank you for sharing your idea. That is a very interesting perspective on causation without correlation, and it makes sense that an exposure affecting multiple mechanisms could result in countervailing effects on an outcome, leading to a null correlation in the population.\nI have not encountered this specific example before, but I can see how it could arise in situations where there are complex and interrelated causal pathways between an exposure and an outcome. For example, in a study investigating the effects of a particular medication on a disease outcome, the medication may affect multiple biological pathways that have opposing effects on the disease outcome. As a result, the overall correlation between medication use and disease outcome may be null or weak, even though the medication is causing changes in the underlying biological pathways and ultimately influencing the disease outcome.\nI hope this example helps to provide a different perspective on causation without correlation, and thank you for bringing up this interesting topic.\n\n\nTo its credit, ChatGPT recognized the possibility of causation without correlation. However, it primarily provided examples where causation exists and correlation would be expected to exist but, for reasons such as event rarity, shoddy measurement, or insufficiently powered tests, researchers are unable to detect an actually existing (i.e., nonzero) correlation. Again, what I wanted was an example where causality exists, yet where we would not expect to detect a correlation (e.g., we might expect r=0)."
  },
  {
    "objectID": "blog-posts/[4]/causation-no-corr.html#sec-dependence",
    "href": "blog-posts/[4]/causation-no-corr.html#sec-dependence",
    "title": "Causation without Correlation?",
    "section": "Causation does require statistical dependence",
    "text": "Causation does require statistical dependence\nOne final point of clarification before getting to an example. The basic criteria are not really wrong. Causation involves statistical dependence between X and (mechanisms of) Y, and statistical dependence may exist despite a lack of observed linear correlation. I think it may be easier for some people to understand how this might happen for methodological reasons (e.g., imprecise measures; insufficient data; mispecified model) than it is to understand how this might happen for theoretical reasons. Counterfactual reasoning can help; so can causal models or directed acyclic graphs (DAGs).\nFor instance, you might be wondering if it is really useful or accurate to say that X causes Y if there is no (total) statistical dependence between X & Y - that is, if (in some populations or samples comprised of units with particular levels of key variables) Y does not reliably change after X changes. Yes, I think so! To understand why, it is helpful to consider an example, to rely on causal models, and to engage in counterfactual thinking. There are many possible examples; for simplicity, let’s imagine only four variables - X, M1, M2, and Y - that are causally related like so:\n\n\nShow code\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(psych)\n# library(devtools)\n# install_github(\"jtextor/dagitty/r\")\nlibrary(dagitty)\n\nXYdag &lt;- dagitty(\"dag{\n  X -&gt; M1 -&gt; Y\n  X -&gt; M2 -&gt; Y\n   }\") \ncoordinates(XYdag) &lt;- list(\n  x=c(X=1, M1=2, M2=2, Y=3),\n  y=c(X=2, M1=1, M2=3, Y=2) )\n\nplot(XYdag)\n\n\n\n\n\n\n\n\n\nIn this hypothetical example, imagine that increasing or “dialing up the knob” on X causes an increase in both M1 and M2. Imagine also that increasing or dialing up M1 causes an increase in Y, whereas an increase in M2 causes a decrease in Y of comparable magnitude in the opposite direction (i.e., countervailing indirect effects). So, when we dial up X, we also causally up M1 and M2, which in turn equivalently dials Y up (through M1) and down (through M2) - meaning Y does not change when X changes despite changes in mediators.\nSo, you might still be wondering whether it is reasonable to describe this situation as one in which X causes Y, or whether this is an example of causation without (XY) correlation. Again, I say YES! To understand why, let’s use counterfactual reasoning. I want you to further imagine that we identify a way to intervene on the X -&gt; M1 -&gt; Y pathway. For instance, perhaps we design an intervention to mitigate or disrupt the X -&gt; M1 causal effect so that, when we dial up X, M1 no longer subsequently increases or it increases to a much lesser degree; that is, our intervention allows us to hold constant the level of M1 following a change in X, thereby negating the positive indirect effect of X on Y through M1. Now in this counterfactual situation, when we dial up X, what would happen to Y? It would change in a causally predictable way: If X increases, Y would decrease due to the negative indirect effect of X on Y through M2!\nI hope this abstract example helps illustrate why, without the proper causal model guiding our statistical modeling decisions and interpretations of data, it is easy to fail to observe statistical dependence where it exists (and vice versa) and then to incorrectly infer a lack of causality (or its presence) from the absence (or presence) of observed correlation. To avoid such traps, what we need is to understand theoretically how and why X is related to Y - e.g., by creating a causal diagram that accurately depicts the causal relationship(s) between these variables and by using counterfactual reasoning. Once we identify the correct causal model generating the data, then we can model the data in a way that permits us to observe statistical dependence and identify the causal effect(s) of X on Y. In short, we really need to understand theory, or logical statements of the causal relations between concepts, to properly model and interpret our data.\nWith all that said, it can be difficult to grasp abstract examples, and it may be tempting to wonder whether such situations really exist in our world. So, let’s draw inspiration from a real study in criminology to add meat to the abstract bones of our example."
  },
  {
    "objectID": "blog-posts/[4]/causation-no-corr.html#sec-sescrim",
    "href": "blog-posts/[4]/causation-no-corr.html#sec-sescrim",
    "title": "Causation without Correlation?",
    "section": "Example from criminology",
    "text": "Example from criminology\nSpecifically, we will draw inspiration from Bradley Wright and colleagues’ (1999) paper in Criminology entitled “Reconsidering the relationship between SES and delinquency: Causation but not correlation.” Seems fitting, eh?\nThe basic idea is this: There is a long history of debates over the SES-delinquency relationship. Some theories specifically posit a negative causal relationship (i.e., low SES -&gt; high delinquency), yet observational research has documented inconsistent patterns (e.g., weak negative, nonexistent, or even positive relationships). Wright and colleagues argue that this state of affairs may be due to SES simultaneously having positive and negative causal effects on crime through countervailing mechanisms. Together, the positive and negative effects of these mechanisms may generally offset each other in many survey datasets, which might result in observing a lack of any bivariate correlation between SES and delinquency (i.e., “total effect” estimate = 0) and/or inconsistent partial correlations (i.e., variable conditional direct effect etimates) depending on which mechanisms are included or excluded from researchers’ statistical models.\nWe will illustrate how something like this might happen using simulated data. Specifically, we will simulate data for parental SES, child delinquency, and two potential countervailing mechanisms - financial strain and perceived risk of detection of delinquent behaviors. In our simulated example, we will assume parental SES does not directly cause child delinquency and that it indirectly causes child delinquency through both mediating mechanisms. Additionally, we will assume that the causal effects of Parental SES on financial strain and perceived risk of detection are equal in magnitude and that the causal effect of financial strain on delinquency is equal in magnitude yet opposite in direction, such that both indirect or mediated effects offset one another. Below is a directed acyclic graph, or DAG, of this simple causal structure.\n\n\nShow code\nSESdag &lt;- dagitty(\"dag{\n  SES -&gt; Strain -&gt; Delinquency\n  SES -&gt; Risk -&gt; Delinquency\n   }\") \ncoordinates(SESdag) &lt;- list(\n  x=c(SES=1, Strain=2, Risk=2, Delinquency=3),\n  y=c(SES=2, Strain=1, Risk=3, Delinquency=2) )\n\nplot(SESdag)\n\n\n\n\n\n\n\n\n\nNow let’s simulate some data. In doing so, note we round data drawn from continuous (i.e., normal & Poisson) distributions to integers; this adds a bit of noise to the data yet also makes our variables more comparable to the types of ordinal, Likert-type measures we see in our field.\n\n\nShow code\n# X = Parental SES\n# Y = Child delinquent behavior\n# F = Mediatior through which high Parent SES might decrease delinquency - e.g., less financial (S)train\n# P = Mediators through which high Parent SES increase delinquency - e.g., lower perceived (R)isk of detection\n\n# Strain -&gt; Delinquency &lt;- Risk \n# Strain &lt;- SES -&gt; Risk\n\nset.seed(1138)\nn &lt;- 1000\n\n# McElreath method (p.153)\n# SES &lt;- rnorm(n)\n# Strain &lt;- rnorm(n,SES)\n# Risk &lt;- rnorm(n,SES)\n# Delinquency &lt;- rnorm(n,Strain-Risk)\n# \n\n# https://www.tandfonline.com/doi/pdf/10.1080/10691898.2020.1752859\nset.seed(1138)\nn &lt;- 1000\nSES &lt;- round(rnorm(n),digits=0)\nStrain &lt;- round(-.5*SES + rnorm(n),digits=0)\nRisk &lt;- round(-.5*SES + rnorm(n),digits=0)\nDelinquency &lt;- round(.5*Strain + -.5*Risk + 0*SES + rpois(n,1),digits=0)\n\nsimdata &lt;- tibble(SES, Strain, Risk, Delinquency)\nsimdata &lt;- simdata %&gt;% mutate(\n  Delinquency = ifelse(Delinquency &lt; 0, Delinquency == 0, Delinquency)\n)\n\nsimdata\n\n\n# A tibble: 1,000 × 4\n     SES Strain  Risk Delinquency\n   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;\n 1    -1      1     0           2\n 2    -1     -1     0           0\n 3     0      1     1           2\n 4     0     -1     0           0\n 5    -1      0     1           0\n 6    -1      1     0           2\n 7     2     -1    -1           1\n 8    -1      0    -1           4\n 9     0      0    -2           2\n10     1      0    -1           4\n# ℹ 990 more rows\n\n\nShow code\nSESplot &lt;- simdata %&gt;% ggplot() +\n  geom_histogram(aes(x=SES, y=..density..),\n                 color=\"#1fa187\", fill=\"#4ac16d\", alpha=.7,\n                 position=\"identity\", \n                 breaks = seq(-4, 4, by = 1)) + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"Parental SES\", y=NULL)\n\nStrainplot &lt;- simdata %&gt;% ggplot() +\n  geom_histogram(aes(x=Strain, y=..density..),\n                 color=\"#1fa187\", fill=\"#4ac16d\", alpha=.7,\n                 position=\"identity\", \n                 breaks = seq(-4, 4, by = 1)) + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"Financial strain\", y=NULL)\n\nRiskplot &lt;- simdata %&gt;% ggplot() +\n  geom_histogram(aes(x=Risk, y=..density..),\n                 color=\"#1fa187\", fill=\"#4ac16d\", alpha=.7,\n                 position=\"identity\", \n                 breaks = seq(-4, 4, by = 1)) + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"Perceived risk of detection\", y=NULL)\n\nDelqplot &lt;- simdata %&gt;% ggplot() +\n  geom_histogram(aes(x=Delinquency, y=..density..),\n                 color=\"#1fa187\", fill=\"#4ac16d\", alpha=.7,\n                 position=\"identity\") + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"Child delinquency\", y=NULL)\n\n\nSESplot + Strainplot + Riskplot + Delqplot\n\n\n\n\n\n\n\n\n\n\nBivariate correlation\nLet’s examine the bivariate correlations between our simulated variables.\n\n\nShow code\n# https://r-coder.com/correlation-plot-r/  \n\npairs.panels(simdata,\n             smooth = FALSE,      # If TRUE, draws loess smooths\n             scale = FALSE,      # If TRUE, scales the correlation text font\n             density = TRUE,     # If TRUE, adds density plots and histograms\n             ellipses = FALSE,    # If TRUE, draws ellipses\n             method = \"pearson\", # Correlation method (also \"spearman\" or \"kendall\")\n             pch = 21,           # pch symbol\n             lm = TRUE,         # If TRUE, plots linear fit rather than the LOESS (smoothed) fit\n             cor = TRUE,         # If TRUE, reports correlations\n             jiggle = FALSE,     # If TRUE, data points are jittered\n             factor = 2,         # Jittering factor\n             hist.col = 3,       # Histograms color\n             stars = TRUE,       # If TRUE, adds significance level with stars\n             ci = TRUE)          # If TRUE, adds confidence intervals\n\n\n\n\n\n\n\n\n\nAs the pairs plot shows, there is virtually no correlation between SES and delinquency (r = -0.01). However, SES is negatively correlated with both mediators - financial strain (r = -0.43) and perceived risk (r = -0.40). Additionally, the mediator-delinquency correlations are similar in magnitude but opposite in direction (r = 0.30 for financial strain; r = -0.35 for perceived risk).\nGiven this, if we estimate a linear model1 regressing delinquency on SES without the mediators, we should see another near-zero association between SES and delinquency because this model essentially reproduces the bivariate correlation (with a partially standardized beta coefficient). This means the total effect of SES - its direct effect plus all indirect effects through other mechanisms like financial strain and perceived risk, all combined - is estimated to be virtually zero (b = -0.01, se = 0.04). Thus, either SES has no direct or indirect causal effects on delinquency, or SES has direct and/or indirect causal effects on delinquency but we have failed to adequately identify it with our statistical model (and with the assumed causal model underlying it). For instance, perhaps the causal effect is non-linear, with positive and negative effects on delinquency at different levels of SES that average out to a null total effect. Or, perhaps SES has countervailing indirect effets through different mediating mechanisms and, together, the mediators offset each other to result in no total causal effect.\nOf course, we know this last explanation is the true data generating process here because we simulated the data accordingly! However, in real-world data analysis, if you were to observe no correlation between two variables, you now know that it is unwise to immediately assume that there is no causal relationship between them.\n\n\nLinear regressions\nThe scatterplot and regression line from our bivariate linear regression model again illustrates the lack of total association between our simulated SES and delinqueny variables.2\n\n\nShow code\nlm1a &lt;- lm(Delinquency ~ SES, data=simdata)\n# summary(lm1a)\nsummary(lm1a)$coefficients[,1:2]\n\n\n               Estimate Std. Error\n(Intercept)  1.09914632 0.03855249\nSES         -0.01125514 0.03849479\n\n\nShow code\n# plot(simdata$SES, simdata$Delinquency)\n# abline(lm1a)\n\n#equation for delinquency regression line  \neqY1a=function(x){\n  coef(lm1a)[2]*x + coef(lm1a)[1]\n  }\n\nlmYplot &lt;- ggplot(simdata,aes(y=Delinquency,x=SES)) +\n  geom_jitter(alpha=.4, shape=21, size=2, width=.2, height=.2, color=\"#009E73\") + \n  stat_function(fun=eqY1a, geom=\"line\", color=\"#009E73\", size=1.5) +\n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"SES\", y=\"Delinquency\")\nlmYplot\n\n\n\n\n\n\n\n\n\nNow, let’s estimate a linear model regressing delinquency on SES and include both mediators as predictors in the model as well and then plot the regression line (with mediators set at their mean values). Once again, we should see a near-zero association between SES and delinquency, but for very different reasons this time. In this model, we are estimating what is commonly referred to as the direct effect of SES after stratifying on (aka, adjusting for) any potential indirect effects through financial strain and perceived risk mechanisms. Of course, we simulated our data in such a way that there would be no direct causal effect of SES on delinquency in our simulated data and, after including both mechanisms in the model, we accurately estimate virtually no direct effect of SES on delinquency (b = -0.03, se = 0.04). Hence, this plot looks comparable to the bivariate one above.\n\n\nShow code\nlm1b &lt;- lm(Delinquency ~ SES + Strain + Risk, data=simdata)\n# summary(lm1b)\nsummary(lm1b)$coefficients[,1:4]\n\n\n               Estimate Std. Error     t value      Pr(&gt;|t|)\n(Intercept)  1.07938412 0.03338240  32.3339287 2.126993e-157\nSES         -0.02905861 0.03980686  -0.7299899  4.655680e-01\nStrain       0.38859596 0.03290744  11.8087577  3.274331e-30\nRisk        -0.43975564 0.03164821 -13.8951191  2.980525e-40\n\n\nShow code\n# plot(simdata$SES, simdata$Delinquency)\n# abline(lm1b)\n\n#equation for delinquency regression line in model with both mediators at means  \neqY1b=function(x){\n  coef(lm1b)[2]*x + coef(lm1b)[1] +\n    coef(lm1b)[3]*mean(simdata$Strain) + coef(lm1b)[4]*mean(simdata$Risk)\n  }\n\nlmYplot2 &lt;- ggplot(simdata,aes(y=Delinquency,x=SES)) +\n  geom_jitter(alpha=.4, shape=21, size=2, width=.2, height=.2, color=\"#009E73\") + \n  stat_function(fun=eqY1b, geom=\"line\", color=\"#009E73\", size=1.5) +\n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"SES\", y=\"Delinquency\")\nlmYplot2\n\n\n\n\n\n\n\n\n\nNote that this model above also estimates a positive effect of financial strain (b = 0.39, se = 0.03) and a negative effect of perceived risk (b = -0.44, se = 0.03) on delinquency. So, we might conclude that these theoretical mechanisms are related to delinquency as expected. But how would we know SES has indirect causal effects on delinquency through these mechanisms - i.e., that these variables mediate the SES-delinquency relationship? Well, we could estimate additional models regressing each mediator on SES; if SES predicts each mediator (which we know it does in our simulated data) and if each mediator predicts delinquency then, with certain strong assumptions in place (e.g., no exposure-mediator interaction and no unmeasured confounding of any paths; see here, here, and here), we can infer indirect causal effects of SES on delinquency. This is essentially the logic behind the classic Baron & Kenny method. We can also extend this logic to test for and estimate the magnitude and confidence intervals around such indirect effects through each specific mediator.3\n\n\nSpringing the causal trap\nBut without jumping ahead to mediation tests, what would have happened if we had failed to specify the appropriate causal model ahead of time and, as a result, we mistakenly included only one mediator in the model with SES predicting delinquency? Let’s add financial strain to the model and exclude perceived risk from the model, then see what happens.\n\n\nShow code\nlm1c &lt;- lm(Delinquency ~ SES + Strain, data=simdata)\n# summary(lm1c)\nsummary(lm1c)$coefficients[,1:3]\n\n\n             Estimate Std. Error   t value\n(Intercept) 1.0982531 0.03642628 30.150019\nSES         0.1790345 0.04027868  4.444895\nStrain      0.3951323 0.03593409 10.996029\n\n\nShow code\n# plot(simdata$SES, simdata$Delinquency)\n# abline(lm1c)\n\n#equation for delinquency regression line in model with one mediator (at its mean)  \neqY1c=function(x){\n  coef(lm1c)[2]*x + coef(lm1c)[1] +\n    coef(lm1c)[3]*mean(simdata$Strain) \n  }\n\nlmYplot3 &lt;- ggplot(simdata,aes(y=Delinquency,x=SES)) +\n  geom_jitter(alpha=.4, shape=21, size=2, width=.2, height=.2, color=\"#009E73\") + \n  stat_function(fun=eqY1c, geom=\"line\", color=\"#009E73\", size=1.5) +\n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"SES\", y=\"Delinquency\")\nlmYplot3\n\n\n\n\n\n\n\n\n\nUh oh. Suddenly, our model estimates a positive effect of SES on delinquency! Why?! Well, since we stratified on (adjusted for) financial strain, we essentially removed SES’s indirect effect on delinquency that operates through financial strain from our causal estimate. However, since we simulated these data, we know that SES also has an indirect effect on delinquency through perceived risk that is excluded from our model. So, the positive causal estimate of SES on delinquency in this model (b = 0.18, se = 0.04) reflects any direct effects of SES on delinquency (which we set to equal “0” in our simulation) and any indirect effects of SES on delinquency through unmeasured mediators - in this case, through perceived risk. We know that, in our simulated example, SES increases delinquency by reducing perceived risk of detection among those with high SES - that is, SES has a positive indirect causal effect on delinquency through perceived risk. Likewise, if we stratify on financial strain, thereby adjusting our estimate for this other known mediator, we are left with a positive estimate of the net causal effect of SES on delinquency (which we know is through perceived risk).\nThis should help illustrate an important point about so-called direct effect estimates - they are not really estimating “direct” effects at all. Rather, like bivariate correlation and regression coefficients, they are simply descriptive statistics that summarize the total effect of a predictor (SES) on an outcome (delinquency) through any and all unmeasured mechanisms.\nThis is an essential point. Imagine we were analyzing real non-simulated observational data and, after including measures of known mediating mechanisms (e.g., financial strain; perceived risk) in our model, we observed no association or “direct effect” of SES on delinquency (like in our second model lm1b above). In that situation, it is possible that there are no other mediating mechanisms through which SES might cause delinquency. However, it is also possible that there are additional unmeasured mechanisms that, combined, offset each other to result in a near-zero total remaining causal effect!\nMoreover, bivariate correlations and partial regression coefficients also may be biased by effects of other unmeasured sources of confounding as well. In our simulation, we made a strong simplifying assumption that there were no such unmeasured sources of confounding and that we had identified all relevant mechanisms. However, with real data, such assumptions often are highly implausible. Hence, if one cares about causal effects of a variable (SES) on an outcome (delinquency) - total, indirect, or otherwise - then it is essential to identify the appropriate causal model and then to include (or exclude) variables as appropriate to accurately estimate the causal effect of interest. One cannot simply let the data speak.\n\n\n\nData cannot speak meme\n\n\n\n\nSimple mediation tests\nFinally, let’s illustrate a simple test of the indirect effect of SES on delinquency using mediate() from the psych package.4\n\n\nShow code\nmediate(Delinquency ~ SES + (Strain) + (Risk), data = simdata, n.iter = 10000) %&gt;% print(short = TRUE)\n\n\n\n\n\n\n\n\n\n\nMediation/Moderation Analysis \nCall: mediate(y = Delinquency ~ SES + (Strain) + (Risk), data = simdata, \n    n.iter = 10000)\n\nThe DV (Y) was  Delinquency . The IV (X) was  SES . The mediating variable(s) =  Strain Risk .\n\nTotal effect(c) of  SES  on  Delinquency  =  -0.01   S.E. =  0.04  t  =  -0.29  df=  998   with p =  0.77\nDirect effect (c') of  SES  on  Delinquency  removing  Strain Risk  =  -0.03   S.E. =  0.04  t  =  -0.73  df=  996   with p =  0.47\nIndirect effect (ab) of  SES  on  Delinquency  through  Strain Risk   =  0.02 \nMean bootstrapped indirect effect =  0.02  with standard error =  0.03  Lower CI =  -0.04    Upper CI =  0.08\nR = 0.5 R2 = 0.25   F = 112.47 on 3 and 996 DF   p-value:  3.83e-79 \n\n To see the longer output, specify short = FALSE in the print statement or ask for the summary\n\n\nAs before, these models estimate a near-zero total effect (c = -0.01) and so-call “direct effect” (c’ = -0.03) of SES on delinquency. However, SES is negatively associated with both mediators, and each mediator has a comparably sized yet opposite effect on delinquency. The text results also indicate that the total indirect effect of SES on delinquency through both mediators is nearly zero as well (Mean bootstrapped indirect effect [ab] of SES on Delinquency through Strain and Risk = 0.02; standard error = 0.03; 95% CI = [-0.04, 0.08]). This should be unsurprising since we simulated the data so that the two indirect effects would equally offset one other, resulting in a total indirect effect of zero.\nWe could re-estimate the model, specifying each mechanism separately as a posited mediator, to calculate an estimate of the specific indirect effect through each mediator. Or, we could multiply the SES-&gt;Mediator path coefficient and the Mediator-&gt;Delinquency path coefficient together to get basic estimates of these specific indirect effects. For instance, using this “product of ab coefficients” approach, we would estimate a negative indirect effect of SES on delinquency through financial strain (-0.48 * 0.39) approximately equal to -0.19 and a positive indirect effect through perceived risk (-0.47 * -0.44) approximately equal to 0.21.5 As expected, these countervailing indirect effects nearly perfectly offset one another!\nSo, this was a long-winded illustration of just one way that two variables might be causally related even in the absence of observing a (bivariate; total; direct) correlation between them!"
  },
  {
    "objectID": "blog-posts/[4]/causation-no-corr.html#sec-caution",
    "href": "blog-posts/[4]/causation-no-corr.html#sec-caution",
    "title": "Causation without Correlation?",
    "section": "Concluding cautions",
    "text": "Concluding cautions\nFinally, remember that although this example was inspired by a published study, ours is also a contrived example using simulated data designed to help you think more deeply about causation and (non)correlation. With simulated data, we create the rules and can ensure strong mediation assumptions are met. Yet, in the real world of messy observational data, there are often countless plausible causal models that could have generated the patterns of correlations in one’s data. For an excellent example, check out Julia Rohrer’s blog entry about hunting for indirect effects in the absence of a total effect (e.g., correlation) between X & Y. She warns:\n\nThird, be wary of mediation in the absence of a total effect. There may be scenarios in which it makes sense, but confounding may be the more plausible alternative explanation in other scenarios.\n\nHer example beautifully, or frighteningly, illustrates how a collider can produce an erroneous inference about an indirect effect. You might be wondering to yourself: what the heck is a collider? Great question. To us, it is the scary monster in our statistical modeling closet that keeps us up at night; neither of us have ever really seen the monster, but we’ve read enough stories about it to be convinced that it is there. We’ll try tackling that one another time…"
  },
  {
    "objectID": "blog-posts/[4]/causation-no-corr.html#footnotes",
    "href": "blog-posts/[4]/causation-no-corr.html#footnotes",
    "title": "Causation without Correlation?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYes, I realize that I simulated the outcome variable, Delinquency, from a Poisson distribution - you got me. I should be specifying a generalized linear regression model (e.g., Poisson distribution with a log link) instead to avoid generating biasing estimates and accurately recover simulated parameters. But, then I would need to get into more advanced issues related to estimating indirect effects in nonlinear models, which would distract from the key point here. Let’s get this straight: I adopted a simple modeling approach that is a poor match to the more complex (simulated) data I am analyzing for the sake of easing interpretation for the reader. Sound familiar? Now, it seems I have painted myself into a corner. Don’t worry - I have a mantra to get us out of this mess, courtesy of my dad: Do as I say and not as I do! If you are considering estimating indirect effects with real-world data, please check out counterfactual causal mediation approaches; various packages in R, like CMAverse or medflex, might do the trick. Moreover, in the course of conducting real science, don’t paint yourself into a corner. You’ll just be stuck in place for a long time and the job won’t be finished, or you’ll get paint on your shoes and make a huge mess that someone has to clean up.↩︎\nWe used geom_jitter() to slightly offset or spread out observations that fall at the exact same place on the plot, which can be helpful in a scatterplot displaying a limited (e.g., ordinal) variable. With this method, observations cluster around their actual values rather than directly on the same crowded points, which permits you to see where data are plentiful or sparse along the observed distributions.↩︎\nIt remains common for researchers to use the Sobel product of coefficients approach for mediation tests and to estimate bias corrected bootstrapped confidence intervals. However, for most observational data applications, I typically recommend using a causal mediation approach that relies on counterfactual reasoning using a potential outcomes framework to estimate controlled and natural direct and indirect effects, along with careful consideration and transparent reporting of the strong assumptions required to interpret mediation results as causal effects.↩︎\nThis is a very basic mediation function that applies the Sobel product of ab coefficients approach mentioned earlier. Remember, do as I say and not as I do! As noted above, I would not recommend this approach for most applications to observational data. However, in this case, the data were simulated from random distributions and a simple causal mediation structure without confounding or exposure-mediator interactions, so we know the strong causal mediation assumptions hold. As such, this simple approach is sufficient for our purposes. That is, assuming you did us a solid by ignoring our Poisson-distributed outcome variable - and all the paint on our shoes.↩︎\nUsing the population parameters we specified to generate our simulated sample, the population ab indirect effect magnitudes equal (-0.5 * 0.5) = -0.25 and (-0.5 * -0.5) = 0.25, respectively.↩︎"
  },
  {
    "objectID": "blog-posts/[6]/modmadness-pt1.html",
    "href": "blog-posts/[6]/modmadness-pt1.html",
    "title": "Moderator Madness, Part 1",
    "section": "",
    "text": "Two lemmings confused by nonlinear interactions (with help from DALL-E)"
  },
  {
    "objectID": "blog-posts/[6]/modmadness-pt1.html#preamble",
    "href": "blog-posts/[6]/modmadness-pt1.html#preamble",
    "title": "Moderator Madness, Part 1",
    "section": "Preamble",
    "text": "Preamble\nThis is the first of a three-part blog series on modeling moderators in criminological data.1 I started writing this series as a single entry designed introduce the need and a method for disentangling indirect and interaction effects in the presence of a potential exposure-mediator interaction. That topic is now the focus of Part 2 and Part 3 in this series.\nAlong the way, I intended to briefly cover issues I routinely find myself raising in manuscript reviews in criminology related to the estimation and interpretation of interaction effects with binary or skewed count outcome variables. First, estimating interactions with such data using linear regression methods can generate misleading interaction terms that are data artifacts of a poorly fitting model. Second, generalized linear regression models with nonlinear link functions (e.g., logistic, Poisson, and negative binomial regression) may generate coefficients that more accurately summarize the underlying data generating process, but these coefficients - and especially the interaction terms - often are misinterpreted.\nWe touched upon this topic in our previous post on collider bias but, as an issue I encounter repeatedly when reviewing manuscripts, I felt it needed a more detailed treatment before digging into exposure-mediator interactions. Well, this important aside ultimately was not brief at all, so it seemed more appropriate to write it as a standalone post. So, this topic is now the focus of Part 1.\nNow, let’s get started with an “imaginary” story about an imaginary author before moving on to illustrate these issues using imaginary (ok, simulated) data."
  },
  {
    "objectID": "blog-posts/[6]/modmadness-pt1.html#sec-twopapers",
    "href": "blog-posts/[6]/modmadness-pt1.html#sec-twopapers",
    "title": "Moderator Madness, Part 1",
    "section": "Two papers walk into a bar…",
    "text": "Two papers walk into a bar…\nImagine the following: In one study, a researcher hypothesizes the existence of a causal mediation process, such that parental support causes delinquency both directly and indirectly through its mediated effect on strong moral beliefs. Then, with this theoretical assumption at work, they build linear regression models to test for and then find evidence of an indirect effect, which leads to a published paper describing support for this hypothesized causal process. That assumed causal process can be simply depicted in the following causal diagram or directed acyclic graph (DAG):\n\n\nShow code\n#|message=FALSE\n\n# devtools::install_github(\"BS1125/CMAverse\")\n\n#Load libraries \n\n# library(here) #start by loading here package for self-referential file directory structure\n# \n# library(groundhog) #load groundhog package for reproducible date-specified library loading\n# # here() #check here() working directory\n# # get.groundhog.folder() # check default groundhog working directory - may be diff than here()\n# set.groundhog.folder(here()) #set groundhog working directory to same as here()\n# groundhog.day=\"2023-06-15\" #assign date as object (at least two days before today)\n# pkgs &lt;- c(\"tidyverse\", \"simstudy\", \"ggplot2\", \"patchwork\", \"truncnorm\", \"see\",\n#           \"dagitty\", \"ggdag\", \"sjPlot\", \"ggthemes\", \"margins\", \n#           \"ggraph\", \"gt\", \"gtsummary\")\n# groundhog.library(\"github::BS1125/CMAverse\", groundhog.day)\n# groundhog.library(pkgs, groundhog.day)\n\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(simstudy)\n  # https://cran.r-project.org/web/packages/simstudy/vignettes/simstudy.html\n  # https://kgoldfeld.github.io/simstudy/articles/simstudy.html\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(truncnorm)\nlibrary(see)\nlibrary(dagitty)\nlibrary(ggdag)\nlibrary(sjPlot)\nlibrary(ggthemes)\nlibrary(margins)\nlibrary(CMAverse)\nlibrary(ggraph)\nlibrary(gt)\nlibrary(gtsummary)\n\n#function to shorten arrows (edges)\n# https://stackoverflow.com/questions/65420136/how-do-you-adjust-the-arrows-in-a-ggplot-of-a-ggdag\nshorten_dag_arrows &lt;- function(tidy_dag, proportion){\n# Update underlying ggdag object\ntidy_dag$data &lt;- dplyr::mutate(tidy_dag$data, \n                             xend = (1-proportion/2)*(xend - x) + x, \n                             yend = (1-proportion/2)*(yend - y) + y,\n                             xstart = (1-proportion/2)*(x - xend) + xend,\n                             ystart = (1-proportion/2)*(y-yend) + yend)\nreturn(tidy_dag)\n}\n\n\n\n#build dag\nnointDAG &lt;- dagify(\n  Delinquency ~ ParentSupport + StrgMoralBlfs,\n  StrgMoralBlfs ~ ParentSupport, \n  exposure = \"StrgMoralBlfs\",\n  outcome = \"Delinquency\",\n  coords=list(\n    x=c(ParentSupport=1, StrgMoralBlfs=1.5, Delinquency=2),\n    y=c(ParentSupport=0, StrgMoralBlfs=0.5, Delinquency=0)\n  )) %&gt;% tidy_dagitty() \n\n#shorten edges\nnointDAGp &lt;- shorten_dag_arrows(nointDAG, 0.08)\n\n#plot dag\nfig1 &lt;- nointDAGp %&gt;% ggplot(aes(x=x, y=y, xend=xend, yend=yend)) +\n  geom_dag_edges(edge_color=\"darkgrey\") +\n  geom_dag_text(label=c(\"Delinquency\", \"Parental\\nSupport\", \"Strong\\nMoral\\nBeliefs\"), \n                color=\"#56B4E9\") +\n  theme_dag() + \n  guides(fill = 'none', color = 'none') +\n  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) +\n    #change default expansion on y-axis min & max\n  # ggtitle(\"DAG w/mediation & no interaction\") + \n  theme(plot.title = element_text(size = 12))\n\nggsave(\"fig1.png\")\n\n\n\n\n\n\n\n\n\nFigure 1. DAG for mediation (& moderation) paper\n\n\n\n\n\n\n\n\n\nImaginary Paper #1\n\n\n\nAfter submitting the mediation paper for review and potential publication, imagine the researcher then considers the possibility that parental support and strong moral beliefs might also interact in predicting delinquency. For instance, perhaps they now posit that moral beliefs have a more pronounced negative effect on delinquency among youth who perceive low parental support, yet moral beliefs might have a weak or null effect (e.g., it might be a redundant cause) among youth who perceive high parental support.\nThough the causal processes for both “paper 1” and “paper 2” could be represented by the same structural DAG depicted in Figure 1 above,2 it is common for criminologists to explicitly depict moderating relationships in causal diagrams. So, for the sake of familiarity, I also present a modified causal diagram depicting the posited moderation (interaction effect) for “paper 2” in Figure 2 below. The moderation indicator is a red dashed arrow to signify its departure from traditional DAG rules.\n\n\nShow code\nintDAG &lt;- dagify(\n  Delinquency ~ ParentSupport + StrgMoralBlfs,\n  StrgMoralBlfs ~ ParentSupport, \n  holder ~ ParentSupport, \n  exposure = \"StrgMoralBlfs\",\n  outcome = \"Delinquency\",\n  coords=list(\n    x=c(ParentSupport=1, StrgMoralBlfs=1.5, holder=1.8, Delinquency=2),\n    y=c(ParentSupport=0, StrgMoralBlfs=0.5, holder=0.3, Delinquency=0)\n  )) %&gt;% tidy_dagitty() \n\n#shorten edges\nintDAGp &lt;- shorten_dag_arrows(intDAG, 0.08)\n\n#create factor variable to isolate edge of interest, permits specifying edge color\nintDAGp &lt;- intDAGp %&gt;% dplyr::mutate(\n  myedge1 = if_else(intDAGp$data$name == \"ParentSupport\" & intDAGp$data$to == \"holder\",\n                    \"yes\", \"no\"), \n  modlinetype = ifelse(myedge1 == \"yes\", \"solid\", \"dashed\")\n  ) \n\n#plot dag\nfig2 &lt;- intDAGp %&gt;% ggplot(aes(x=x, y=y, xend=xend, yend=yend)) +\n  geom_dag_edges(aes(x = xstart, y = ystart, edge_color=myedge1, \n                     edge_linetype = modlinetype), show.legend = FALSE) +\n  geom_dag_text(data = function(x) filter(x, name != \"holder\"), \n                label=c(\"Delinquency\", \"Parental\\nSupport\", \"Strong\\nMoral\\nBeliefs\"), \n                color=\"#56B4E9\") +\n  theme_dag() + \n  # guides(fill = 'none', color = 'none', edge_color = 'none') +\n  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) + #change default expansion on y-axis min & max\n  scale_edge_colour_manual(values=c(\"darkgrey\", \"maroon\")) + #change second color to highlight focal myedge1 \n  # ggtitle(\"DAG w/mediation & interaction\") + \n  theme(plot.title = element_text(size = 12))\nggsave(\"fig2.png\")\n\n\n\n\n\n\n\n\n\nFigure 2. Modified causal diagram depicting moderation\n\n\n\n\n\n\n\n\n\nImaginary Paper #2\n\n\n\nNo problem! We know what to do - just build another regression model, throw in an interaction term, and test for the interaction, right? Another paper, another brick in the wall of (cargo cult) science.\nPlease, don’t leave just yet. I promise this is not another blog entry about piecemeal or salami sliced publications.3 While on the subject of what this blog is not about, I will also refrain from discussing the perverse structural incentives that motivate piecemeal publishing.4\nThose are topics for another day. In this blog series, my main focus is to introduce some common issues criminologists face, often unknowingly, when modeling moderating relationships. Ultimately, my aim in Part 2 and Part 3 will be to build upon the examples in Part 1 to introduce a statistical issue that might be wreaking havoc behind the scenes in many situations like the one described above: the the inability to distinguish mediation from moderation in commonly used regression-based tests of indirect or interaction effects in the presence of an exposure-mediator interaction. In doing so, I will make the case that both studies should really be combined into a single study in which the researcher explicitly models both the mediating and moderating relationships and then uses a potential outcomes approach to decompose the overlapping indirect and interaction effects. But, before we get there, I want to point out a couple other interaction-related pitfalls that threaten to snare researchers on the road to testing interaction effects.\n\nWhen data are normally non-normal, it’s interactions all the way down\nBefore attempting to tackle the problem of distinguishing mediation from moderation (in Parts 2 and 3), let’s first consider that the outcome variable in the imaginary papers discussed above - delinquent behaviors - is a relatively rare event. As such, delinquency measures tend to be quite positively skewed, resembling rare Poisson or negative binomial event count distributions.\nWhy does this matter? Well, as some criminologists have warned, testing a moderation hypothesis using a multiplicative interaction term in a linear regression model fit to a highly skewed outcome variable like delinquency can generate significant interaction effect estimates that are statistical artifacts caused by improper model specification. Meanwhile, if these outcomes are modeled using generalized linear equations with nonlinear link functions (e.g., logistic; Poisson; negative binomial), then the interpretation of interaction terms changes drastically and, technically, all model coefficients are conditional - essentially, it is interactions all the way down.\nPut simply, conceptualizing, estimating, and interpreting interaction effects is much harder than many people realize when their outcome variable is binary, rare event, and/or highly skewed, as is often the case when studying crime. In these situations, I will illustrate why it is advisable to specify the proper functional form, to use caution or restraint when interpreting coefficients, and to visualize interactions by plotting them, preferably on the (predicted probability or event rate) outcome scale.\n\n\n\n“It’s not you, it’s me.” Nonlinear interactions are statistical heartbreakers."
  },
  {
    "objectID": "blog-posts/[6]/modmadness-pt1.html#sec-outline",
    "href": "blog-posts/[6]/modmadness-pt1.html#sec-outline",
    "title": "Moderator Madness, Part 1",
    "section": "Outline of the post",
    "text": "Outline of the post\nIn Part 1, I will illustrate some of these issues with two examples using simulated data.\n\nExample 1\nIn the first example, I assume the causal process from the first imaginary paper (“paper 1”) is the true underlying data generating process by simulating data that include a direct effect of parental support on delinquency and an indirect effect through strong moral beliefs. Importantly, in this first example, I do not include a multiplicative interaction term (i.e., an exposure-mediator interaction) in the linear equation predicting logged delinquency event rates when simulating the data. So, if a linear model estimates a non-negligible and statistically significant interaction coefficient, then the result might be due to random sampling variation, or it could be an artifact from inappropriate model specification (e.g., applying a linear model to a skewed outcome variable).\nThe central aim of this first example is to demonstrate such an interaction artifact in a linear model. Along the way, I hope to reinforce some important intuitions about generalized linear models with nonlinear link functions (e.g., logistic; Poisson; negative binomial): (1) that these models are fundamentally interactive in the outcome scale of interest; and (2) that you should ignore the sign and statistical significance of interaction coefficients and, instead, improve inferences through plotting potential interactions in the outcome scale of interest.\n\n\nExample 2\nIn the second example, I assume that the true data generating process underlying both imaginary papers (i.e., “paper 1” and “paper 2” in our example above) is an integrated causal model in which moral beliefs is both a mediating and moderating mechanism. That is, in the simulated data for the second example, there is a true indirect effect of parental support on delinquency through strong moral beliefs as well as a direct effect of parental support on delinquency that varies systematically across levels of (i.e., “interacts with”) strong moral beliefs.\nIn Part 1, I will simply illustrate how adding a small multiplicative (exposure-mediator) interaction term on the estimation scale might further change predicted counts on natural outcome scale. In doing so, I will use this example again to reinforce the lesson that you should ignore the sign and statistical significance of interaction coefficients from nonlinear models.\nIn Parts 2 and 3 of the blog series, I will illustrate how an exposure-mediator interaction entangles indirect and interaction effects in a way that requires decomposition of these effects. Part 3 will also pick up here using similar simulated data from this example to illustrate how one can accomplish effect decomposition in R with a causal mediation approach that involves clever estimation of potential outcomes and transparent acknowledgement of strong causal assumptions underlying those estimates."
  },
  {
    "objectID": "blog-posts/[6]/modmadness-pt1.html#sec-Ex1",
    "href": "blog-posts/[6]/modmadness-pt1.html#sec-Ex1",
    "title": "Moderator Madness, Part 1",
    "section": "Example 1: No interaction on linear estimation scale",
    "text": "Example 1: No interaction on linear estimation scale\nLet’s simulate some data.5 Parental support is a continuous, normally distributed, mean-centered variable. Strong moral beliefs is a negatively skewed ordinal variable ranging from 0 to 5, created by reverse-scoring a truncated Poisson-distributed weak moral beliefs variable. Delinquency is a positively skewed, Poisson-distributed event count variable ranging from 0 to a truncated theoretical maximum of 7 (observed max = 6 in first simulation).\nIn the first simulation, parental support causes strong moral beliefs (positive association), whereas both parental support and strong moral beliefs cause delinquency (negative associations). There is no multiplicative interaction between parental support and strong moral beliefs in the linear equation predicting logged delinquency event rates.\n\n\nShow code\noptions(scipen=0, digits = 3)\n\n# Simulate data (Sim.1)\n\nset.seed(1138)\nn &lt;- 850 \n\ndef &lt;- defData(varname = \"ParentSupport\", dist = \"normal\", \n               formula = 0, variance = 1)\ndef &lt;- defData(def, varname = \"WeakMoralBlfs\", dist = \"poisson\",\n    formula = \"-.3 + (-.5)*ParentSupport\", link = \"log\")\ndef &lt;- defData(def, varname = \"Delinquency\", dist = \"poisson\",\n    formula = \"-.7 + (-.25)*ParentSupport + .4*WeakMoralBlfs\", link = \"log\")\nsimdat &lt;- genData(n, def)\n\n# cap LowMoral at 5 (0-5 item) if necessary - randomly replace any oob values with values in bounds \ninds &lt;- simdat$WeakMoralBlfs &gt; 5\nsimdat$WeakMoralBlfs[inds] &lt;- sample(0:5, sum(inds), replace = TRUE)\nsimdat$StrgMoralBlfs &lt;- 5 - simdat$WeakMoralBlfs\n\n# cap Delinquency at 7 (0-7 item) if necessary - randomly replace any oob values with in bounds values\ninds &lt;- simdat$Delinquency &gt; 7\nsimdat$Delinquency[inds] &lt;- sample(0:7, sum(inds), replace = TRUE)\n\n# Plot variable distributions\n\nParSupplot &lt;- simdat %&gt;% ggplot(aes(x=ParentSupport, y=..density..)) +\n  geom_histogram(alpha=.5, position=\"identity\", \n                 color = \"#009E73\", fill = \"#009E73\", \n                 breaks = seq(-4, 4, by = 1)) + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"Parental Support\", y=NULL)\n\nStrgMoralplot &lt;- simdat %&gt;% ggplot(aes(x=StrgMoralBlfs, y=..density..)) +\n  geom_histogram(alpha=.5, position=\"identity\", \n                 color = \"#009E73\", fill = \"#009E73\") + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"Strong moral beliefs\", y=NULL)\n\nDelqplot &lt;- simdat %&gt;% ggplot(aes(x=Delinquency, y=..density..)) +\n  geom_histogram(alpha=.5, position=\"identity\", \n                 color = \"#009E73\", fill = \"#009E73\") + \n  theme_minimal() + \n  theme(axis.text.y=element_blank(),  \n        axis.ticks.y=element_blank()\n        ) +\n  labs(x=\"Delinquency\", y=NULL)\n\n\nParSupplot + StrgMoralplot + Delqplot + \n  guide_area() + plot_layout(guides = 'collect')\n\n\n\n\n\nFigure 3. Simulated variable distributions\n\n\n\n\n\nModel & plot interaction artifact\nNow, let’s build a model for our hypothetical “paper 2” in which we test the hypothesis that parental support and strong moral beliefs interact to predict delinquency.\nRecall, I included an indirect effect but did not explicitly include an interaction when simulating the data, so some readers might not expect to observe a statistically significant interaction coefficient if we include a multiplicative interaction term. Yet, nonlinear models complicate things, as such models generate conditional effect estimates that might still be interactive on particular scales (e.g., on probability or event count scale versus linear scale of estimation).\nTo illustrate, I will present results of a linear model regressing delinquency on parental support, strong moral beliefs, and their interaction, as well as a comparable generalized linear (aka, “nonlinear”) model specifying a Poisson distribution for delinquency with a log link. Though I will present the key coefficients from regression models, I will not get into model performance or checks, and I will rely primarily on examining marginal effects plots at low (-2SD) and high (+2SD) parental support values in the outcome scale (predicted delinquency event counts) using sjPlot::plot_model() function to interpret results and determine the existence of interactions.\nAdditionally - and this is important - in building the “imaginary paper 2” model, I conceptualize moral beliefs as the focal cause and parental support as the moderator in this Part 1 entry, despite the fact that parental support was the focal cause and moral beliefs was the mediating mechanism in imaginary paper 1. Why would I switch things up like this? Because I can. It is inconsequential to the statistical issues I want to illustrate here. However, doing so permits me to reinforce a key theme found throughout our blog: Correlations - including indirect and conditional (interaction) estimates - are statistically symmetric and can be modeled in a variety of correct and incorrect ways. Here, I want you to imagine how easy it would be for an author to write a paper using the tables and plots below, all while knowing that it might not accurately depict the underlying causal processes used to motivate and generate the simulated data. As we have discussed in previous posts on causation without correlation and on colliders, data analysis alone cannot tell us that our models are incorrectly specified; only theory (and our theory-based DAG) can do that for us.6\n\n\n\nData cannot speak meme\n\n\n\n\nShow code\n#|message=FALSE\n\n# Sim.1 linear model\nlm1 &lt;- lm(Delinquency ~ ParentSupport * StrgMoralBlfs, data=simdat)\n\n# Sim.1 nonlinear model\nglm1 &lt;- glm(Delinquency ~ ParentSupport * StrgMoralBlfs, data=simdat, family=\"poisson\")\n\n# Set table theme\ntheme_gtsummary_compact()\n\n# function for custom p-values\nroundp &lt;- function(x) {\n    if_else(\n      is.na(x), \n      NA_character_,\n      if_else(x &lt; 0.001, format(x, digits = 3, scientific = TRUE), format(round(x, 3), scientific = F))\n    )\n  } \n\n# function for reg output w/custom p-values\nregsum &lt;- function(mymod) {\n  tbl_regression(mymod, intercept=TRUE, \n                 pvalue_fun = roundp) %&gt;%\n  add_significance_stars(\n        hide_se = FALSE,\n        hide_ci = FALSE,\n        hide_p = FALSE\n      )\n}\n\nEx1tab1 &lt;- regsum(lm1) %&gt;%\n  as_gt() %&gt;%\n  gt::tab_header(title = \"Linear model, Simulation 1\") \n\nEx1tab2 &lt;- regsum(glm1) %&gt;%\n  as_gt() %&gt;%\n  gt::tab_header(title = \"Nonlinear Poisson model, Simulation 1\") \n\n\n\nResults (Simulation 1)\nNote: Click on the tabs to switch between models.\n\nLinear modelNonlinear Poisson model\n\n\n\n\nShow code\nEx1tab1\n\n\n\n\n\n\n\n\nLinear model, Simulation 1\n\n\nCharacteristic\nBeta1\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n2.3***\n0.177\n1.9, 2.6\n4.03e-35\n\n\nParentSupport\n-0.78***\n0.159\n-1.1, -0.46\n1.24e-06\n\n\nStrgMoralBlfs\n-0.36***\n0.040\n-0.44, -0.28\n6.34e-19\n\n\nParentSupport * StrgMoralBlfs\n0.14***\n0.036\n0.07, 0.21\n1.30e-04\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\nEx1tab2\n\n\n\n\n\n\n\n\nNonlinear Poisson model, Simulation 1\n\n\nCharacteristic\nlog(IRR)1,2\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n1.3***\n0.178\n0.94, 1.6\n2.91e-13\n\n\nParentSupport\n-0.13\n0.140\n-0.41, 0.14\n0.340\n\n\nStrgMoralBlfs\n-0.39***\n0.042\n-0.47, -0.31\n2.52e-20\n\n\nParentSupport * StrgMoralBlfs\n-0.03\n0.035\n-0.10, 0.04\n0.372\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 IRR = Incidence Rate Ratio, SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\nNote there is a statistically significant multiplicative interaction term in the linear model (b = 0.14, p &lt; 0.001). Though the interaction term is not significant in the nonlinear Poisson model, remember that we cannot interpret these beta coefficients the same way as we do linear regression coefficients. As noted earlier, models with nonlinear link functions are fundamentally conditional and potentially interactive on different scales of interest; relying on the significance and sign or direction of coefficients alone can lead to serious misinterpretation of results from regression models with nonlinear link functions. Instead, I prefer to rely on plots of predicted delinquency event rates to interpret model results, which lend themselves to more natural interpretations in the original outcome metric.\n\n\nShow code\n#|message=FALSE\n\n# Plot interaction in outcome scale\n\n#use -2SD & +2SD for low & high parental support, respectively, to plot interaction  \nLowParSup &lt;- mean(simdat$ParentSupport) - 2*sd(simdat$StrgMoralBlfs)\n\nHiParSup &lt;-  mean(simdat$ParentSupport) + 2*sd(simdat$StrgMoralBlfs)\n\n\nplot_lm1 &lt;- plot_model(lm1, type = \"pred\",  \n                       terms = c(\"StrgMoralBlfs\", \"ParentSupport [-2,2]\")) + \n  theme_minimal() + coord_cartesian(xlim=c(0,5), ylim=c(0,7)) + scale_colour_colorblind(labels = c(\"Low\", \"High\")) + \n  scale_fill_colorblind() + labs(x=\"Strong Moral Beliefs\", y=\"Delinquency\", title=\"Linear model, Sim.1\")  \n\nplot_glm1 &lt;- plot_model(glm1, type = \"pred\",  \n                       terms = c(\"StrgMoralBlfs\", \"ParentSupport [-2,2]\")) + \n  theme_minimal() + coord_cartesian(xlim=c(0,5), ylim=c(0,7)) + scale_colour_colorblind(labels = c(\"Low\", \"High\")) + \n  scale_fill_colorblind() + labs(x=\"Strong Moral Beliefs\", y=\"Delinquency\", title=\"Nonlinear model, Sim.1\")  \n\n\nplot_lm1 + plot_glm1 + plot_layout(guides = 'collect') &\n  theme(legend.position = 'bottom',\n        legend.direction = 'horizontal')\n\n\n\n\n\n\n\n\n\nA comparison of the effects plotted in the predicted event rate metric suggests there is an interaction in the linear model (i.e., the predicted event rate lines are not parallel) but no interaction in the nonlinear model (i.e., lines are nearly parallel). Recall, the data were simulated from a mediation model without any interactions between these two causes in the linear estimation scale, so we suspect the observed interaction in the linear model outcome scale is likely a data artifact created by applying a linear model to a skewed outcome variable.\n\n\n\nIn nonlinear models, it’s interactions all the way down\nYou might be thinking that we can solve this interaction artifact problem by simply specifying a Poisson distribution rather than a linear model. After all, the nonlinear Poisson model is a better match to the underlying data generating process and, as desired, that model does not show an interaction in the outcome scale. That is certainly important since, as I noted earlier, applying a linear model to skewed outcome data indeed can generate interaction artifacts. Unfortunately, things are not so simple. When we use nonlinear link functions, all our model coefficients are conditional, and our model-based predictions are inherently scale-dependent.\nWhat does this mean? Well, imagine I were to adjust for another covariate in model - say, a normally distributed control variable with a mean = 0. The focal coefficients and predicted event rate plots may change substantially after adjusting for this new covariate - even if the covariate is only correlated with the outcome and uncorrelated with either of the focal predictors! (I will illustrate this later in Example 1c.) Again, this scale-dependence is due to the nonlinear transformation in generalized linear models; traditional linear regression coefficients do not share this conditional property because the outcome scale is constant.\nMuch has been written about this topic; I recommend this post for a brief primer and accessible examples using logistic regression. I particularly appreciate their “Quote of the day”:\n\nDepartures from additivity imply the presence of interaction types, but additivity does not imply the absence of interaction types. (Greenland & Rothman, 1998)\n\nI will try to further strengthen this intuition by slightly modifying the first example.\n\n\n\nGreenland & Rothman (1998) said it with the best words. But reading is so hard… ;)\n\n\n\n\nExample 1b: Slight modification to simulated data\nIn the code below, I made only one slight modification to the data simulation in Example 1: I specified a stronger linear effect of moral beliefs on delinquency by increasing from b = 0.4 to b = 0.6. I did not add a multiplicative interaction term, nor did I explicitly change the functional form or nature of the relationships in our simulation. Rather, I simply increased the strength of the linear correlation between the mediator and the outcome. Let’s see what happens.\n\n\nShow code\n#|message=FALSE\n\noptions(scipen=0, digits = 3)\n\n# Simulate data (Sim.1b)\n\nset.seed(1138)\nn &lt;- 850 \n\ndef1b &lt;- defData(varname = \"ParentSupport\", dist = \"normal\", \n               formula = 0, variance = 1)\ndef1b &lt;- defData(def1b, varname = \"WeakMoralBlfs\", dist = \"poisson\",\n    formula = \"-.3 + (-.5)*ParentSupport\", link = \"log\")\ndef1b &lt;- defData(def1b, varname = \"Delinquency\", dist = \"poisson\",\n    formula = \"-.7 + (-.25)*ParentSupport + .6*WeakMoralBlfs\", link = \"log\")\nsimdat1b &lt;- genData(n, def1b)\n\n# cap LowMoral at 5 (0-5 item) - randomly replace oob values with values in bounds \ninds &lt;- simdat1b$WeakMoralBlfs &gt; 5\nsimdat1b$WeakMoralBlfs[inds] &lt;- sample(0:5, sum(inds), replace = TRUE)\nsimdat1b$StrgMoralBlfs &lt;- 5 - simdat1b$WeakMoralBlfs\n\n# cap Delinquency at 7 (0-7 item) - randomly replace oob values with in bounds values\ninds &lt;- simdat1b$Delinquency &gt; 7\nsimdat1b$Delinquency[inds] &lt;- sample(0:7, sum(inds), replace = TRUE)\n\n# Sim.1b linear model\nlm1b &lt;- lm(Delinquency ~ ParentSupport * StrgMoralBlfs, data=simdat1b)\n\n# Sime.1b nonlinear model\nglm1b &lt;- glm(Delinquency ~ ParentSupport * StrgMoralBlfs, data=simdat1b, family=\"poisson\")\n\nEx1tab1b &lt;- regsum(lm1b) %&gt;%\n  as_gt() %&gt;%\n  gt::tab_header(title = \"Linear model, Sim.1b\") \n\nEx1tab2b &lt;- regsum(glm1b) %&gt;%\n  as_gt() %&gt;%\n  gt::tab_header(title = \"Nonlinear model, Sim.1b\") \n\n# Plot interaction\n\nplot_lm1b &lt;- plot_model(lm1b, type = \"pred\",  \n                       terms = c(\"StrgMoralBlfs\", \"ParentSupport [-2,2]\")) + \n  theme_minimal() + coord_cartesian(xlim=c(0,5), ylim=c(0,7)) + scale_colour_colorblind(labels = c(\"Low\", \"High\")) + \n  scale_fill_colorblind() + labs(x=\"Strong Moral Beliefs\", y=\"Delinquency\", title=\"Linear model, Sim.1b\")  \n\nplot_glm1b &lt;- plot_model(glm1b, type = \"pred\",\n                        terms = c(\"StrgMoralBlfs\", \n                                 \"ParentSupport [-2,2]\")) + \n  theme_minimal() + coord_cartesian(xlim=c(0,5), ylim=c(0,7)) +\n  scale_colour_colorblind(labels = c(\"Low\", \"High\")) +\n  scale_fill_colorblind() +\n  labs(x=\"Strong Moral Beliefs\", y=\"Delinquency\", \n       title=\"Nonlinear model, Sim.1b\")  \n\n\n\nResults (Sim.1b, Stronger covariate effect)\n\nLinear modelNonlinear Poisson modelPrediction Plots\n\n\n\n\nShow code\nEx1tab1b\n\n\n\n\n\n\n\n\nLinear model, Sim.1b\n\n\nCharacteristic\nBeta1\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n3.7***\n0.202\n3.3, 4.1\n1.50e-63\n\n\nParentSupport\n-1.2***\n0.181\n-1.5, -0.80\n3.24e-10\n\n\nStrgMoralBlfs\n-0.64***\n0.045\n-0.73, -0.56\n4.72e-41\n\n\nParentSupport * StrgMoralBlfs\n0.21***\n0.041\n0.13, 0.29\n5.56e-07\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\nEx1tab2b\n\n\n\n\n\n\n\n\nNonlinear model, Sim.1b\n\n\nCharacteristic\nlog(IRR)1,2\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n2.0***\n0.147\n1.8, 2.3\n5.58e-44\n\n\nParentSupport\n0.03\n0.118\n-0.20, 0.27\n0.779\n\n\nStrgMoralBlfs\n-0.52***\n0.036\n-0.59, -0.45\n1.00e-47\n\n\nParentSupport * StrgMoralBlfs\n-0.09**\n0.030\n-0.15, -0.03\n0.004\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 IRR = Incidence Rate Ratio, SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n(plot_lm1b + plot_lm1) / (plot_glm1b + plot_glm1) + \n  plot_layout(guides = 'collect') &\n  theme(legend.position = 'bottom',\n        legend.direction = 'horizontal')\n\n\n\n\n\n\n\n\n\n\n\n\nAs before, I specified a mediating relationship but did not specify an interaction in the equation used to generate the data. However, now both the linear and nonlinear models show statistically significant interaction terms. Moreover, the prediction plots also suggest the existence of an interaction in both the linear and nonlinear models in the outcome scale (i.e., the lines are not parallel).\nAgain, this has occurred despite the fact that the data were generated from a mediation model without a multiplicative interaction term in the equation, so what is happening? Well, the simulated relationships are linear and non-interactive (parallel) in the estimation scale - in this case, when predicting logged delinquency event rates. However, remember how I said that all model coefficients in generalized linear models with nonlinear link functions are conditional and model-based predictions are inherently scale-dependent? This is an example of what I meant. I did not add an interaction in the linear model - I only increased the strength of the relationship between a predictor and the outcome. Yet, this change affected the outcome scale and, likewise, the model coefficients generated to describe predictor-outcome relationships changed as well. Moreover, the nonlinear transformation used to plot our results on the scale of interest - in this case, exponentiating the linear equation to plot predicted delinquency event counts - causes an interaction (i.e., nonparallel lines) in the outcome scale of interest.\n\n\n\nExample 1c: A different slight modification to simulated data\nStill not convinced? Let’s go back to the first simulation (Sim.1), then add an exogenous covariate that is related to delinquency but unrelated to either parental support or moral beliefs to the data and our regression models and see what happens. This time, we will focus solely on the nonlinear model, and we will present the coefficients and plots for both this Sim.1c and the original Sim.1 to permit comparisons of the focal interaction term on the log event rate scale and on the predicted event rate scale.\n\n\nShow code\n#|message=FALSE\n\noptions(scipen=0, digits = 3)\n\n# Simulate data (Sim.1c)\n\nset.seed(1138)\nn &lt;- 850 \n\ndef1c &lt;- defData(varname = \"ExogenousCovariate\", dist = \"normal\", \n               formula = 0, variance = 1) \ndef1c &lt;- defData(def1c, varname = \"ParentSupport\", dist = \"normal\", \n               formula = 0, variance = 1)\ndef1c &lt;- defData(def1c, varname = \"WeakMoralBlfs\", dist = \"poisson\",\n    formula = \"-.3 + (-.5)*ParentSupport\", link = \"log\")\ndef1c &lt;- defData(def1c, varname = \"Delinquency\", dist = \"poisson\",\n    formula = \"-.7 + .5*ExogenousCovariate + (-.25)*ParentSupport + .4*WeakMoralBlfs\", link = \"log\")\nsimdat1c &lt;- genData(n, def1c)\n\n# cap LowMoral at 5 (0-5 item) - randomly replace oob values with values in bounds \ninds &lt;- simdat1c$WeakMoralBlfs &gt; 5\nsimdat1c$WeakMoralBlfs[inds] &lt;- sample(0:5, sum(inds), replace = TRUE)\nsimdat1c$StrgMoralBlfs &lt;- 5 - simdat1c$WeakMoralBlfs\n\n# cap Delinquency at 7 (0-7 item) - randomly replace oob values with in bounds values\ninds &lt;- simdat1c$Delinquency &gt; 7\nsimdat1c$Delinquency[inds] &lt;- sample(0:7, sum(inds), replace = TRUE)\n\n# Sime.1c nonlinear model\nglm1c &lt;- glm(Delinquency ~ ExogenousCovariate + ParentSupport * StrgMoralBlfs, data=simdat1c, family=\"poisson\")\n\nEx1tab2c &lt;- regsum(glm1c) %&gt;%\n  as_gt() %&gt;%\n  gt::tab_header(title = \"Nonlinear model, Sim.1c\") \n\n# Plot interaction\nplot_glm1c &lt;- plot_model(glm1c, type = \"pred\",\n                        terms = c(\"StrgMoralBlfs\", \n                                 \"ParentSupport [-2,2]\")) + \n  theme_minimal() + coord_cartesian(xlim=c(0,5), ylim=c(0,7)) +\n  scale_colour_colorblind(labels = c(\"Low\", \"High\")) +\n  scale_fill_colorblind() +\n  labs(x=\"Strong Moral Beliefs\", y=\"Delinquency\", \n       title=\"Nonlinear model, Sim.1c\")  \n\n\n\nResults (Sim.1c, Exogenous covariate)\n\nModel coefficientsPrediction Plots\n\n\n\nShow code\nEx1tab2c \nEx1tab2\n\n\n\n\n\n\n\n\n\nNonlinear model, Sim.1c\n\n\nCharacteristic\nlog(IRR)1,2\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n1.4***\n0.155\n1.0, 1.7\n1.84e-18\n\n\nExogenousCovariate\n0.45***\n0.037\n0.38, 0.52\n1.17e-34\n\n\nParentSupport\n0.07\n0.107\n-0.14, 0.28\n0.541\n\n\nStrgMoralBlfs\n-0.39***\n0.038\n-0.47, -0.32\n1.55e-25\n\n\nParentSupport * StrgMoralBlfs\n-0.08**\n0.027\n-0.13, -0.03\n0.003\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 IRR = Incidence Rate Ratio, SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\n\nNonlinear Poisson model, Simulation 1\n\n\nCharacteristic\nlog(IRR)1,2\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n1.3***\n0.178\n0.94, 1.6\n2.91e-13\n\n\nParentSupport\n-0.13\n0.140\n-0.41, 0.14\n0.340\n\n\nStrgMoralBlfs\n-0.39***\n0.042\n-0.47, -0.31\n2.52e-20\n\n\nParentSupport * StrgMoralBlfs\n-0.03\n0.035\n-0.10, 0.04\n0.372\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 IRR = Incidence Rate Ratio, SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\nplot_glm1c + plot_glm1 + plot_layout(guides = 'collect') &\n  theme(legend.position = 'bottom',\n        legend.direction = 'horizontal')\n\n\n\n\n\n\n\n\n\n\n\n\nAgain, the only change here from Sim.1 to Sim.1c is the addition of an exogenous covariate. Those familiar with linear regression models might expect the addition of a control variable that is unrelated to other predictors in the model will have little to no impact on the coefficients for those other variables. Yet, this is not the case in generalized linear models with nonlinear link functions, where any change that affects the outcome scale will also change the coefficients describing predictor-outcome relationships. In this case, after including the exogenous covariate, our nonlinear model now shows a significant linear focal interaction coefficient on the log event rate scale, while our plots show nonparallel lines implying a substantial interaction between moral beliefs and parental support on the predicted delinquency event rate scale.\nHopefully, you have seen enough to be convinced that one should never rely simply upon the direction and magnitude of an interaction term to make inferences about interactions in a nonlinear model.\n\n\n\nDon’t hate nonlinear interactions. But do treat them more like bees than honey.\n\n\n\n\n\nExample 1: Fit between model predictions & simulation function\nNow, let’s return to the initial simulated data (Sim.1) and overlay a plot of an idealized function that closely represents the causal equation used to generate the simulated the data (dashed line) with plots of the predicted event counts from the linear and nonlinear models. This should give us a good sense of how well our model-based predictions fit or accurately describe the underlying data-generating process.\n\n\nShow code\n#|message=FALSE\n\n# Create a sequence of strong moral beliefs values from 0 to 6\nmoralblfs &lt;- seq(0, 5, length.out = 6)\n\n# Calculate delq values at low parental support (-2) \ndelq &lt;- exp(-0.7 + (-0.25)*(-2) + (0.4)*(5-moralblfs))\n#cap delq values at max=7 & round to integer to match sim\ndelq &lt;- round(if_else(delq &gt; 7, 7, delq), digits=0)\ngroup_col &lt;- \"-2\"\nsim1eqlow &lt;- tibble(moralblfs, delq, group_col)\n\n\n# Calculate delq values at high parental support (2) \ndelq &lt;- exp(-0.7 + (-0.25)*(2) + (0.4)*(5-moralblfs))\n#cap delq values at max=7 & round to integer to match sim\ndelq &lt;- round(if_else(delq &gt; 7, 7, delq), digits=0)\ngroup_col &lt;- \"2\"\nsim1eqhi &lt;- tibble(moralblfs, delq, group_col)\n\nsim1eq &lt;- bind_rows(sim1eqlow, sim1eqhi)\n\n\n# Plot the function\nplot_glm1eq &lt;- ggplot() +\n  geom_smooth(data=sim1eq, method = \"glm\", se = FALSE,\n       method.args = list(family = \"poisson\"), \n              aes(x=moralblfs, y=delq,\n                  group=group_col, col=group_col), \n       linetype = \"dashed\", size=2) + \n  scale_color_manual(values=c(\"darkgrey\", \"#E69F00\")) + \n  theme_minimal() + \n  xlab(\"Strong moral beliefs\") +\n  ylab(\"Delinquency\") +\n  ggtitle(\"Data-generating functions used to simulate Sim.1 data\")\n\n\n#Overlap function with linear & nonlinear models\n\nplot_lm1fit &lt;- plot_lm1 + \n  geom_smooth(data=sim1eq, method = \"glm\", se = FALSE,\n       method.args = list(family = \"poisson\"), \n              aes(x=moralblfs, y=delq,\n                  group=group_col, col=group_col), \n       linetype = \"dashed\", size=1) + \n  ggtitle(\"Linear model fit to sim function\")\n\n\nplot_glm1fit &lt;- plot_glm1 + \n  geom_smooth(data=sim1eq, method = \"glm\", se = FALSE,\n       method.args = list(family = \"poisson\"), \n              aes(x=moralblfs, y=delq,\n                  group=group_col, col=group_col), \n       linetype = \"dashed\", size=1) + \n  ggtitle(\"Nonlinear model fit to sim function\")\n\nplot_lm1fit + plot_glm1fit + plot_layout(guides = 'collect') &\n  theme(legend.position = 'bottom',\n        legend.direction = 'horizontal')\n\n\n\n\n\n\n\n\n\nAt this point, it should be unsurprising that the nonlinear model provides a better fit to the underlying data-generating function. Still, sometimes visualizations simply help reaffirm what we already know. Now, let’s simulate the data again with a sample size of n=8,500 instead of n=850 and recreate these fit plots to see how sample size affects precision.\n\n\nShow code\n#|message=FALSE\n\n# Simulate data\n\nset.seed(1138)\nn &lt;- 8500\n\ndef &lt;- defData(varname = \"ParentSupport\", dist = \"normal\", \n               formula = 0, variance = 1)\ndef &lt;- defData(def, varname = \"WeakMoralBlfs\", dist = \"poisson\",\n    formula = \"-.3 + (-.5)*ParentSupport\", link = \"log\")\ndef &lt;- defData(def, varname = \"Delinquency\", dist = \"poisson\",\n    formula = \"-.7 + (-.25)*ParentSupport + .4*WeakMoralBlfs\", link = \"log\")\nsimdat &lt;- genData(n, def)\n\n# cap LowMoral at 5 (0-5 item) if necessary - randomly replace any oob values with values in bounds \ninds &lt;- simdat$WeakMoralBlfs &gt; 5\nsimdat$WeakMoralBlfs[inds] &lt;- sample(0:5, sum(inds), replace = TRUE)\nsimdat$StrgMoralBlfs &lt;- 5 - simdat$WeakMoralBlfs\n\n# cap Delinquency at 7 (0-7 item) if necessary - randomly replace any oob values with in bounds values\ninds &lt;- simdat$Delinquency &gt; 7\nsimdat$Delinquency[inds] &lt;- sample(0:7, sum(inds), replace = TRUE)\n\n# Sim.1 linear model\nlm1 &lt;- lm(Delinquency ~ ParentSupport * StrgMoralBlfs, data=simdat)\n\n# Sim.1 nonlinear model\nglm1 &lt;- glm(Delinquency ~ ParentSupport * StrgMoralBlfs, data=simdat, family=\"poisson\")\n\n# Plot interaction\n\nplot_lm1 &lt;- plot_model(lm1, type = \"pred\",  \n                       terms = c(\"StrgMoralBlfs\", \"ParentSupport [-2,2]\")) + \n  theme_minimal() + coord_cartesian(xlim=c(0,5), ylim=c(0,7)) + scale_colour_colorblind(labels = c(\"Low\", \"High\")) + \n  scale_fill_colorblind() + labs(x=\"Strong Moral Beliefs\", y=\"Delinquency\", title=\"Linear model, Sim.1\")  \n\nplot_glm1 &lt;- plot_model(glm1, type = \"pred\",  \n                       terms = c(\"StrgMoralBlfs\", \"ParentSupport [-2,2]\")) + \n  theme_minimal() + coord_cartesian(xlim=c(0,5), ylim=c(0,7)) + scale_colour_colorblind(labels = c(\"Low\", \"High\")) + \n  scale_fill_colorblind() + labs(x=\"Strong Moral Beliefs\", y=\"Delinquency\", title=\"Nonlinear model, Sim.1\")  \n\n#Overlap function with linear & nonlinear models\n\nplot_lm1fit2 &lt;- plot_lm1 + \n  geom_smooth(data=sim1eq, method = \"glm\", se = FALSE,\n       method.args = list(family = \"poisson\"), \n              aes(x=moralblfs, y=delq,\n                  group=group_col, col=group_col), \n       linetype = \"dashed\", size=1) + \n  labs(x=\"n=8,500\", y=element_blank(), title=element_blank()) \n\nplot_glm1fit2 &lt;- plot_glm1 + \n  geom_smooth(data=sim1eq, method = \"glm\", se = FALSE,\n       method.args = list(family = \"poisson\"), \n              aes(x=moralblfs, y=delq,\n                  group=group_col, col=group_col), \n       linetype = \"dashed\", size=1) + \n  labs(x=\"n=8,500\", y=element_blank(), title=element_blank()) \n\n# modify titles + axes\n\nplot_lm1fitb &lt;- plot_lm1fit + \n  labs(x=\"n=850\", y=element_blank(), title=\"Linear model\")  \n\nplot_glm1fitb &lt;- plot_glm1fit + \n  labs(x=\"n=850\", y=element_blank(), title=\"Nonlinear model\") \n\n\n(plot_lm1fitb + plot_glm1fitb) /  (plot_lm1fit2 + plot_glm1fit2) + plot_layout(guides = 'collect') &\n  theme(legend.position = 'bottom',\n        legend.direction = 'horizontal')\n\n\n\n\n\n\n\n\n\nAgain, the nonlinear model is a better fit to the idealized function than the linear model. Additionally, the one exception where the nonlinear model predictions diverge from the idealized data-generating function is not unexpected. First, there is increased sampling variability in the prediction space where data are especially sparse (i.e., low parental support & extremely weak moral beliefs, or top left section of each plot). Second, I resampled out-of-bounds Poisson-generated observations in this sparse sampling space (e.g., strong moral beliefs &lt; 0; delinquency &gt; 7) to better match truncated ordinal measures found in real-world data, and the simple idealized function (i.e., the dashed line) does not perfectly capture this more complex mixture process used to generate the simulated data.\n\n\nPair introverted coefficients with extroverted plots on the outcome scale\nI hope it is clear by now that using a generalized linear model with a nonlinear link function to describe a set of relationships between variables complicates things, as these models are fundamentally interactive. Moreover, the nature of the interactions in these models varies across scales of estimation or interest (e.g., log odds/event rate; predicted probability/event count; odds/event rate ratio) in ways that often are too difficult to grasp from model coefficients alone.\nThis does not mean that we should avoid such models and substitute linear models instead “for the sake of interpretation” - I see this one regularly when reviewing manuscripts - since, as illustrated above, a nonlinear model may be a much better fit to the underlying data generating process than a classic linear model. It also does not mean that the coefficients are somehow wrong or fundamentally uninterpretable.\nRather, you might think of your regression coefficients as panelists at a conference that is organized to describe hidden signals in your data. With a properly applied model, coefficients from these “nonlinear” models are the eccentric and introverted panelist using an overhead projector to show complex equations without any graphs. They are efficiently delivering astute and precise descriptions in a concise way - well below the presentation time allotted - but their combination of complexity, concision, and aloofness tend to lose their audience, who routinely misinterpret their results.\n\n\n\nDon’t be that guy. Plot those introverted interaction coefficients.\n\n\nSo, instead of ditching these coefficients, we should instead aim to be extremely cautious with modeling and interpreting findings and, likewise, we should educate ourselves about and commit to adopting good practices when using such models. For instance, we can pair our introverted nonlinear coefficients with plots in the outcome scale of interest for meaningful interpretations. Such visualizations are the flashy, tech savvy, extroverted panelist that has learned there is substantial social value in translating Professor Introvert’s equations into visualizations that maintain their descriptive accuracy while delivering them in an aesthetically pleasing package that is intellectually accessible to the audience.\nNow, we should be ready to move on to Example 2, where I will introduce an exposure-mediator interaction to the simulated data. Recall, in Parts 2 and 3 of this blog series, I will use similar simulated data from Example 2 to learn about decomposing indirect and interaction effects with a potential outcomes approach. In the conference organized to describe hidden signals in your data, potential outcomes estimates are the venerable keynote speakers that inspire us to do more while also secretly stoking our insecurities by making us question things that we thought were well understood. For now, I will simply illustrate how the regression coefficients and outcome scale plots change with the addition of a small exposure-mediator interaction."
  },
  {
    "objectID": "blog-posts/[6]/modmadness-pt1.html#sec-Ex2",
    "href": "blog-posts/[6]/modmadness-pt1.html#sec-Ex2",
    "title": "Moderator Madness, Part 1",
    "section": "Example 2: Multiplicative interaction on linear estimation scale",
    "text": "Example 2: Multiplicative interaction on linear estimation scale\nIn simulating data for Example 2 (Simulation 2), I modified the first simulated dataset (Sim.1) by adding a small multiplicative interaction term to the linear equation predicting delinquency (b = -0.12 x ParentSupport x WeakMoralBlfs). Then, after making this small change and simulating the data, I once again tabled results from linear and nonlinear Poisson regression models, plotted the predicted delinquency event rates for both models, and overlayed the idealized data generating function (dashed lines) to help visualize model fit.\n\n\nShow code\n#|message=FALSE \n\noptions(scipen=0, digits = 3)\n\n# Simulate data (Sim.2)\n\nset.seed(1138)\nn &lt;- 850\n\ndef2 &lt;- defData(varname = \"ParentSupport\", dist = \"normal\", \n               formula = 0, variance = 1)\ndef2 &lt;- defData(def2, varname = \"WeakMoralBlfs\", dist = \"poisson\",\n    formula = \"-.3 + (-.5)*ParentSupport\", link = \"log\")\ndef2 &lt;- defData(def2, varname = \"Delinquency\", dist = \"poisson\",\n    formula = \"-.7 + (-.25)*ParentSupport + .4*WeakMoralBlfs + \n    (-.12)*ParentSupport*WeakMoralBlfs\", link = \"log\")\nsimdat2 &lt;- genData(n, def2)\n\n# simdat2 %&gt;% sjPlot::view_df()\n# simdat2 %&gt;% \n#   ggplot(aes(x=WeakMoralBlfs, y=Delinquency)) +\n#   geom_point()\n\n# cap LowMoral at 5 (0-5 item) - randomly replace oob values with values in bounds \ninds2 &lt;- simdat2$WeakMoralBlfs &gt; 5\nsimdat2$WeakMoralBlfs[inds2] &lt;- sample(0:5, sum(inds2), replace = TRUE)\nsimdat2$StrgMoralBlfs &lt;- 5 - simdat2$WeakMoralBlfs\n\n# cap Delinquency at 7 (0-7 item) - randomly replace oob values with in bounds values\ninds2 &lt;- simdat2$Delinquency &gt; 7\nsimdat2$Delinquency[inds2] &lt;- sample(0:7, sum(inds2), replace = TRUE)\n\n# simdat2 %&gt;% sjPlot::view_df()\n# simdat2 %&gt;%\n#   ggplot(aes(x=WeakMoralBlfs, y=Delinquency)) +\n#   geom_point()\n\n# Sim.2 linear model\nlm2 &lt;- lm(Delinquency ~ ParentSupport * StrgMoralBlfs, data=simdat2)\n\n# Sim.2 nonlinear model\nglm2 &lt;- glm(Delinquency ~ ParentSupport * StrgMoralBlfs, data=simdat2, family=\"poisson\")\n\n# Regression output\n\nEx2tab1 &lt;- regsum(lm2) %&gt;%\n  as_gt() %&gt;%\n  gt::tab_header(title = \"Linear model, Sim.2\") \n\nEx2tab2 &lt;- regsum(glm2) %&gt;%\n  as_gt() %&gt;%\n  gt::tab_header(title = \"Nonlinear model, Sim.2\") \n\n#Plot interactions \n\nplot_lm2 &lt;- plot_model(lm2, type = \"pred\",  \n                       terms = c(\"StrgMoralBlfs\", \"ParentSupport [-2,2]\")) + \n  theme_minimal() + coord_cartesian(xlim=c(0,5), ylim=c(-1,10)) + scale_colour_colorblind() + \n  scale_fill_colorblind() + labs(x=\"Strong Moral Beliefs\", y=\"Delinquency\", title=\"Linear model, Sim.2\")\n\nplot_glm2 &lt;- plot_model(glm2, type = \"pred\",  \n                       terms = c(\"StrgMoralBlfs\", \"ParentSupport [-2,2]\")) + \n  theme_minimal() + coord_cartesian(xlim=c(0,5), ylim=c(-1,10)) + scale_colour_colorblind() + \n  scale_fill_colorblind() + labs(x=\"Strong Moral Beliefs\", y=\"Delinquency\", title=\"Nonlinear model, Sim.2\")\n\n# Data generating functions\n\n# Create a sequence of strong moral beliefs values from 0 to 6\nmoralblfs &lt;- seq(0, 5, length.out = 6)\n\n# Calculate delq values at low parental support (-2) \ndelq2 &lt;- exp(-0.7 + (-0.25)*(-2) + (0.4)*(5-moralblfs) + (-.12)*(-2)*(5-moralblfs))\n#cap delq values at max=7 & round to integer to match sim\ndelq2 &lt;- round(if_else(delq2 &gt; 7, 7, delq2), digits=0)\ngroup_col &lt;- \"-2\"\nsim2eqlow &lt;- tibble(moralblfs, delq2, group_col)\n\n# Calculate delq values at high parental support (2) \ndelq2 &lt;- exp(-0.7 + (-0.25)*(2) + (0.4)*(5-moralblfs) + (-.12)*(2)*(5-moralblfs))\n#cap delq values at max=7 & round to integer to match sim\ndelq2 &lt;- round(if_else(delq2 &gt; 7, 7, delq2), digits=0)\ngroup_col &lt;- \"2\"\nsim2eqhi &lt;- tibble(moralblfs, delq2, group_col)\n\nsim2eq &lt;- bind_rows(sim2eqlow, sim2eqhi)\n\n\n# Plot the function\nplot_glm2eq &lt;- ggplot() +\n  geom_smooth(data=sim2eq, method = \"glm\", se = FALSE,\n       method.args = list(family = \"poisson\"), \n              aes(x=moralblfs, y=delq2,\n                  group=group_col, col=group_col), \n       linetype = \"dashed\", size=2) + \n  scale_color_manual(values=c(\"darkgrey\", \"#E69F00\")) + \n  theme_minimal() + \n  xlab(\"Strong moral beliefs\") +\n  ylab(\"Delinquency\") +\n  ggtitle(\"Data-generating functions used to simulate Sim.2 data\")\n\n#Overlap function with linear & nonlinear models\n\nplot_lm2fit &lt;- plot_lm2 + \n  geom_smooth(data=sim2eq, method = \"glm\", se = FALSE,\n       method.args = list(family = \"poisson\"), \n              aes(x=moralblfs, y=delq2,\n                  group=group_col, col=group_col), \n       linetype = \"dashed\", size=1) + \n  ggtitle(\"Linear model, Sim.2\")\n\n\nplot_glm2fit &lt;- plot_glm2 + \n  geom_smooth(data=sim2eq, method = \"glm\", se = FALSE,\n       method.args = list(family = \"poisson\"), \n              aes(x=moralblfs, y=delq2,\n                  group=group_col, col=group_col), \n       linetype = \"dashed\", size=1) + \n  ggtitle(\"Nonlinear model, Sim.2\")\n\n\n\nResults (Simulation 2)\n\nLinear modelNonlinear Poisson modelPrediction Plots\n\n\n\n\nShow code\nEx2tab1\n\n\n\n\n\n\n\n\nLinear model, Sim.2\n\n\nCharacteristic\nBeta1\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n2.5***\n0.185\n2.1, 2.8\n2.14e-37\n\n\nParentSupport\n-1.6***\n0.166\n-1.9, -1.3\n8.69e-21\n\n\nStrgMoralBlfs\n-0.40***\n0.042\n-0.48, -0.32\n1.19e-20\n\n\nParentSupport * StrgMoralBlfs\n0.30***\n0.037\n0.23, 0.37\n3.09e-15\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\nEx2tab2\n\n\n\n\n\n\n\n\nNonlinear model, Sim.2\n\n\nCharacteristic\nlog(IRR)1,2\nSE2\n95% CI2\np-value\n\n\n\n\n(Intercept)\n1.3***\n0.171\n0.99, 1.7\n8.34e-15\n\n\nParentSupport\n-0.37**\n0.126\n-0.61, -0.12\n0.003\n\n\nStrgMoralBlfs\n-0.39***\n0.041\n-0.47, -0.31\n1.93e-21\n\n\nParentSupport * StrgMoralBlfs\n0.00\n0.031\n-0.06, 0.06\n0.980\n\n\n\n1 *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n2 IRR = Incidence Rate Ratio, SE = Standard Error, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n#|message=FALSE \n\nplot_lm2fit + plot_glm2fit + plot_layout(guides = 'collect') &\n  theme(legend.position = 'bottom',\n        legend.direction = 'horizontal')\n\n\n\n\n\n\n\n\n\n\n\n\nAs before, there is a statistically significant interaction coefficient in the linear regression model. In comparison, the interaction coefficient is essentially zero (b = 0.00) in the nonlinear model. Some might mistakenly consider this a win for the linear model, as we specified an interaction on the linear estimation scale when simulating the data. Yet, by now, you know better than to rely on the sign and magnitude of that coefficient to make inferences about interactions in nonlinear models.\nIn the linear model, the significant interaction term implies that freeing the regression parameter estimates to permit non-parallel slopes improves the model’s linear predictive fit to the nonlinear data. The linear regression model does its best to reflect the conditional mean structure of the nonlinear relationship, but there is no mechanism to ensure the linear predictions are a good fit to the data. In Example 2, a quick visual comparison of the solid prediction lines to the dashed lines reveals that the linear model’s fit to the idealized data-generating function is quite poor. In fact, this model would lead to understating the effect of moral beliefs at low levels of parental support (solid black prediction line). Even worse, the linear model’s results might lead to the problematic inference that moral beliefs has a positive effect on delinquency at high levels of parental support (solid orange prediction line) - rather than the correct and opposite inference of a negligible to weak negative effect.\nIn contrast, the fit of the nonlinear model is quite good yet again, as expected. Additionally, the non-parallel prediction lines imply the existence of a small interaction between parental support and moral beliefs on the predicted delinquency event rate scale.\nThe plots below are intended to help you visualize how the inclusion of this small interaction term on the linear estimation scale when simulating the data affected predicted delinquency event rates on the outcome’s natural interpretation scale. In those plots, I removed the idealized function (dashed line) and instead added predicted delinquency event rates from models in Example 1 instead. Recall, the only difference between the simulated datasets in Examples 1 and 2 is the omission (in Sim.1) or inclusion (in Sim.2) of a small interaction term (b = -0.12). So, differences between the predicted delinquency event rates across Sim.2 (solid lines) and Sim.1 (dotted lines) are due to the interaction.\n\n\nShow code\n#|message=FALSE \n\n# Get model data\nplot_lm1_dat &lt;-get_model_data(lm1,\n               type = \"pred\",\n               terms = c(\"StrgMoralBlfs\", \"ParentSupport [-2,2]\"),\n               ci.lvl = .95)\n\nplot_glm1_dat &lt;-get_model_data(glm1,\n               type = \"pred\",\n               terms = c(\"StrgMoralBlfs\", \"ParentSupport [-2,2]\"),\n               ci.lvl = .95)\n\n# Reverse-engineer ggplot call into code for reference\n  # https://coolbutuseless.github.io/2019/04/26/introducing-the-ggreverse-package-for-turning-ggplots-back-in-to-code/\n\n# plot_lm2_code &lt;- ggreverse::convert_to_code(plot_lm2)\n# plot_lm2_code\n\n# Overlay plot_lm1 (with intervals) on plot_lm2  \n# plot_lm2 + \n#   ggdist::geom_lineribbon(data=plot_lm1_dat, \n#               mapping = aes(y = predicted,\n#                             x = x, \n#                             ymin = conf.low, \n#                             ymax = conf.high, \n#                             group = group, \n#                             color = group),\n#               alpha = 0.85, \n#               position = position_identity(), \n#               stat = \"identity\") + \n#     scale_colour_colorblind(labels = c(\"Low\", \"High\")) \n\n\n# Overlay plot_lm1 (simple line, no intervals) on plot_lm2  \nplot_lm2xlm1 &lt;- plot_lm2 +\n  geom_line(data=plot_lm1_dat,\n            mapping = aes(y = predicted, x = x, group = group),\n            alpha = 0.85, linetype = \"dotted\", linewidth=1.5,\n            position = position_identity(), stat = \"identity\") +\n  theme_minimal() + coord_cartesian(xlim=c(0,5), ylim=c(-1,10)) + \n  scale_colour_colorblind(labels = c(\"Low\", \"High\")) +\n  ggtitle(\"Linear model, Sim.2 vs. Sim.1\")\n\n# Overlay plot_glm1 (simple line, no intervals) on plot_glm2  \nplot_glm2xglm1 &lt;- plot_glm2 +\n  geom_line(data=plot_glm1_dat,\n            mapping = aes(y = predicted, x = x, group = group),\n            alpha = 0.85, linetype = \"dotted\", linewidth=1.5,\n            position = position_identity(), stat = \"identity\") +\n  theme_minimal() + coord_cartesian(xlim=c(0,5), ylim=c(-1,10)) + \n  scale_colour_colorblind(labels = c(\"Low\", \"High\")) +\n  ggtitle(\"Nonlinear model, Sim.2 vs. Sim.1\")\n\n\nplot_lm2xlm1 + plot_glm2xglm1 + plot_layout(guides = 'collect') &\n  theme(legend.position = 'bottom',\n        legend.direction = 'horizontal')\n\n\n\n\n\n\n\n\n\nSee how the addition of a small interaction on the linear estimation scale changed the slopes of the predicted delinquency event rates? Note, too, that this occurs even in the nonlinear model, despite the fact that the interaction coefficient was essentially zero magnitude (b = 0.00)!\nIn addition to examining changes in predicted delinquency event rates, we could discuss this interaction in terms of introducing “excess risks” of delinquency. But, how might we interpret the interaction and precisely estimate those excess risks in light of the co-occurring mediation process that we also know exists in these data? This will be the focus of Part 2 and Part 3 of this series."
  },
  {
    "objectID": "blog-posts/[6]/modmadness-pt1.html#sec-intermission",
    "href": "blog-posts/[6]/modmadness-pt1.html#sec-intermission",
    "title": "Moderator Madness, Part 1",
    "section": "Intermission",
    "text": "Intermission\nOk, that’s enough of the from me on this topic. There are a lot of great resources out there but, to wrap up this first example, I will echo some great advice from Trenton Mize’s (2019, p.112-3) insightful primer on the topic:\n\n“Estimating, interpreting, and presenting nonlinear interaction effects requires more effort and consideration than doing the same for linear interaction effects. However, the current methodological literature and statistical software provide the guidance and ability to fully investigate these types of effects. In an effort to summarize the key things to consider:\n\n\n\nInclude a product (interaction) term in the model if you want to investigate whether the effect of one independent variable is contingent on the level of a second independent variable.\nIgnore the coefficient of the product term: It does not necessarily provide accurate information about the significance, magnitude, or even the direction of the underlying interaction effect on the predictions.\nPlot the predictions to determine the nature of the underlying interaction effect on the metric of interest.\nDetermine the size and significance of the effects of interest using marginal effects, not regression coefficients.\nUse tests of second differences (whether two marginal effects are equal) to determine whether an interaction effect is significant for specific values of interest of your independent variables\nAbsent substantive or theoretically interesting values of the focal independent or control variables to test the interaction effect, use average marginal effects to summarize whether there is an interaction effect present on average in the data.”\n\n\nIn this post, I have tried to build or strengthen your intuition about the importance of the first four points. The last two points (#5 & #6) about testing interactions with marginal effects are also extremely important, but I will need to wait to tackle these in greater detail in a different post. Or, better yet, read Andrew Heiss’ excellent “Marginalia” blog post on the topic, followed by his post on marginal effects in generalized linear mixed models.\nAs the curtains close on Part 1 and the stage is being reset, go stretch your limbs and grab refreshments, then return to check out Part 2 and Part 3 of this series. In that post, you will learn why our moderator madness work is not yet done: There is an interaction between the focal cause or exposure (parental support) and the mediator (moral beliefs) in the Example 2 data (Sim.2), which means mediation and moderation are statistically entangled! Return to your seats for the second act to learn how to conduct a 4-way decomposition of a total effect in the presence of an exposure-mediator interaction using a potential outcomes approach.\n\n\n\nParts 2 and 3 have finally arrived! Hope you did not hold your breath as you waited."
  },
  {
    "objectID": "blog-posts/[6]/modmadness-pt1.html#footnotes",
    "href": "blog-posts/[6]/modmadness-pt1.html#footnotes",
    "title": "Moderator Madness, Part 1",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nInitially, I anticipated writing a two-part series. However, the second post ended up being too long for a single entry, so I split it into Parts 2 and 3. Upon realizing this, I revisited Part 1 to make several minor edits to reference Parts 2 and/or 3 (instead of a singular Part 2) throughout.↩︎\nThis is because effect heterogeneity (interactions) are assumed in DAGs, so the statistical flow of relational information remains the same and only the mathematical functional form of the relationships change across the two proposed processes. Relatedly, we cannot know from the data alone whether that dashed red line should be drawn as it is or, instead, whether the dashed red line should originate at moral beliefs and intersect the causal path between parental support and delinquency.↩︎\nThis hot topic riled up criminologists’ feathers about a decade ago (cf. p.23 here, p.21 here, and additional discussion here). Yet, this old problematic practice continues to be disturbingly commonplace in our field, as well as in neighboring disciplines and beyond. To be crystal clear, I am NOT encouraging it here.↩︎\nPerverse structural incentives, which are deeply embedded in modern academic publishing, motivate all sorts of career-oriented pragmatic forays through the garden of forking paths on the way to piecemeal publication. You know, the ones that compel scholars to increase CV lines and citation counts by carving up their measures, switching outcomes, adding new subgroups, swapping analytic methods, variably positing different “process” models (e.g., main effects; indirect effects; interaction effects; and other combinations of mediation and moderation), and even to commit fraud in pursuit of career advancement.↩︎\nThe three focal variables, sample size, and blog post itself are loosely inspired by research using the Pocono Bullying Study data.↩︎\nThis raises an even bigger issue - that modeling mediation and moderation to test or make inferences about causal processes requires very strong assumptions, some of which often are irrevocably violated when applied to observational and cross-sectional data. At risk of stating the obvious, I am not implying that one could conduct a convincing study akin to “paper 1” or “paper 2” using real-world data akin to the simulated data in these examples. Rather, to conduct convincing studies on these imaginary topics, a researcher would need to do much more than properly model, plot, interpret, and even decompose their interactions; they would also need to spend serious time, energy, and resources on improving the precision of the research questions, constructing defensible causal diagrams to guide carefully planned research, and identifying potential threats to causal inferences (e.g., confounders; colliders; sampling, response, measurement, and analytic limitations; alternative interpretations).↩︎"
  },
  {
    "objectID": "blog-posts/[8]/dup-index.html",
    "href": "blog-posts/[8]/dup-index.html",
    "title": "Near Duplicates in Survey Data Series",
    "section": "",
    "text": "You thought The Shining was scary? Have you looked under your data for near duplicates?\nYou have reached the landing page for our “Near Duplicates in Survey Data” series. Click below to read the posts in this series:"
  },
  {
    "objectID": "blog-posts/[8]/dup-index.html#trust-issues",
    "href": "blog-posts/[8]/dup-index.html#trust-issues",
    "title": "Near Duplicates in Survey Data Series",
    "section": "Trust Issues",
    "text": "Trust Issues\n\n\n\n\n\n\n\n\nPost 1: Near duplicates in survey data: Like “Multiplicity” but without the humor. (Image from Multiplicity)\n\n\n\n\n\n\n\nTrust Issues: Examining Near Duplicates in Survey Data\nDo you know how to detect exact or near duplicate rows in your data? Read on to learn more!"
  },
  {
    "objectID": "blog-posts/[8]/dup-index.html#stumbling-in-the-dark",
    "href": "blog-posts/[8]/dup-index.html#stumbling-in-the-dark",
    "title": "Near Duplicates in Survey Data Series",
    "section": "Stumbling in the Dark",
    "text": "Stumbling in the Dark\n\n\n\n\n\n\n\n\nPost 2: For this non-programmer, iterating on a percentmatch function in R was not entirely unlike stumbling in the dark. (Image created using DALL-E)\n\n\n\n\n\n\n\nStumbling in the Dark: Building/Iterating an R Function to Match Stata’s percentmatch\nIf you are looking for more information about the modified R function we used to detect near duplicates, then you have come to the right place. (Code shared; detailed write-up forthcoming)"
  },
  {
    "objectID": "blog-posts/[8]/dup-index.html#trust-issues-part-2",
    "href": "blog-posts/[8]/dup-index.html#trust-issues-part-2",
    "title": "Near Duplicates in Survey Data Series",
    "section": "Trust Issues, Part 2",
    "text": "Trust Issues, Part 2\n\n\n\n\n\n\n\n\nPost 3: Investigating near duplicates in different data: Will the sequel live up to the original? (Image from Matrix: Reloaded)\n\n\n\n\n\n\n\nTrust Issues, Part 2: Investigating Near Duplicates in Different Data\nThis follow-up to our first entry on near duplication in survey data analyzes near duplicates in three more international survey data sets. (Forthcoming)"
  },
  {
    "objectID": "blog-posts.html",
    "href": "blog-posts.html",
    "title": "a blog for criminologists, reluctant or otherwise",
    "section": "",
    "text": "RRR: Mediation Makes My Head Hurt!\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\nmediation\n\n\n\nOur first Reluctantly Rapid Response (RRR) post addresses a confusing mediation issue.\n\n\n\n\n\nMay 13, 2024\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\nModerator Madness, Part 3\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\nmoderation\n\n\nmediation\n\n\n\nExposure-mediator interaction? No problem! Disentangle indirect and interaction effects with CMAverse in R\n\n\n\n\n\nFeb 26, 2024\n\n\n75 min\n\n\n\n\n\n\n\n\n\n\n\n\nModerator Madness, Part 2\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\nmoderation\n\n\nmediation\n\n\n\nIs your mediator also a moderator? Learn how counterfactuals and potential outcomes can help decompose a total effect into four distinct components.\n\n\n\n\n\nFeb 23, 2024\n\n\n36 min\n\n\n\n\n\n\n\n\n\n\n\n\nNear Duplicates in Survey Data Series\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\nsurvey research\n\n\nduplication\n\n\nfraud\n\n\n\nDo you know how to detect exact or near duplicate rows in your data? Read on to learn more!\n\n\n\n\n\nOct 10, 2023\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nModerator Madness, Part 1\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\nmoderation\n\n\n\nProperly model, plot, and interpret your nonlinear interactions.\n\n\n\n\n\nJul 18, 2023\n\n\n48 min\n\n\n\n\n\n\n\n\n\n\n\n\nAre you afraid of colliders?\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\n\nLearn to fear colliders, the rancor in your regression model. Then, learn to face those fears and overcome colliders with a DAG, the elegant weapon of a Jedi scientist.\n\n\n\n\n\nJun 6, 2023\n\n\n65 min\n\n\n\n\n\n\n\n\n\n\n\n\nCausation without Correlation?\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\nmediation\n\n\n\nYou’ve heard the phrase ‘correlation does not imply causation.’ But does causation imply correlation?\n\n\n\n\n\nApr 10, 2023\n\n\n39 min\n\n\n\n\n\n\n\n\n\n\n\n\nDr. Charles R. Tittle’s intellectual contributions\n\n\n\n\n\n\ngeneral\n\n\n\nThis post is dedicated to the intellectual contributions of our late mentor, Dr. Charles R. Tittle.\n\n\n\n\n\nMar 12, 2023\n\n\n31 min\n\n\n\n\n\n\n\n\n\n\n\n\nCheck out some of our favorite sites\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\nbayesian\n\n\n\n\n\n\n\n\n\nMar 11, 2023\n\n\n8 min\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome to the reluctant criminologists\n\n\n\n\n\n\ngeneral\n\n\n\nYou found our repository for sharing course material and ideas. Congrats! Or condolences. Anyway, in this first post, we discuss our motives and aims for this site.\n\n\n\n\n\nMar 10, 2023\n\n\n8 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "course-materials/2_grad_RnR/index.html",
    "href": "course-materials/2_grad_RnR/index.html",
    "title": "Replication & reproducibility in social science (Graduate-level)",
    "section": "",
    "text": "Workflow, not just code, often hinders reproducibility. Artwork by @allison_horst\nIn the fall of 2021, Jon was on the schedule to teach a new course titled “Replication & Reproducibility in Social Science” as a substitute for IU Criminal Justice Department’s typical graduate “Methods” degree requirement. The same semester, Jake was scheduled to teach the “Social Research Methods” course to first-year MA students in UNCW’s Department of Sociology and Criminology. He decided to join Jon in revising the class to focus on replication and reproducibility. The result was a jointly designed course focusing on replication and reproducibility issues broadly across the social sciences, but with specific examples from sociology and criminology. You can take a look at both Jon’s syllabus and Jake’s syllabus for the course. They are basically identical, but Jon’s syllabus includes a complete reference list for the assigned and recommended readings. Also, because of a weird scheduling quirk, Jake had to combine two weeks into one (Hype and Perverse Incentives).\nIn addition to teaching our students about replication and reproducibility issues more generally, we also wanted to help them learn some practical skills to help them produce more reliable and transparent research. To do this, we had students complete two sets of assignments: 1) R Assignments intended to provide a basic introduction to conducting reproducible research using the R Statistical Computing Environment and RStudio and 2) a Reproducibility Project where they had the reproduce the (descriptive) results of a published article on a topic of interest to them. The “R Assignments” ended up being a basic introduction to data wrangling, data visualization and reporting, and reproducible workflow with a primary emphasis on the Tidyverse suite of packages. The “Reproducibility Project” was an opportunity for students to apply these new skills to a topic that interested them, get their hands dirty with real-world data, and develop an appreciation for the challenges involved in computationally reproducing published work when you do not have access to the code used to clean, wrangle and analyze the data.\nWe have included these assignments as they were assigned in Jon’s class with light editing, where necessary, for student privacy reasons. In a forthcoming blog post we will discuss what we learned from designing this course and note what we would change going forward (and what Jake did change when revising the course for senior-level undergraduate criminology majors)."
  },
  {
    "objectID": "course-materials/2_grad_RnR/index.html#r-assignments",
    "href": "course-materials/2_grad_RnR/index.html#r-assignments",
    "title": "Replication & reproducibility in social science (Graduate-level)",
    "section": "R Assignments",
    "text": "R Assignments\n\n\n\n\n\nLearning a new language like R can be frustrating. We all need breaks to breathe and vent. Artwork by @allison_horst\n\n\n\n\n\n\nAssignment 1: Getting Started in R\nThe purpose of this first assignment is to demonstrate that you have downloaded the “base R” and “RStudio” statistical programs and can open a SPSS datafile in RStudio.\n\n\n\n\n\n\n\n\nComputers crash. Files get corrupted or deleted. Plan on it in your workflow with cloud-based backups. Artwork by @allison_horst\n\n\n\n\n\n\nAssignment 2: Introduction to R Markdown\nThe purpose of this second assignment is to help you begin to explore your data in R and to do so within an RMarkdown document. The specific activities were inspired by the SPSS Exercises from the end of Chapter 1 in Bachman and Paternoster’s Statistics for Criminology & Criminal Justice, 4th Ed.\n\n\n\n\n\n\n\n\nStart with a blank canvas and build a masterpiece using ggplot2(). Artwork by @allison_horst\n\n\n\n\n\n\nAssignment 3: Direct Reproduction\nThe purpose of this assignment is to reproduce findings from a published study in R, particularly one where the data are housed on ICPSR. In order to accomplish this we will need to do and learn the following: - Identify the data being used in the now classic study by Mark Warr published in Criminology titled: “Age, Peers, and Delinquency” (Warr, 1993) - Download it from ICPSR - Identify and wrangle the specific variables/items used in the study using the dplyr package that is a part of the Tidyverse. - Combine multiple data sets into one. - Reproduce the first part of Figure 1 from Warr’s (1993) study (as displayed on pg. 22 in his article) by introducing you to the powerful data visualization package ggplot2, which is also a part of the Tidyverse.\n\n\n\n\n\n\n\n\nYou’ve learned so much! This is just the beginning of a challenging but worthwhile journey. Artwork by @allison_horst\n\n\n\n\n\n\nAssignment 4: Conceptual Replication\nThe purpose of this assignment is to perform a conceptual replication of some observations in Orcutt’s (1987) paper in Criminology titled: “Differential Association and Marijuana Use: A Closer Look at Sutherland (with a Little Help from Becker).” Since Orcutt’s (1987) original data are unavailable, we will assess whether some of his findings can be repeated with and generalize to a similar sample in the NYS data."
  },
  {
    "objectID": "course-materials/2_grad_RnR/index.html#reproducibility-project",
    "href": "course-materials/2_grad_RnR/index.html#reproducibility-project",
    "title": "Replication & reproducibility in social science (Graduate-level)",
    "section": "Reproducibility Project",
    "text": "Reproducibility Project\n\n\n\n\n\nFinding open crime data is challenging. Working with it can be even more challenging. Artwork from the Openscapes blog “Tidy Data for reproducibility, efficiency, and collaboration” by Julia Lowndes and Allison Horst”\n\n\n\n\n\n\nProject Assignment 1: Find Article with Data to Replicate\nThe primary purpose of this first project assignment is to find an article on a topic of interest to you that has data available online via ICSPR (or another repository); eventually, you will be required to use these data in an attempt to reproduce a basic descriptive finding reported in a table or figure from the article. A secondary purpose of this assignment is to develop a sense of how (un)common it is to find research articles in the top journals of your field for which the authors have openly shared their data and code for reproducibility purposes.\n\n\n\n\n\n\n\n\nYes, there is always more to learn, which means we can continue to grow and improve! Artwork by @allison_horst\n\n\n\n\n\n\nProject Assignment 2: Describe Reproduction, Share Image, Summarize Data\nUnlike previous assignments, this assignment was not organized into various numbered “parts” for students to follow and complete. Rather, it showed students some basics about publishing with R Markdown (e.g., inserting an image, editing the YAML header, etc.) and asked students to summarize the raw versions of the variables needed for their reproduction.\n\n\n\n\n\n\n\n\nFirst draft: You’ve learned the basics. Draw two ovals to start drawing the owl. Credit: Richard McElreath’s clever application of the “draw the owl” analogy to learning coding and statistics.\n\n\n\n\n\n\nProject Assignment 3: First Draft of Reproduction\nStudents are asked to create a first draft of their reproduction project which was ultimately peer-reviewed by one of their classmates. The directions are similar to Project Assignment 2 except students were expected to recode all variables and produce relatively clean and publication-ready versions of their tables and figures.\n\n\n\n\n\n\n\n\nFinal draft: Now, use what you’ve learned - and learn what you need - to draw the rest of the owl! Credit: Richard McElreath’s clever application of the “draw the owl” analogy to learning coding and statistics.\n\n\n\n\n\n\nProject Assignment 4: Final Draft of Reproduction\nStudents are asked to finalize their reproduction project and provide a reproducible file structure. Essentially, they were asked to apply the skills they had learned throughout the course to produce an article or blog reproducing some (descriptive) results of a published study."
  },
  {
    "objectID": "course-materials/4_grad_stats_Ducate/index.html",
    "href": "course-materials/4_grad_stats_Ducate/index.html",
    "title": "Introduction to statistics in R for criminologists",
    "section": "",
    "text": "Welcome to the R community! Artwork by @allison_horst\n\n\nThe following assignments were modified from Jon Brauer’s original undergraduate statistics course by Caitlin Ducate, an assistant professor in the Department of Social Science at Texas A&M University San Antonio. Here is a recent course syllabus. As with the original version, most of the assignments are based on exercises found in Bachman, Paternoster, & Wilson’s Statistics for Criminology & Criminal Justice, 5th Ed., which are referred to throughout as “BPW” book. Changes from original version mostly involve simplifying or adding additional images for clearer instructions; the most notable change in this version is that Brauer’s original Assignment #3 has been split into two separate assignments (Assignments #3 and #4).\nLike the original version, the R assignments for this course are designed to provide a (relatively) gentle introduction to elementary foundations of frequentist statistics using R via RStudio & R Markdown. Though initially designed for Master’s students, the course is comparable to introductory statistics courses that undergraduate students take as well as the initial statistics course in a sequence that many graduate students take in pursuit of PhD degrees in criminology/criminal justice. Also, certain features of the course (e.g,. book selection; certain R package choices) were designed with the goal in mind of easing the transition to R for students and faculty with prior experience using SPSS. Hence, the R assignments may also provide a helpful bridge for graduate students prior to taking more advanced statistics courses that use R and, likewise, may be useful for criminologists at any educational or career stages interested in learning to use R for the first time.\n\n\n\n\n\nBelieve you can do this. We do! Artwork by @allison_horst\n\n\n\n\n\n\nIntroduction: Tips, troubleshooting, and why R?\nBefore you begin the assignments below, we recommend watching this brief introductory video. In it, Dr. Caitlin Ducate explains why it is worth your time to learn data analysis skills in R/RStudio, describes basic features of the R language, highlights things you can do in R, and gives advice for troubleshooting with R.\n\n\nIntroductory video (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of here() package by @allison_horst\n\n\n\n\n\n\nAssignment 1: Getting Started in R\nThe purpose of this first assignment is to demonstrate that you have downloaded the “base R” and “RStudio” statistical programs and can open a SPSS datafile in RStudio. Additionally, you will learn how to create, edit, and knit an R Markdown file.\n\n\nVideo walkthrough for Assignment 1 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of R Markdown by @allison_horst\n\n\n\n\n\n\nAssignment 2: Navigating Data\nIn this assignment, you will create an R Markdown file in which to save and present your work for this class. Additionally, following the goals of BPW’s chapter 1, you will use R/RStudio to view variables in a data file and find information about variables, including variable names, labels, and values. This assignment should help you navigate R/RStudio and become comfortable finding basic information within data files.\n\n\nVideo walkthrough for Assignment 2 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of tidy data by Julia Lowndes and Allison Horst\n\n\n\n\n\n\nAssignment 3: Describing Data Distributions\nChapter 2 of B&P’s book focused on data distributions. In this assignment, you will learn how to generate frequency tables in R.\n\n\nVideo walkthrough for Assignment 3 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of dplyr::mutate() by @allison_horst\n\n\n\n\n\n\nAssignment 4: Recode & Visualize Variables\nChapter 3 of B&P’s book focused on visualizing data. In this assignment, you will learn how to recode variables and create a simple graph in R.\n\n\nVideo walkthrough for Assignment 4 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtwork by @allison_horst\n\n\n\n\n\n\nAssignment 5: Central Tendency\nBPW’s chapter 4 focused on measures of central tendency (e.g., mean, median, and mode,) and their advantages and disadvantages as single statistical descriptions of a data distribution. Likewise, in this assignment, you will learn how to use R to calculate measures of central tendency and other statistics (e.g., skewness; kurtosis) that us help standardize and efficiently describe the shape of a data distribution. You will also get additional practice with creating frequency tables and simple graphs in R.\n\n\nVideo walkthrough for Assignment 5 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of ggplot2() by @allison_horst\n\n\n\n\n\n\nAssignment 6: Dispersion\nBPW’s chapter 5 covered measures of dispersion, including variation ratio, range, interquartile range, variance, and standard deviation. We use measures of dispersion to summarize the “spread” (rather than central tendency) of a data distribution. Likewise, in this assignment, you will learn how to use R to calculate measures of dispersion and create boxplots that help us standardize and efficiently describe the spread of a data distribution. You will also get additional practice with creating frequency tables and simple graphs in R, and you will learn how to modify some elements (e.g., color) of a ggplot object.\n\n\nVideo walkthrough for Assignment 6 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nArtful depiction of dplyr::filter() by @allison_horst\n\n\n\n\n\n\nAssignment 7: Probability & Cross-tabulations\nBPW’s chapter 6 provided an introduction to probability, including foundational rules of probability and probability distributions. In the current assignment, you will gain a better understanding of frequentist probability by learning to create and interpret cross-tabulations or joint frequency contingency tables and by calculating z-scores.\n\n\nVideo walkthrough for Assignment 7 (by Caitlin Ducate)\n\n\n\n\n\n\n\n\n\n\n\nVisualizing confidence intervals around sample statistics\n\n\n\n\n\n\nAssignment 8: Sampling Variability & Confidence Intervals\nIn this assignment, we dig deeper into the process of making statistical inferences about population parameters from sample statistics. For instance, you will learn to think about sample descriptive statistics (e.g., a sample mean or correlation coefficient) as point estimates of population parameters. Relatedly, following BPW’s chapter 7, you will learn how to calculate confidence intervals around a point estimate in R and to interpret them appropriately. Additionally, you will learn how to simulate data from a probability distribution, which should help you better understand sampling variability and the need for interval estimates.\n\n\n\n\n\n\n\n\nVisualizing a one-sample hypothesis test\n\n\n\n\n\n\nAssignment 9: One-sample Null Hypothesis Test\nFollowing BPW’s chapter 8, in this assignment you will learn how to conduct a two-tail z-test and t-test and then, given the test results and the null hypothesis, to make an appropriate inference about the population parameter by either rejecting or failing to reject the null hypothesis. Along the way, you will explore plots of data distributions from random samples drawn from simulated population data. This exploration is intended to help you visualize the sampling distribution of a sample mean, which should lead to a better understanding of the underlying mechanisms that allow us to make valid population inferences from samples with null hypothesis significance testing.\n\n\n\n\n\n\n\n\nVisualizing a Chi-squared critical value\n\n\n\n\n\n\nAssignment 10: Chi-squared Test of Independence\nAs in BPW’s chapter 9, in this assignment you will learn how to make population inferences about the relationship between two categorical variables by conducting a chi-squared test of independence on a sample contingency table (crosstab). Additionally, we will briefly introduce you to the phi-coefficient and Cramer’s V, two measures of association that can be interpreted to describe the strength of an association between variables in a crosstab.\n\n\n\n\n\n\n\n\nVisualizing a two-sample hypothesis test\n\n\n\n\n\n\nAssignment 11: Two-sample Null Hypothesis Test\nBPW’s chapter 10 focused on null hypothesis tests to make inferences about the equality of two group means or proportions using sample data. Likewise, in this assignment, you will learn how to make an inference about the (in)equality of two population group means by conducting an independent sample t-test and then determining whether to reject or fail to reject the null hypothesis of no difference in population group means. We will also use simulations to visualize the sampling distribution of sample mean differences, briefly introduce Levene’s test of equality of population group variances, and introduce the half-violin/half-dotplot as a way to visualize variable distributions and potential outliers for two (or more) groups.\n\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{ducate,\n  author = {Ducate, Caitlin},\n  title = {Introduction to Statistics in {R} for Criminologists},\n  url = {https://www.reluctantcriminologists.com/course-materials/4_grad_stats_Ducate},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nDucate, Caitlin. n.d. “Introduction to Statistics in R for\nCriminologists.” https://www.reluctantcriminologists.com/course-materials/4_grad_stats_Ducate."
  },
  {
    "objectID": "course-materials/rnr.html",
    "href": "course-materials/rnr.html",
    "title": "Replication and reproducibility",
    "section": "",
    "text": "Materials for course dedicated to teaching students about replication and reproducibility issues in social science. Substantive readings in course also cover several core philosophies of science, with the aim of helping students understand logic of scientific inquiry and how/why replication and reproducibility are central to scientific knowledge construction. The first set of assignments in each course provide students a foundation for conducting minimally reproducible research using R Markdown. The second set of assignments guide students through the reproduction and/or conceptual replication of results from a published article. Course versions were designed for graduate and advanced undergraduate (senior seminar) students.\n\n\n\n\n\n\n\n\nVersion 1: tracing ovals (Brauer)\n\n\n\n\nReplication & Reproducibility in the Social Sciences\n(Brauer; IUB CJUS-P680; Graduate)\nRecent syllabus\nAssignments for graduate level replication and reproducibility course. Includes a crash course for conducting minimally reproducible research using R (#1-#4) and a ‘reproducibility project’ (#5-#8) where students reproduce or conceptually replicate results from a published article of their choice. Designed for accelerated Master’s (“4+1”) and PhD students.\n\n\n\n\n\n\n\n\n\n\nVersion 2: drawing owls (Day)\n\n\n\n\nCriminology in Crisis: Replication & Reproducibility\n(Day; UNCW CRM-495; Undergraduate)\nRecent syllabus\nAssignments for replication and reproducibility course for undergraduate seniors. Includes a crash course for conducting reproducible research using R (#1-#7) and a ‘reproducibility project’ (#8-#14) where students reproduce or conceptually replicate results from a published article using NYS data. Designed for advanced undergraduate (senior seminar) students.\n\n\n\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "reluctant criminologists",
    "section": "",
    "text": "general\n\n\nrstats\n\n\ncausality\n\n\nmediation\n\n\n\nOur first Reluctantly Rapid Response (RRR) post addresses a confusing mediation issue.\n\n\n\n\n\nMay 13, 2024\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\nmoderation\n\n\nmediation\n\n\n\nExposure-mediator interaction? No problem! Disentangle indirect and interaction effects with CMAverse in R\n\n\n\n\n\nFeb 26, 2024\n\n\n75 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\nmoderation\n\n\nmediation\n\n\n\nIs your mediator also a moderator? Learn how counterfactuals and potential outcomes can help decompose a total effect into four distinct components.\n\n\n\n\n\nFeb 23, 2024\n\n\n36 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\nsurvey research\n\n\nduplication\n\n\nfraud\n\n\n\nDo you know how to detect exact or near duplicate rows in your data? Read on to learn more!\n\n\n\n\n\nOct 10, 2023\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\nmoderation\n\n\n\nProperly model, plot, and interpret your nonlinear interactions.\n\n\n\n\n\nJul 18, 2023\n\n\n48 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\n\nLearn to fear colliders, the rancor in your regression model. Then, learn to face those fears and overcome colliders with a DAG, the elegant weapon of a Jedi scientist.\n\n\n\n\n\nJun 6, 2023\n\n\n65 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\nmediation\n\n\n\nYou’ve heard the phrase ‘correlation does not imply causation.’ But does causation imply correlation?\n\n\n\n\n\nApr 10, 2023\n\n\n39 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\n\nThis post is dedicated to the intellectual contributions of our late mentor, Dr. Charles R. Tittle.\n\n\n\n\n\nMar 12, 2023\n\n\n31 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\nbayesian\n\n\n\n\n\n\n\n\n\nMar 11, 2023\n\n\n8 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\n\nYou found our repository for sharing course material and ideas. Congrats! Or condolences. Anyway, in this first post, we discuss our motives and aims for this site.\n\n\n\n\n\nMar 10, 2023\n\n\n8 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#blog-posts",
    "href": "index.html#blog-posts",
    "title": "reluctant criminologists",
    "section": "",
    "text": "general\n\n\nrstats\n\n\ncausality\n\n\nmediation\n\n\n\nOur first Reluctantly Rapid Response (RRR) post addresses a confusing mediation issue.\n\n\n\n\n\nMay 13, 2024\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\nmoderation\n\n\nmediation\n\n\n\nExposure-mediator interaction? No problem! Disentangle indirect and interaction effects with CMAverse in R\n\n\n\n\n\nFeb 26, 2024\n\n\n75 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\nmoderation\n\n\nmediation\n\n\n\nIs your mediator also a moderator? Learn how counterfactuals and potential outcomes can help decompose a total effect into four distinct components.\n\n\n\n\n\nFeb 23, 2024\n\n\n36 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\nsurvey research\n\n\nduplication\n\n\nfraud\n\n\n\nDo you know how to detect exact or near duplicate rows in your data? Read on to learn more!\n\n\n\n\n\nOct 10, 2023\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\nmoderation\n\n\n\nProperly model, plot, and interpret your nonlinear interactions.\n\n\n\n\n\nJul 18, 2023\n\n\n48 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\n\nLearn to fear colliders, the rancor in your regression model. Then, learn to face those fears and overcome colliders with a DAG, the elegant weapon of a Jedi scientist.\n\n\n\n\n\nJun 6, 2023\n\n\n65 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\nmediation\n\n\n\nYou’ve heard the phrase ‘correlation does not imply causation.’ But does causation imply correlation?\n\n\n\n\n\nApr 10, 2023\n\n\n39 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\n\nThis post is dedicated to the intellectual contributions of our late mentor, Dr. Charles R. Tittle.\n\n\n\n\n\nMar 12, 2023\n\n\n31 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\nrstats\n\n\ncausality\n\n\nbayesian\n\n\n\n\n\n\n\n\n\nMar 11, 2023\n\n\n8 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneral\n\n\n\nYou found our repository for sharing course material and ideas. Congrats! Or condolences. Anyway, in this first post, we discuss our motives and aims for this site.\n\n\n\n\n\nMar 10, 2023\n\n\n8 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#course-materials",
    "href": "index.html#course-materials",
    "title": "reluctant criminologists",
    "section": "course materials",
    "text": "course materials\n\n\n\n\n\n\n\n\n 1: Introduction to statistics in R for criminologists (Artwork by @allison_horst)\n\n\n\n\n\n\n\n\n\n\n\n\n 2: Replication & reproducibility in social science (Artwork by @allison_horst)"
  },
  {
    "objectID": "index.html#supplementary-files",
    "href": "index.html#supplementary-files",
    "title": "reluctant criminologists",
    "section": "supplementary files",
    "text": "supplementary files\n\n\n\n\n\n\n\n\n 3: Supplementary materials (Illustration by Alison Hill and Allison Horst, for RStudio)"
  },
  {
    "objectID": "supp/LB-JRB-supp/index.html#osf-preregistration",
    "href": "supp/LB-JRB-supp/index.html#osf-preregistration",
    "title": "Supplementary materials for Bègue & Brauer (Forth.)",
    "section": "OSF Preregistration",
    "text": "OSF Preregistration\n\nGratifiability and sexual aggression"
  },
  {
    "objectID": "supp/LB-JRB-supp/index.html#manuscript-draft",
    "href": "supp/LB-JRB-supp/index.html#manuscript-draft",
    "title": "Supplementary materials for Bègue & Brauer (Forth.)",
    "section": "Manuscript Draft",
    "text": "Manuscript Draft\n\nComing soon"
  }
]