---
title: "Moderator Madness, Part 2"
author: "Jon Brauer"
date: "2024-01-30"
image: med-or-mod-cartoon2.jpg
image-alt: "Two lemmings confused by exposure-mediator interactions (with help from DALL-E)"
description: "Is your mechanism both mediating and moderating? Disentangle indirect and interaction effects with potential outcomes decomposition."
citation:
  url: https://reluctantcriminologists.com/blog-posts/[7]/modmadness-pt2.html
categories: [general, rstats, causality, moderation, mediation]
format:
  html:
    code-fold: true
    code-summary: "Show code"
execute: 
  warning: false
draft: true
---

```{r}
#|echo=FALSE

#explicitly set graphics device to png(type=cairo) to knit ggblend plots properly
knitr::opts_chunk$set(dev = "png", dev.args = list(type = "cairo-png"))
```


![Two lemmings confused by exposure-mediator interactions (with help from DALL-E)](med-or-mod-cartoon2.jpg)

In [Part 1](https://reluctantcriminologists.com/blog-posts/[6]/modmadness-pt1.html), I covered issues related to estimating and interpreting interaction effects with binary or skewed count outcome variables. In Part 2, I introduce the need and a method for disentangling indirect and interaction effects in the presence of a potential exposure-mediator interaction. 

My primary goals in this post are to (1) introduce counterfactual causality, exposure-mediator interactions, and key terminology and logic underlying a "causal mediation" approach to decomposing total effects within a potential outcomes framework; and (2) illustrate how to conduct total effect decomposition using simulated crime data with the `CMAverse` software package in R and introduce the important assumptions required to interpret the generated model parameters as estimates of causal effects. 

Ready to dip your toes into the deep end?  

## Section A: Counterfactuals, potential outcomes, and effect decomposition

### Comprehending counterfactuals

Have you ever stubbed your toe in the dark? Think back to one of those times. Did you say "ouch" or some other four letter word? What do you think **caused** you to stub your toe? 

Let's add some details to this example: Imagine that you are in an unfamiliar room, at night, with blackout curtains drawn closed over a single window. With the curtains closed, the room lacks sufficient light to help you see obstacles in your path. You are tip-toing across the room in search of a light switch when suddenly - "OUCH!" - you stub your toe on what feels like the leg of a chair. Your mind suddenly and angrily turns to the curtains: "If I had just left those #&%@! curtains open, I never would have stubbed my toe!" 

![Your thoughts communicate a causal claim about the world - that the closed window curtain caused your pain.](counterfac1.jpg)

There are two important things to note about this imaginary angry thought. First, it communicates a causal belief or claim. Specifically, your momentary thought communicates a belief that the closed window curtains are (at least partly) responsible for you stubbing your toe. Put differently, you view the closed curtains as a *cause* of the undesired outcome - perhaps not the only cause, but a noteworthy cause nonetheless. 

Second, the structure of this angry thought conveys an implicit view of causal claims as dependent upon contrasts between plausible "potential outcomes" across observed and "counterfactual" conditions. That is, your momentary thought contrasts an observed or factual initial condition (the closed curtain) with a *counterfactual* initial condition (an open curtain), and then implies a different potential outcome (i.e, a stubbed versus an unstubbed toe) might have occurred if the observed initial condition would have been changed to the counterfactual condition instead. 

![Causal claims depend upon contrasts between "potential outcomes" across observed and counterfactual conditions.](counterfac2.jpg)

Many social scientific questions and claims reflect a similar counterfactual logic or, at least, can be recast in counterfactual terms: 

- *If politicians had not campaigned on these platforms or had not signed those policies into law, then US incarceration rates would not have increased exponentially...* 
- *If we intervene in those neighborhoods in these ways, then crime rates in those neighborhoods will reduce...* 
- *If that group had those different characteristics, then they would have received better (worse) criminal justice outcomes...*   
- *If those adults had not experienced adverse childhood experiences, then they might not have participated in violent criminal behaviors...*  

In our [earlier post on causation without correlation](https://reluctantcriminologists.com/blog-posts/%5B4%5D/causation-no-corr), we also noted that counterfactual reasoning is central to statistical tests of causal claims and even underlies justifications for randomized controlled trials themselves:  

> "We seem to engage in counterfactual thinking naturally, as it appears central to [imagination and rational agency](https://plato.stanford.edu/entries/counterfactuals/). Pearl and Mackenzie go so far as to claim that the ability to use counterfactual thinking to make “explanation-seeking inferences reliably and repeatably” is what “most distinguishes human from animal intelligence, as well as from model-blind versions of AI and machine learning” ([2018](https://www.basicbooks.com/titles/judea-pearl/the-book-of-why/9780465097616/), p.33). Moreover, the belief that randomization in controlled experiments offers a valid mechanism for making causal inferences relies upon counterfactual reasoning about potential outcomes; these counterfactual justifications underlying classical statistics were proposed by pioneers Jersey Neyman and Sir Ronald Fisher [a century ago](https://www.cambridge.org/core/books/abs/causal-inference-for-statistics-social-and-biomedical-sciences/brief-history-of-the-potential-outcomes-approach-to-causal-inference/B8CEDDC08F0E0D6C577847F0CBE4E6A3)! Meanwhile, principled counterfactual frameworks using potential outcomes to make causal inferences with observational data have been in use [since the 1970s](https://en.wikipedia.org/wiki/Rubin_causal_model) and represent arguably [the best approach to causal identification with observational data today](https://jech.bmj.com/content/76/11/960)."

### Prepare for potential outcomes notation 

With that said, let's recast our hypothetical toe-stubbing example into the language of counterfactuals and potential outcomes. 

In this simple example, we have two initial "exposure" or "treatment" conditions: *curtains closed* and *curtains open*. We will denote  *curtains open* as X=0 and *curtains closed* as X=1. Likewise, we have two "potential outcome" conditions: *unstubbed toe*, denoted as Y=0, and *stubbed toe*, denoted as Y=1. 

Given these and our causal expectations, we can write two potential outcomes equations, Y(0)=0 (or Y0=0) and Y(1)=1 (or Y1=1), that respectively represent our expectation of a *stubbed toe* when curtains are closed and our expectation of an *unstubbed toe* when curtains are open. Here, I am (loosely) adopting [Pearl's *do-calculus* notation](http://causality.cs.ucla.edu/blog/index.php/2013/10/26/comments-on-kennys-summary-of-causal-mediation/), where these two equations are abbreviations of longer structural equations for outcome probability expectations under different initial conditions where we *do* X=0 or X=1. The first equation, Y(0), is shorthand for Y(do[x=0])=0, which means that we expect the value of Y to equal "0" (i.e., we expect an unstubbed toe) when we *do* X=0 (i.e., when we open the curtains). Similarly, the second equation, Y(1), is shorthand for Y(do[x=1])=1, which means that we expect the value of Y to be "1" (i.e., we expect a stubbed toe) when we *do* X=1 (i.e., when we close the curtains). Technically, we expect the probability to be closer to zero or one when we do X=0 or X=1, respectively, but just bear with me here. 

![We can recast our thought experiment into the language of potential outcomes.](counterfac3.jpg)

Additionally, [as we have explained before](https://reluctantcriminologists.com/blog-posts/%5B5%5D/colliders#sec-dagsaber), it is usually helpful to communicate our causal assumptions transparently using a causal diagram or a DAG. In the DAG below, we collapse our exposure conditions and potential outcomes into two variables connected by an arrow to represent our expectation of a causal relationship between curtains (open versus closed) and uttering a four-letter word (unstubbed versus stubbed toe).    

```{r}
library(tidyverse)
library(here)
library(simstudy)
  # https://cran.r-project.org/web/packages/simstudy/vignettes/simstudy.html
  # https://kgoldfeld.github.io/simstudy/articles/simstudy.html
library(ggplot2)
library(patchwork)
# library(psych) #detach to ensure alpha works with ggplot
  # library(devtools)
  # install_github("jtextor/dagitty/r")
library(dagitty)
library(ggdag)
library(truncnorm)
library(see)
  # devtools::install_github("strengejacke/strengejacke")
library("sjPlot")
library("ggthemes")
library("margins")
library("ggdist")
library(gt)
library(gtsummary)
library(ggraph)
library(CMAverse)
library(ggExtra)
library(ggeffects)
library(ggblend)

```

```{r}
#| label: DAG1
#| fig-cap: "Figure 1. Simple DAG representing causal effect of window curtains on stubbed toes (ouch!)"


ouchDAG <- dagify(
  Ouch ~ Curtains,
  exposure = "Curtains",
  outcome = "Ouch",
  coords=list(
    x=c(Curtains=0, Ouch=2),
    y=c(Curtains =1, Ouch=1)
  )) %>% tidy_dagitty() %>% 
  dplyr::mutate(focal = ifelse(name != "Curtains", "#56B4E9", "#CC79A7"))


#function to shorten arrows (edges)
# https://stackoverflow.com/questions/65420136/how-do-you-adjust-the-arrows-in-a-ggplot-of-a-ggdag
shorten_dag_arrows <- function(tidy_dag, proportion){
# Update underlying ggdag object
tidy_dag$data <- dplyr::mutate(tidy_dag$data, 
                             xend = (1-proportion/2)*(xend - x) + x, 
                             yend = (1-proportion/2)*(yend - y) + y,
                             xstart = (1-proportion/2)*(x - xend) + xend,
                             ystart = (1-proportion/2)*(y-yend) + yend)
return(tidy_dag)
}

ouchDAG1 <- shorten_dag_arrows(ouchDAG, 0.08)


ouchDAG1 <- ouchDAG1 %>% ggplot(aes(x=x, y=y, xend=xend, yend=yend)) +
  geom_dag_edges() +
  geom_dag_text(aes(color = focal)) + 
  theme_dag() + 
  guides(fill = 'none', color = 'none') +
  scale_color_manual(values = c("#56B4E9","#CC79A7")) +
  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) +
    #change default expansion on y-axis min & max
  ggtitle("DAG1") + 
  theme(plot.title = element_text(size = 12))

ouchDAG1
```

### Is your mechanism a mediator, a moderator, or both?  

Now, let's step back and revisit our causal assumptions. Do we *really* think the closed curtains directly caused us to stub our toes? When interrogating a causal claim, it is usually a good idea to ask "how" and "why" questions, as doing so might illuminate mechanisms that can help us better identify, predict, and explain causal relationships. For instance, *why* do we think the closed curtains caused us to stub our toe? *How* might the closed curtains have caused such an outcome to occur?  

In this case, you probably do not think that the closed window curtains *directly* caused toe stubbing. Rather, you likely expect that closed curtains *indirectly* caused this painful outcome by blocking light from entering the room through the window. In contrast, had the window curtains been open, then there might have been more ambient light in the room and, with sufficient light, you might have been better able to see and to avoid colliding with hazardous objects. 

Let's recast these more precise mechanistic beliefs as potential outcomes and communicate them graphically with a new DAG. 

![Specifying mechanisms can help us identify, predict, and explain causal relationships.](counterfac4.jpg)

```{r}
#| label: DAG2
#| fig-cap: "Figure 2. DAG of indirect causal effect of window curtains through light on stubbed toes"

ouchDAG2 <- dagify(
  Ouch ~ Light ,
  Light ~ Curtains, 
  exposure = "Curtains",
  outcome = "Ouch",
  coords=list(
    x=c(Curtains=0, Light=1, Ouch=2),
    y=c(Curtains =1, Light=1, Ouch=1)
  )) %>% tidy_dagitty() %>% 
  dplyr::mutate(focal = ifelse(name != "Curtains", "#56B4E9", "#CC79A7"))


ouchDAG2 <- shorten_dag_arrows(ouchDAG2, 0.08)


ouchDAG2 <- ouchDAG2 %>% ggplot(aes(x=x, y=y, xend=xend, yend=yend)) +
  geom_dag_edges() +
  geom_dag_text(aes(color = focal)) + 
  theme_dag() + 
  guides(fill = 'none', color = 'none') +
  scale_color_manual(values = c("#56B4E9","#CC79A7")) +
  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) +
    #change default expansion on y-axis min & max
  ggtitle("DAG2") + 
  theme(plot.title = element_text(size = 12))

ouchDAG2
```

After examining this DAG, many of you might immediately assume it that it displays a classic indirect causal effect or mediating relationship. However, it is worth taking a moment to ponder whether you think light really is a mediator, or instead whether it is a moderator, or perhaps both? For example, consider that opening the curtains might reduce the chances of stubbing your toes when it is light outside and, hence, when doing so lets sufficient light in the room for you to see obstacles in your path. In contrast, when it is not light outside, opening the curtains might not let sufficient light in and, in those situations, opening the curtains (i.e., *doing* X=0) might not reduce (i.e., cause) the probability of stubbing toes. 

Put differently, we might posit a heterogeneous causal effect of opening the curtains on the probability of toe stubbing, where the causal effect is strongest when accompanied by sufficient light but weakest or nonexistent when not accompanied by sufficient light.

If you are a social scientist, you might also be accustomed to seeing an intersecting arrow in a causal diagram to depict this type of conditional effect or moderating relationship, like below: 

```{r}
#| label: Moderation
#| fig-cap: "Figure 3. Causal graph of light moderating the effect of window curtains on stubbed toes"

ouchDAG2b <- dagify(
  Ouch ~ Curtains ,
  holder ~ Light, 
  exposure = "Curtains",
  outcome = "Ouch",
  coords=list(
    x=c(Curtains=0, Light=1, holder=1, Ouch=2),
    y=c(Curtains =1, Light=0, holder=1, Ouch=1)
  )) %>% tidy_dagitty() %>% 
  dplyr::mutate(focal = ifelse(name != "Window", "#56B4E9", "#CC79A7"))


ouchDAG2b <- shorten_dag_arrows(ouchDAG2b, 0.08)


#create factor variable to isolate edge of interest, permits specifying edge color
ouchDAG2b <- ouchDAG2b %>% dplyr::mutate(
  myedge1 = if_else(ouchDAG2b$data$name == "Light" & ouchDAG2b$data$to == "holder",
                    "yes", "no"), 
  modlinetype = ifelse(myedge1 == "yes", "solid", "dashed")
  ) 

#plot dag
fig3 <- ouchDAG2b %>% ggplot(aes(x=x, y=y, xend=xend, yend=yend)) +
  geom_dag_edges(aes(x = xstart, y = ystart, edge_color=myedge1, 
                     edge_linetype = modlinetype), show.legend = FALSE) +
  geom_dag_text(data = function(x) filter(x, name != "holder"), 
                color="#56B4E9") +
  theme_dag() + 
  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) + #change default expansion on y-axis min & max
  scale_edge_colour_manual(values=c("darkgrey", "maroon")) + #change second color to highlight focal myedge1 
  # ggtitle("DAG w/mediation & interaction") + 
  ggtitle("Classic Moderation Diagram") + 
  theme(plot.title = element_text(size = 12))

fig3 

```

So, is light a mediator, or a moderator, or is it both? Well, it turns out that mediation and moderation are [not always as distinguishable](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4220271/) as one might think. 

In fact, this potential overlap is communicated by a proper DAG of mediating and moderating relationships. As we noted [in Part 1](https://reluctantcriminologists.com/blog-posts/%5B6%5D/modmadness-pt1#two-papers-walk-into-a-bar), a traditional DAG does not use intersecting arrows to depict moderation. Rather, arrows indicate information flow, while heterogeneous (moderation) effects are captured in the functional forms of the mathematical equations used to model causal relationships. Likewise, below is a DAG that illustrates the possibility of (heterogeneous) direct and indirect effects of closed curtains on stubbing toes.  

```{r}
#| label: DAG3
#| fig-cap: "Figure 4. DAG of direct and indirect causal effects of window curtains through light on stubbed toes"

ouchDAG3 <- dagify(
  Ouch ~ Curtains + Light ,
  Light ~ Curtains, 
  exposure = "Curtains",
  outcome = "Ouch",
  coords=list(
    x=c(Curtains=0, Light=1, Ouch=2),
    y=c(Curtains =0, Light=1, Ouch=0)
  )) %>% tidy_dagitty() %>% 
  dplyr::mutate(focal = ifelse(name != "Curtains", "#56B4E9", "#CC79A7"))


ouchDAG3 <- shorten_dag_arrows(ouchDAG3, 0.08)


ouchDAG3 <- ouchDAG3 %>% ggplot(aes(x=x, y=y, xend=xend, yend=yend)) +
  geom_dag_edges() +
  geom_dag_text(aes(color = focal)) + 
  theme_dag() + 
  guides(fill = 'none', color = 'none') +
  scale_color_manual(values = c("#56B4E9","#CC79A7")) +
  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) +
    #change default expansion on y-axis min & max
  ggtitle("DAG3") + 
  theme(plot.title = element_text(size = 12))

ouchDAG3
```

An important takeaway message is that when we are examining causal systems that we think might involve a mediating mechanism, it is important to formally assess whether there is evidence of a non-negligible **exposure-mediator interaction**. An exposure-mediator interaction is a situation where the effect of the focal cause or exposure (opening or closing the curtains) on an outcome (toe stubbing) varies across the range of values of the posited mediating mechanism (ambient light levels in the room). 
Often, when testing mediation hypotheses, assessing this possibility will entail the inclusion of a multiplicative interaction term representing a potential exposure-mediator interaction (X\*M) into your model. If the multiplicative interaction coefficient departs from zero, then you likely need to account for the joint possibility of mediation and moderation, or of indirect and interaction effects, in your modeling approach.[^Statsig-note] In this situation, you can use the "causal mediation" or potential outcomes decomposition approach to sort them out.[^Theory-note] 

[^Theory-note]:
At this point, you might be wondering: "Do I really need to do this? The [insert] theory I am testing does not predict such an interaction!" Well, failure to examine and adjust for the possibility of an exposure-mediator interaction is equivalent to forcing your model of the data generating process to conform to a strong and potentially incorrect theoretical assumption about underlying data generating processes. 
In SEM parlance, it is equivalent to “fixing” the effect of X on Y through M to be the same at all values of M. In situations where the effect of X on Y indeed varies across strata of M, failure to account for it could result in biased or incomplete inferences. In contrast, allowing for and decomposing a potential exposure-mediator interaction is, in SEM terms, akin to “freeing” that parameter, thus permitting a test of that strong theoretical assumption. In situations where no such interaction exists, the magnitude of the interaction will approach zero, and traditional and “causal” mediation approaches (e.g., “controlled” and “natural” effect estimates) will converge to the same values. In those situations, decomposition would be unnecessary yet nonetheless informative. 
In short, there is substantial upside and little downside apart from learning the skills to testing and accounting for exposure-mediator interactions whether or not one exists, yet there are potentially substantial inferential risks to *not* doing so when one exists. So, just how *a priori* confident are you in that likely imprecise and discursive theory of yours? 

[^Statsig-note]:
Do NOT rely on statistical significance of the interaction coefficient to make this determination as those tests are notoriously underpowered; also, as [I discussed in the first post in this series](https://reluctantcriminologists.com/blog-posts/%5B6%5D/modmadness-pt1#example-1), such inferences are particularly unreliable in nonlinear models.

### Four-way decomposition with toy example

The first thing to note about causal mediation effect decomposition is that it generates population-average inferences about counterfactual conditions. Recall, we cannot observe counterfactual causality among individual units because we can only observe one of two (or more) possible conditions for any individual unit. In our example, either the curtains were closed or open, and either we did or did not stub our toe. If the curtains were closed and we stubbed our toe, then we cannot observe the counterfactual condition in which the curtains instead would have been open to see what might have happened to our toes. However, we *can* make causal inferences about potential outcomes across counterfactual conditions with sufficient data from populations, a careful research design, and a proper causal (theoretical) model. In our example, that would require many observations of mechanism states (ambient light levels in the room) and outcome occurrences (stubbed toes) in the room under both exposure and non-exposure conditions (when the curtains were open and when curtains were closed) along with some assumptions. 

![Given some key assumptions, we can estimate counterfactual causal effects as population-average differences in potential outcomes.](counterfac5.jpg)

I will work through an example using simulated crime-relevant data later. First, though, I hope to build upon your intuitions about how this decomposition procedure works using some toy data based on our toe stubbing example. The goal of this example is to introduce you to key terminology and the conceptual basis for potential outcomes effect decomposition before getting into a more realistic applied example in which we will use software to perform the decomposition for us. 

Note that this first toy example is intended as a simple application of [VanderWeele's initial 4-way effect decomposition example](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4220271/#S2title) in which exposure and mediator values are set at specific counterfactual values (setting M to 0 or 1). Later, I will briefly introduce more [complex counterfactual logic](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4220271/#S1title) (e.g., setting M at its expected value when X=0 or X=1), which will be required for estimating and interpreting "natural" direct and indirect effects found in `CMAverse` output. For more and better resources on this topic, I recommend reading VanderWeele's 2014 paper itself, as well as his tutorials and short video course on causal mediation, all of which are available [on his website](https://www.hsph.harvard.edu/tyler-vanderweele/tools-and-tutorials/).  

```{r}
#| tbl-cap: Toy toe-stubbing data
#| tbl-subcap: ["X=1", "X=0"]
#| layout-ncol: 2

ouchdat <- tribble(
~CurtainClosed, ~AmpleLight, ~StubToe,
1,	0,	1,
1,	0,	1,
1,	0,	1,
1,	0,	1,
1,	0,	1,
1,	0,	0,
1,	0,	0,
1,	0,	0,
1,	0,	0,
1,	0,	0,
1,  1,  0,
0,	1,	0,
0,	1,	0,
0,	1,	0,
0,	1,	0,
0,	1,	0,
0,	1,	0,
0,	1,	0,
0,	1,	0,
0,	0,	1,
0,	0,	0,
)

head(ouchdat,n=11) %>% gt()
tail(ouchdat,n=10) %>% gt()

```

These data represent n = 21 curtains, light, and toe stubbing observations. In approximately half of the cases, the curtains were closed (*CurtainClosed* = 1; n = 11); in the other cases, the  curtains were open (*CurtainClosed* = 0; n = 10). The overall probability of stubbing toes, or P(Y), is 0.33 (*StubToe* = 1; n = 7/21). We will use these hypothetical "observed" probabilities to represent (counterfactual) expectations. 

Y0 and Y1  
The probability of stubbing toes varies across exposure conditions. The probability of stubbing toes given the curtains were open, denoted by P(Y|do[X=0]) or abbreviated to Y0, is 0.2. That is, we stubbed our toes in 2 out of 10 cases in which curtains were open. In contrast, we stubbed our toes in 5 out of 11 cases in which curtains were closed, which means that P(Y|do[X=1]), or Y1, is equal to 0.45. 

![Y0 and Y1](Y0Y1-pic.png)

#### Total Effect (TE)

In this example, we can calculate the *total effect* (TE) simply as the difference between the outcome probabilities across exposed and unexposed conditions. The estimated total effect of closing curtains on toe stubbing is Y1 - Y0, or 0.455 - 0.2, which equals 0.255. Put differently, opening curtains reduces the predicted probability of toe stubbing by about 26 percentage points (from ~45.5% to 20%). 

![Total effect (TE) = Y1 - Y0](TE-pic.png)

M0 and M1  
What about our mechanism? The probability of experiencing sufficient ambient light in the room to be able to see obstacles is P(M) = 0.43, since 9 out of 21 cases had a *Light* value = 1. Like stubbing our toes, the probability of experiencing sufficient light also varied across exposure conditions. Specifically, the probability of sufficient light given the curtains were open, denoted by P(M|do[X=0]) or abbreviated to M0, is 0.80 (i.e., 8/10). In contrast, there was sufficient light in the room in only 1 out of 11 cases in which the curtains were closed, which means that P(M|do[X=1]) or M1 = 0.09. 

![M0 and M1](M0M1-pic.png)

Now, let's consider jointly how the probability of stubbing our toes changes given different combinations of exposure and mediator conditions, or given that we open or close curtains and simultaneously observe the presence or absence of sufficient ambient light in the room. 

Y00  
Let's start with the probability of stubbing toes given open curtains and the absence of sufficient light, which we will denote as P(Y|do[X=0],do[M=0]) and abbreviate to Y00. Given some assumptions, this quantity represents the expected probability of stubbing our toes if we *do* X=0 (i.e., if we open the curtains) and if we were able to set the mechanism to absent, or M=0. In other words, we are setting the room to insufficient light, or *Light* = 0, with the curtains open. There were 2 observed cases in which X=0 and M=0. Perhaps these cases represented especially dark nights during which the open window curtains were not effective in increasing the amount of ambient light in the room. In half of these cases (1/2), we stubbed our toes, meaning **Y00 = 0.5**. 

![Y00](Y00-pic.png)

Y10  
Now, imagine we *do* X=1 instead (i.e., we close the curtains) and we continue hold the mechanism constant at the value of "0". That is, we set the room to insufficient light, or *Light* = 0, with the curtains closed. There are ten observed cases in which the curtains were closed and there was insufficient ambient light in the room. We stubbed our toes in five of these ten cases, meaning P(Y|do[X=1],do[M=0]) or **Y10 = 0.5**. 

![Y10](Y10-pic.png)

#### CDE

With the quantities above, we now have enough information to calculate the *controlled direct effect*, or CDE, of X on Y. Conceptually, the CDE of an exposure is the expected effect that an exposure would have on the outcome if the mechanism (M) were fixed at a specific value (m). Here is the potential outcomes equation for the CDE: 

CDE = Y1m - Y0m, where we set M to a specific value "m"  

Commonly, we might wish to estimate the controlled direct effect when the mediator is equal to zero. In this case, the CDE of an exposure is the expected effect that an exposure would have on the outcome if the mechanism were removed or fixed at M=0. Here, when we set M to m=0, the CDE is equivalent to the difference between Y10 and Y00, or the estimated effect on Y of *doing* X in the absence of the mechanism:

CDE(M=0) = Y10 - Y00  
         = 0.5 - 0.5  
         = 0.0  

In essence, this value of 0.0 indicates that *doing* X = 1 (i.e., closing the curtains) instead of doing X = 0 is expected to have no effect on the probability of toe stubbing once we remove from the equation the effect that opening curtains has on the mechanism (ie., letting sufficient ambient light into the room). Put differently, closing the window curtains is not expected to have a direct effect on stubbing toes above and beyond any indirect effects it has on the ambient light levels in the room. 

Think of it this way: You are in a dark room with curtains closed (do[X=1],do[M=0]) and, after opening the curtains, the room remained just as dark as it was before (do[X=0],do[M=0]). A CDE = 0 indicates that the probability of stubbing your toes would remain unchanged in that situation, where opening or closing the curtains does not add any ambient light into the dark room (Y10 - Y00 = 0). Either way, it is dark, and you are predicted to have a coinflip's chance (Y10 = Y00 = .50) of stubbing your toes.

![Controlled direct effect (CDE) = Y1m - Y0m](CDE-pic.png)

Y01  
In addition to Y10 and Y00, there are additional quantities we can estimate that will help us further decompose the total effect into other meaningful components like the CDE. For instance, what if we were to open the curtains (do[X=0]) while also holding constant a sufficient amount of ambient light in the room (do[M=1])? In our toy data, there were eight observations in which the windows were open and we experienced sufficient ambient light in the room that allowed us to see. We stubbed our toe in only one of these eight cases (1/8), so P(Y|do[X=0],do[M=1]) or **Y01 = 0.125**. 

![Y01](Y01-pic.png)

Y11  
Now, imagine instead we close the curtains (do[X=1]) and continue holding a sufficient amount of ambient light in the room constant (do[M=1]). There is only one observation in these toy data with X=1 and M=1. Perhaps a hall light was on, or perhaps we used our cell phone backlight to provide ambient light when the curtains were closed. In any case, we did not stub our toe in this one instance (0/1), so P(Y|do[X=1],do[M=1]) or **Y11 = 0.0**.  

![Y11](Y11-pic.png)

#### TE = CDE + INTref + INTmed + PIE
With the various quantities calculated above (e.g., M0; M1; Y00; Y10; Y01; Y11), now we have enough information to decompose the total effect of X on Y into four different components. Specifically, the total effect, or TE, is a composite value representing the sum of the controlled direct effect (CDE); reference interaction (INTref); mediated interaction (INTmed); and the pure indirect effect (PIE). I already covered the CDE above. Below, I will describe the remaining three components: INTref, INTmed, and PIE.  

#### INTref
When we observe a nonzero total effect of an exposure on an outcome, a common thing to do is to test whether the exposure operates indirectly through a posited mediating mechanism(s). However, an observed total effect might wholly (or partly) reflect the operation of an additive interaction between the exposure and a mechanism *rather than* (or in addition to) a mediation process as is often assumed. 

Yes, you read that right. An observed total effect of an exposure on an outcome might (only) reflect the presence of an interaction effect, and failure to account for this when testing indirect effect hypotheses using traditional mediation tests could result in erroneously attributing moderation to mediation, or vice versa. Moderator madness indeed! If you cannot recall learning about this in your graduate stats courses, then you are not alone.

At this point, you can probably guess that we account for this possibility by decomposing the total effect into its various possible constituent parts. As implied here, one of the components that may comprise a total effect is the *reference interaction* (INTref), which is an additive interaction that operates only if mediator is present in the absence of the exposure. As [VanderWeele explains (p.750)](https://www.hsph.harvard.edu/wp-content/uploads/sites/603/2018/04/MedInt_Ep.pdf), the reference interaction component is nonzero when "the effect on the outcome of setting both the exposure and the mediator to present differs from the sum of the effect of having only the exposure present and the effect of having only the mediator present." 

Though that might sound confusing, this is essentially a classic interaction effect. Do you find yourself preferring our probability notation yet? Either way, let's use it to calculate INTref. 

The INTref component is nonzero when [P(Y|do[X=1],do[M=1]) - P(Y|do[X=0],do[M=0])] is not equal to [(P(Y|do[X=1]) - P(Y|do[X=0])] + [(P(Y|do[M=1]) - P(Y|do[M=0])]. Let's check this with our toy data, using our abbreviated notation for quantities that we have already calculated:

Y11 - Y00  
= 0.0 - 0.5   
= -0.5  

[Y1 - Y0] + [(P(Y|do[M=1]) - P(Y|do[M=0])]  
= [0.45 - 0.2] + [.11 - 0.5]  
= -0.25 + -0.39  
= -0.64  

Since -0.5 is not equal to -0.64, we would expect a nonzero INTref estimate. 

We can use the quantities calculated earlier to estimate the reference interaction using the equations provided in [VanderWeele's Table 1 on p.751](https://www.hsph.harvard.edu/wp-content/uploads/sites/603/2018/04/MedInt_Ep.pdf): 

INTref = (Y11 - Y10 - Y01 + Y00)(M0)  
       = (0.0 - 0.5 - 0.125 + 0.5)(0.8)  
       = (-.125)(0.8)  
       = -0.1  

Here, our toy data show a small reference interaction. What does this mean and where did it come from? Well, first remember that a reference interaction is an additive interaction that operates only if mediator is present in the absence of the exposure. Likewise, we observed the mechanism (sufficient ambient light) when the curtains were open and when they were closed, so a nonzero reference interaction estimate is possible. The logic here, which mirrors that of a classic interaction, is that we must be able to assess the effect of *doing* X=1 (versus X=0) both in the absence and in the presence of the mechanism. Then, if the estimated effect of doing X differs across those conditions (or across levels of the mechanism), we would have a nonzero exposure-mediator "reference interaction." 

![A reference interaction is not what it sounds like. Well, maybe it is, if it sounds like an additive interaction effect that operates only if mediator is present in the absence of the exposure. (DALL-E)](DALL-E-INTref.png)

Now, recall that we did not stub our toes in that one time we observed closed curtains and the mechanism present (Y11 = 0/1 = 0.0). However, we did stub our toe in one of the eight instances with open curtains and the mechanism present (Y01 = 1/8 = 0.125). Meanwhile, the probability of stubbing our toes was equal across exposure conditions in the absence of the mediator (Y10 = 5/10 = 0.5; Y00 = 1/2 = 0.5). 

From these comparisons, it appears that doing X=1 instead of X=0 (closing curtains) slightly *reduced* the probability of toe stubbing with the mechanism present (Y11 - Y01 = 0.0 - 0.125 = -.125), whereas doing X=1 instead of X=0 had no effect on the probability of toe stubbing with the mechanism absent (Y10 - Y00 = 0.5 - 0.5 = 0). In the equation above, we essentially used these same comparisons and then weighted the resulting difference-in-differences value by the expectation of observing the mediator in the absence of exposure (i.e., M0 = probability of observing M=1 given we do[X=0]).[^ContrastEQ-note]

[^ContrastEQ-note]: 
Are you wondering what the (Y11 - Y10 - Y01 + Y00) term represents? Well, you can think of it as contrasting the effect of X (i.e., doing X=1 - doing X=0) in the mechanism's presence (M=1) versus its absence (M=0). Alternatively, you can also think of it as contrasting the effect of M (i.e,. doing M=1 - doing M=0) in the exposure's presence (X=1) versus its absence (X=0). Let's use the latter to show our work:  
(Effect of M | X=1) - (Effect of M | X=0)  
   = (Y11 - Y10) - (Y01 - Y00)  
From here, we just do a bit of basic algebra:  
   = Y11 - Y10 + (-1)(Y01 - Y00)  
   = Y11 - Y10 - Y01 + Y00  

Strong caveat: If these were real data, I would strongly recommend against making any inferences from this INTref estimate given it was generated using a very small sample (e.g., only n=1 observation for one of the cells). Unfortunately, such [noisy and unreliable inferences](https://journals.sagepub.com/doi/full/10.1177/0049124119826158) are all too common in criminology. But, that is an entry for another day. 

One final point about the INTref component: As [VanderWeele explains (p.755)](https://www.hsph.harvard.edu/wp-content/uploads/sites/603/2018/04/MedInt_Ep.pdf), the INTref "requires the mediator to operate, but the effect does not come about by the exposure changing the mediator — it simply requires that the mediator is present even when the exposure is absent; the effect is 'unmediated,' in the sense that it does not operate by the exposure changing the mediator, but it requires the presence of the mediator nonetheless." In contrast, the remaining two components (PIE and INTmed) both involve mediation such that *doing* X (i.e., the exposure) affects the outcome at least partly by changing the mediator. Now, let's move to the next component. 

#### PIE 
As noted above, when we observe a total effect of an exposure on an outcome, that total effect might also reflect an indirect effect of the exposure operating through a specific mediating mechanism(s). In this four-way decomposition, the "pure indirect effect" (PIE) component is the analogue of this classic indirect effect. Formally, the PIE component represents the effect of the mediator in the absence of the exposure, and it is non-zero only if: (1) the exposure itself affects mediator and (2) the mediator affects the outcome when the exposure is absent. 

Here, closing curtains decreases light in the room, and light reduces the chances of stubbing toes when the curtains are open. Using the equations in [VanderWeele's Table 1](https://www.hsph.harvard.edu/wp-content/uploads/sites/603/2018/04/MedInt_Ep.pdf), we can estimate the PIE component using the quantities calculated earlier by estimating the effect of *doing* M in the absence of X (Y01 - Y00) and then weighting this contrast by the effect of *doing* X on the mediator (M1-M0):

PIE = (Y01 - Y00)(M1 - M0)  
    = (0.125 - 0.5)(0.09 - 0.8)  
    = (-0.375)(-0.71)  
    = 0.266  

Recall, the total effect of closing the curtains on toe stubbing was 0.255. Closing curtains primarily increases our chances of stubbed toes indirectly by blocking light out of the room. In this case, the indirect effect estimate is quite close to the total effect estimate (0.266 versus 0.255). However, it does not always work out this way. In fact, as we will see, the only reason it worked out this way in our toy example is because the other two nonzero components, INTref and INTmed, were of approximately equal magnitude with opposite signs, so they cancel each other out when summing for the total effect. 

This is an important point. If we had relied strictly on the total effect, or on traditional mediation test procedures, to make inferences about the exposure's effect on the outcome via the primary mediating mechanism, then we would have been close to accurately estimating the indirect effect. However, we would have done so only by luck or accident, and we would have missed completely the other two nonzero interaction components. 

![Pure indirect effects: As American as apple PIE? (DALL-E)](DALL-E-surreal-pie.png)

Speaking of those other two interaction components, we already discussed INTref; now, let's move on to INTmed, our fourth component.

#### INTmed
So far, we have discussed controlled direct effects, reference interaction effects, and pure indirect effects. Each of these is analogous (in certain situations) to well-known direct effects, interaction effects (moderation), and indirect effects (mediation), though their empirical connections as distinct components of a total effect may be less widely appreciated or understood. 

This is good time to introduce the most important use cases for decomposition: When there is no exposure-mediator interaction (and strong causal assumptions hold), then traditional approaches to detecting interaction effects or testing indirect effects are often reliable and decomposition procedures may be unnecessary. However, **when there is a nonzero exposure-mediator interaction, then traditional approaches become problematic, decomposition is essential, and the constituent components comprising a total effect become more complex - and potentially more numerous**. For instance, in such situations, we may find a fourth nonzero component also contributes to the total effect - the "mediated interaction" or *INTmed*.

The "mediated interaction" or INTmed component represents an additive interaction that operates only if the exposure has an effect on the mechanism. As [VanderWeele explains (p.750)](https://www.hsph.harvard.edu/wp-content/uploads/sites/603/2018/04/MedInt_Ep.pdf), when the INTmed component is nonzero, this means that "the exposure causes the mediator, and the presence of the mediator is itself necessary for the exposure to have an effect on the outcome." 

In our toy example, the probability of stubbing our toes varies across values of X (i.e., whether curtains are open or closed); that is, P(Y|do[X=x],do[M=1]) varies across do[X=0] and do[X=1]. Given the presence of the mechanism (sufficient ambient light), the probability of stubbing toes is higher when the exposure is "absent" (X=0, or curtains open) than it is when the exposure is present (X=1, or curtains closed). We can check this with our data:

Curtains open: P(Y|do[X=0],do[M=1]) = Y01 = 1/8 = 0.125  
Curtains closed: P(Y|do[X=1],do[M=1]) = Y11 = 0/1 = 0.0  

We can also use the quantities estimated earlier to calculate the INTmed component. Like the INTref component, we are essentially generating a weighted difference-in-difference contrast. Like the PIE component, we are weighting that contrast by the effect of *doing* X on the mediator (M1 - M0):

INTmed = (Y11 - Y10 - Y01 + Y00)(M1 - M0)  
       = (0.0 - 0.5 - 0.125 + 0.5)(0.09 - 0.8)  
       = (-0.125)(-0.71)  
       = 0.089  

Recall, when the mechanism was present in this toy example (i.e., *Light*=1), toe stubbing was less likely when the curtains were closed (Y11 = 0.0) than when they were open (Y01 = 0.125). In other words, closing the curtains (do[X=1]) reduced the probability of toe stubbing in the presence of the mechanism. However, this effect was only observed in the presence of the mechanism; when *Light*=0, the probability of toe stubbing was the same whether the curtains were open (Y00 = 0.5) or closed (Y10 = 0.5). Moreover, closing the curtain reduced the probability of observing the mechanism (M1 - M0 = 0.09 - 0.80 = -0.71). So, the exposure causes this conditional effect, meaning it is a mediated interaction (INTmed). 

![A mediated interaction is not what it sounds like either. Unless it sounds like an additive interaction that operates only if the exposure has an effect on the mechanism. (DALL-E)](DALL-E-INTmed.png)

Put differently, since *opening* the curtains increases light in the room, and opening the curtains appears to increase toe stubbing when light is present, then the exposure actually increases risks of toe stubbing by increasing the conditions (light) under which it amplifies the risks of the  outcome occurring. Again, this is a mediated interaction. 

Another caveat: I strongly caution against such real world inferences when data are so sparse; like our INTref, this mediated interaction is based on a comparison generated from n=1 observation in one of the cells! If we had more (and real) data, I highly doubt we would observe a negative effect of closing curtains on toe stubbing in the presence of the mechanism. Still, despite the implausibility of this toy example, I hope it helps you better understand the components that comprise a total effect. 

#### Revisiting TE

Before moving on to a simulated example, I want to revisit the *total effect* (TE) that we just decomposed into four component parts. Recall earlier how we calculated the total effect of X on Y as the difference between the outcome probabilities across exposed and unexposed conditions (Y1 - Y0)?  

TE = Y1 - Y0  
   = 0.455 - .20  
   = 0.255  

Well, after decomposing these four constituent components of the total effect, we can also calculate the total effect by summing these four components. This is a good way to check that our calculations were correct!  

TE = CDE + INTref + INTmed + PIE  
   = 0 + (-0.1) + 0.089 + 0.266  
   = 0.255  

It worked! Whew. 

![I wasn't worried. Were you?](not-worried.gif)

## Section B. Effect Decomposition with Simulated Data and CMAverse 

At this point, I am hoping the toy example above helped build your intuitions about the 4-way decomposition process and that you feel ready to move on to a more complicated and realistic use case with simulated data and the [`CMAverse` R package](https://bs1125.github.io/CMAverse/). Though we took a long and winding road to arrive here, as I explained in our [Moderator Madness, Part 1 post](https://reluctantcriminologists.com/blog-posts/%5B6%5D/modmadness-pt1#example-2), this is the goal that initially motivated this two-part blog series:

> The central aim of ["Moderator Madness, Part 2"] will be to illustrate how exposure-mediator interactions entangle mediation and moderation processes in a way that requires decomposition of the effect. Effect decomposition is accomplished with a [causal mediation approach](https://www.hsph.harvard.edu/tyler-vanderweele/tools-and-tutorials/) that involves clever estimation of potential outcomes and transparent acknowledgement of strong causal assumptions underlying those estimates..."

>"...[I]n Part 2 of the blog series, I will pick up here using the same simulated data from this example to illustrate how the addition of an exposure-mediator interaction entangles indirect and interaction effects in a way that requires decomposition of these effects. I will also illustrate how one can accomplish effect decomposition with a causal mediation approach that involves clever estimation of potential outcomes and transparent acknowledgement of strong causal assumptions underlying those estimates."

Before diving in, I should explain that this section is meant for social scientists that already have some familiarity with traditional "product of coefficients (*ab* path) approaches to modeling mediation processes and are looking for a very basic introduction to [less well known yet generally preferred](https://pubmed.ncbi.nlm.nih.gov/34239282/) "causal mediation" methods. If you find yourself in the position of testing or estimating indirect effects and unaware of the causal mediation approach, then I strongly encourage you to read more on the topic. There are lots of excellent [summaries](https://www.publichealth.columbia.edu/research/population-health-methods/causal-mediation), [overviews of software alternatives](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7853644/), and introductory primers on [causal mediation](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10368791/) and on [CMAverse specifically](https://journals.lww.com/epidem/Fulltext/2021/09000/CMAverse__A_Suite_of_Functions_for_Reproducible.23.aspx). Additionally, the [CMAverse quickstart](https://bs1125.github.io/CMAverse/articles/quickstart.html) website itself is a great place to start. If nothing else, I hope this entry serves as a segue for folks curious about advancing beyond traditional mediation approaches by learning more about causal mediation approaches.[^Methods-note]  

[^Methods-note]:
Given the aims, I will not get into detailed issues or advanced modeling options, such as differences between [regression-based](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10368791/), [weighting-based](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4214081/), *g-formula*, or [other estimation methods](https://bs1125.github.io/CMAverse/articles/overview.html) available in CMAverse. However, some available methods may be better suited for your particular modeling situation, and some choices may be better than others [depending upon your specific causal estimand of interest](https://www.tandfonline.com/doi/full/10.1080/10705511.2022.2104287).   

Without further ado, let's get to it! 

### DAG of simulated data-generating processes

For this illustration, I will generate simulated data that are very similar to those found in [Example 2 from our "Moderator Madness: Part 1" post](https://reluctantcriminologists.com/blog-posts/%5B6%5D/modmadness-pt1#outline-of-the-post).[^Sim-note] In that post, I stated:

[^Sim-note]: 
Similar, but not identical. For instance, I made small changes to the magnitude of some coefficients, which modified the relative contributions of various components to the total effect. 

> In the second example, I assume that the true data generating process underlying both imaginary papers (i.e., "paper 1" and "paper 2" in our example above) is an integrated causal model in which moral beliefs is both a mediating and moderating mechanism. That is, in the simulated data for the second example, there is a true indirect effect of *parental support* on delinquency through *strong moral beliefs* as well as a direct effect of *parental support* on *delinquency* that varies systematically across levels of (i.e., "interacts with") *strong moral beliefs*. 

Thus, the simulated data here contain the same three focal variables. The exposure, *parental support* practices, is conceptualized as a variable measure of parental intervention(s) on youth attitudes and behaviors; it is generated here as a continuous, normally distributed, mean-centered variable. The mechanism, youths' *strong moral beliefs*, is generated as a negatively skewed ordinal variable ranging from 0 to 5, which was created by reverse-scoring a truncated Poisson-distributed *weak moral beliefs* variable. The outcome, *delinquency*, is a positively skewed, Poisson-distributed event count variable ranging from 0 to a truncated theoretical maximum of 7. 

Again, the simulated data will be generated using the following hypothetical causal mediation and moderation assumptions: *Parental support* practices are a somewhat effective cause of youth's internalization of *strong moral beliefs*, and *strong moral beliefs* effectively cause fewer delinquent behavior events (i.e., they constrain temptations, promote resistance to, or encourage selection out of delinquency). Thus, the data generating processes include causal mediation or indirect effects of an exposure through a mechanism. 

Additionally, *parental support* directly discourages or reduces involvement in youth delinquency.[^Direct-note] However, this effect varies across levels of the mechanism. Specifically, parental support's negative effect on youth delinquency is most pronounced among youth with weak moral beliefs (i.e., low *strong moral beliefs* index scores); these youth are most at risk of engaging in delinquency, so effective parental interventions have the greatest potential to enact behavioral change among these youth. In contrast, youth with strong moral beliefs are highly unlikely to engage in delinquency irrespective of the degree of parental support they experience; therefore, parental support is largely ineffective among youth with the highest *strong moral beliefs* index scores. This means the data generating processes include moderation or interaction effects. 

[^Direct-note]:
Of course, in many situations, a "direct effect" estimate itself may (and likely does) represent an aggregate or composite summary of other indirect effects operating through unmeasured mechanisms.  

Moreover, since parental support both operates indirectly through and interacts with youth's strong moral beliefs, the data generating processes also involve an exposure-mediator interaction. That is, some of parental support's conditional effect on delinquency might be attributable to a *reference interaction*, or heterogeneity in the effect of parental support across levels of the mechanism (e.g., across youth with weak versus strong moral beliefs). Yet, since parental support also partly causes strong moral beliefs, then parental support is partly responsible for setting the very levels across which it conditionally affects delinquency. This means that some of parental support's conditional effect also is likely attributable to a *mediated interaction*. 

In causal mediation analysis using potential outcomes, the *mediated interaction* component will be variously attributed to quantities representing the direct effect of the exposure or, instead, to quantities representing the indirect effect through the mechanism; which a researcher chooses to report will depend upon one's focal research questions and estimand of interest. I will explain this in more detail later. For now, let's check out a modified version of [Part 1's basic DAG](https://reluctantcriminologists.com/blog-posts/%5B6%5D/fig1.png), which concisely communicates the causal assumptions underlying the data generating processes for our simulation.   

```{r}

# modified from Valeri & VanderWeele 2013, Fig.2 

# causalDAG2 <- dagify(
#   Y ~ A + M + C1 + C2,
#   M ~ A + C1 + C2,
#   A ~ C1,
#   exposure = "A",
#   outcome = "Y",
#   coords=list(
#     x=c(A=1, M=1.5, Y=2, C1=1.5, C2=1.9),
#     y=c(A=1, M=2, Y=1, C1=1.4, C2=1.75)
#   )) %>% tidy_dagitty() 

# change to simplified version from 
  # https://bs1125.github.io/CMAverse/articles/quickstart.html

causalDAG2 <- dagify(
  Y ~ A + M + C,
  M ~ A + C,
  A ~ C,
  exposure = "A",
  outcome = "Y",
  coords=list(
    x=c(A=1, M=1.5, Y=2, C=1.5),
    y=c(A=1, M=2, Y=1, C=3)
  )) %>% tidy_dagitty()


#shorten edges
causalDAG2p <- shorten_dag_arrows(causalDAG2, 0.08)

#create factor variable to isolate edge of interest, permits specifying edge color
causalDAG2p <- causalDAG2p %>% dplyr::mutate(
  myedge1 = if_else(causalDAG2p$data$name == "C", "yes", "no"),
  # myedge1 = if_else(causalDAG2p$data$name == "C1" | causalDAG2p$data$name == "C2",
  #                   "yes", "no"), 
  modlinetype = ifelse(myedge1 == "yes", "solid", "solid") #change 2nd "solid" to "dashed" if desired
  ) 


#plot dag
fig4 <- causalDAG2p %>% ggplot(aes(x=x, y=y, xend=xend, yend=yend)) +
  geom_dag_edges(aes(x = xstart, y = ystart, edge_color=myedge1, 
                     edge_linetype = modlinetype), show.legend = FALSE) +
  geom_dag_text(label=c("A\n(Parental\nSupport)", "C\n(Measured Confounders\nNot Affected by Exposure)", "M\n(Moral\nBeliefs)", "Y\n(Delinquency)"), 
                color="#56B4E9") +
  theme_dag() + 
  guides(fill = 'none', color = 'none') +
  scale_y_continuous(expand=expansion(mult=c(0.2,0.2))) +
    #change default expansion on y-axis min & max
  # ggtitle("Modified Figure 2 from Valeri & VanderWeele 2013") + 
  scale_edge_colour_manual(values=c("darkgrey", "maroon")) + 
  theme(plot.title = element_text(size = 12))


```



```{r}
#| label: DAG4
#| echo: false
#| fig-cap: "Figure 4. DAG illustrating 'no unmeasured confounding' assumptions underlying causal mediation (modified from Fig.2 in Valeri & VanderWeele 2013)"

fig4
```

### "Causal mediation" assumptions

Readers might notice some changes here to Part 1's DAG, such as the addition of common "causal mediation" notations to variable names (e.g. exposure label "A" to "Parental Support" variable) and the addition of "measured confounders." With the addition of confounders, I hope to remind readers that interpreting results and making causal inferences from results of "causal mediation" models - as well as from traditional mediation models - requires important, and perhaps untenable, assumptions about the lack of unmeasured sources of confounding of the X-M, M-Y, or X-Y relationships.[^Assume-note] [Valeri and VanderWeele (2013)](https://pubmed.ncbi.nlm.nih.gov/23379553/) succinctly describe these essential assumptions:

[^Assume-note]:
Again, traditional and causal mediation approaches both rest upon similar confounding assumptions. In addition to these assumptions, there are lots of other considerations as well when deciding whether a mediation model is appropriate for your situation (e.g., cross-sectional data). Too often, [a mediation model may not be appropriate](https://journals.sagepub.com/doi/10.1177/25152459221095827), but researchers use them anyway. Still, even in situations where the appropriateness of their assumptions are dubious, I think most social science areas would benefit generally from researchers thinking carefully about and transparently stating the assumptions they are making when interpreting results - whether results are from mediation models or otherwise. Likewise, reading more about causal mediation methods may help towards these ends, as the explicit and formal statement of assumptions necessary to generate valid causal inferences from mediation models is an important area of emphasis in the causal mediation literature. 

> "...controlled direct effects require (i) no unmeasured treatment-outcome confounding and (ii) no unmeasured mediator-outcome confounding. Natural direct and indirect effects require these assumptions and also (iii) no unmeasured treatment-mediator confounding and (iv) no mediator-outcome confounder affected by treatment." (p.??)

> "It is important to note that randomizing the treatment is not enough to rule out confounding issues in mediation analysis. This is because randomization of the treatment rules out the problem of treatment-outcome and treatment-mediator confounding but does not guarantee that the assumption of no confounding of mediator-outcome relationship holds. This is because even if the treatment is randomized, the mediator generally will not be." (p.??)

I think my simulated example is complex enough for an introductory tutorial without including any confounding of the modeled relationships. However, once one is familiar with CMAverse code, terminology, and interpretation of results, it is relatively trivial to extend the example by including and adjusting for measured confounders.

### Terminology

Before getting to the simulation, it is probably a good idea to introduce some minor changes in terminology and basic notation that you will encounter when using CMAverse to perform effect decomposition. 

#### Variables 

First, the focal variables are labeled as follows: 

Exposure == A    (Alternatively referred to as "X" above)  
Mediator == M      
Outcome  == Y    
Confounders == C (Ignored throughout, but [choose wisely](https://reluctantcriminologists.com/blog-posts/%5B5%5D/colliders))  

Though I do not include confounders in this example, two types of outcome confounders are sometimes distinguished as C1 (exposure-outcome confounders) and C2 (mediator-outcome confounders). Note that there may also be potential confounding of the exposure-mediator relationship.   

#### Controlled versus Natural Effects 

Second, depending upon the model and options selected, the CMAverse output may contain terms that do not exactly match the four-way effect decomposition components described above.

Direct Effects: You should recognize the *controlled direct effect* (CDE). However, the output may also contain estimates for a *pure natural direct effect* (PNDE) and a *total natural direct effect* (TNDE). 

Indirect Effects: Instead of encountering a *pure indirect effect* (PIE) estimate, the output might instead contain estimates for a *pure natural indirect effect* and a *total natural indirect effect*.  

You can find [more detailed descriptions elsewhere](https://www.publichealth.columbia.edu/research/population-health-methods/causal-mediation) of the differences between controlled and natural effects. As explained above, controlled direct effects hold the mediator constant at a specific value (M=m). For example, a controlled direct effect (CDE) might contrast expected outcomes across X=0 and X=1 while holding the mechanism constant at a specific value like M=0. 

In contrast, understanding natural effects requires comprehending some of those counterfactual contrasts that we illustrated earlier. Remember that, in the presence of mediation, the mediator is expected to change as the exposure changes. So, setting the mediator to a constant value (e.g., M=0) may not provide a realistic or "natural" contrast. Natural effects allow the mediator to vary as it "naturally" would across exposure conditions. Natural effects are then estimated by holding the mediator constant at specific counterfactual values that the mediator would be expected to take under specified exposure conditions, such as setting M at the value we would expect it to be when we do[X=0] (i.e., M0) or when we do[X=1] (i.e., M1). 

For example, a (pure) natural direct effect might be estimated as a contrast between: (1) the expected outcome value when X=1 and M is set to its expected value when X=0 and (2) the expected outcome when X=0 and M is still set to its expected value when X=0. Modifying the notation used above, you might summarize this contrast as Y(do[X=1],do[M~X=0~]) - Y(do[X=0],do[M~X=0~]), or Y10 - Y00.[^Natural-note] 

[^Natural-note]: 
Note that the Y(do[X=1],do[M~X=0~]) may be an unobservable counterfactual condition (e.g., in the presence of mediation). We cannot in fact simultaneously observe Y with X set to =1 and M set to equal its expected value when X=0. After all, if we do X=1 and X has an effect on M, then M would also change to its (population average) value at X=1; M would not stay at its expected value when X=0! [These slides](https://www.nimhd.nih.gov/docs/hd-workshop/day1/roleWorkInHD-2020_10_kaufman_mediationAnalysesToRacialEthnic.pdf) (especially slide 12) offer a concise description of this issue.

Once you wrap your head around these important distinctions between natural and controlled effects, then you may find yourself beginning to comprehend other important issues related to mediation, moderation, and effect decomposition. 

First, in a linear model without interactions (i.e., where INTref=0 and INTmed=0), the CDE estimates will not change across different values of M. Additionally, in such models, controlled and natural direct effects will converge on the same estimates. This is because doing X=1 (versus X=0) will have the same effect on Y at all values of M, so doing M=0 or doing M~X=0~ will generate the same effect estimate.

Second, as you have probably figured out by now, things are not as straightforward in more complex models with nonlinear link functions or exposure-mediator interactions. Specifically, when there are nonlinearities or exposure-mediator interactions, one could conceivably estimate a different CDE estimate for every possible value of M! This makes it impossible to perform effect decomposition in the presence of an interaction using controlled effects. However, the counterfactual contrasts underlying natural direct and indirect effect estimates are uniquely defined so there is a single value even in the presence of nonlinearities and exposure-mediator interactions. This permits us to perform effect decomposition even in those situations involving more complex causal relationships.

#### Pure versus Total Effects 

I just told you that there is only one natural direct and natural indirect effect. Yet, your CMAverse output will probably show more than one natural direct and indirect effect estimate! Do not lose trust in me just yet. It is more accurate to say that there is only one "pure" natural direct effect, and there is only one "total" natural direct effect estimate. 

![When interpreting "pure" and "total" effects, remember the "total" cat won the fight over the INTmed component.](catfight.jpg)

So, what is the differences between "pure" and "total" effects? It boils down to that nonzero "mediated interaction" or INTmed estimate we find when there is an exposure-mediator interaction. Recall, the INTmed estimate describes how, in the presence of both mediation and interaction, we can contribute some differences in the effect of X on Y across different levels of M to the fact that X *causes* different levels of M. So, in a decomposition, should we attribute INTmed effects to mediation processes or to moderation processes? That is, are they indirect effects, or interaction effects? Fundamentally, they are both, but there may be advantages to attributing that INTmed component to the "direct" effect of X on Y at specific counterfactual values of M (i.e., absorbed into heterogeneous estimates of direct effects across values of M) or to the "indirect" effect of X on Y through M. In any case, there are a few important points to remember when interpreting these effects. 

First, "pure" effects do *not* include the INTmed component, whereas "total" effects do include the INTmed component. So, for instance, a "pure direct effect" essentially summarizes the effect of X on Y that is due to its controlled direct effect (CDE) and heterogeneity across M that is not due to mediation (i.e. to INTref but not INTmed), while a "total indirect effect" contains both the "pure" indirect effect (PIE) of X on Y through M and any effect of X on Y across levels of M that is due to mediation (i.e., INTmed). 

Second, we always pair the following effect estimates:  

- Pure natural direct effect & total natural indirect effect (PNDE & TNIE)
- Total natural direct effect & pure natural direct effect (TNDE & PNIE) 

Perhaps the reasons we do this are now obvious to you. These pairings ensure that the INTmed component is always counted once and only once - either in the (total) direct effect estimate or in the (total) indirect effect estimate. Likewise, in a linear model, the PNDE + TNIE estimates will sum to the same value as the TNDE + PNIE estimates. Which pair you choose to interpret, then, depends upon your research question, goals, and estimand of interest. 

![Relationship between 4-way effect decomposition and CMAverse effect estimates. Modified from Table 4 in Vanderweele 2014](effects-table.jpg)

Third, in the absence of an exposure-mediator interaction - such as when the interaction term equals zero or when you ignore a nonzero interaction term by not specifying or including it in the model - then the CDE, TNDE, and PNDE estimates all will converge to the same value. Conceptually, this is because the INTref and INTmed components will be fixed to zero, either by the data or by the researcher. 

That's enough talking. Let's start walking with a simulation. 

### Simulate data 

Unlike in Part 1, this analysis will be based on n=10,000 simulated observations, which will allow us to generate precise estimates of the focal components. We have more than enough going on; we do not need to deal simultaneously with issues related to noisy estimates.   

```{r}
#|message=FALSE 

options(scipen=0, digits = 3)

# Simulate data (Sim.2)

set.seed(1138)
n <- 10000

def2 <- defData(varname = "ParentSupport", dist = "normal", 
               formula = 0, variance = 1)
def2 <- defData(def2, varname = "WeakMoralBlfs", dist = "poisson",
    formula = "-.3 + (-.3)*ParentSupport", link = "log")
def2 <- defData(def2, varname = "Delinquency", dist = "poisson",
    formula = "-.7 + (-.25)*ParentSupport + .4*WeakMoralBlfs + 
    (-.15)*ParentSupport*WeakMoralBlfs", link = "log")
simdat2 <- genData(n, def2)

# simdat2 %>% sjPlot::view_df()
# simdat2 %>% 
#   ggplot(aes(x=WeakMoralBlfs, y=Delinquency)) +
#   geom_point()

# cap LowMoral at 5 (0-5 item) - randomly replace oob values with values in bounds 
inds2 <- simdat2$WeakMoralBlfs > 5
simdat2$WeakMoralBlfs[inds2] <- sample(0:5, sum(inds2), replace = TRUE)
simdat2$StrgMoralBlfs <- 5 - simdat2$WeakMoralBlfs

# cap Delinquency at 7 (0-7 item) - randomly replace oob values with in bounds values
inds2 <- simdat2$Delinquency > 7
simdat2$Delinquency[inds2] <- sample(0:7, sum(inds2), replace = TRUE)

# simdat2 %>% sjPlot::view_df()
# simdat2 %>%
#   ggplot(aes(x=WeakMoralBlfs, y=Delinquency)) +
#   geom_point()

#Even with n=10k, need to consider collapsing low values for StrgMoralBlfs and recenter to min=0
#Raise points re: rare events & skewed data
    # out of n=10k, 18.1% of cases have StrgMoralBlfs <=3 
      # (nrow(subset(simdat2, StrgMoralBlfs <=3))/10000)*100
    # out of n=10k, 1.02% (n=102) of cases have StrgMoralBlfs <=1 
      # (nrow(subset(simdat2, StrgMoralBlfs <=1))/10000)*100
    # out of n=10k, 0.17% (n=17) of cases have StrgMoralBlfs <=0 
      # (nrow(subset(simdat2, StrgMoralBlfs <=1))/10000)*100

#Collapse [0,1] values & recenter StrgMoralBlfs from 0-4
simdat3 <- simdat2 %>% 
  mutate(
    StrgMoralBlfs = if_else(
      StrgMoralBlfs <= 1, 1, StrgMoralBlfs), 
    StrgMoralBlfs = StrgMoralBlfs - 1
    )
# summary(simdat3$StrgMoralBlfs)

p <- ggplot(simdat3, aes(x = ParentSupport, y = StrgMoralBlfs)) +
  geom_point()

# Densigram
ggMarginal(p, type = "densigram")




```

Note joint distribution... lack of observations at high ParentSupport and low StrgMoralBlfs. This is expected given mediation processes; high parental support causes strong moral beliefs... 

### Regression & Plot

```{r}
#|message=FALSE 

# Sim.2 linear model
lm2 <- lm(Delinquency ~ ParentSupport * StrgMoralBlfs, data=simdat3)

# Sim.2 nonlinear model
glm2 <- glm(Delinquency ~ ParentSupport * StrgMoralBlfs, data=simdat3, family="poisson")

# function for custom p-values
roundp <- function(x) {
    if_else(
      is.na(x), 
      NA_character_,
      if_else(x < 0.001, format(x, digits = 3, scientific = TRUE), format(round(x, 3), scientific = F))
    )
  } 

# function for reg output w/custom p-values
regsum <- function(mymod) {
  tbl_regression(mymod, intercept=TRUE, pvalue_fun = roundp) %>%
  add_significance_stars(
        hide_se = FALSE,
        hide_ci = FALSE,
        hide_p = FALSE
      )
}

# Regression output

Ex2tab1 <- regsum(lm2) %>%
  as_gt() %>%
  gt::tab_header(title = "Linear regression predicting delinquency values")

Ex2tab2 <- regsum(glm2) %>%
  as_gt() %>%
  gt::tab_header(title = "Poisson regression predicting delinquency event rates")


#Plot interactions 
  #plot at all four values: minimum (0), (1), median (2), and maximum (3) strong moral beliefs
  #show x-axis from approx -2sd to 2sd parental support
plot_lm2 <- plot_model(lm2, type = "pred", show.data = FALSE,   
                       terms = c("ParentSupport", "StrgMoralBlfs [0,2,4]")) + 
  geom_hline(yintercept=7, linetype="dashed") +
  theme_minimal() + coord_cartesian(xlim=c(-2,2), ylim=c(-1,8)) +
  scale_colour_colorblind() +
  scale_fill_colorblind() +
  labs(x="Parental Support", 
       y="Delinquency",
       title="Predicted conditional marginal effects of parent support on delinquency", 
       subtitle="Plotted at minimum (0), scale midpoint (2), & maximum (4) strong moral beliefs\n(Linear regression, n=10k simulated observations)")  

plot_glm2 <- plot_model(glm2, type = "pred",  show.data=FALSE,
                       terms = c("ParentSupport", "StrgMoralBlfs [0,2,4]")) + 
  geom_hline(yintercept=7, linetype="dashed") +
  theme_minimal() + coord_cartesian(xlim=c(-2,2), ylim=c(-1,8)) + 
  scale_colour_colorblind() +
  scale_fill_colorblind() +
  labs(x="Parental Support", 
       y="Delinquency",
       title="Predicted conditional marginal effects of parent support on delinquency", 
       subtitle="Plotted at minimum (0), scale midpoint (2), & maximum (4) strong moral beliefs\n(Poisson regression, n=10k simulated observations)")

```

#### Results (Simulation 2) 

As is typically the case with real-world crime data, there are some nonlinearities in the data generating processes underlying our simulated data. Yet, I will start with a linear model. Why? Well, because so many people in our field seem to be infatuated with them...

:::: {.panel-tabset}

##### Linear Model Results 

```{r}
Ex2tab1
```

##### Prediction Plots


```{r}
#|message=FALSE 

plot_lm2
# plot_lm2 & 
#   theme(legend.position = 'bottom',
#         legend.direction = 'horizontal') 

```
##### Prediction Plots with Data


```{r}
#|message=FALSE 


#dev = "png" 
#dev.args = list(type = "cairo-png")

#use ggeffects::ggpredict() to save plot_model data for use in ggplot 
lm2df <- ggpredict(lm2, terms = c("ParentSupport", "StrgMoralBlfs [0,2,4]"))

#save subsets of simdat3 to plot observations where StrgMoralBlfs in (0,2,4)
simdat3sub <- simdat3 %>%
  filter(StrgMoralBlfs %in% c(0,2,4)) %>%
  mutate(
    StrgMoralBlfs = as_factor(StrgMoralBlfs))

# prediction plot with data subset - use ggblend to improve overlap viz
predplot1 <- ggplot(data=simdat3sub, aes(x=ParentSupport, y=Delinquency, 
                            color=StrgMoralBlfs, group=StrgMoralBlfs)) + 
  geom_hline(yintercept=7, linetype="dashed") +
  # geom_point(data=simdat3sub[simdat3sub$StrgMoralBlfs == 0], alpha=0.4)  +
  # geom_point(data=simdat3sub[simdat3sub$StrgMoralBlfs %in% c(2,4)], alpha=0.1) +
  geom_point() |> partition(vars(StrgMoralBlfs)) |> blend("lighten") |>
  blend("multiply", alpha = 0.4)+
  scale_colour_colorblind() +
  scale_fill_colorblind() +
  theme_minimal() + coord_cartesian(xlim=c(-2,2), ylim=c(-1,8)) + 
  geom_line(data=lm2df, aes(x=x, y=predicted,
                             linetype=group, color=group), inherit.aes=FALSE) +  
  geom_ribbon(data=lm2df, aes(x=x, y=predicted, 
                               ymin=conf.low, ymax=conf.high, fill=group), 
              alpha=0.3, inherit.aes=FALSE) +
  scale_linetype_manual(values = c("solid", "solid", "solid")) + 
  guides(linetype="none", fill="none") + 
  labs(x="Parental Support",
       y="Delinquency",
       title="Predicted conditional marginal effects of parent support on delinquency", 
       subtitle="Plotted at minimum (0), scale midpoint (2), & maximum (4) strong moral beliefs\n(Poisson regression, n=10k simulated observations)") 

predplot1

```
::::

While the linear model uncovered a sizeable interaction between parental support and moral beliefs, the plot reveals some areas of poor fit between the model predictions and the underlying data - including out of bounds predictions below "0" on predicted delinquency counts. You expected this, of course, because you read the [Part 1](https://reluctantcriminologists.com/blog-posts/[6]/modmadness-pt1.html) entry.

The second figure (third tab above) gives you a sense of the relatively poor fit of the model predictions by overlaying these prediction lines with a scatterplot of the relevant data (i.e., subset of Strong Moral Beliefs values equal to "0", "2", and "4").  

Let's compare these results with the nonlinear model. 

:::: {.panel-tabset}

##### Nonlinear Poisson model

```{r}
Ex2tab2
```

##### Prediction Plots

```{r}
#|message=FALSE 

plot_glm2

```

##### Prediction Plots with Data 

```{r}
#|message=FALSE 

#use ggeffects::ggpredict() to save plot_model data for use in ggplot 
glm2df <- ggpredict(glm2, terms = c("ParentSupport", "StrgMoralBlfs [0,2,4]"))

#prediction plot with data subset & ggblend
predplot2 <- ggplot(data=simdat3sub, aes(x=ParentSupport, y=Delinquency, 
                            color=StrgMoralBlfs, group=StrgMoralBlfs)) + 
  geom_hline(yintercept=7, linetype="dashed") +
  # geom_point(data=simdat3sub[simdat3sub$StrgMoralBlfs == 0], alpha=0.4)  +
  # geom_point(data=simdat3sub[simdat3sub$StrgMoralBlfs %in% c(2,4)], alpha=0.1) +
  geom_point() |> partition(vars(StrgMoralBlfs)) |> blend("lighten") |>
  blend("multiply", alpha = 0.4) +
  scale_colour_colorblind() +
  scale_fill_colorblind() +
  theme_minimal() + coord_cartesian(xlim=c(-2,2), ylim=c(-1,8)) + 
  geom_line(data=glm2df, aes(x=x, y=predicted,
                             linetype=group, color=group), inherit.aes=FALSE) +  
  geom_ribbon(data=glm2df, aes(x=x, y=predicted, 
                               ymin=conf.low, ymax=conf.high, fill=group), 
              alpha=0.4, inherit.aes=FALSE) +
  scale_linetype_manual(values = c("solid", "solid", "solid")) + 
  guides(linetype=FALSE, fill=FALSE) + 
  labs(x="Parental Support",
       y="Delinquency",
       title="Predicted conditional marginal effects of parent support on delinquency", 
       subtitle="Plotted at minimum (0), scale midpoint (2), & maximum (4) strong moral beliefs\n(Poisson regression, n=10k simulated observations)") 

predplot2
```

::::

For some in our field, documenting an additive interaction like this, whether generated with linear or nonlinear model specifications, would be deemed sufficient ground for declaring a contribution to existing literature and for publishing a manuscript in a peer-reviewed journal. (Remember the [hypothetical paper #2](https://reluctantcriminologists.com/blog-posts/%5B6%5D/modmadness-pt1#two-papers-walk-into-a-bar) from Part 1?)

Yet, note that this model does not account for the possibility of an indirect effect of parental support on delinquency through the moderating mechanism. So, to test for indirect effects, a researcher might use what is popularly known as the classic ["Baron and Kenny" (1986) causal steps approach](https://www.psych.mcgill.ca/perpg/fac/falk/tutorials/mediation/methods/#baron-kenny-1986) to detecting indirect effects. This "traditional" approach to testing mediation hypotheses usually involves estimating a series of regression models and then, depending upon the specific procedures adopted, estimating a "difference in coefficients" or "product of coefficients" representing causal path estimates (e.g., *ab* paths) paired with a test of significance. (See [MacKinnon and colleagues' 2002](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2819363/) paper, and especially their Table 1, for a summary of these traditional approaches).[^Kenny-note] 

[^Kenny-note]:
If you have not read it yourself, then you might be unaware that [Baron & Kenny's (1986) classic paper](https://psycnet.apa.org/doiLanding?doi=10.1037%2F0022-3514.51.6.1173) was actually about distinguishing between mediation and moderation concepts, with an emphasis on testing indirect and interaction hypotheses *in the same analysis*. You might also be surprised to learn that [Judd and Kenny's (1981) classic mediation paper](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=6c841fdea3122bdbd49570fc2ee0efcd3aad9913) outlined the core causal assumptions necessary for valid mediation analysis and explicitly discussed exposure-mediator interactions. So, in some important ways, this entry is trying help get our field caught up to leading mediation advice published over 40 years ago. Unfortunately, for decades, researchers following the "Baron and Kenny" causal steps approach to mediation largely have ignored Judd and Kenny's earlier discussions of causal assumptions pertaining to confounding or exposure-mediator interactions. [David Kenny](https://davidakenny.net/cm/mediate.htm#id.3dy6vkm) suggests this might be partly due (among other important reasons) to the fact that Baron and Kenny's highly cited paper "does not even mention confounding as an assumption"; rather, that paper did "discuss reliability and interaction" and it "suggests to the reader to consult Judd and Kenny (1981a) for more information about assumptions." Sadly, you might *not* be surprised to learn that, according to Kenny, the "initial submission did discuss confounding, but the editor suggested cutting that section and unfortunately the authors complied." Let's focus on improving our analytic approaches to mediation and moderation for now, then work on problematic reviewer, editor, and publisher practices at a later date.  

For this illustration, I will use `psych::mediate()` to estimate "traditional" direct and indirect effects of parental support on delinquency through moral beliefs. This package by default relies upon the "product of coefficients" estimation approach with bootstrapped standard errors, which is a very popular method in social sciences due perhaps to its status for years as the default method for testing indirect effects in [SEM programs like Mplus](https://www.statmodel.com/download/Causal.pdf) as well as the increasing popularity of [PROCESS modeling](https://processmacro.org/index.html) in other stats programs.

#### Linear mediation model, traditional *ab* approach

Traditional product of coefficients approach

```{r}
psych::mediate(Delinquency ~ ParentSupport + (StrgMoralBlfs), data = simdat3, n.iter = 10000) %>% print(short = TRUE)
```

Results from the "traditional" mediation analysis show an indirect effect estimate of -0.11. You can calculate the indirect effect estimate yourself from the path diagram by multiplying the so-called *a* and *b* path coefficients, or (0.22)x(-0.49) = -0.11, hence the "product of coefficients" terminology. 

The estimate is also statistically significant. Of course, with a simulated sample size of n=10,000, pretty much any non-zero estimate will be significant. You will rarely find us pointing to statistical significance as a useful information signal in our blog entries; we will cover that topic another time. To me, a better question here might be whether, given a causal indirect effect of this estimated magnitude, a change in exposure (e.g., from "0" to "1") would be predicted to generate differences of substantively meaningful magnitudes on the outcome scale indirectly through mechanistic changes in the mediator. 

You might notice that our interaction plots above depicting predicted marginal effects provide us substantially greater leverage for answering this type of question. Still, we are on a mission here, so I will avoid the temptation to embark on a yet another tangent, this time about effect sizes. Instead, I will simply note that this indirect effect output and path diagram might be viewed as sufficient for some scholars in our field to declare another contribution and submit yet another paper to the publication pile. (Remember [hypothetical paper #1](https://reluctantcriminologists.com/blog-posts/%5B6%5D/modmadness-pt1#two-papers-walk-into-a-bar) from Part 1?)   

![Scientists don't let scientists publish crap. Decompose total effects into mediation and moderation components, and do it all in a single paper. (DALL-E)](DALL-E-dung-heap-small.png)

Let's move to `CMAverse`, starting with a simple linear mediation model that reproduces key results from the "traditional" mediation approach.  

#### Linear mediation model, decomposition, no EMint 

Equivalent to traditional approach. 

For all models, estimating effect of moving from exposure A=0 to exposure Astar=1 

```{r}
#| output: FALSE

set.seed(1138)
est2 <- cmest(data = simdat3, model = "rb", outcome = "Delinquency", exposure = "ParentSupport",
                mediator = "StrgMoralBlfs", EMint = FALSE,
                mreg = list("linear"), yreg = "linear",
                astar = 0, a = 1, mval = list(0),
                estimation = "imputation", inference = "bootstrap", nboot = 20)

```

:::: {.panel-tabset}

##### Results: linear no EMint

```{r}
est2dat <- as.data.frame(est2$effect.pe) %>% rownames_to_column("CMA_est") 

est2dattab <- est2dat %>%
  add_column(
    trad_est = c("direct", "--", "--", "indirect", "--", "total", "prop_med"), 
    estimate = c(-.33, NA, NA, -.11, NA, -.44, .25)) %>%
  rename("linear_noEM" = "est2$effect.pe") %>% 
  relocate(trad_est, estimate) 

est2dattab %>%
  gt() %>% 
    tab_spanner(label = "CMAverse", columns = c("CMA_est", "linear_noEM")) %>%
    tab_spanner(label = "Traditional", columns = c("trad_est","estimate")) %>%
    cols_add('blank' = '', .after = 'estimate') %>%
    cols_label('blank' = md('&emsp;&emsp;&emsp;'))  

```

##### Default plot: linear no EMint
```{r}
ggcmest(est2) +
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 30, vjust = 0.8))

```


##### Full output: linear no EMint

```{r}
summary(est2)

```

::::

First, note that CDE == PNDE == TNDE and that  PNIE == TNIE ...

This is because we set `EMint=FALSE`, which means we did not specify an exposure-mediator interaction. Of course, this does not mean there is no exposure-mediator interaction in the data. On the contrary, we simulated the data to include one! Rather, it just means we ignored the possibility by essentially fixing the exposure-mediator interaction parameter to equal "0" in our model. 

This is also what happens by default in the traditional "product of coefficients" mediation approach. In fact, you can see that the estimates from both approaches converge in this case: 

The pm or prop_med refers to proportion mediated. ... 

Also, since we have a continuous exposure variable, ParentSupport, we could define different meaningful contrasts (e.g., -1SD vs. 1SD; max vs. min). Since ParentSupport is standardized exposure variable, by setting `a=0` and `astar=1`, I am specifying the exposure contrast as the predicted difference in Y at mean parental support values (ParentSupport=0) and +1SD parental support values (ParentSupport=1). The setting `mval = list(0)` indicates that I want controlled direct effect estimates to be calculated at m=0 (StrgMoralBlfs=0).    

#### Linear mediation model, decomposition, with EMint 

Now, let's estimate another linear model in CMAverse but instead allow for the possibility of an exposure-mediator interaction. 

```{r}
#| output: FALSE

set.seed(1138)
est3 <- cmest(data = simdat3, model = "rb", outcome = "Delinquency", exposure = "ParentSupport",
                mediator = "StrgMoralBlfs", EMint = TRUE,
                mreg = list("linear"), yreg = "linear",
                astar = 0, a = 1, mval = list(0),
                estimation = "imputation", inference = "bootstrap", nboot = 20)

```

:::: {.panel-tabset}

##### Results: linear with EMint

```{r}
est3dat <- as.data.frame(est3$effect.pe) %>% rownames_to_column("CMA_est") 

est3dattab <- left_join(est2dattab, est3dat, by="CMA_est") %>%
  rename("linear_EM" = "est3$effect.pe") 

est3dattab %>%
  gt() %>% 
    tab_spanner(label = "CMAverse", columns = c("CMA_est", "linear_noEM", "linear_EM")) %>%
    tab_spanner(label = "Traditional", columns = c("trad_est","estimate")) %>%
    cols_add('blank' = '', .after = 'estimate') %>%
    cols_label('blank' = md('&emsp;&emsp;&emsp;'))  

```

##### Default plot: linear with EMint
```{r}
ggcmest(est3) +
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 30, vjust = 0.8))

```

##### Custom plot: linear with EMint

```{r}

#save estimates and intervals data
est3dat <- as.data.frame(est3[9:12]) %>%
  rownames_to_column("CMA_est")


# drop proportion estimates
est3dat %>%
  filter(!CMA_est %in% c("pm", "pe", "pnie(prop)", "intref(prop)","intmed(prop)","cde(prop)", "int")) %>%
  mutate(CMA_est = factor(CMA_est, levels=c("intmed", "intref", "te", "tnie", "pnie", "tnde", "pnde", "cde"))) %>%
  # reorder the coefficients so that the largest is at the top of the plot
  # mutate(term = fct_reorder(CMA_est, effect.pe)) %>%
  ggplot(aes(effect.pe, CMA_est)) +
  geom_point() + 
  geom_errorbarh(aes(xmin = effect.ci.low, xmax = effect.ci.high), height = .1) +
  # add in a dotted line at zero
  geom_vline(xintercept = 0, lty = 2) +
  labs(
    x = "Estimated effects on linear difference scale",
    y = NULL,
    title = "Effect estimates from causal mediation decomposition"
  )

```

##### Full output: linear with EMint

```{r}
summary(est3)

```

::::

Look at differences... due to sizeable exposure-mediator interaction. WHen we ignored the exposure-mediator interaction (i.e, by using traditional *ab* method or by setting `EMint=FALSE` in CMAverse), the "proportion mediated" estimate was about 25%. After accounting for the sizeable exposure-mediator interaction, the proportion mediated estimate dropped to 4.5%. Recall, the TNIE represents the "total" indirect effects of X on Y through M, including the "pure" indirect effect component (PIE) and the part of the exposure-mediator interaction that is due to mediation (INTmed). Since the PIE and INTmed components are of similar size yet opposite signs, they largely cancel each other out (0.25 vs. -0.21). This results in a very small "total" natural indirect effect estimate (TNIE) and, likewise, a small proportion mediated estimated (PM = TNIE/TE). However, the proportion of the total effect that is due to the pure indirect effect (PIE) remains approximately 25%. 

One lesson should be apparent by now: If you are going to interpret any of these estimates, proportion or otherwise, it is important to know precisely what each estimate means and which causal contrasts you do (and do not) wish to make. Such determinations require an understanding of the various decomposition components described earlier and careful consideration of which components align best with your causal estimand of interest. 

There are various other important differences across these model results. I will highlight only a couple of them. 

First, the CDE is much larger in the linear model with the exposure-mediator interaction specified, and it is no longer equivalent to the PNDE or TNDE. This is because the effect of parental support varies across values of the mediator, and we estimated the CDE at m=0 (i.e., at the lowest value of strong moral beliefs) where the effect of parental support is strongest. You can see this in the regression effect plots we presented earlier. Had we estimated the CDE at a different value (e.g., m=4), the CDE would have been much smaller or even negligible in magnitude. 
The PNDE, however, is largely unchanged. Substantively, the PNDE indicates that doing astar=1 instead of a=0, or increasing from mean levels of parental support (a=0) to one-SD unit above the mean levels of parental support (astar=1), is predicted to reduce delinquency by -0.33 units on the linear difference scale in the absence of the exposure.  

See [Table 1](https://bs1125.github.io/CMAverse/articles/overview.html) for description of all the various effect estimates generated by CMAverse in linear decomposition models... I dropped all proportion measures (i.e., everything after mediated interaction or INTmed) from custom coefficient plots. However, I kept proportion mediated (pm) in comparison tables.  

Consistent with Section A in post. Proportion estimates tend to mess up scale when plotting... Also, I usually ignore proportion estimates... monotonicity assumptions... estimands of interest are not likely to be about proportions of total effect attributable to different components... 

Now, we know the linear model is not appropriate for these data; this is frequently the case when analyzing criminological data as well. Yet, my hope is that these poor-fitting models help ease the transition given the familiarity that many readers will likely have with linear models. As you will soon see, output and interpretations get a bit more complicated with nonlinear models due to changes in the outcome scale. 

Below, I will estimate models with and without EM interactions again, but this time I will specify a Poisson distribution for the outcome variable. This means that the predicted contrasts will be described on the event rate ratio scale instead of the linear difference scale. See [Table 2 here](https://bs1125.github.io/CMAverse/articles/overview.html) for descriptions of the various causal estimates on the ratio scale that are output by CMAverse, and the [`cmest` documentation](https://bs1125.github.io/CMAverse/reference/cmest.html) for for descriptions of which causal estimates are generated under different modeling specifications.    

#### Nonlinear decomposition model, no EM interaction 

```{r}
#| output: FALSE

set.seed(1138)
est4 <- cmest(data = simdat3, model = "rb", outcome = "Delinquency", exposure = "ParentSupport",
                mediator = "StrgMoralBlfs", EMint = FALSE,
                mreg = list("linear"), yreg = "poisson",
                astar = 0, a = 1, mval = list(0),
                estimation = "imputation", inference = "bootstrap", nboot = 20)
```


:::: {.panel-tabset}

##### Results: nonlinear no EMint

```{r}

est4dat <- as.data.frame(est4$effect.pe) %>% rownames_to_column("CMA_est2") %>%
  mutate(CMA_est = if_else(CMA_est2=="Rcde","cde",CMA_est2),
         CMA_est = if_else(CMA_est2=="Rpnde","pnde",CMA_est), 
         CMA_est = if_else(CMA_est2=="Rtnde","tnde",CMA_est),
         CMA_est = if_else(CMA_est2=="Rpnie","pnie",CMA_est),
         CMA_est = if_else(CMA_est2=="Rtnie","tnie",CMA_est),
         CMA_est = if_else(CMA_est2=="Rte","te",CMA_est)
  )

est4dattab <- left_join(est3dattab, est4dat, join_by("CMA_est")) %>%
  rename("nonlin_noEM" = "est4$effect.pe") 

est4dattab %>%
  gt() %>% 
    tab_spanner(label = "CMAverse (linear)", 
                columns = c("CMA_est", "linear_noEM", "linear_EM")) %>%
    tab_spanner(label = "CMAverse (nonlinear)", 
                columns = c("CMA_est2", "nonlin_noEM")) %>%
    tab_spanner(label = "Traditional (linear)", 
                columns = c("trad_est","estimate")) %>%
    cols_add('blank' = '', .after = 'estimate') %>%
    cols_label('blank' = md('&emsp;&emsp;&emsp;')) %>%
    cols_add('blank2' = '', .before = 'CMA_est2') %>%
    cols_label('blank2' = md('&emsp;&emsp;&emsp;')) 


```

##### Default plot: nonlinear no EMint
```{r}
ggcmest(est4) +
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 30, vjust = 0.8))

```


##### Full output: nonlinear no EMint

```{r}
summary(est4)

```

::::


#### Nonlinear decomposition model, with EM interaction 

```{r}
#| output: FALSE

set.seed(1138)
est5 <- cmest(data = simdat3, model = "rb", outcome = "Delinquency", exposure = "ParentSupport",
                mediator = "StrgMoralBlfs", EMint = TRUE,
                mreg = list("linear"), yreg = "poisson",
                astar = 0, a = 1, mval = list(0),
                estimation = "imputation", inference = "bootstrap", nboot = 20)
```



:::: {.panel-tabset}

##### Results: nonlinear with EMint

```{r}
est5dat <- as.data.frame(est5$effect.pe) %>% rownames_to_column("CMA_est2") %>%
  mutate(CMA_est = if_else(CMA_est2=="Rcde","cde",CMA_est2),
         CMA_est = if_else(CMA_est2=="Rpnde","pnde",CMA_est), 
         CMA_est = if_else(CMA_est2=="Rtnde","tnde",CMA_est),
         CMA_est = if_else(CMA_est2=="Rpnie","pnie",CMA_est),
         CMA_est = if_else(CMA_est2=="Rtnie","tnie",CMA_est),
         CMA_est = if_else(CMA_est2=="Rte","te",CMA_est)
  )

est5dattab <- full_join(est4dattab, est5dat, join_by("CMA_est2")) %>%
  rename("nonlin_EM" = "est5$effect.pe",
         "CMA_est" = "CMA_est.x") %>%
  select(!CMA_est.y) %>% 
  filter(!CMA_est2 %in% c("ERcde(prop)", "ERintref(prop)", "ERintmed(prop)", 
                          "ERpnie(prop)", "pm", "int", "pe")) %>% 
  mutate(
    trad_est = if_else(is.na(trad_est), "--", trad_est), 
    CMA_est = if_else(is.na(CMA_est), "--", CMA_est)
  )

est5dattab %>%
  gt() %>% 
    tab_spanner(label = "CMAverse (linear)", 
                columns = c("CMA_est", "linear_noEM", "linear_EM")) %>%
    tab_spanner(label = "CMAverse (nonlinear)", 
                columns = c("CMA_est2", "nonlin_noEM", "nonlin_EM")) %>%
    tab_spanner(label = "Traditional (linear)", 
                columns = c("trad_est","estimate")) %>%
    cols_add('blank' = '', .after = 'estimate') %>%
    cols_label('blank' = md('&emsp;&emsp;&emsp;')) %>%
    cols_add('blank2' = '', .before = 'CMA_est2') %>%
    cols_label('blank2' = md('&emsp;&emsp;&emsp;')) 

```

##### Default plot: nonlinear, with EMint
```{r}
ggcmest(est5) +
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 30, vjust = 0.8))

```

##### Risk ratio plot: nonlinear, with EMint

```{r}

#save estimates and intervals data
est5dat <- as.data.frame(est5[9:12]) %>%
  rownames_to_column("CMA_est")


# drop proportion estimates
est5dat %>%
  filter(!CMA_est %in% c("pm", "pe", "ERpnie(prop)", "ERintref(prop)",
                         "ERintmed(prop)","ERcde(prop)", "int", 
                         "ERpnie", "ERintmed", "ERintref", "ERcde")) %>%
  mutate(CMA_est = factor(CMA_est, levels=c("Rte", "Rtnie", "Rpnie", "Rtnde", "Rpnde", "Rcde"))) %>%
  # reorder the coefficients so that the largest is at the top of the plot
  # mutate(term = fct_reorder(CMA_est, effect.pe)) %>%
  ggplot(aes(effect.pe, CMA_est)) +
  geom_point() + 
  geom_errorbarh(aes(xmin = effect.ci.low, xmax = effect.ci.high), height = .1) +
  # add in a dotted line at zero
  geom_vline(xintercept = c(0,1), lty = 2) +
  labs(
    x = "Estimated effects on risk ratio scale",
    y = NULL,
    title = "Effect estimates from causal mediation decomposition (risk ratios)"
  )

```

##### Excess Risk plot: nonlinear, with EMint

```{r}

# drop proportion estimates
est5dat %>%
  filter(!CMA_est %in% c("pm", "pe", "ERpnie(prop)", "ERintref(prop)",
                         "ERintmed(prop)","ERcde(prop)", "int", 
                         "Rte", "Rtnie", "Rpnie", "Rtnde", "Rpnde", "Rcde")) %>%
  mutate(CMA_est = factor(CMA_est, levels=c("ERpnie", "ERintmed", "ERintref", "ERcde"))) %>%
  # reorder the coefficients so that the largest is at the top of the plot
  # mutate(term = fct_reorder(CMA_est, effect.pe)) %>%
  ggplot(aes(effect.pe, CMA_est)) +
  geom_point() + 
  geom_errorbarh(aes(xmin = effect.ci.low, xmax = effect.ci.high), height = .1) +
  # add in a dotted line at zero
  geom_vline(xintercept = 0, lty = 2) +
  labs(
    x = "Estimated effects on excess risks scale",
    y = NULL,
    title = "Effect estimates from causal mediation decomposition (excess risks)"
  )

```

##### Full output: nonlinear with EMint

```{r}
summary(est5)

```
::::


Rate ratio interpretations ...  accessible discussions of interpreting risk and rate ratio estimates, see [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8351073/) and [here](https://sph.unc.edu/wp-content/uploads/sites/112/2015/07/nciph_ERIC7.pdf).


"Excess rate ratio" (or "excess risk ratio" in logistic regressions) may help with interpreting relative effect estimates ... I prefer these to proportion estimates in nonlinear models for assessing relative contributions of mediation, interaction, & direct effects. For more information on relative excess ratio estimates, see [VanderWeele and Tchetgen Tchetgen (2014)](https://www.hsph.harvard.edu/tyler-vanderweele/wp-content/uploads/sites/603/2018/04/AttributingInt_Ep.pdf). [VanderWeele and Knol's 2014](https://www.hsph.harvard.edu/wp-content/uploads/sites/603/2018/04/InteractionTutorial_EM.pdf) tutorial on interaction is also helpful here; additionally, it contains a wealth of information that may be new to readers about estimating and interpreting interactions, including distinctions between concepts such as *statistical*, *mechanistic*, and *sufficient cause* interactions. 

