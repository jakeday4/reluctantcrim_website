{
  "hash": "da91b941987e75be4542a3b6b9bb59a4",
  "result": {
    "markdown": "---\ntitle: \"Thoughts on Kurz's blog re:power\"\nauthor: \"Jon Brauer\"\ndate: \"2023-04-15\"\nformat:\n  html:\n    code-fold: true\n    code-summary: \"Show code\"\nexecute: \n  warning: false\ndraft: true\n---\n\n\n## Inspiration\n\nI have relied heavily on Solomon Kurz's writings in his translational bookdown projects, so I was excited to continue the journey following his new blog series on causal inferences from RCT designs. Here are my thoughts about the first post, which you can find [here](https://solomonkurz.netlify.app/blog/2023-04-12-boost-your-power-with-baseline-covariates/).\n\n## Reproduction\n\nLet's reproduce his work.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# packages\nlibrary(tidyverse)\nlibrary(broom)\n\n# adjust the global plotting theme\ntheme_set(theme_gray(base_size = 12) +\n            theme(panel.grid = element_blank()))\n```\n:::\n\n\n### Data \n\nRead in data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhoran1971 <- tibble(\n  sl = c(letters[1:22], letters[1:20], letters[1:19], letters[1:19]),\n  sn = 1:80,\n  treatment = factor(rep(1:4, times = c(22, 20, 19, 19))),\n  pre = c(149.5, 131.25, 146.5, 133.25, 131, 141, 145.75, 146.75, 172.5, 156.5, 153, 136.25, 148.25, 152.25, 167.5, 169.5, 151.5, 165, 144.25, 167, 195, 179.5,\n          127, 134, 163.5, 155, 157.25, 121, 161.25, 147.25, 134.5, 121, 133.5, 128.5, 151, 141.25, 164.25, 138.25, 176, 178, 183, 164,\n          149, 134.25, 168, 116.25, 122.75, 122.5, 130, 139, 121.75, 126, 159, 134.75, 140.5, 174.25, 140.25, 133, 171.25, 198.25, 141.25,\n          137, 157, 142.25, 123, 163.75, 168.25, 146.25, 174.75, 174.5, 179.75, 162.5, 145, 127, 146.75, 137.5, 179.75, 168.25, 187.5, 144.5),\n  post = c(149, 130, 147.75, 139, 134, 145.25, 142.25, 147, 158.25, 155.25, 151.5, 134.5, 145.75, 153.5, 163.75, 170, 153, 178, 144.75, 164.25, 194, 183.25,\n           121.75, 132.25, 166, 146.5, 154.5, 114, 148.25, 148.25, 133.5, 126.5, 137, 126.5, 148.5, 145.5, 151.5, 128.5, 176.5, 170.5, 181.5, 160.5,\n           145.5, 122.75, 164, 118.5, 122, 125.5, 129.5, 137, 119.5, 123.5, 150.5, 125.75, 135, 164.25, 144.5, 135.5, 169.5, 194.5, 142.5,\n           129, 146.5, 142.25, 114.5, 148.25, 161.25, 142.5, 174.5, 163, 160.5, 151.25, 144, 135.5, 136.5, 145.5, 185, 174.75, 179, 141.5)) %>% \n  mutate(treatment = factor(treatment, labels = c(\"delayed\", \"placebo\", \"scheduled\", \"experimental\")))\n\n# what is this?\nhead(horan1971)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 5\n  sl       sn treatment   pre  post\n  <chr> <int> <fct>     <dbl> <dbl>\n1 a         1 delayed    150.  149 \n2 b         2 delayed    131.  130 \n3 c         3 delayed    146.  148.\n4 d         4 delayed    133.  139 \n5 e         5 delayed    131   134 \n6 f         6 delayed    141   145.\n```\n:::\n:::\n\n\nSubset to two conditions. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nhoran1971 <- horan1971 %>% \n  filter(treatment %in% c(\"delayed\", \"experimental\"))\n\nhoran1971 %>% \n  count(treatment)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  treatment        n\n  <fct>        <int>\n1 delayed         22\n2 experimental    19\n```\n:::\n:::\n\n\nVisualize Y_post (post-treatment weight) across treatment (experimental) & control (delayed) groups.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhoran1971 %>%  \n  ggplot(aes(x = post)) +\n  geom_histogram(binwidth = 5) +\n  xlab(\"post-treatment weight (lbs)\") +\n  facet_wrap(~ treatment, labeller = label_both)\n```\n\n::: {.cell-output-display}\n![](Kurz_power_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nMean difference in Y_post across groups. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nhoran1971 %>% \n  group_by(treatment) %>% \n  summarise(mean = mean(post),\n            sd = sd(post),\n            n = n(),\n            percent_missing = mean(is.na(post)) * 100)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 5\n  treatment     mean    sd     n percent_missing\n  <fct>        <dbl> <dbl> <int>           <dbl>\n1 delayed       154.  16.3    22               0\n2 experimental  151.  18.3    19               0\n```\n:::\n:::\n\n\nData wrangling. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nhoran1971 <- horan1971 %>% \n  # make a mean-centered version of pre\n  mutate(prec = pre - mean(pre))\n\n\nhoran1971 <- horan1971 %>% \n  mutate(delayed      = ifelse(treatment == \"delayed\", 1, 0),\n         experimental = ifelse(treatment == \"experimental\", 1, 0))\n\nhoran1971 %>% \n  distinct(treatment, delayed, experimental)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  treatment    delayed experimental\n  <fct>          <dbl>        <dbl>\n1 delayed            1            0\n2 experimental       0            1\n```\n:::\n:::\n\n\n### ANOVA (OLS-based) model. \n\nFit & summarize ANOVA (unconditional mean difference)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fit the ANOVA-type model with OLS\nols1 <- lm(\n  data = horan1971,\n  post ~ 1 + experimental\n)\n\n# summarize\nsummary(ols1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = post ~ 1 + experimental, data = horan1971)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-36.829  -9.079  -4.818   9.932  40.182 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   153.818      3.674  41.864   <2e-16 ***\nexperimental   -2.489      5.397  -0.461    0.647    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 17.23 on 39 degrees of freedom\nMultiple R-squared:  0.005424,\tAdjusted R-squared:  -0.02008 \nF-statistic: 0.2127 on 1 and 39 DF,  p-value: 0.6472\n```\n:::\n:::\n\n\nIsolate key ANOVA estimate & add 95%CI.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(ols1, conf.int = TRUE) %>% \n  slice(2) %>% \n  mutate_if(is.double, round, digits = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 7\n  term         estimate std.error statistic p.value conf.low conf.high\n  <chr>           <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n1 experimental    -2.49       5.4     -0.46    0.65    -13.4      8.43\n```\n:::\n:::\n\n\n### Introduce baseline covariate, or Y_pre\n\nBaseline covariate, Y_pre (pre-treatment weight), is highly correlated with Y_post outcome\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhoran1971 %>% \n  group_by(treatment) %>% \n  summarise(r = cor(pre, post))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  treatment        r\n  <fct>        <dbl>\n1 delayed      0.955\n2 experimental 0.909\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# for the annotation\nr_text <- horan1971 %>% \n  group_by(treatment) %>% \n  summarise(r = cor(pre, post)) %>% \n  mutate(pre  = 130,\n         post = 190,\n         text = str_c(\"italic(r)==\", round(r, digits = 3)))\n\n# plot!\nhoran1971 %>%  \n  ggplot(aes(x = pre, y = post)) +\n  geom_abline(color = \"white\") +\n  geom_point() +\n  geom_text(data = r_text,\n            aes(label = text),\n            color = \"red4\", parse = TRUE) +\n  coord_equal(xlim = c(110, 200),\n              ylim = c(110, 200)) +\n  facet_wrap(~ treatment, labeller = label_both)\n```\n\n::: {.cell-output-display}\n![](Kurz_power_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nSummarize mean of Y_pre \n\n\n::: {.cell}\n\n```{.r .cell-code}\nhoran1971 %>% \n  summarise(pre_mean = mean(pre),\n            pre_sd = sd(pre),\n            pre_min = min(pre))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  pre_mean pre_sd pre_min\n     <dbl>  <dbl>   <dbl>\n1     155.   17.5     123\n```\n:::\n:::\n\n\n### ANCOVA (OLS-based) models. \n\nFit & summarize ANCOVA (conditional mean difference) models by stratifying on Y_pre (centered and non-centered versions).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fit with the centered `prec` covariate\nols2 <- lm(\n  data = horan1971,\n  post ~ 1 + experimental + prec\n)\n\n# fit with the non-centered `pre` covariate\nols3 <- lm(\n  data = horan1971,\n  post ~ 1 + experimental + pre\n)\n\n# summarize the centered model\nsummary(ols2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = post ~ 1 + experimental + prec, data = horan1971)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.5810  -3.3996  -0.4384   2.7288  13.9824 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  154.78354    1.36142 113.693   <2e-16 ***\nexperimental  -4.57237    2.00226  -2.284   0.0281 *  \nprec           0.90845    0.05784  15.705   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.379 on 38 degrees of freedom\nMultiple R-squared:  0.8672,\tAdjusted R-squared:  0.8602 \nF-statistic: 124.1 on 2 and 38 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\n# summarize the non-centered model\nsummary(ols3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = post ~ 1 + experimental + pre, data = horan1971)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.5810  -3.3996  -0.4384   2.7288  13.9824 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  14.12281    8.99835   1.569   0.1248    \nexperimental -4.57237    2.00226  -2.284   0.0281 *  \npre           0.90845    0.05784  15.705   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.379 on 38 degrees of freedom\nMultiple R-squared:  0.8672,\tAdjusted R-squared:  0.8602 \nF-statistic: 124.1 on 2 and 38 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nIsolate key ANCOVA estimate & add 95%CI. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(ols2, conf.int = TRUE) %>% \n  slice(2) %>% \n  mutate_if(is.double, round, digits = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 7\n  term         estimate std.error statistic p.value conf.low conf.high\n  <chr>           <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n1 experimental    -4.57         2     -2.28    0.03    -8.63     -0.52\n```\n:::\n:::\n\n\nVisualize ANOVA & ANCOVA estimates + intervals. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# wrangle\nbind_rows(tidy(ols1, conf.int = TRUE), tidy(ols2, conf.int = TRUE)) %>% \n  filter(term == \"experimental\") %>% \n  mutate(model = factor(c(\"ANOVA\", \"ANCOVA\"), levels = c(\"ANOVA\", \"ANCOVA\"))) %>% \n\n  # plot!\n  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = model)) +\n  geom_vline(xintercept = 0, color = \"white\") +\n  geom_pointrange() +\n  scale_x_continuous(expression(beta[1]~(mu[experimental]-mu[waitlist])), expand = expansion(add = 5)) +\n  ylab(NULL)\n```\n\n::: {.cell-output-display}\n![](Kurz_power_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n## Statistical Power for Free?  \n\nAt this point, Kurz states: \n\n> \"Both the ANOVA and ANCOVA models are known to produce unbiased estimates of the population parameters, but the ANCOVA model tends to produce estimates that are more precise (e.g., O’Connell et al., 2017). Thus if you have a high-quality baseline covariate laying around, it’s a good idea to throw it into the model.\"\n\nHe further notes: \n\n> \"...this pattern will arise again and again when you use OLS models. Adding baseline covariates will generally shrink your standard errors. It’s like getting statistical power for free. Perhaps a more helpful line of inquiry is: How can I use this information to better design my studies?\"\n\nStatistical power for free! Is this really an exception to the [TNSTAAFL](https://en.wikipedia.org/wiki/There_ain%27t_no_such_thing_as_a_free_lunch) (\"There's no such thing as a free lunch) adage? Before Milton Friedman ressurects [in opposition](https://www.youtube.com/watch?v=YmqoCHR14n8), let's take a closer look at what might be happening here. \n\nMight this simply be due to fundamental differences between the ANOVA and ANCOVA model estimates? The ANOVA model estimates the unconditional mean difference in post-treatment weight across groups, whereas the ANCOVA model estimates the mean difference in post-treatment weight across groups *at the average pre-treatment weight*. The ANOVA model's standard error (SE) and 95%CIs communicate uncertainty in that estimate due to observed variation in the data, irrespective of the sources of that variation. The ANCOVA model's SE and 95%CIs are estimated from a model that makes more restrictive assumptions about the sources of variation in the data - for instance, it imposes an assumption that the estimated treatment effect is constant across strata of the baseline covariate (i.e., pre-treatment weight). \n\nNow, imagine there are substantial baseline differences in the distributions of pre-treatment weight across groups, or imagine that the treatment effect actually varies (i.e., there is effect heterogeneity) across levels of pre-treatment weight (Y_pre). Why might stratification on baseline Y_pre values result in smaller CIs and (the illusion of) increased power of the statistical test in the ANCOVA model? Well, for one, if the experimental treatment indeed had different effects for people with different baseline covariate (Y_pre) values, then the current OLS-based ANCOVA model above ignores this existing treatment heterogeneity. In contrast, the ANOVA model still estimates the mean difference between groups in post-treatment weights (Y_post). If there were no baseline distributional differences and the treatment has nearly the same effect on everyone in the treatment group, then I would expect the ANOVA model to estimate that effect relatively precisely (i.e., with narrower CIs). However, if the treatment effect varies, then the ANOVA estimate will necessarily capture that existing variation in its standard error and resulting confidence limits (i.e., with wide CIs). Put simply, the ANOVA model does not have the luxury of adjusting out or restrictively assuming away variation due to sources like effect heterogeneity - it's SE and CIs must capture the existing variation when estimating the average treatment effect across the entire sample. \n\nLet's see if any of this might be happening in the current example. Below, I will rerun the OLS-based ANCOVA model, but this time I also include an interaction term. My hunch is that the treatment estimate might vary across levels of baseline pre-treatment weight and, if so, then it might do so in a way that as one \"slides\" the estimates around Y_pre values, the resulting CIs will be captured by the overall ANOVA bounds. Maybe I'm wrong, which might lead me to learn something about power along the way.\n\n### Alternative ANCOVA model\n\nTo simplify the process, I will create new Y_pre variables centered at the minimum and maximum pre-treatment weight values, then re-estimate the `ols2` model at the mean(Y_pre), min(Y_pre), and max(Y_pre) values, and finally plot the estimated mean differences alongside the ANOVA estimate. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nhoran1971 <- horan1971 %>% \n  # make min-centered & max-centered version of pre\n  mutate(premin = pre - min(pre), \n         premax = pre - max(pre))\n\n\n# fit with the Y_pre variables at different locations \nols4min <- lm(\n  data = horan1971,\n  post ~ 1 + experimental + premin + experimental*premin\n)\n\nols4c <- lm(\n  data = horan1971,\n  post ~ 1 + experimental + prec + experimental*prec\n)\n\nols4max <- lm(\n  data = horan1971,\n  post ~ 1 + experimental + premax + experimental*premax\n)\n\n\n# summarize the centered model\nsummary(ols4min)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = post ~ 1 + experimental + premin + experimental * \n    premin, data = horan1971)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.286  -3.055  -0.174   2.358  13.560 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         124.70416    2.96158  42.107  < 2e-16 ***\nexperimental         -2.32029    4.23537  -0.548    0.587    \npremin                0.94610    0.08530  11.092 2.53e-13 ***\nexperimental:premin  -0.07072    0.11691  -0.605    0.549    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.433 on 37 degrees of freedom\nMultiple R-squared:  0.8685,\tAdjusted R-squared:  0.8579 \nF-statistic: 81.47 on 3 and 37 DF,  p-value: 2.314e-16\n```\n:::\n\n```{.r .cell-code}\nsummary(ols4c)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = post ~ 1 + experimental + prec + experimental * \n    prec, data = horan1971)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.286  -3.055  -0.174   2.358  13.560 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       154.82354    1.37452 112.639  < 2e-16 ***\nexperimental       -4.57168    2.01917  -2.264   0.0295 *  \nprec                0.94610    0.08530  11.092 2.53e-13 ***\nexperimental:prec  -0.07072    0.11691  -0.605   0.5489    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.433 on 37 degrees of freedom\nMultiple R-squared:  0.8685,\tAdjusted R-squared:  0.8579 \nF-statistic: 81.47 on 3 and 37 DF,  p-value: 2.314e-16\n```\n:::\n\n```{.r .cell-code}\nsummary(ols4max)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = post ~ 1 + experimental + premax + experimental * \n    premax, data = horan1971)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.286  -3.055  -0.174   2.358  13.560 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         192.82324    3.77461  51.084  < 2e-16 ***\nexperimental         -7.41212    5.11039  -1.450    0.155    \npremax                0.94610    0.08530  11.092 2.53e-13 ***\nexperimental:premax  -0.07072    0.11691  -0.605    0.549    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.433 on 37 degrees of freedom\nMultiple R-squared:  0.8685,\tAdjusted R-squared:  0.8579 \nF-statistic: 81.47 on 3 and 37 DF,  p-value: 2.314e-16\n```\n:::\n:::\n\n\nNow let's plot these estimates and intervals along with the ANOVA estimate. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#unconditional (ANOVA) & conditional (ANCOVA) mean difference estimates: \n\n# wrangle\nbind_rows(tidy(ols1, conf.int = TRUE), tidy(ols4min, conf.int = TRUE), \n          tidy(ols4c, conf.int = TRUE), tidy(ols4max, conf.int = TRUE)) %>%\n  filter(term == \"experimental\") %>%\n  mutate(model = factor(c(\"ANOVA\", \"ANCOVA_Ypremin\", \"ANCOVA_Yprec\", \"ANCOVA_Ypremax\"), \n                        levels = c(\"ANOVA\", \"ANCOVA_Ypremin\", \"ANCOVA_Yprec\", \"ANCOVA_Ypremax\"))) %>%\n\n  # plot!\n  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = model)) +\n  geom_vline(xintercept = 0, color = \"white\") +\n  geom_pointrange() +\n  scale_x_continuous(expression(beta[1]~(mu[experimental]-mu[waitlist])), expand = expansion(add = 5)) +\n  ylab(NULL)\n```\n\n::: {.cell-output-display}\n![](Kurz_power_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nTo recap, what have I done here? First, I added an interaction term to the ANCOVA model to allow for the possibility of treatment heterogeneity across strata of the baseline covariate. Second, I reestimated the model using pre-treatment variables centered at different locations - that is, at the pre-treatment minimum, mean, and maximum weights - to facilitate generation of the (potentially variable) estimate of the treatment effect at these different baseline covariate values. If there were no treatment effect differences across pre-treatment weight strata, then all three new ANCOVA models would have generated comparable mean difference estimates. However, the model implies there **are** treatment effect differences across different pre-treatment weights, which is not too surprising. After all, those in heavier pre-treatment weight groups (e.g., \"Y_premax\") at baseline have more to lose in an effective experimental treatment condition than do those in lighter pre-treatment weight groups (e.g., \"Y_premin\"). \n\nLikewise, once I take these potential differences into account, the 95% CIs around our ANCOVA model estimates at these three strata together are much wider and more closely overlap the overall ANOVA estimate's bounds. Note, too, that the overlap is not perfect. This is unsurprising given our model specifications. After all, our ANCOVA stratifies on baseline weight and assumes that a particular functional (multiplicative linear) form adequately summarizes the interactive relationship between pre-treatment weight and the experimental treatment effect, while the ANOVA model summarizes post-treatment differences in weight that are due to all possible sources, including potential experimental effects and existing baseline pre-treatment differences. Likewise, in estimating the treatment effect across the strata of the pre-treatment variable (i.e., across different pre-treatment weights), estimation of standard errors and resulting CIs are affected by available data within each strata which, unsurprisingly, are not constant across Y_pre strata.\n\nBut is it that simple? Does this imply that an ANOVA and an ANCOVA estimate will have more similar confidence limits if there is no effect heterogeneity? Let's explore this question with a simulation - maybe this will help us build a better intuition for what is happening in the ANOVA and ANCOVA models.\n\n## Simulated Example without Effect Heterogeneity\n\nTo generate the simulated data, I will use the observed statistical estimates from the example above as the population parameters in the simulation. For instance, I will first use `rnorm()` to simulate two groups of pre-treatment weights from a normally distributed population of pre-treatment weights summarized by the same group means and standard deviations observed in the \"pre\" weights above. Then, I use the [`faux`](https://debruine.github.io/faux/) package to simulate post-treatment weights from a population with the same overall mean and standard deviation obsvered for the \"post\" weights, and correlated with our simulated pre-treatment weights at a population average of *r*=0.95, plus a population-expected treatment effect of -4.57 for the experimental treatment group. \n\nI will start with very large samples - two groups of n=10,000 each - to ensure our samples reflect the population parameters. Then, I will repeat the simulation with two groups of n=1,000, and finally repeat a third time with two groups of n=22 participants to better match the real-world example above.\n\n### Simulation example #1 (n=10,000/group)\n\n#### Simulate data \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(\"faux\")\n#faux package removed from CRAN\n#archive: https://cran.r-project.org/src/contrib/Archive/faux/\n\n# install.packages(\"groundhog\")\n\nlibrary(\"groundhog\")\ngroundhog.library(faux, \"2023-03-01\", tolerate.R.version='4.2.2')\n\n\n#Illustrate sample mean differences for two independent population groups \nnval <- 20000 #treat\nngrp <- 10000\nset.seed(1138) \n\nmeanpret <- mean(horan1971$pre[horan1971$treatment==\"experimental\"])\nsdpret <- sd(horan1971$pre[horan1971$treatment==\"experimental\"])\nmeanprec <- mean(horan1971$pre[horan1971$treatment==\"delayed\"])\nsdprec <- sd(horan1971$pre[horan1971$treatment==\"delayed\"])\n\n#sim two pre-treatment columns (groups) of rnorm values with \"nval\" size \n\npretrt <- rnorm(n=nval, mean=meanpret, sd=sdpret) %>% as_tibble_col(column_name = \"pre\")\nprecon <- rnorm(n=nval, mean=meanprec, sd=sdprec) %>% as_tibble_col(column_name = \"pre\")\npre <- rbind(pretrt, precon)\n\nsimdata <- tibble(\n  sn = 1:nval, \n  treatment = factor(rep(1:2, times = c(ngrp, ngrp)))) %>% \n  mutate(treatment = factor(treatment, labels = c(\"experimental\", \"control\")),\n         experimental = ifelse(treatment == \"experimental\", 1, 0)\n         )  \n\nsimdata <- cbind(simdata, pre)\n\nsimdata <- simdata %>% \n  mutate(\n    post = round(-4.57*experimental + rnorm_pre(pre, mu = mean(horan1971$post), sd = sd(horan1971$post), r = 0.95), digits=2), \n    prec = pre - mean(pre), \n    premin = pre - min(pre), \n    premax = pre - max(pre)\n  )\n\nhead(simdata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  sn    treatment experimental      pre   post       prec   premin    premax\n1  1 experimental            1 144.6470 140.90 -10.258896 56.47521 -81.79768\n2  2 experimental            1 144.5391 140.78 -10.366772 56.36733 -81.90555\n3  3 experimental            1 164.3527 158.80   9.446877 76.18098 -62.09191\n4  4 experimental            1 157.7138 139.61   2.807936 69.54204 -68.73085\n5  5 experimental            1 144.9790 142.61  -9.926859 56.80725 -81.46564\n6  6 experimental            1 144.4601 145.79 -10.445780 56.28832 -81.98456\n```\n:::\n:::\n\n\nSummarize & plot Y_pre distributions\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimdata %>% \n  group_by(treatment) %>% \n  summarise(mean = mean(pre),\n            sd = sd(pre),\n            n = n())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  treatment     mean    sd     n\n  <fct>        <dbl> <dbl> <int>\n1 experimental  155.  17.7 20000\n2 control       155.  17.7 20000\n```\n:::\n\n```{.r .cell-code}\nsimdata %>%  \n  ggplot(aes(x = pre)) +\n  geom_histogram(binwidth = 5) +\n  xlab(\"pre-treatment weight (lbs)\") +\n  facet_wrap(~ treatment, labeller = label_both)\n```\n\n::: {.cell-output-display}\n![](Kurz_power_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nSummarize & plot Y_post distributions\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimdata %>% \n  group_by(treatment) %>% \n  summarise(mean = mean(post),\n            sd = sd(post),\n            n = n())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  treatment     mean    sd     n\n  <fct>        <dbl> <dbl> <int>\n1 experimental  148.  17.0 20000\n2 control       153.  17.1 20000\n```\n:::\n\n```{.r .cell-code}\nsimdata %>%  \n  ggplot(aes(x = post)) +\n  geom_histogram(binwidth = 5) +\n  xlab(\"post-treatment weight (lbs)\") +\n  facet_wrap(~ treatment, labeller = label_both)\n```\n\n::: {.cell-output-display}\n![](Kurz_power_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nPre-post correlation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimdata %>% \n  group_by(treatment) %>% \n  summarise(r = cor(pre, post))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  treatment        r\n  <fct>        <dbl>\n1 experimental 0.950\n2 control      0.950\n```\n:::\n:::\n\n\n#### Fit models\n\nLet's check the ANOVA estimate first.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ANOVA (OLS)\nsimols1 <- lm(\n  data = simdata,\n  post ~ 1 + experimental\n)\n\nsummary(simols1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = post ~ 1 + experimental, data = simdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-71.756 -11.405   0.044  11.434  74.024 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  152.6254     0.1206 1265.83   <2e-16 ***\nexperimental  -4.4892     0.1705  -26.33   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 17.05 on 39998 degrees of freedom\nMultiple R-squared:  0.01703,\tAdjusted R-squared:  0.01701 \nF-statistic: 693.1 on 1 and 39998 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\ntidy(simols1, conf.int = TRUE) %>% \n  slice(2) %>% \n  mutate_if(is.double, round, digits = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 7\n  term         estimate std.error statistic p.value conf.low conf.high\n  <chr>           <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n1 experimental    -4.49      0.17     -26.3       0    -4.82     -4.15\n```\n:::\n:::\n\n\nOur ANOVA estimate (-4.49) is close to the population specified treatment effect (-4.57). Given how large our sample is, the confidence intervals [-4.82, -4.15] might seem somewhat imprecise. \n\nNow, let's fit the ANCOVA models and allow for the possibility of treatment effect heterogeneity across baseline pre-treatment weights. We did not specify effect heterogeneity in the population, so we do not expect our large samples to show evidence of much, if any, interaction.   \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ANCOVA (OLS) with interaction to capture any effect heterogeneity  \nsimols4min <- lm(\n  data = simdata,\n  post ~ 1 + experimental + premin + experimental*premin\n)\n\nsimols4c <- lm(\n  data = simdata,\n  post ~ 1 + experimental + prec + experimental*prec\n)\n\nsimols4max <- lm(\n  data = simdata,\n  post ~ 1 + experimental + premax + experimental*premax\n)\n\n\n# summarize the centered model\nsummary(simols4min)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = post ~ 1 + experimental + premin + experimental * \n    premin, data = simdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-21.5773  -3.6340   0.0106   3.5920  21.3581 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         91.580137   0.146640 624.521   <2e-16 ***\nexperimental        -4.442811   0.207694 -21.391   <2e-16 ***\npremin               0.914961   0.002124 430.753   <2e-16 ***\nexperimental:premin -0.001109   0.003008  -0.369    0.712    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.328 on 39996 degrees of freedom\nMultiple R-squared:  0.904,\tAdjusted R-squared:  0.904 \nF-statistic: 1.256e+05 on 3 and 39996 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nsummary(simols4c)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = post ~ 1 + experimental + prec + experimental * \n    prec, data = simdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-21.5773  -3.6340   0.0106   3.5920  21.3581 \n\nCoefficients:\n                    Estimate Std. Error  t value Pr(>|t|)    \n(Intercept)       152.639222   0.037677 4051.216   <2e-16 ***\nexperimental       -4.516850   0.053284  -84.770   <2e-16 ***\nprec                0.914961   0.002124  430.753   <2e-16 ***\nexperimental:prec  -0.001109   0.003008   -0.369    0.712    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.328 on 39996 degrees of freedom\nMultiple R-squared:  0.904,\tAdjusted R-squared:  0.904 \nF-statistic: 1.256e+05 on 3 and 39996 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nsummary(simols4max)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = post ~ 1 + experimental + premax + experimental * \n    premax, data = simdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-21.5773  -3.6340   0.0106   3.5920  21.3581 \n\nCoefficients:\n                      Estimate Std. Error  t value Pr(>|t|)    \n(Intercept)         218.094400   0.156588 1392.793   <2e-16 ***\nexperimental         -4.596221   0.221694  -20.732   <2e-16 ***\npremax                0.914961   0.002124  430.753   <2e-16 ***\nexperimental:premax  -0.001109   0.003008   -0.369    0.712    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.328 on 39996 degrees of freedom\nMultiple R-squared:  0.904,\tAdjusted R-squared:  0.904 \nF-statistic: 1.256e+05 on 3 and 39996 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\n#Plot mean difference estimates: \n\n# wrangle\nbind_rows(tidy(simols1, conf.int = TRUE), tidy(simols4min, conf.int = TRUE), \n          tidy(simols4c, conf.int = TRUE), tidy(simols4max, conf.int = TRUE)) %>%\n  filter(term == \"experimental\") %>%\n  mutate(model = factor(c(\"ANOVA\", \"ANCOVA_Ypremin\", \"ANCOVA_Yprec\", \"ANCOVA_Ypremax\"), \n                        levels = c(\"ANOVA\", \"ANCOVA_Ypremin\", \"ANCOVA_Yprec\", \"ANCOVA_Ypremax\"))) %>%\n\n  # plot!\n  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = model)) +\n  geom_vline(xintercept = 0, color = \"white\") +\n  geom_pointrange() +\n  scale_x_continuous(expression(beta[1]~(mu[experimental]-mu[waitlist])), expand = expansion(add = 5)) +\n  ylab(NULL) + \n  ggtitle(\"Simulation #1, n=10,000 per group\") \n```\n\n::: {.cell-output-display}\n![](Kurz_power_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\nThe first thing to note is that all four point estimates - the unconditional ANOVA estimate and the three conditional ANCOVA estimates at the maximum, mean, and minimum values of the baseline covariate - are very similar. This is unsurprising since I did not specify any population treatment effect heterogeneity when generating the simulated data, which means we forced the data to conform to an expectation that the treatment has the same effect on weight irrespective of one's pre-treatment baseline weight. \n\nThe next thing to note is that the ANCOVA estimate of the conditional mean difference in post-treatment weights between experimental and baseline groups is far more precise - that is, it has much smaller confidence interval - at the mean value of the Y_pre variable (Yprec) compared to the ANOVA estimate. This is the same pattern referenced in Kurz's post sometimes interpreted as free precision or statistical power. Moreover, a glance at the model summary output shows its point estimate (-4.52) to be a little closer to the population-specified treatment effect (-4.57) than was the ANOVA estimate (-4.49). \n\nNow, note that the other two ANCOVA estimates have *wider* confidence intervals compared to the unconditional ANOVA estimate. Essentially, these models communicate greater uncertainty in estimating treatment effects at the tails of the baseline covariate's distribution, where data are more sparse. This should help remind us that ANCOVA model *estimates and uncertainty are conditional* on the location of covariates; the ANOVA estimate, in contrast, is *unconditional*, meaning it does not depend on any specific value of a covariate in the model. \n\nConceptually, it might be helpful to think of the ANOVA estimate as summarizing our best guess of the group difference in the outcome (post-treatment weights) that might be due to any and all sources combined - and as summarizing our uncertainty in that best guess given the total amount of outcome variation (e.g., spread of post-treatment weights) observed across both groups. In our example, this means the ANOVA estimate of post-treatment differences is affected by both of the things that we specified as causally relevant in our simulation: (1) it is affected by the average group differences that are due to experimental treatment effects (-4.57*experimental) and any random sampling variation around that  average treatment differences, and (2) by any average baseline differences in pre-treatment weight that existed due to research design and/or random sampling variation. \n\nHence, if what we really care about is an estimate of the causal effect of an experimental treatment on an outcome, then the ANOVA's unconditional estimate is not a very good fit for that aim. The ANCOVA model, though, helps us adjust out or cleanse our unconditional estimate of average differences and sources of variation/uncertainty that are caused by things that are not our experimental treatment. For more information about the relationship between ANOVA and the average treatment effect, [check out this paper](https://www.tandfonline.com/doi/abs/10.1080/00273171.2022.2068122).)\n\nNow, let's rerun the simulation with smaller groups of n=1,000 each.\n\n### Simulation example #2 (n=1,000/group)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Illustrate sample mean differences for two independent population groups \nnval <- 2000 #treat\nngrp <- 1000\nset.seed(1138) \n\n#sim two pre-treatment columns (groups) of rnorm values with \"nval\" size \n\npretrt <- rnorm(n=nval, mean=meanpret, sd=sdpret) %>% as_tibble_col(column_name = \"pre\")\nprecon <- rnorm(n=nval, mean=meanprec, sd=sdprec) %>% as_tibble_col(column_name = \"pre\")\npre <- rbind(pretrt, precon)\n\nsimdata <- tibble(\n  sn = 1:nval, \n  treatment = factor(rep(1:2, times = c(ngrp, ngrp)))) %>% \n  mutate(treatment = factor(treatment, labels = c(\"experimental\", \"control\")),\n         experimental = ifelse(treatment == \"experimental\", 1, 0)\n         )  \n\nsimdata <- cbind(simdata, pre)\n\nsimdata <- simdata %>% \n  mutate(\n    post = round(-4.57*experimental + rnorm_pre(pre, mu = mean(horan1971$post), sd = sd(horan1971$post), r = 0.95), digits=2), \n    prec = pre - mean(pre), \n    premin = pre - min(pre), \n    premax = pre - max(pre)\n  )\n\n# ANOVA (OLS)\nsimols1 <- lm(\n  data = simdata,\n  post ~ 1 + experimental\n)\n\n# ANCOVA (OLS) with interaction to capture any effect heterogeneity  \nsimols4min <- lm(\n  data = simdata,\n  post ~ 1 + experimental + premin + experimental*premin\n)\n\nsimols4c <- lm(\n  data = simdata,\n  post ~ 1 + experimental + prec + experimental*prec\n)\n\nsimols4max <- lm(\n  data = simdata,\n  post ~ 1 + experimental + premax + experimental*premax\n)\n\n\n#Plot mean difference estimates: \n\n# wrangle\nbind_rows(tidy(simols1, conf.int = TRUE), tidy(simols4min, conf.int = TRUE), \n          tidy(simols4c, conf.int = TRUE), tidy(simols4max, conf.int = TRUE)) %>%\n  filter(term == \"experimental\") %>%\n  mutate(model = factor(c(\"ANOVA\", \"ANCOVA_Ypremin\", \"ANCOVA_Yprec\", \"ANCOVA_Ypremax\"), \n                        levels = c(\"ANOVA\", \"ANCOVA_Ypremin\", \"ANCOVA_Yprec\", \"ANCOVA_Ypremax\"))) %>%\n\n  # plot!\n  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = model)) +\n  geom_vline(xintercept = 0, color = \"white\") +\n  geom_pointrange() +\n  scale_x_continuous(expression(beta[1]~(mu[experimental]-mu[waitlist])), expand = expansion(add = 5)) +\n  ylab(NULL) + \n  ggtitle(\"Simulation #2, n=1,000 per group\") \n```\n\n::: {.cell-output-display}\n![](Kurz_power_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\nIn the second example, we still have pretty large samples, so what the heck happened here? Let's check summaries of the pre-treatment weight distributions, as well as summary outputs from the ANOVA model and the ANCOVA model with the centered pre-treatment weight baseline covariate, to see if they can shed any light on this.\n\nSummarize & plot Y_pre distributions\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimdata %>% \n  group_by(treatment) %>% \n  summarise(mean = mean(pre),\n            sd = sd(pre),\n            n = n())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  treatment     mean    sd     n\n  <fct>        <dbl> <dbl> <int>\n1 experimental  155.  17.6  2000\n2 control       156.  17.9  2000\n```\n:::\n\n```{.r .cell-code}\nsimdata %>%  \n  ggplot(aes(x = pre)) +\n  geom_histogram(binwidth = 5) +\n  xlab(\"pre-treatment weight (lbs)\") +\n  facet_wrap(~ treatment, labeller = label_both)\n```\n\n::: {.cell-output-display}\n![](Kurz_power_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n\n```{.r .cell-code}\nsummary(simols1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = post ~ 1 + experimental, data = simdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-63.828 -11.542  -0.196  11.500  59.892 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  153.2678     0.3847  398.43   <2e-16 ***\nexperimental  -5.5072     0.5440  -10.12   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 17.2 on 3998 degrees of freedom\nMultiple R-squared:  0.02499,\tAdjusted R-squared:  0.02475 \nF-statistic: 102.5 on 1 and 3998 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nsummary(simols4c)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = post ~ 1 + experimental + prec + experimental * \n    prec, data = simdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.5670  -3.6084  -0.0088   3.6110  18.3608 \n\nCoefficients:\n                    Estimate Std. Error  t value Pr(>|t|)    \n(Intercept)       152.826898   0.118452 1290.206   <2e-16 ***\nexperimental       -4.622233   0.167517  -27.593   <2e-16 ***\nprec                0.918004   0.006613  138.822   <2e-16 ***\nexperimental:prec   0.006700   0.009429    0.711    0.477    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.295 on 3996 degrees of freedom\nMultiple R-squared:  0.9077,\tAdjusted R-squared:  0.9076 \nF-statistic: 1.309e+04 on 3 and 3996 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nCompared to our first simulation example (n=10,000/group), the ANOVA and ANCOVA (at centered baseline) estimates are more divergent in this second example with smaller groups (n=1,000 each). The ANOVA estimate (-5.51) is substantially off the population mark (-4.57), whereas the ANCOVA estimate is much closer (-4.62). Why? \n\nWell, recall that the ANOVA model provides and *unconditional* estimate of the post-treatment differences between groups - ignoring any potential reasons for those differences, such as pre-treatment sampling variability or confounding. Yet, there is a small pre-treatment difference in weights due to sampling variability: the experimental group started off as approximately one pound (0.96) lighter on average than the control group before treatment. If we add this pre-existing difference to our population-expected treatment effect, we would expect an unconditional estimate of the group difference in post-treatment weights to be close to (-4.57 - 0.96) -5.53 pounds. Likewise, the ANOVA estimate is close, at -5.51 pounds. In short, baseline differences in pre-treatment weight shifts our ANOVA estimate about 1 unit (lbs) to the left in our plot.\n\nAgain, the unconditional ANOVA estimate summarizes post-treatment differences in weight from *all* sources. In contrast, the ANCOVA model stratifies on the centered baseline covariate to provide an estimate of the post-treatment differences in weights conditional on a specific strata of the baseline covariate (i.e., at the average pre-treatment weight). After holding constant pre-treatment weight at the baseline covariate's mean, the ANCOVA model better estimates (-4.62) the population-expected post-treatment difference in group weight attributable to the treatment (-4.57). (Though the ANCOVA model estimate would also be confounded by any other unmeasured causes of difference, had we included any such confounding causes in our simulation).   \n\nFinally, note that the ANCOVA estimates vary somewhat across strata of the baseline covariate (i.e., across minimum, mean, and maximum pre-treatment values). Recall, I did not specify any such differences in the simulation; rather, these appeared due to sampling variation - and as samples get smaller, such \"apparent interactions\" are more likely to occur as artifacts of sampling variation. \n\nNow, let's run this one more time with smaller group sizes of n=22 each to provide a better match to the real-world example used in Kurz's post. \n\n### Simulation example #3 (n=22/group)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Illustrate sample mean differences for two independent population groups \nnval <- 44 #treat\nngrp <- 22\nset.seed(1138) \n\n#sim two pre-treatment columns (groups) of rnorm values with \"nval\" size \n\npretrt <- rnorm(n=nval, mean=meanpret, sd=sdpret) %>% as_tibble_col(column_name = \"pre\")\nprecon <- rnorm(n=nval, mean=meanprec, sd=sdprec) %>% as_tibble_col(column_name = \"pre\")\npre <- rbind(pretrt, precon)\n\nsimdata <- tibble(\n  sn = 1:nval, \n  treatment = factor(rep(1:2, times = c(ngrp, ngrp)))) %>% \n  mutate(treatment = factor(treatment, labels = c(\"experimental\", \"control\")),\n         experimental = ifelse(treatment == \"experimental\", 1, 0)\n         )  \n\nsimdata <- cbind(simdata, pre)\n\nsimdata <- simdata %>% \n  mutate(\n    post = round(-4.57*experimental + rnorm_pre(pre, mu = mean(horan1971$post), sd = sd(horan1971$post), r = 0.95), digits=2), \n    prec = pre - mean(pre), \n    premin = pre - min(pre), \n    premax = pre - max(pre)\n  )\n\n# ANOVA (OLS)\nsimols1 <- lm(\n  data = simdata,\n  post ~ 1 + experimental\n)\n\n# ANCOVA (OLS) with interaction to capture any effect heterogeneity  \nsimols4min <- lm(\n  data = simdata,\n  post ~ 1 + experimental + premin + experimental*premin\n)\n\nsimols4c <- lm(\n  data = simdata,\n  post ~ 1 + experimental + prec + experimental*prec\n)\n\nsimols4max <- lm(\n  data = simdata,\n  post ~ 1 + experimental + premax + experimental*premax\n)\n\n\n\n# Summarize & plot Y_pre distributions\n\nsimdata %>% \n  group_by(treatment) %>% \n  summarise(mean = mean(pre),\n            sd = sd(pre),\n            n = n())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  treatment     mean    sd     n\n  <fct>        <dbl> <dbl> <int>\n1 experimental  159.  16.6    44\n2 control       154.  19.2    44\n```\n:::\n\n```{.r .cell-code}\nsimdata %>%  \n  ggplot(aes(x = pre)) +\n  geom_histogram(binwidth = 5) +\n  xlab(\"pre-treatment weight (lbs)\") +\n  facet_wrap(~ treatment, labeller = label_both)\n```\n\n::: {.cell-output-display}\n![](Kurz_power_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n\n```{.r .cell-code}\nsummary(simols1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = post ~ 1 + experimental, data = simdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.250 -14.274  -0.652  10.976  44.840 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  148.8298     2.6870  55.390   <2e-16 ***\nexperimental   0.2139     3.7999   0.056    0.955    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 17.82 on 86 degrees of freedom\nMultiple R-squared:  3.683e-05,\tAdjusted R-squared:  -0.01159 \nF-statistic: 0.003168 on 1 and 86 DF,  p-value: 0.9552\n```\n:::\n\n```{.r .cell-code}\nsummary(simols4c)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = post ~ 1 + experimental + prec + experimental * \n    prec, data = simdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.5645  -3.0508  -0.3504   3.5406  11.7802 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       151.554009   0.852739 177.726  < 2e-16 ***\nexperimental       -5.218918   1.208225  -4.319 4.26e-05 ***\nprec                0.947323   0.044478  21.299  < 2e-16 ***\nexperimental:prec  -0.005457   0.067966  -0.080    0.936    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.592 on 84 degrees of freedom\nMultiple R-squared:  0.9038,\tAdjusted R-squared:  0.9004 \nF-statistic: 263.2 on 3 and 84 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\n#Plot mean difference estimates: \n\n# wrangle\nbind_rows(tidy(simols1, conf.int = TRUE), tidy(simols4min, conf.int = TRUE), \n          tidy(simols4c, conf.int = TRUE), tidy(simols4max, conf.int = TRUE)) %>%\n  filter(term == \"experimental\" | term == \"prec\") %>%\n  mutate(model = factor(c(\"ANOVA\", \"ANCOVA_Ypremin\", \"ANCOVA_Yprec\", \"Baseline_diff_prec\", \"ANCOVA_Ypremax\"), \n                        levels = c(\"ANOVA\", \"ANCOVA_Ypremin\", \"ANCOVA_Yprec\", \"Baseline_diff_prec\", \"ANCOVA_Ypremax\"))) %>%\n  # plot!\n  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = model)) +\n  geom_vline(xintercept = 0, color = \"white\") +\n  geom_pointrange() +\n  scale_x_continuous(expression(beta[1]~(mu[experimental]-mu[waitlist])), expand = expansion(add = 5)) +\n  ylab(NULL) + \n  ggtitle(\"Simulation #3, n=22 per group\") \n```\n\n::: {.cell-output-display}\n![](Kurz_power_files/figure-html/unnamed-chunk-25-2.png){width=672}\n:::\n:::\n\n\nFirst, note that at pre-treatment baseline the simulated experimental group (159.41) is about 5.75 pounds heavier on average than the control group (mean=153.66). In the above plot, I added this estimated baseline difference to the plot (\"Baseline_diff_prec\"), as it might help us visualize what is happening in the ANOVA estimate. Specifically, the baseline pre-treatment weight difference should shift the ANOVA estimate of post-treatment differences to the right, since the ANOVA model provides an unconditional estimate that essentially is an aggregated summary of all sources of post-treatment differences in weight - including treatment effects and pre-existing weight differences. Sure enough, the ANOVA model estimate and the coefficient plots bear out this expectation. \n\nSecond, we see the same pattern of differences in uncertainty across ANCOVA estimates where the baseline covariate is centered at different values (e.g., at the minimum, mean, or maximum pre-treatment  weight). Conditional ANCOVA estimates are just that - they are conditional on specific values of the covariate - and thus they tend to be more certain at the center of a distribution and are less certain at the tails of a covariate distribution. Meanwhile, the ANOVA model's unconditional estimate summarizes post-treatment differences and variation/uncertainty from all sources, including experimental effects and baseline differences in pre-treatment weight.  \n\n### On sampling variation and average treatment effects\n\nNow, let's wrap up with a couple more illustrations using simulation #3. First, we will use the `margins` package to add an estimate of the experiment's average marginal effect (AME). Kurz's first post does not really get into this, though it sound like he plans to discuss marginal effects in later posts in the series. As such, we will not get into details here. For now, you might think of the AME conceptually as follows: It is the effect estimate that we would get if we followed our approach of fitting an ANCOVA model with new baseline covariates that were recentered at all observed values of pre-treatment weight, extracted the estimates and uncertainty intervals from each of those models, and then averaged all these into a single estimate and corresponding uncertainty interval. \n\nUnder certain conditions, such as a linear model with no effect heterogeneity, the ANCOVA estimate from a model with a baseline covariate centered at its mean will converge with the AME estimate and interval. However, in other situations, such as when effect heterogeneity is present (i.e., interactions exist) and/or when fitting a generalized linear model with a nonlinear link function, these estimates will not always converge. For now, let's just add them to our plot to provide a bit more information.   \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"margins\")\nx <- lm(post ~ 1 + experimental + prec + experimental*prec, data = simdata)\n\nmargins_summary(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       factor     AME     SE       z      p   lower   upper\n experimental -5.2189 1.2084 -4.3190 0.0000 -7.5872 -2.8506\n         prec  0.9446 0.0340 27.7961 0.0000  0.8780  1.0112\n```\n:::\n\n```{.r .cell-code}\namecoef <- tidy(x, conf.int = TRUE) %>% filter(term == \"experimental\")\n\n# wrangle\nplot22_1138 <- bind_rows(tidy(simols1, conf.int = TRUE), tidy(simols4min, conf.int = TRUE), \n          tidy(simols4c, conf.int = TRUE), tidy(simols4max, conf.int = TRUE), \n          amecoef) %>%\n  filter(term == \"experimental\") %>%\n  mutate(model = factor(c(\"ANOVA\", \"ANCOVA_Ypremin\", \"ANCOVA_Yprec\", \n                           \"ANCOVA_Ypremax\", \"AME_treatment\"), \n                        levels = c(\"ANOVA\", \"ANCOVA_Ypremin\", \"ANCOVA_Yprec\", \n                                   \"ANCOVA_Ypremax\", \"AME_treatment\"))) %>%\n\n  # plot!\n  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = model)) +\n  geom_vline(xintercept = 0, color = \"white\") +\n  geom_pointrange() +\n  scale_x_continuous(expression(beta[1]~(mu[experimental]-mu[waitlist]))) +\n  coord_cartesian(xlim=c(-20,10)) +\n  ylab(NULL) + \n  ggtitle(\"Sim #3, seed=1138\") \n\nplot22_1138\n```\n\n::: {.cell-output-display}\n![](Kurz_power_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\nAs implied, the AME estimate converges with the ANCOVA estimate using the centered baseline covariate in this example. But what if we had a different random sample? Interestingly, this particular random sample shows no evidence of effect heterogeneity, even though random sampling variation led to such an artifact in simulation #2 with the larger samples (n=1,000 per group). As you might know, with small samples, we should expect a great deal of sampling variation and, as such, noisy estimates that jump around a lot. To some degree, the wider intervals in the ANOVA and ANCOVA at minimum and maximum baseline covariate values communicates this greater uncertainty. But what about the ANCOVA estimate at centered baseline weight or the AME - do these sufficiently convey uncertainty inherent in estimating from small samples? \n\nTo probe this intuition, let's change the random seed to draw a couple new samples and then generate the same plot. I started with \"1138,\" which is one of my [favorite nerdy random seeds](https://en.wikipedia.org/wiki/1138_(number)). Let's just add one, add two, and subtract one to the random seed and see what happens.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Illustrate sample mean differences for two independent population groups \nnval <- 44 #treat\nngrp <- 22\n\n# 1139 \n\nset.seed(1139) \n\n#sim two pre-treatment columns (groups) of rnorm values with \"nval\" size \n\npretrt <- rnorm(n=nval, mean=meanpret, sd=sdpret) %>% as_tibble_col(column_name = \"pre\")\nprecon <- rnorm(n=nval, mean=meanprec, sd=sdprec) %>% as_tibble_col(column_name = \"pre\")\npre <- rbind(pretrt, precon)\n\nsimdata <- tibble(\n  sn = 1:nval, \n  treatment = factor(rep(1:2, times = c(ngrp, ngrp)))) %>% \n  mutate(treatment = factor(treatment, labels = c(\"experimental\", \"control\")),\n         experimental = ifelse(treatment == \"experimental\", 1, 0)\n         )  \n\nsimdata <- cbind(simdata, pre)\n\nsimdata <- simdata %>% \n  mutate(\n    post = round(-4.57*experimental + rnorm_pre(pre, mu = mean(horan1971$post), sd = sd(horan1971$post), r = 0.95), digits=2), \n    prec = pre - mean(pre), \n    premin = pre - min(pre), \n    premax = pre - max(pre)\n  )\n\n# ANOVA (OLS)\nsimols1 <- lm(\n  data = simdata,\n  post ~ 1 + experimental\n)\n\n# ANCOVA (OLS) with interaction to capture any effect heterogeneity  \nsimols4min <- lm(\n  data = simdata,\n  post ~ 1 + experimental + premin + experimental*premin\n)\n\nsimols4c <- lm(\n  data = simdata,\n  post ~ 1 + experimental + prec + experimental*prec\n)\n\nsimols4max <- lm(\n  data = simdata,\n  post ~ 1 + experimental + premax + experimental*premax\n)\n\nx <- lm(post ~ 1 + experimental + prec + experimental*prec, data = simdata)\n\namecoef2 <- tidy(x, conf.int = TRUE) %>% filter(term == \"experimental\")\n\n# wrangle\nplot22_1139 <- bind_rows(tidy(simols1, conf.int = TRUE), tidy(simols4min, conf.int = TRUE), \n          tidy(simols4c, conf.int = TRUE), tidy(simols4max, conf.int = TRUE), \n          amecoef2) %>%\n  filter(term == \"experimental\") %>%\n  mutate(model = factor(c(\"ANOVA\", \"ANCOVA_Ypremin\", \"ANCOVA_Yprec\", \n                           \"ANCOVA_Ypremax\", \"AME_treatment\"), \n                        levels = c(\"ANOVA\", \"ANCOVA_Ypremin\", \"ANCOVA_Yprec\", \n                                   \"ANCOVA_Ypremax\", \"AME_treatment\"))) %>%\n\n  # plot!\n  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = model)) +\n  geom_vline(xintercept = 0, color = \"white\") +\n  geom_pointrange() +\n  scale_x_continuous(expression(beta[1]~(mu[experimental]-mu[waitlist]))) +\n  coord_cartesian(xlim=c(-20,10)) +\n  ylab(NULL) + \n  ggtitle(\"Sim #3, seed=1139\") \n\n# 1140\n\nset.seed(1140) \n\n#sim two pre-treatment columns (groups) of rnorm values with \"nval\" size \n\npretrt <- rnorm(n=nval, mean=meanpret, sd=sdpret) %>% as_tibble_col(column_name = \"pre\")\nprecon <- rnorm(n=nval, mean=meanprec, sd=sdprec) %>% as_tibble_col(column_name = \"pre\")\npre <- rbind(pretrt, precon)\n\nsimdata <- tibble(\n  sn = 1:nval, \n  treatment = factor(rep(1:2, times = c(ngrp, ngrp)))) %>% \n  mutate(treatment = factor(treatment, labels = c(\"experimental\", \"control\")),\n         experimental = ifelse(treatment == \"experimental\", 1, 0)\n         )  \n\nsimdata <- cbind(simdata, pre)\n\nsimdata <- simdata %>% \n  mutate(\n    post = round(-4.57*experimental + rnorm_pre(pre, mu = mean(horan1971$post), sd = sd(horan1971$post), r = 0.95), digits=2), \n    prec = pre - mean(pre), \n    premin = pre - min(pre), \n    premax = pre - max(pre)\n  )\n\n# ANOVA (OLS)\nsimols1 <- lm(\n  data = simdata,\n  post ~ 1 + experimental\n)\n\n# ANCOVA (OLS) with interaction to capture any effect heterogeneity  \nsimols4min <- lm(\n  data = simdata,\n  post ~ 1 + experimental + premin + experimental*premin\n)\n\nsimols4c <- lm(\n  data = simdata,\n  post ~ 1 + experimental + prec + experimental*prec\n)\n\nsimols4max <- lm(\n  data = simdata,\n  post ~ 1 + experimental + premax + experimental*premax\n)\n\nx <- lm(post ~ 1 + experimental + prec + experimental*prec, data = simdata)\n\namecoef3 <- tidy(x, conf.int = TRUE) %>% filter(term == \"experimental\")\n\n# wrangle\nplot22_1140 <- bind_rows(tidy(simols1, conf.int = TRUE), tidy(simols4min, conf.int = TRUE), \n          tidy(simols4c, conf.int = TRUE), tidy(simols4max, conf.int = TRUE), \n          amecoef3) %>%\n  filter(term == \"experimental\" ) %>%\n  mutate(model = factor(c(\"ANOVA\", \"ANCOVA_Ypremin\", \"ANCOVA_Yprec\", \n                           \"ANCOVA_Ypremax\", \"AME_treatment\"), \n                        levels = c(\"ANOVA\", \"ANCOVA_Ypremin\", \"ANCOVA_Yprec\", \n                                   \"ANCOVA_Ypremax\", \"AME_treatment\"))) %>%\n\n  # plot!\n  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = model)) +\n  geom_vline(xintercept = 0, color = \"white\") +\n  geom_pointrange() +\n  scale_x_continuous(expression(beta[1]~(mu[experimental]-mu[waitlist]))) +\n  coord_cartesian(xlim=c(-20,10)) +\n  ylab(NULL) + \n  ggtitle(\"Sim #3, seed=1140\") \n\n\n# 1137\n\nset.seed(1137) \n\n#sim two pre-treatment columns (groups) of rnorm values with \"nval\" size \n\npretrt <- rnorm(n=nval, mean=meanpret, sd=sdpret) %>% as_tibble_col(column_name = \"pre\")\nprecon <- rnorm(n=nval, mean=meanprec, sd=sdprec) %>% as_tibble_col(column_name = \"pre\")\npre <- rbind(pretrt, precon)\n\nsimdata <- tibble(\n  sn = 1:nval, \n  treatment = factor(rep(1:2, times = c(ngrp, ngrp)))) %>% \n  mutate(treatment = factor(treatment, labels = c(\"experimental\", \"control\")),\n         experimental = ifelse(treatment == \"experimental\", 1, 0)\n         )  \n\nsimdata <- cbind(simdata, pre)\n\nsimdata <- simdata %>% \n  mutate(\n    post = round(-4.57*experimental + rnorm_pre(pre, mu = mean(horan1971$post), sd = sd(horan1971$post), r = 0.95), digits=2), \n    prec = pre - mean(pre), \n    premin = pre - min(pre), \n    premax = pre - max(pre)\n  )\n\n# ANOVA (OLS)\nsimols1 <- lm(\n  data = simdata,\n  post ~ 1 + experimental\n)\n\n# ANCOVA (OLS) with interaction to capture any effect heterogeneity  \nsimols4min <- lm(\n  data = simdata,\n  post ~ 1 + experimental + premin + experimental*premin\n)\n\nsimols4c <- lm(\n  data = simdata,\n  post ~ 1 + experimental + prec + experimental*prec\n)\n\nsimols4max <- lm(\n  data = simdata,\n  post ~ 1 + experimental + premax + experimental*premax\n)\n\nx <- lm(post ~ 1 + experimental + prec + experimental*prec, data = simdata)\n\namecoef4 <- tidy(x, conf.int = TRUE) %>% filter(term == \"experimental\")\n\n# wrangle\nplot22_1137 <- bind_rows(tidy(simols1, conf.int = TRUE), tidy(simols4min, conf.int = TRUE), \n          tidy(simols4c, conf.int = TRUE), tidy(simols4max, conf.int = TRUE), \n          amecoef4) %>%\n  filter(term == \"experimental\") %>%\n  mutate(model = factor(c(\"ANOVA\", \"ANCOVA_Ypremin\", \"ANCOVA_Yprec\", \n                          \"ANCOVA_Ypremax\", \"AME_treatment\"), \n                        levels = c(\"ANOVA\", \"ANCOVA_Ypremin\", \"ANCOVA_Yprec\", \n                                   \"ANCOVA_Ypremax\", \"AME_treatment\"))) %>%\n\n  # plot!\n  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = model)) +\n  geom_vline(xintercept = 0, color = \"white\") +\n  geom_pointrange() +\n  scale_x_continuous(expression(beta[1]~(mu[experimental]-mu[waitlist]))) +\n  coord_cartesian(xlim=c(-20,10)) +\n  ylab(NULL) +\n  ggtitle(\"Sim #3, seed=1137\") \n\n\nlibrary(patchwork)\n\n(plot22_1137 + plot22_1138) / (plot22_1139 + plot22_1140)\n```\n\n::: {.cell-output-display}\n![](Kurz_power_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\nOh my - look at the differences across these plots! This is what happens when we use really small samples - our samples and sample-based estimates are noisy and unreliable. If we were interested in effect heterogeneity, such as differences in the experimental treatment effect for people with different baseline pre-treatment weights, then we would likely draw completely different inferences from each of these samples! \n\nAlso, note how the ANOVA estimate jumps around a lot. By now, this should be unsurprising. After all, recall the unconditional ANOVA estimate is summarizing post-treatment group differences from all causes, including from highly variable sample-dependent group differences in baseline weight and  treatment effects. Moreover, this is compounded by the fact that ANOVA's mean-based estimate is sensitive to another problem with small samples: their distributions often fail to adequately reflect the underlying population distributions from which they were drawn. Graefe and colleagues, [in their paper referenced earlier](file:///C:/Users/Jon/Downloads/GraefeHahnMayer2022.pdf), warn about relying on ANOVA to estimate an average treatment effect (ATE): \n\n> \"For the ATE being a meaningful effect, however, a representative sample or knowledge of the distribution of the covariate is essential. If the distribution of the covariate in the sample does not reflect the distribution in the population of interest, all approaches may result in incorrect estimations of ATEs and the computed average treatment effects themselves do not represent average causal effects but arbitrary computed differences between means. In this case, conditional treatment effects can and should be interpreted.\"\n\nLikewise, note that the ANCOVA with a centered baseline covariate and the AME estimates are relatively more stable across these plots. Let's extract the AME estimates and plot them together so we can more easily compare them. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nbind_rows(amecoef, amecoef2, amecoef3, amecoef4) %>%\n  mutate(model = factor(c(\"AME_1138\", \"AME_1139\", \"AME_1140\", \"AME_1137\"), \n                        levels = c(\"AME_1138\", \"AME_1139\", \"AME_1140\", \"AME_1137\"))) %>%\n\n  # plot!\n  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = model)) +\n  geom_vline(xintercept = 0, color = \"white\") +\n  geom_pointrange() +\n  scale_x_continuous(expression(beta[1]~(mu[experimental]-mu[waitlist]))) +\n  ylab(NULL) +\n  ggtitle(\"Sim #3, AMEs by random seed\")\n```\n\n::: {.cell-output-display}\n![](Kurz_power_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\nThese findings corroborate the quote above and confirm Kurz's advice that \"...if you have a high-quality baseline covariate laying around, it’s a good idea to throw it into the model.\"  \n\nThe reason, though, really is not because you can expect ANCOVA to improve the statistical power of your test. To be clear, you might expect a derived estimated of the statistical power of an ANCOVA-based test of a null hypothesis to be greater than the power estimate derived for an ANOVA-based test of a null hypothesis that was motivated by the same substantive question. However, at this point, it should be clear that the ANOVA and ANCOVA models might be generating fundamentally different estimates or \"tests,\" depending on your data and the causal and design processes that generated them. Rather, if you care about estimating the causal effect of a (randomized) experimental treatment, then what really matters is that you fit a model that adequately specifies the underlying causal structure that generated the data and that you stratify on or adjust for alternative (non-treatment) causes of post-treatment differences if any exist. Inclusion of baseline differences - or other approaches to analyzing within-unit change - can help in this regard by serving as a proxy to adjust for other unobserved causal processes that might generate observed differences in post-treatment outcomes above and beyond the experimental treatment effect of interest.  \n\nIn short, count me as a skeptic of power-based arguments for selecting any particular model or determining covariate inclusion and, instead, as a believer that there is still no such thing as a free (power) lunch. \n",
    "supporting": [
      "Kurz_power_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}